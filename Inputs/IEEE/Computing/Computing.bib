@INPROCEEDINGS {,
author = {C. Baber and D. J. Haniff},
booktitle = {2012 16th International Symposium on Wearable Computers},
title = {Wearable Computers for the Fire Service and Police Force: Technological and Human Factors},
year = {1999},
volume = {},
issn = {1530-0811},
pages = {185},
abstract = {Wearable computer applications can be defined broadly as situationally-aware and situationally-unaware. A situationally-aware fire-fighter application which is under development is described and a situationally-unaware police force application is presented. However, underlying these developments is the issue of the appropriateness of the user interface for these applications.},
keywords = {wearable computers;fire service;police force;interface design},
doi = {10.1109/ISWC.1999.806922},
url = {https://doi.ieeecomputersociety.org/10.1109/ISWC.1999.806922},
publisher = {IEEE Computer Society},
address = {Los Alamitos, CA, USA},
month = {oct}
}

@INPROCEEDINGS {8537866,
author = {L. Yang and Y. Liang and D. Wu and J. Gault},
booktitle = {2018 IEEE 4th International Conference on Collaboration and Internet Computing (CIC)},
title = {Train and Equip Firefighters with Cognitive Virtual and Augmented Reality},
year = {2018},
volume = {},
issn = {},
pages = {453-459},
abstract = {It is important to reduce loss caused by fires through improved operations performed by virtual and augmented reality (VR/AR) trained and equipped fire-fighters. This paper collaborates with firefighting professionals to training firefighting skills with VR/AR systems. The system is also integrated with computational models and decision tools to provide situational awareness and address challenges faced by firefighters on the fire ground.},
keywords = {fires;optical sensors;training;buildings;augmented reality;computational modeling},
doi = {10.1109/CIC.2018.00068},
url = {https://doi.ieeecomputersociety.org/10.1109/CIC.2018.00068},
publisher = {IEEE Computer Society},
address = {Los Alamitos, CA, USA},
month = {oct}
}

@INPROCEEDINGS {9319056,
author = {J. T. Doswell and J. Johnson and B. Brockington and A. Mosby and A. Chinery},
booktitle = {2020 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR)},
title = {Juxtopia® CAMMRAD PREPARE: Wearable AI-AR Platform for Clinical Training Emergency First Response Teams},
year = {2020},
volume = {},
issn = {},
pages = {226-230},
abstract = {The Juxtopia® Open-Wear research team collaborated with the Maryland Fire &amp; Rescue Institute (MFRI) to test how the Juxtopia® artificial intelligent (AI) wearable augmented reality (AR) intervention may better deliver a hands-free clinical training intervention to firefighter Emergency Medical Technicians (EMT) and prepare them for effective response to hazardous material (HAZMAT) incidences. During a controlled study, human subjects participated in a minimal risk research (i.e., both as victims or caregivers) in which firefighter EMTs participated in a simulated training exercise that mimicked their real-world operations. During the study, there were two testing days. Day one included (10) victims and (20) caregivers who participated in a full day of training and familiarized themselves with wearable AR Head Mounted Display (HMD) and a Juxtopia® Virtual Tutor (JVT) software application. The results demonstrated that an AI instructor enabled AR system can train EMTs in core clinical skills for effective HAZMAT response.},
keywords = {task analysis;resists;hazardous materials;injuries;software;standards;certification},
doi = {10.1109/AIVR50618.2020.00047},
url = {https://doi.ieeecomputersociety.org/10.1109/AIVR50618.2020.00047},
publisher = {IEEE Computer Society},
address = {Los Alamitos, CA, USA},
month = {dec}
}

@INPROCEEDINGS {9262618,
author = {J. T. Doswell and J. Jolmson and B. Brockingon and A. Mosby and S. Salaam and A. Chinery},
booktitle = {2020 22nd Symposium on Virtual and Augmented Reality (SVR)},
title = {Juxtopia® CAMMRAD Prepare: A Wearable AI-AR Platform for Clinical Training Emergency First Response Teams},
year = {2020},
volume = {},
issn = {},
pages = {164-168},
abstract = {This paper discusses a Juxtopia® Open-Wear research collaboration with the Maryland Fire &amp; Rescue Institute (MFRI) to evaluate how an artificial intelligent (AI) wearable augmented reality (AR) intervention quantifiably improves hands-free clinical training proficiency of firefighter United States (U.S.) Emergency Medical Technicians (EMT) and prepares them for administering effective clinical skills (e.g., Tourniquet) in response to hazardous materials (hazmat) incidences. The AI-AR system, Juxtopia® Context-Aware Mobile Mixed Reality Assistive Device (CAMMRAD) Prepare E-Training system was evaluated in a two day controlled study including firefighter EMTs subjects who participated in simulated training exercise that mimicked their real-world operations. Results of the study indicates a need for AI-AR training to continually improve EMT clinical skill proficiency.},
keywords = {xenon;artificial intelligence},
doi = {10.1109/SVR51698.2020.00036},
url = {https://doi.ieeecomputersociety.org/10.1109/SVR51698.2020.00036},
publisher = {IEEE Computer Society},
address = {Los Alamitos, CA, USA},
month = {nov}
}

@INPROCEEDINGS {8433542,
author = {D. Collington and J. Doswell and J. Johnson and M. Messam and S. Salaam and A. Boykin},
booktitle = {2018 IEEE 18th International Conference on Advanced Learning Technologies (ICALT)},
title = {The Pervasive Rapid E-Preparedness Augmented Reality Environment (PREPARE) E-Learning Intervention for HAZWOPER Training of Fire Fighter/EMTs},
year = {2018},
volume = {},
issn = {2161-377X},
pages = {377-379},
abstract = {A Juxtopia research team collaborated with the Maryland Fire &amp; Rescue Institute (MFRI) to test how the Juxtopia® wearable augmented reality (AR) intervention may better deliver a hands-on clinical training intervention to firefighter Emergency Medical Technicians (EMT) and prepare them for effective response to HAZMAT (hazardous materials) incidences. During a controlled study, human subjects participated in a minimal risk research study (i.e., both as victims or caregivers) in which firefighter EMTs participated in a simulated training exercise that mimicked their real-world operations. This study consisted of two testing days. Day one included 10 participants that completed a full day of training and familiarity with wearable augmented reality (AR) goggles and a Juxtopia® Virtual Tutor (JVT) software application, which is derived from the Juxtopia® Intelligent Virtual Instructor (JiVi) platform. Day two included the completion of four psychomotor clinical skills performed by EMTs. It also included the application of moulage injuries for victims, using the Juxtopia® CAMMRAD PREPARE system to administer clinical skills on patient actors. This paper discusses the research methods and results.},
keywords = {training;eye protection;injuries;augmented reality;task analysis;hazardous materials;fires},
doi = {10.1109/ICALT.2018.00096},
url = {https://doi.ieeecomputersociety.org/10.1109/ICALT.2018.00096},
publisher = {IEEE Computer Society},
address = {Los Alamitos, CA, USA},
month = {jul}
}

@INPROCEEDINGS {10108579,
author = {C. Schonauer and M. Roussou and J. Ruggeberg and J. Ruggeberg and L. Katsikaris and S. Rogkas and D. Christopoulos},
booktitle = {2023 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)},
title = {Creating Informal Learning and First Responder Training XR Experiences with the ImmersiveDeck},
year = {2023},
volume = {},
issn = {},
pages = {53-60},
abstract = {In recent years eXtended Reality (XR) technologies have matured and have become affordable, yet creating XR experiences for training and learning in many cases is still a time-consuming and costly process, hindering widespread adoption. One factor driving effort is that content and features commonly required by many applications get re-implemented for each experience, instead of sharing and reusing these resources by means of a common platform. In this paper we present two XR experiences in the context of informal learning and first responder training along with the shared platform they have been created with and the creation process. Furthermore, we have technically evaluated relevant parts of the platform for feasibility of use with experience requirements and confirmed ap-plicability. Finally, we present an informal expert evaluation of the content creation process&#x27;s user experience for the informal learning experience along with guidelines derived from the findings.},
keywords = {training;three-dimensional displays;extended reality;design methodology;conferences;user interfaces;user experience},
doi = {10.1109/VRW58643.2023.00016},
url = {https://doi.ieeecomputersociety.org/10.1109/VRW58643.2023.00016},
publisher = {IEEE Computer Society},
address = {Los Alamitos, CA, USA},
month = {mar}
}

@INPROCEEDINGS {9419218,
author = {J. G. Grandi and Z. Cao and M. Ogren and R. Kopper},
booktitle = {2021 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)},
title = {Design and Simulation of Next-Generation Augmented Reality User Interfaces in Virtual Reality},
year = {2021},
volume = {},
issn = {},
pages = {23-29},
abstract = {We present a methodology for the simulation of next-generation Augmented Reality (AR) User Interfaces (UIs) within immersive Virtual Reality (VR). We use a user-centered model to support design decisions for specialized operations in high stakes fields, and present augmented reality user interface designs for two use cases in public safety: a law enforcement traffic stop and a firefighting search and rescue scenario. By utilizing VR to simulate AR, we can design and evaluate the benefits of idealized UIs that are unencumbered by hardware limitations. We discuss the trade-offs of Virtual Reality as a medium for simulation and training of next-generation Augmented Reality User Interfaces.},
keywords = {training;solid modeling;three-dimensional displays;law enforcement;conferences;computational modeling;user interfaces},
doi = {10.1109/VRW52623.2021.00011},
url = {https://doi.ieeecomputersociety.org/10.1109/VRW52623.2021.00011},
publisher = {IEEE Computer Society},
address = {Los Alamitos, CA, USA},
month = {apr}
}

@INPROCEEDINGS {,
author = {J. Bardram and J. Bunde-Pedersen},
booktitle = {2013 IEEE 33rd International Conference on Distributed Computing Systems Workshops},
title = {IASO — An Activity-Based Computing Platform for Wearable Computing},
year = {2005},
volume = {6},
issn = {1545-0678},
pages = {484-490},
abstract = {Displaying and navigating complex information on wearable computers is very different from accessing the some information while sitting at your desk. Limitations in hardware, screen-size, input- and output devices are not met with changes in the software running the wearable system. We propose using the ABC-framework as a middleware layer providing collaboration, adaptation, activity sharing and context-awareness for wearable applications. Furthermore, enhancements in the user-interface and interaction techniques overcome some of the hardware limitations. The proposed system makes wearable computers usable by e.g. emergency workers, policemen and firefighters.},
keywords = {null},
doi = {10.1109/ICDCSW.2005.68},
url = {https://doi.ieeecomputersociety.org/10.1109/ICDCSW.2005.68},
publisher = {IEEE Computer Society},
address = {Los Alamitos, CA, USA},
month = {jun}
}

@INPROCEEDINGS {9090440,
author = {R. S. Clifford and T. McKenzie and S. Lukosch and R. W. Lindeman and S. Hoermann},
booktitle = {2020 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)},
title = {The Effects of Multi-sensory Aerial Firefighting Training in Virtual Reality on Situational Awareness, Workload, and Presence},
year = {2020},
volume = {},
issn = {},
pages = {93-100},
abstract = {Situational Awareness (SA) and managing workload are key factors in aerial firefighting, also known as Air Attack. Training for Air Attack is logistically challenging, risky, expensive, and difficult to practise in naturalistic settings. Simulation training in Virtual Reality (VR) has good potential to mitigate these challenges. This paper explored the application of VR Air Attack training with two multisensory immersive display types, an Oculus Rift CV1 VR Head Mounted Display (HMD) and a 270° Cylindrical Projection Display (CPD). Firefighters training to become Air Support Supervisors were recruited to participate in the study. SA, workload, and sense of presence in the virtual environment were measured. Qualitative data on the firefighters’ user experience and their subjective evaluation of the systems were also collected. This was to gain insights on the suitability of the two systems for Air Attack training, and whether the new systems were an improvement on earlier designs. The results show that the participants experienced a high level of SA, workload and presence in both conditions, with a direct comparison tentatively suggesting that the HMD system invoked slightly higher SA, greater overall presence and lower workload. The collected qualitative data suggest that the participating firefighters appreciated both systems for their realism, extensibility, cost-effectiveness, and accessibility. In particular participants noted that the virtual experience facilitated their understanding of the Air Attack role, and they recommended the use of virtual reality simulation training to supplement existing Air Attack training.},
keywords = {training;visualization;virtual environments;helicopters;virtual reality},
doi = {10.1109/VRW50115.2020.00023},
url = {https://doi.ieeecomputersociety.org/10.1109/VRW50115.2020.00023},
publisher = {IEEE Computer Society},
address = {Los Alamitos, CA, USA},
month = {mar}
}

@INPROCEEDINGS {9994987,
author = {C. R. Nelson and J. L. Gabbard and J. B. Moats and R. K. Mehta},
booktitle = {2022 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)},
title = {User-Centered Design and Evaluation of ARTTS: an Augmented Reality Triage Tool Suite for Mass Casualty Incidents},
year = {2022},
volume = {},
issn = {1554-7868},
pages = {336-345},
abstract = {In this work we present ARTTS: a head-worn Augmented Reality (AR) Triage Tool Suite containing an initial sorting tool, virtual assessment tool, and virtual triage tag to assist emergency responders in mass casualty incidents. The initial sorting tool can prompt novice responders through first-wave tasks to aid recalibration from shock to triage. The virtual assessment tool provides novice responders, potentially confused by the chaos, with a walkthrough of the SALT triage flowchart. Finally, current emergency medical triage processes leverage static paper tags susceptible to loss or illegible damage. ARTTS’ virtual triage tags are dynamic, can be updated through responder interaction, and employ user interface emergent features based on individual patient conditions. This paper describes ARTTS’ capabilities, as well as the applied user-centered design process including review of existing triage material, subject-matter expert interview transcripts, wireframing, application of usability and user-centered design principles, as well as iterative usability subject-matter expert assessments and design walkthroughs. The ARTTS user experience aims to enhance, not upend, existing triage processes. Finally, this paper provides a usability evaluation comparing ARTTS’ virtual triage tag to a physical paper triage tag. Our tag achieved requisite System Usability Scale (SUS) scores and showed negligible differences to the paper triage tag on usability and mental workload.},
keywords = {training;hospitals;user centered design;user interfaces;user experience;recording;usability},
doi = {10.1109/ISMAR55827.2022.00049},
url = {https://doi.ieeecomputersociety.org/10.1109/ISMAR55827.2022.00049},
publisher = {IEEE Computer Society},
address = {Los Alamitos, CA, USA},
month = {oct}
}

@INPROCEEDINGS {8010675,
author = {X. Wu and R. Dunne and Z. Yu and W. Shi},
booktitle = {2017 IEEE/ACM International Conference on Connected Health: Applications, Systems and Engineering Technologies (CHASE)},
title = {STREMS: A Smart Real-Time Solution toward Enhancing EMS Prehospital Quality},
year = {2017},
volume = {1},
issn = {},
pages = {365-372},
abstract = {Emergency medical service (EMS) systems are public services that provide quick response, transportation as well as appropriate emergency medical care to the emergent patient. For EMS, every second is critical. Unfortunately, current EMS systems have many challenges: lack effective communication between EMS providers and hospital professionals, less attention on care quality and limited resources of medical equipment and personnel. Motivated by this, in this paper, we explore the use of wearable sensing, smart mobile device as well as video technology to propose STREMS: an efficient smart real-time prehospital communication system for EMS. Specifically, we first introduce a cost-effective wearable physiological sensing solution to support multi-dimensional telemetry monitoring for an ambulance operating at as Basic Life Support, a type of EMS service level without sophisticated medical equipment or paramedics. Then we propose to build a cloud-based real-time data sharing platform, enabling automated streaming all gathered prehospital data (e.g., vital signs, EKG and image/short videos about accident scene) to the hospital prior to ambulance arrival, thus giving a more complete figure about the incoming patient. This can significantly decrease the handoff time and improve the efficiency at the hospital. Additionally, a live point to point video communication is proposed to support EMS telemedicine to enhance prehospital care quality through directly video conversation to assist EMS providers in consultation, triage, early medical examination and treatment. We implemented STREMS as an Android mobile app and evaluated its feasibility over the broadband cellular network in the city of Detroit. In a moving context, our results demonstrate STREMS can successfully deliver 100% of emergency data to the hospital in less than 1.5s, on average 0.75s for reporting a new case and 0.05s for health data. As the live video with 1280×720 pixel resolution, STREMS only works when the vehicle speed is less than 40MPH.},
keywords = {hospitals;streaming media;mobile communication;biomedical monitoring;real-time systems;sensors},
doi = {10.1109/CHASE.2017.120},
url = {https://doi.ieeecomputersociety.org/10.1109/CHASE.2017.120},
publisher = {IEEE Computer Society},
address = {Los Alamitos, CA, USA},
month = {jul}
}

@INPROCEEDINGS {9974360,
author = {K. A. Kapalo and K. Pfeil and J. Bonnell and J. LaViola},
booktitle = {2022 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)},
title = {Comparing Firefighters&#x27; Perceived Workload Using 2D vs. 3D Building Plans to Support Emergency Response Preplanning in a Simulated Fire Scenario},
year = {2022},
volume = {},
issn = {},
pages = {634-639},
abstract = {Firefighters rely on visual information to make tactical decisions during structure fire events. Consequently, user interface design for public safety requires a comprehensive understanding of how these visual cues impact performance in terms of expertise and domain knowledge, as well as cognitive load. However, very few studies have captured baseline measures (e.g., subjective workload) associated with the use of pre-incident planning, the phase prior to deciding how to extinguish the fire. Virtual environments and 3D modeling have been suggested as a tool that can better support the exploration of emerging technology to better support pre-incident planning practices. Sixty-four (n &#x3D; 64) North American firefighters participated in this study. Our work focuses on providing baseline data to define effective ways to present building and hazard information to incident commanders using both current systems (e.g., 2D diagrams) and emerging technologies (e.g., 3D models, virtual reality, augmented reality).},
keywords = {human computer interaction;solid modeling;visualization;three-dimensional displays;buildings;cognitive load;data models},
doi = {10.1109/ISMAR-Adjunct57072.2022.00131},
url = {https://doi.ieeecomputersociety.org/10.1109/ISMAR-Adjunct57072.2022.00131},
publisher = {IEEE Computer Society},
address = {Los Alamitos, CA, USA},
month = {oct}
}

@INPROCEEDINGS {9090526,
author = {J. G. Grandi and Z. Cao and M. Ogren and R. Kopper},
booktitle = {2020 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)},
title = {Simulating Next-Generation User Interfaces for Law Enforcement Traffic Stops},
year = {2020},
volume = {},
issn = {},
pages = {826-827},
abstract = {We present the design of a next-generation user interface for law enforcement officers, developed to assist with current traffic procedures. Our design leverages the futuristic capabilities of augmented reality displays, integrating real and virtual elements. Our team has created a traffic stop scenario in immersive virtual reality, where the participant assumes the role of a police officer and interacts with a simulated augmented user interface and a virtual driver.},
keywords = {user interfaces;law enforcement;vehicles;three-dimensional displays;next generation networking;image color analysis;safety},
doi = {10.1109/VRW50115.2020.00264},
url = {https://doi.ieeecomputersociety.org/10.1109/VRW50115.2020.00264},
publisher = {IEEE Computer Society},
address = {Los Alamitos, CA, USA},
month = {mar}
}

@INPROCEEDINGS {8443754,
author = {S. Preum and S. Shu and J. Ting and V. Lin and R. Williams and J. Stankovic and H. Alemzadeh},
booktitle = {2018 ACM/IEEE 9th International Conference on Cyber-Physical Systems (ICCPS)},
title = {Towards a Cognitive Assistant System for Emergency Response},
year = {2018},
volume = {},
issn = {},
pages = {347-348},
abstract = {This abstract presents our preliminary results on development of a cognitive assistant system for emergency response that aims to improve situational awareness and safety of first responders. This system integrates a suite of smart wearable sensors, devices, and analytics for real-time collection and analysis of in-situ data from incident scene and providing dynamic data-driven insights to responders on the most effective response actions to take.},
keywords = {real-time systems;tools;data mining;natural language processing;decision making;pipelines;emergency services},
doi = {10.1109/ICCPS.2018.00047},
url = {https://doi.ieeecomputersociety.org/10.1109/ICCPS.2018.00047},
publisher = {IEEE Computer Society},
address = {Los Alamitos, CA, USA},
month = {apr}
}

@INPROCEEDINGS {7034778,
author = {M. Karunarathne and S. A. Jones and S. W. Ekanayake and P. N. Pathirana},
booktitle = {2014 IEEE International Conference on Big Data and Cloud Computing (BdCloud)},
title = {Remote Monitoring System Enabling Cloud Technology upon Smart Phones and Inertial Sensors for Human Kinematics},
year = {2014},
volume = {},
issn = {},
pages = {137-142},
abstract = {Stroke is a common neurological condition which is becoming increasingly common as the population ages. This entails healthcare monitoring systems suitable for home use, with remote access for medical professionals and emergency responders. The mobile phone is becoming the easy access tool for self-evaluation of health, but it is hindered by inherent problems including computational power and storage capacity. This research proposes a novel cloud based architecture of a biomedical system for a wearable motion kinematic analysis system which mitigates the above mentioned deficiencies of mobile devices. The system contains three subsystems: 1. Bio Kin WMS for measuring the acceleration and rotation of movement 2. Bio Kin Mobi for Mobile phone based data gathering and visualization 3. Bio Kin Cloud for data intensive computations and storage. The system is implemented as a web system and an android based mobile application. The web system communicates with the mobile application using an encrypted data structure containing sensor data and identifiable headings. The raw data, according to identifiable headings, is stored in the Amazon Relational Database Service which is automatically backed up daily. The system was deployed and tested in Amazon Web Services.},
keywords = {monitoring;cloud computing;servers;biomedical monitoring;mobile communication;biosensors},
doi = {10.1109/BDCloud.2014.62},
url = {https://doi.ieeecomputersociety.org/10.1109/BDCloud.2014.62},
publisher = {IEEE Computer Society},
address = {Los Alamitos, CA, USA},
month = {dec}
}

@INPROCEEDINGS {10216772,
author = {N. Mannuru and M. Kanumuru and S. Sharma},
booktitle = {2022 International Conference on Computational Science and Computational Intelligence (CSCI)},
title = {Mobile AR Application for Navigation and Emergency Response},
year = {2022},
volume = {},
issn = {},
pages = {1137-1142},
abstract = {Emergency response, navigation, and evacuation are key essentials for effective rescue and safety management. Situational awareness is a key ingredient when fire responders or emergency response personnel responds to an emergency. They have to quickly assess the layout of a building or a campus upon entry. Moreover, the occupants of a building or campus also need situational awareness for navigation and emergency response. We have developed an integrated situational awareness mobile augmented reality (AR) application for smart campus planning, management, and emergency response. Through the visualization of integrated geographic information systems and real-time data analysis, our mobile application provides insights into operational implications and offers information to support effective decision-making. Using existing building features, the authors demonstrate how the mobile AR application provides contextualized 3D visualizations that promote and support spatial knowledge acquisition and cognitive mapping thereby enhancing situational awareness. A limited user study was conducted to test the effectiveness of the proposed mobile AR application using the mobile phone usability questionnaire (MPUQ) framework. The results show that the mobile AR application was relatively easy to use and that it can be considered a useful application for navigation and evacuation.},
keywords = {three-dimensional displays;navigation;operating systems;buildings;data visualization;emergency services;planning},
doi = {10.1109/CSCI58124.2022.00203},
url = {https://doi.ieeecomputersociety.org/10.1109/CSCI58124.2022.00203},
publisher = {IEEE Computer Society},
address = {Los Alamitos, CA, USA},
month = {dec}
}

@INPROCEEDINGS {10108586,
author = {M. Ismael and R. McCall and M. Cornil and M. Griffin and J. Baixauli},
booktitle = {2023 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)},
title = {Radiological Incident System using Augmented Reality (RISAR)},
year = {2023},
volume = {},
issn = {},
pages = {591-592},
abstract = {This paper presents an Augmented Reality (AR) solution called RISAR that allows for the real-time visualisation of Radiological hazards based on sensor data captured from detectors as well as Unmanned Aerial and Ground Vehicles. RISAR improves safety for first responders during radiological events by enhancing their situation awareness. This lowers the risk of harm, and with it any health impacts and costs.},
keywords = {three-dimensional displays;costs;conferences;data visualization;detectors;real-time systems;land vehicles},
doi = {10.1109/VRW58643.2023.00138},
url = {https://doi.ieeecomputersociety.org/10.1109/VRW58643.2023.00138},
publisher = {IEEE Computer Society},
address = {Los Alamitos, CA, USA},
month = {mar}
}

@INPROCEEDINGS {9407673,
author = {A. Douklias and M. Krommyda and A. Amditis},
booktitle = {2021 Asia-Pacific Conference on Communications Technology and Computer Science (ACCTCS)},
title = {Resilient Communications for the First Responders at the Field},
year = {2021},
volume = {},
issn = {},
pages = {37-42},
abstract = {Rescue operations in both small-scale emergencies and major natural or man-made disasters are very challenging. The first responders are requested to explore unknown and potentially hazardous environments, risking their own well-being in order to save others. New innovative technologies are essential to support the first responders in their tasks, ensuring their safety and the effectiveness of their operations. These technologies, that may include wearable devices, automated vehicles and drones or back-end services require communications in order to operate in full capacity. Available infrastructure often fails in cases of emergency, while some operational environments may not even support them to begin with. Aiming to alleviate this barrier, a resilient, field deployable system, that can support the communication between all the equipment deployed at the field and multiple backhaul networks is presented here. The design of the communications, the hardware solutions that support the design as well as the selected configurations are discussed in detail.},
keywords = {wide area networks;wearable computers;throughput;reliability engineering;hardware;safety;topology},
doi = {10.1109/ACCTCS52002.2021.00016},
url = {https://doi.ieeecomputersociety.org/10.1109/ACCTCS52002.2021.00016},
publisher = {IEEE Computer Society},
address = {Los Alamitos, CA, USA},
month = {jan}
}

@INPROCEEDINGS {8798315,
author = {F. Ling and C. Elvezio and J. Bullock and S. Henderson and S. Feiner},
booktitle = {2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)},
title = {A Hybrid RTK GNSS and SLAM Outdoor Augmented Reality System},
year = {2019},
volume = {},
issn = {},
pages = {1044-1045},
abstract = {In the real world, we are surrounded by potentially important data. For example, military personnel and first responders may need to understand the layout of an environment, including the locations of designated assets, specified in latitude and longitude. However, many augmented reality (AR) systems cannot associate absolute geographic coordinates with the coordinate system in which they track. We describe a simple approach for developing a wide-area outdoor wearable AR system that uses RTK GNSS position tracking to align together and georegister multiple smaller maps from an existing SLAM tracking system.},
keywords = {global navigation satellite system;simultaneous localization and mapping;augmented reality;servers;cameras;global positioning system;base stations},
doi = {10.1109/VR.2019.8798315},
url = {https://doi.ieeecomputersociety.org/10.1109/VR.2019.8798315},
publisher = {IEEE Computer Society},
address = {Los Alamitos, CA, USA},
month = {mar}
}

@INPROCEEDINGS {6999217,
author = {D. Rodriguez and S. Heuer and A. Guerra and W. Stork and B. Weber and M. Eichler},
booktitle = {2014 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)},
title = {Towards automatic sensor-based triage for individual remote monitoring during mass casualty incidents},
year = {2014},
volume = {},
issn = {},
pages = {544-551},
abstract = {The enormous effort necessary to perform the triage of victims after a mass casualty event can be effectively reduced by the introduction of networked embedded technologies and automated decision support systems. Paper cards and analog communication devices are commonly used by the first responders and do not assist effectively the triage and the organization on the field. In this paper a new sensor-based triage platform is presented. This approach is based on the automatic remote monitoring and assessment of the physical, the respiration and the circulation condition of the patient. It consists basically on a wrist wearable device with wireless communication functions. Together with practitioners from the red cross we defined a new algorithm to evaluate the physiological condition of the patient, where the goal is the automated distinction between minor and major affected victims. This information is continuously reported to the rescue manager to support the tactical planning of the operation. This paper discusses the implementation and the evaluation of the new sensor-based triage method. Experimental data for algorithm validation was recorded along emergency drills and during real emergencies.},
keywords = {legged locomotion;heart rate;acceleration;monitoring;biomedical monitoring;medical services;wireless communication},
doi = {10.1109/BIBM.2014.6999217},
url = {https://doi.ieeecomputersociety.org/10.1109/BIBM.2014.6999217},
publisher = {IEEE Computer Society},
address = {Los Alamitos, CA, USA},
month = {nov}
}

@INPROCEEDINGS {,
author = {J. Auxier and M. Gandy and D. Ashbrook and T. Starner},
booktitle = {2012 16th International Symposium on Wearable Computers},
title = {The Gesture Pendant: A Self-illuminating, Wearable, Infrared Computer Vision System for Home Automation Control and Medical Monitoring},
year = {2000},
volume = {},
issn = {1530-0811},
pages = {87},
abstract = {In this paper, we present a wearable device for control of home automation systems via hand gestures. This solution has many advantages over traditional home automation interfaces in that those with loss of vision, motor skills, and mobility can use it. By combining other sources of context with the pendant, we can reduce the number and complexity of gestures while maintaining functionality. As users input gestures, the system can also analyze their movements for pathological tremors. This information can then be used for medical diagnosis, therapy, and emergency services. Currently, the Gesture Pendant can recognize control gestures with an accuracy of 95% and user-defined gestures with an accuracy of 97% it can detect tremors above 2HZ within plus or minus 0.1 Hz.},
keywords = {wearable computing;gesture recognition;home automation;enabling technology;tremor;medical monitoring;input device;computer vision},
doi = {10.1109/ISWC.2000.888469},
url = {https://doi.ieeecomputersociety.org/10.1109/ISWC.2000.888469},
publisher = {IEEE Computer Society},
address = {Los Alamitos, CA, USA},
month = {oct}
}

@INPROCEEDINGS {,
author = {K. Rainer and N. Sturm and M. Roth and G. Chroust},
booktitle = {Computational Intelligence, Modelling and Simulation, International Conference on},
title = {Simulation as a New Approach to First Responders Training},
year = {2009},
volume = {},
issn = {},
pages = {159-163},
abstract = {The perception and awareness of chemical, biological, radiological and nuclear (&quot;CBRN&quot;) emergencies is rising. These hazards are not directly detectable by human senses and thus no inborn reactions exist. As a consequence, special tools to detect these dangers have to be utilized. Since these dangers tend to affect large areas, it is necessary to establish standardized, coherent “Best Practices”, which have to be specifically trained under realistic but safe conditions. Modern technology allows simulating complex scenarios. The goal of the SimRad project is the user centered development and utilization of training and communication tools for all aspects of effective management of emergency situations, including team coordination. Regarding the process flow of First Responders intervention, emergency activities can be dissected into individual sub processes. This provides the basis for a purposeful optimization of individual activities through simulations, ranging from rough approximations to realistic simulations using Mixed Reality technology.},
keywords = {simulation;first responder;cbrn;emergency response},
doi = {10.1109/CSSim.2009.43},
url = {https://doi.ieeecomputersociety.org/10.1109/CSSim.2009.43},
publisher = {IEEE Computer Society},
address = {Los Alamitos, CA, USA},
month = {sep}
}

@INPROCEEDINGS {9090470,
author = {S. Sharma and J. Stigall and S. Bodempudi},
booktitle = {2020 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)},
title = {Situational Awareness-based Augmented Reality Instructional (ARI) Module for Building Evacuation},
year = {2020},
volume = {},
issn = {},
pages = {70-78},
abstract = {Emergency response in indoor building evacuation is essential for effective rescue and safety management. First responders often lack the situational awareness capability to quickly assess the layout of a building upon initial entry. For occupants of the building, situational awareness becomes more important in cases of active shooter events or circumstances of fire and smoke. One of the challenges is to provide user-specific personalized evacuation routes in real-time. In multilevel building environments, the complexity of the architecture creates problems for both visual and mental representation of the 3D spaces. This paper presents three cutting edge Augmented Reality Instructional (ARI) modules that overcome the visual limitations associated with the traditional, static 2D methods of communicating evacuation plans for multilevel buildings. Using existing building features, the authors demonstrate how the three modules provide contextualized 3D visualizations that promote and support spatial knowledge acquisition and cognitive mapping thereby enhancing situational awareness. These ARI visualizations are developed for first responders and building occupants to help increase emergency preparedness and mitigate the evacuation related risks in multilevel building rescues and safety management. Specifically, the paper describes the design and implementation of the ARI modules and reports the results of the pilot studies conducted to evaluate their perceived usefulness, ease-of-use, and usability. The results suggest the desirability of further heuristic examination of three-dimensional situational awareness-based ARI application effectiveness in multilevel building evacuations.},
keywords = {buildings;three-dimensional displays;visualization;two dimensional displays;education;augmented reality;emergency services},
doi = {10.1109/VRW50115.2020.00020},
url = {https://doi.ieeecomputersociety.org/10.1109/VRW50115.2020.00020},
publisher = {IEEE Computer Society},
address = {Los Alamitos, CA, USA},
month = {mar}
}

@INPROCEEDINGS {7892294,
author = {W. Brandao and M. Pinho},
booktitle = {2017 IEEE Virtual Reality (VR)},
title = {Using augmented reality to improve dismounted operators&#x27; situation awareness},
year = {2017},
volume = {},
issn = {2375-5334},
pages = {297-298},
abstract = {Whether it in the military, law enforcement or private security, dismounted operators tend to deal with a large amount of volatile information that may or may not be relevant according to a variety of factors. In this paper we draft some ideas on the building blocks of an augmented reality system aimed to improve the situational awareness of dismounted operators by filtering, organizing, and displaying this information in a way that reduces the strain over the operator.},
keywords = {augmented reality;navigation;machine vision;time measurement;position measurement;hardware},
doi = {10.1109/VR.2017.7892294},
url = {https://doi.ieeecomputersociety.org/10.1109/VR.2017.7892294},
publisher = {IEEE Computer Society},
address = {Los Alamitos, CA, USA},
month = {mar}
}

@ARTICLE {9134928,
author = {J. Shang and S. Chen and J. Wu and S. Yin},
journal = {IEEE Transactions on Mobile Computing},
title = {ARSpy: Breaking Location-Based Multi-Player Augmented Reality Application for User Location Tracking},
year = {2022},
volume = {21},
number = {02},
issn = {1558-0660},
pages = {433-447},
abstract = {Augmented reality (AR) applications that overlay the perception of the real world with digitally generated information are on the cusp of commercial viability. AR has appeared in several commercial platforms like Microsoft HoloLens and smartphones. They extend the user experience beyond two dimensions and supplement the normal 3D world of a user. A typical location-based multi-player AR application works through a three-step process, wherein the system collects sensory data from the real world, identifies objects based on their context, and finally, renders information on top of senses of a user. However, because these AR applications frequently exchange data with users, they have exposed new individual and public safety issues. In this paper, we develop ARSpy, a user location tracking system solely based on network traffic information of the user, and we test it on location-based multi-player AR applications. We demonstrate the effectiveness and efficiency of the proposed scheme via real-world experiments on 12 volunteers and show that we could obtain the geolocation of any target with high accuracy. We also propose three mitigation methods to mitigate these side channel attacks. Our results reveal a potential security threat in current location-based multi-player AR applications and serve as a critical security reminder to a vast number of AR users.},
keywords = {geology;global positioning system;throughput;databases;servers;cryptography},
doi = {10.1109/TMC.2020.3007740},
url = {https://doi.ieeecomputersociety.org/10.1109/TMC.2020.3007740},
publisher = {IEEE Computer Society},
address = {Los Alamitos, CA, USA},
month = {feb}
}

@INPROCEEDINGS {10132123,
author = {Z. Yang and C. Lee and L. Kung and J. Huang},
booktitle = {2023 IEEE 9th Intl Conference on Big Data Security on Cloud (BigDataSecurity), IEEE Intl Conference on High Performance and Smart Computing, (HPSC) and IEEE Intl Conference on Intelligent Data and Security (IDS)},
title = {Home health care system for the Elderly based on IMU wearable device},
year = {2023},
volume = {},
issn = {},
pages = {210-215},
abstract = {This paper proposes a human behavior recognition system based on a chest wearable device, which is used for the medical care of the elderly. In today’s aging society, it is very important for the quality of life and care of the elderly. Many nursing institutions seek technical support and respond to nurses. Due to insufficient manpower to control the behavior and health status of the elderly, the demand for an indoor positioning system (IPS) cannot be ignored. Using low-power Bluetooth to construct a location-based service (LBS) on a wearable device equipped with a nine-axis inertial sensor IMU and barometer can judge the posture of the wearer, including standing, walking, sitting, lying, and falling. The resultant force value is calculated by the three-axis acceleration, and the three-axis acceleration and the three-axis gyroscope are obtained through the gradient descent algorithm. The Euler angle and the altitude converted by the barometer can judge the behavior of sitting and standing up and the event of a fall. There is also an emergency button on the device, which allows the wearer to send a distress message, and monitor the wearer’s current behavior in real-time through the mobile APP and cloud, recording the wearer’s behavior and the physiological data of the bracelet and providing it for medical analysis.},
keywords = {cloud computing;wearable computers;medical services;aging;barometers;behavioral sciences;security},
doi = {10.1109/BigDataSecurity-HPSC-IDS58521.2023.00044},
url = {https://doi.ieeecomputersociety.org/10.1109/BigDataSecurity-HPSC-IDS58521.2023.00044},
publisher = {IEEE Computer Society},
address = {Los Alamitos, CA, USA},
month = {may}
}

@INPROCEEDINGS {,
author = {V. Gay and P. Leijdekkers},
booktitle = {Proceedings of the 26th IEEE International Symposium on Computer-Based Medical Systems},
title = {A Self-Test to Detect a Heart Attack Using a Mobile Phone and Wearable Sensors},
year = {2008},
volume = {},
issn = {1063-7125},
pages = {93-98},
abstract = {This paper describes a heart attack self-test application for a mobile phone that allows potential victims, without the intervention of a medical specialist, to quickly assess whether they are having a heart attack. Heart attacks can occur anytime and anywhere. Using pervasive technology such as a mobile phone and a small wearable ECG sensor it is possible to collect the user&#x27;s symptoms and to detect the onset of a heart attack by analysing the ECG recordings. If the application assesses that the user is at risk, it will urge the user to call the emergency services immediately. If the user has a cardiac arrest the application will automatically determine the current location of the user and alert the ambulance services and others to the person&#x27;s location.},
keywords = {heart attack selft-test;mobile health monitoring;wearable sensors;mobile health application},
doi = {10.1109/CBMS.2008.59},
url = {https://doi.ieeecomputersociety.org/10.1109/CBMS.2008.59},
publisher = {IEEE Computer Society},
address = {Los Alamitos, CA, USA},
month = {jun}
}

@INPROCEEDINGS {8453942,
author = {A. Fayoumi and K. BinSalman},
booktitle = {2018 IEEE 20th Conference on Business Informatics (CBI)},
title = {Effective Remote Monitoring System for Heart Disease Patients},
year = {2018},
volume = {},
issn = {2378-1971},
pages = {114-121},
abstract = {Despite the advancement that has been seen in all life aspects and in particular in technology, patients still struggle in receiving the care and emergent support they need due to the ever-increasing cost of healthcare services and the increasing number of chronic diseases patients. Information technology can offer promising solutions to 21&#x60;st century human, in particularly what is called internet of things (IoTs) and remote based services. We design and develop a solution where patients can use wearable sensors that can offer a prediction and alerting in their heart disease conditions. The solution seems promising when it is combined with medical profile data, better decisions can be made and alerting of emergency can be timely which can help to save lives. We use data gathered from few people to build our analytics and decision model.},
keywords = {monitoring;biomedical monitoring;heart;diseases;sensor systems},
doi = {10.1109/CBI.2018.10056},
url = {https://doi.ieeecomputersociety.org/10.1109/CBI.2018.10056},
publisher = {IEEE Computer Society},
address = {Los Alamitos, CA, USA},
month = {jul}
}

@INPROCEEDINGS {8432318,
author = {L. Ben Amor and I. Lahyani and M. Jmaiel and K. Drira},
booktitle = {2018 IEEE 32nd International Conference on Advanced Information Networking and Applications (AINA)},
title = {Anomaly Detection and Diagnosis Scheme for Mobile Health Applications},
year = {2018},
volume = {},
issn = {2332-5658},
pages = {777-784},
abstract = {Mobile healthcare applications highly depend on healthcare data, which is collected from wearable or implantable sensors. However, sensor readings may be inaccurate due to resource-constrained devices, sensor misplacement, patient with smearing, and other environmental related causes. Analyzing healthcare data is of paramount importance to provide high quality-care services and reduce false medical diagnosis. In this paper, we propose an online approach to detect inaccurate measurements and to raise alerts only when patients seem to be in emergency situations. The proposed approach is based on robust principal component analysis and adaptive threshold for multivariate anomaly detection, and on contribution plots for univariate anomaly diagnosis. We apply our proposed approach on real medical dataset. Our experimental results prove the effectiveness of our approach in detecting and diagnosing anomalous physiological measurements. The reduced time and space complexities of our approach make it useful and efficient for real time mobile health applications.},
keywords = {sensors;biomedical monitoring;medical services;anomaly detection;correlation;monitoring;robustness},
doi = {10.1109/AINA.2018.00116},
url = {https://doi.ieeecomputersociety.org/10.1109/AINA.2018.00116},
publisher = {IEEE Computer Society},
address = {Los Alamitos, CA, USA},
month = {may}
}

@INPROCEEDINGS {9156152,
author = {N. Alhassoun and N. Venkatasubramanian},
booktitle = {2020 IEEE International Conference on Pervasive Computing and Communications Workshops (PerCom Workshops)},
title = {Cross-Layer Energy Optimization for IoT-Enabled Smart Spaces},
year = {2020},
volume = {},
issn = {},
pages = {1-2},
abstract = {Perpetual IoT systems are essential to many safety and mission-critical applications, e.g. assisted living, healthcare and public safety, which are characterized by continuous monitoring (24/7) and ubiquitous sensing. While IoT-enabled many applications and services, several limitations arise in operating IoT deployments in a resilient manner over time; challenges include the energy cost and constraints. In our research, we aim to handle energy challenges caused by perpetual operations in each level of the system architecture (device, communication, and processing). We use a semantic approach that utilizes context of extracted activities of daily living (ADLs) and indoor space-state (normal, anomaly, and emergency) to drive energy optimized sensor activations. In addition, we are uniquely leveraging features such as: heterogeneity of IoT devices (wearable, ambient, and vision) in terms of: energy cost, energy source (battery-operated and wall-powered IoT devices), processing capability, mobility, communication technologies and transmission protocol (NB-IoT, LTE-M, LoRa, Wi-Fi, 4G/5G, Bluetooth, Zigbee, etc.), processing location (device, edge, could). To validate our approach, we developed an elderly fall detection system using multi-personal and in-situ sensing IoT devices derived from real-world deployments; using our measurements to drive larger simulations. We show that our proposed algorithms such as, Cost-Function-Gradient can achieve greater than 4X reductions in energy dissipation and doubling system-lifetime without loss of sensing accuracy.},
keywords = {sensors;safety;semantics;senior citizens;energy consumption;energy efficiency;optimization},
doi = {10.1109/PerComWorkshops48775.2020.9156152},
url = {https://doi.ieeecomputersociety.org/10.1109/PerComWorkshops48775.2020.9156152},
publisher = {IEEE Computer Society},
address = {Los Alamitos, CA, USA},
month = {mar}
}

@INPROCEEDINGS {205331,
author = {M. Goul and A. Philippakis and S. Richards and T. Sandman and A. Schamp},
booktitle = {Twenty-Third Annual Hawaii International Conference on System Sciences},
title = {Project CoEx: a distributed artificial intelligence orientation to the design of a cooperating experts&#x27; electronic meeting system},
year = {1990},
volume = {3},
issn = {},
pages = {89-100 vol.3},
abstract = {The authors discuss opportunistic avenues for synergizing co-evolution of the DAI (distributed artificial intelligence) and EMS (electronic meeting systems) fields. The focus is on CoEx, an EMS designed to support multiple cooperating experts involved in the task of using/prototyping/maintaining a distributed knowledge-based system. The CoEx system includes an object-oriented interface built on an extended relational DBMS platform implemented on a network of Sun model 386i workstations. CoEx is a shell system for conducting research in the general area of expert-team work.},
keywords = {artificial intelligence;medical services;knowledge based systems;decision support systems;relational databases;prototypes;information systems;educational institutions;sun;object oriented modeling},
doi = {10.1109/HICSS.1990.205331},
url = {https://doi.ieeecomputersociety.org/10.1109/HICSS.1990.205331},
publisher = {IEEE Computer Society},
address = {Los Alamitos, CA, USA},
month = {jan}
}

@INPROCEEDINGS {7457161,
author = {A. Ometov and P. Masek and L. Malina and R. Florea and J. Hosek and S. Andreev and J. Hajny and J. Niutanen and Y. Koucheryavy},
booktitle = {2016 IEEE International Conference on Pervasive Computing and Communication Workshops (PerCom Workshops)},
title = {Feasibility characterization of cryptographic primitives for constrained (wearable) IoT devices},
year = {2016},
volume = {},
issn = {},
pages = {1-6},
abstract = {The Internet of Things (IoT) employs smart devices as its building blocks for developing a ubiquitous communication framework. It thus supports a wide variety of application domains, including public safety, healthcare, education, and public transportation. While offering a novel communication paradigm, IoT finds its requirements closely connected to the security issues. The role of security following the fact that a new type of devices known as wearables constitute an emerging area. This paper delivers an applicability study of the state-of-the-art cryptographic primitives for wearable IoT devices, including the pairing-based cryptography. Pairing-based schemes are well-recognized as fundamental enablers for many advanced cryptographic applications, such as privacy protection and identity-based encryption. To deliver a comprehensive view on the computational power of modern wearable devices (smart phones, watches, and embedded devices), we perform an evaluation of a variety of them utilizing bilinear pairing for real-time communication. In order to deliver a complete picture, the obtained bilinear pairing results are complemented with performance figures for classical cryptography (such as block ciphers, digital signatures, and hash functions). Our findings show that wearable devices of today have the needed potential to efficiently operate with cryptographic primitives in real time. Therefore, we believe that the data provided during this research would shed light on what devices are more suitable for certain cryptographic operations.},
keywords = {cryptography;performance evaluation;androids;humanoid robots;digital signatures;optimization},
doi = {10.1109/PERCOMW.2016.7457161},
url = {https://doi.ieeecomputersociety.org/10.1109/PERCOMW.2016.7457161},
publisher = {IEEE Computer Society},
address = {Los Alamitos, CA, USA},
month = {mar}
}

@INPROCEEDINGS {,
author = {H. Maamar and A. Boukerche and R. W. Pazzi and E. Petriu},
booktitle = {2010 IEEE International Symposium on Parallel &amp; Distributed Processing, Workshops and Phd Forum (IPDPSW 2010)},
title = {A supplying partner strategy for mobile networks-based 3D streaming - proof of concept},
year = {2010},
volume = {},
issn = {},
pages = {1-6},
abstract = {With the advances of wireless communication and mobile computing, there is a growing interest among researchers about augmented reality and streaming 3D graphics on mobile devices for training first responders to be better prepared in a case of disaster scenarios. However, several challenges need to be resolved before this technology become a commodity. One of the major difficulties in 3D streaming over thin mobile devices is related to the supplying partner strategy as it is not easy to discover the peer that has the correct information and that posses enough bandwidth to send the required data quickly and efficiently to the peers in need. In this paper, we propose a new supplying partner strategy for mobile networks-based 3D streaming. The primary goal of the work presented in this paper is first to address the thin mobile devices low storage capabilities; and second to avoid the flooding problem that most wireless mobile networks suffer from. Our proposed protocol is based on the quick discovery of multiple supplying partners, by optimizing the time required by peers to acquire data, avoiding unnecessary messages propagation and network congestion, and decreasing the latency and the network bandwidth over utilization.},
keywords = {},
doi = {10.1109/IPDPSW.2010.5470795},
url = {https://doi.ieeecomputersociety.org/10.1109/IPDPSW.2010.5470795},
publisher = {IEEE Computer Society},
address = {Los Alamitos, CA, USA},
month = {apr}
}

@INPROCEEDINGS {7504744,
author = {J. Nishida and K. Suzuki},
booktitle = {2016 IEEE Virtual Reality (VR)},
title = {bioSync: Wearable haptic I/O device for synchronous kinesthetic interaction},
year = {2016},
volume = {},
issn = {2375-5334},
pages = {243-244},
abstract = {This paper presents a synchronous kinesthetic interaction among people through haptic input/output based on biosignal measurement and stimulation. Users are able to bi-directionally transmit kinesthetic experiences such as rigidity of joints or exertion of muscles in addition to physical bodily motion. Such interaction would be very important in the fields of rehabilitation and sports training. In this study, we introduce a set of wearable devices that is capable of both electromyogram (EMG) measurement and electrical muscle stimulation (EMS) simultaneously on the same muscle by using common electrodes. To achieve smooth kinesthetic bi-directional interaction, we propose a new method for discharging the residual potential of the stimulation in order to enable fastest simultaneous operation (40Hz). Through a performance evaluation, participants could recognize the teacher&#x27;s exertion strength on a 5-point scale without visual information.},
keywords = {electrodes;muscles;training;electromyography;switches;haptic interfaces;performance evaluation},
doi = {10.1109/VR.2016.7504744},
url = {https://doi.ieeecomputersociety.org/10.1109/VR.2016.7504744},
publisher = {IEEE Computer Society},
address = {Los Alamitos, CA, USA},
month = {mar}
}
