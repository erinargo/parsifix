@article{ODEN20154052,
title = {Embedding Emotional Intelligence into Military Training Contexts},
journal = {Procedia Manufacturing},
volume = {3},
pages = {4052-4059},
year = {2015},
note = {6th International Conference on Applied Human Factors and Ergonomics (AHFE 2015) and the Affiliated Conferences, AHFE 2015},
issn = {2351-9789},
doi = {https://doi.org/10.1016/j.promfg.2015.07.976},
url = {https://www.sciencedirect.com/science/article/pii/S2351978915009774},
author = {Kevin B. Oden and Monika Lohani and Marissa McCoy and James Crutchfield and Susan Rivers},
keywords = {Emotional intelligence, Immersion training, Virtual characters},
abstract = {Even the most junior Warfighters must effectively interact and negotiate with locals from communities that do not share their religious beliefs, social perspectives or customs. These cultural differences introduce a layer of uncertainty into chaotic operational contexts that are marked by moments of intense stress, and often contribute to strong emotional responses such as anxiety or anger. Unchecked, these emotional responses can escalate and lead Warfighters to make judgments and decisions they might not otherwise make. In high stakes situations, even the slightest mistake may have tragic consequences; thus, a need exists to equip Warfighters with skills that allow them to recognize/regulate their emotions. Emotional Intelligence (EI) “is the ability to monitor one's own and other's feelings and emotions, to discriminate among them and to use this information to guide one's thinking and actions” [1]. Learning effective strategies to manage our emotions is critical for laying a strong foundation for the development of positive relationships [2], [3]. Being able to effectively build positive relationships in diverse settings is a key attribute of cross cultural competence that may be improved through EI training. By practicing emotion recognition/regulation strategies, individuals will begin to replace ineffective decision-making with productive responses to challenging situations. In order to understand how emotions can influence decision making and social judgment, various moderating factors need to be considered, including cultural, group, and individual differences in emotional recognition/regulation [4]. We provide a brief overview of the operational need, define the basic tenets of EI, and describe how this approach could be implemented within an existing military training setting. We describe how emotion recognition and regulation skills would be exercised and evaluated and list potential benefits of using immersive training for skill development. Finally, we conclude with recommendations for future research and development in this area.}
}
@article{JEELANI2021105473,
title = {Safety challenges of UAV integration in construction: Conceptual analysis and future research roadmap},
journal = {Safety Science},
volume = {144},
pages = {105473},
year = {2021},
issn = {0925-7535},
doi = {https://doi.org/10.1016/j.ssci.2021.105473},
url = {https://www.sciencedirect.com/science/article/pii/S0925753521003167},
author = {Idris Jeelani and Masoud Gheisari},
keywords = {Construction safety, UAVs in construction, Drones, Human-robot interaction, Risks of UAVs},
abstract = {The use of Unmanned Aerial Vehicles (UAVs) in construction is growing at an unprecedented level, making the construction industry one of the fastest commercial adopters of UAVs. UAVs are widely used through different phases of construction, from aerial mapping, safety and quality monitoring and site logistics to structural inspection and maintenance assessment. While there is significant research about the benefits of UAVs for specific construction-related tasks, there is a dearth of research examining the impact of working with or near UAVs on the health and safety of workers. In this theory-driven paper, we examined UAV integration in construction workplaces from a health and safety perspective, categorized the potential ways UAVs might affect the construction workers’ health and safety, and provided a roadmap for future research in this area. The study used inferential and VR visualization techniques to identify the risks posed by UAVs, which were categorized into three groups of (1) physical risks, (2) attentional costs, and (3) psychological impacts. We then proposed a concurrent and cross-functional two-branch research road map to advance our knowledge about human-UAV interactions and develop regulatory and technological measures to ensure safe integration of UAVs in construction. The first branch shall empirically evaluate different ways UAVs can adversely impact workers’ health and safety. The second branch shall use these findings to develop regulatory and administrative interventions to guide the UAVs’ safe operation on construction sites and develop innovative hardware and software components for future UAVs to ensure their safe co-operation with human workers.}
}
@article{CONGES2023104002,
title = {Situational awareness and decision-making in a crisis situation: A crisis management cell in virtual reality},
journal = {International Journal of Disaster Risk Reduction},
volume = {97},
pages = {104002},
year = {2023},
issn = {2212-4209},
doi = {https://doi.org/10.1016/j.ijdrr.2023.104002},
url = {https://www.sciencedirect.com/science/article/pii/S221242092300482X},
author = {Aurélie Conges and Loïc Breard and William Patruno and Anouar Ouro-Sao and Nicolas Salatge and Audrey Fertier and Matthieu Lauras and Jacob Graham and Frédérick Benaben},
keywords = {Crisis management, Situational awareness, Decision-support, Virtual reality},
abstract = {In a constantly evolving and hyper-connected world, the crises we are facing are changing, exceeding borders, and impacting every sector of activity. More data can be gathered from the crisis site, arriving in a large flow of various types from multiple sources such as sensors, open data, or social media. This huge amount of data coming continuously from the crisis site leads to an ever-changing situational awareness that must be built and understood as quickly as it is evolving to ensure a relevant and effective crisis response. To build a shared situational awareness, decision-makers can gather in a room where they can share and compare the information they receive from the crisis site to build a common operational picture that they can use to make decisions and implement them: this is a crisis management cell. However, the tools in traditional crisis management cells may not be able to keep up with the new requirements induced by these changes: we need modular and dynamic tools able to adapt to the crisis and the needs of the crisis managers while ensuring collaboration and information sharing not only between the stakeholders but also with remote experts that might be needed to understand the situation. We need to start conceiving the future crisis management cell that would meet the new exigencies of crisis management. This paper proposes our version of that future crisis management cell, using virtual reality to provide a dynamic and modular crisis management cell linked to artificial intelligence and decision-support systems.}
}
@article{MARSH201161,
title = {Serious games continuum: Between games for purpose and experiential environments for purpose},
journal = {Entertainment Computing},
volume = {2},
number = {2},
pages = {61-68},
year = {2011},
note = {Serious Games Development and Applications},
issn = {1875-9521},
doi = {https://doi.org/10.1016/j.entcom.2010.12.004},
url = {https://www.sciencedirect.com/science/article/pii/S1875952110000224},
author = {Tim Marsh},
keywords = {Serious games, Definition, Categorization, Continuum},
abstract = {While many categorizations and definitions have attempted to elucidate the elusive term serious games, we are still some way off formulating an agreed understanding of what serious games are and can be. This article argues that the term serious games challenges our understanding of generally accepted characteristics such as, challenge, play and fun, which are largely associated with and borrowed from video games. It is argued that key to understanding what serious games encapsulate is to look beyond these characteristics. This article proposes a definition and way to frame serious games technologies, applications and environments along a continuum of gaming characteristics or gameness. From those with traditional gaming activities and characteristics (challenge, play, fun, etc.) at one end to those with minimal traditional gaming characteristics at the other end, whose main purpose is to provide experience and emotion to convey meaning. The main advantages of the definition and continuum are to establish a shared understanding and arena for current and emerging serious games, frame and connect currently fragmented groups into a cohesive serious games movement and community and open opportunities for future collaborative research and development. In addition, it helps in identifying characteristics for the design and assessment of serious games.}
}
@article{VUJICIC2022101838,
title = {Keeping up with the drones! Techno-social dimensions of tourist drone videography},
journal = {Technology in Society},
volume = {68},
pages = {101838},
year = {2022},
issn = {0160-791X},
doi = {https://doi.org/10.1016/j.techsoc.2021.101838},
url = {https://www.sciencedirect.com/science/article/pii/S0160791X21003134},
author = {Miroslav D. Vujičić and James Kennell and Uglješa Stankov and Ulrike Gretzel and Đorđije A. Vasiljević and Alastair M. Morrison},
keywords = {Drone, Tourist videography, Destination management, Marketing, Visual turn, User generated content},
abstract = {Tourists are increasingly using drones on vacation, but how they use them and the nature of the videos that they produce are not well understood. Conceptual advances in the study of tourist videography have produced a new model of these practices which is applied here to explain the nature of tourist videography with drones. An international sample of 351 vacation drone videos was subjected to content analysis, and an analysis of their metadata. The results show a significant variation in the content, technological and social practice of production of vacation drone videos depending on the type of video creator and, therefore, empirically validate and expand extant knowledge of drone videography as an emerging visual practice in tourism contexts. The findings establish that analysing the videos from the perspective of videography generates insights that are of value to destination management organizations and tourist businesses. We conclude that destination management organizations should see vacation drone videos as a new type of user-generated content for their destinations, as well as a potential source of innovative marketing ideas, and that they should engage more proactively with vacation drone videographers to maximise the impact of this opportunity.}
}
@article{CECIL20181265,
title = {A Collaborative Manufacturing Approach supporting adoption of IoT Principles in Micro Devices Assembly},
journal = {Procedia Manufacturing},
volume = {26},
pages = {1265-1277},
year = {2018},
note = {46th SME North American Manufacturing Research Conference, NAMRC 46, Texas, USA},
issn = {2351-9789},
doi = {https://doi.org/10.1016/j.promfg.2018.07.141},
url = {https://www.sciencedirect.com/science/article/pii/S2351978918308175},
author = {J. Cecil},
keywords = {Advanced Manufacturing, Internet of Things (IoT), Cyber-Physical Systems (CPS), Micro Devices Assembly (MDA), Virtual Reality (VR)},
abstract = {Micro Devices Assembly (MDA) is an emerging domain involving the assembly of micron sized objects and devices. In this paper, the focus is the design of an IoT based Cyber Physical approach for the assembly of micro devices. An advanced IoT based framework comprising of integrated cyber and physical components has been developed to accomplish a targeted set of MDA life cycle activities which include assembly planning, Virtual Reality (VR) based assembly analysis, command generation and physical assembly. Advanced VR based environments using semi-immersive and fully immersive technologies (including Oculus Rift based platforms) have been designed to support assembly analysis where plans can be proposed, compared and validated. An information centric modeling approach is proposed to help design the data/information exchange among the various cyber and physical components and provide a structured foundation to design such complex IoT based approaches and frameworks.}
}
@article{BHAUMIK2023488,
title = {An Intelligent Virtual Environment for Designers with Reduced Motor Abilities},
journal = {Procedia Computer Science},
volume = {218},
pages = {488-503},
year = {2023},
note = {International Conference on Machine Learning and Data Engineering},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2023.01.031},
url = {https://www.sciencedirect.com/science/article/pii/S1877050923000315},
author = {Rahul Bhaumik and Tarun Kumar and Unais Sait},
keywords = {Virtual Reality, design tool, intelligent interface, gaze-based input, artificial intelligence},
abstract = {Conventional CAD modelling software demands substantial utilisation of input modalities like the keyboard and mouse for creating 3-dimensional (3D) models. The dexterity measures involved in controlling input modalities could pose challenges to users with motor disabilities—including the inability to move their limbs, particularly their upper and lower arms, and fingers, due to traumatic damage or congenital problems. In order to meet these challenges, this paper proposes a virtual reality (VR)-based medium to help users with motor disabilities build simple 3D models for architectural design. The concept of operating buttons using head-gaze in the VR environment has been utilised to perform scaling—a 3D object manipulation method—to create simplified building models. Moreover, navigation in the VR space using tilting of the head has been employed with the user seated on a revolving chair, thus eliminating the need for any limbic movement. Unity game engine was used to develop two variations of the VR model with a different button layout for creating simple cuboidal volumes mimicking buildings in the virtual environment. Both variations have been tested with 32 individuals against a specific performance indicator (i.e., task completion time) and self-reported metrics, such as the perception of effort applied and degree of visual clutter, followed by retrospective participant feedback sessions. One of the VR application's variants (i.e., variant 1) produced promising results regarding overall usability and effort demand. This paper also proposes a methodological framework for an AI-based, intelligent, and adaptive VR application interface that caters to the user's abilities and pain points in real-time. In the future, this framework could be instrumental in creating a comprehensive gaze-based VR tool for 3D modelling having multiple functions to help users with motor disabilities.}
}
@article{MANCA20131,
title = {Bridging between Virtual Reality and accident simulation for training of process-industry operators},
journal = {Advances in Engineering Software},
volume = {55},
pages = {1-9},
year = {2013},
issn = {0965-9978},
doi = {https://doi.org/10.1016/j.advengsoft.2012.09.002},
url = {https://www.sciencedirect.com/science/article/pii/S0965997812001299},
author = {Davide Manca and Sara Brambilla and Simone Colombo},
keywords = {Operator Training Simulator, HSE, Dynamic accident simulation, Virtual Reality, Augmented–Virtual Reality, Accident consequences},
abstract = {This paper discusses a training solution based on Virtual Reality (VR) and Augmented–Virtual Reality (AVR), specifically tailored for the (chemical) process industry, and a related proof-of-concept experiment. The suggested approach, compared to traditional training systems, has the potential to improve operators’ cognitive readiness by addressing the three components of situation awareness, namely (i) “experiencing” the plant and its units, (ii) comprehending their meaning and purpose, and (iii) learning how to project the current status in the near future. The paper discusses the benefits of integrating and interlinking a dynamic process simulator with a dynamic accident simulator in order to train operators (particularly field operators) to respond effectively to abnormal situations, thus enabling them to recognize and recover anomalies and malfunctions, especially when they might lead to accidents. A practical example is shown to support this point.}
}
@article{MAROCCO2021103917,
title = {Integrating disruptive technologies with facilities management: A literature review and future research directions},
journal = {Automation in Construction},
volume = {131},
pages = {103917},
year = {2021},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2021.103917},
url = {https://www.sciencedirect.com/science/article/pii/S092658052100368X},
author = {Marco Marocco and Ilaria Garofolo},
keywords = {Building information modelling (BIM), Digital twin (DT), Facilities management (FM), Operation & maintenance (O&M), Literature review},
abstract = {Facilities Management (FM) has received increasing attention from the Architecture, Engineering, Construction and Operation (AECO) industry over the last decade. Disruptive technologies have the potential to advance the Operation and Maintenance (O&M) phase in different application fields. With the increasing industry interest, there is a need to review the current status of research developments in FM. In this review, 70 journal articles published from 2011 to 2020 were reviewed. This paper aims to provide a comprehensive review of the applications of disruptive technologies for FM, analyse research trends and identify research gaps and potential future research directions. This article focuses on only academic articles including topics, such as operations and maintenance, information management, emergency management and energy management. Eventually, it is hoped that this review will provide researchers with clarity of where research endeavours are most needed and helpful insights to address FM challenges.}
}
@article{PULIDOHERRERA201345,
title = {Improving data fusion in personal positioning systems for outdoor environments},
journal = {Information Fusion},
volume = {14},
number = {1},
pages = {45-56},
year = {2013},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2012.01.009},
url = {https://www.sciencedirect.com/science/article/pii/S1566253512000103},
author = {E. {Pulido Herrera} and H. Kaufmann and J. Secue and R. Quirós and G. Fabregat},
keywords = {Pedestrian positioning, Dead reckoning, Fault detection, Adaptive Kalman filtering, Chi-square test, Causal diagnosis},
abstract = {A fault detection and correction methodology for personal positioning systems for outdoor environments is presented. We demonstrate its successful use in a system consisting of a global positioning system receiver and an inertial measurement unit. Localization is based on the dead reckoning algorithm. In order to obtain more reliable information from data fusion, which is carried out with Kalman filtering, the proposed methodology involves: (1) evaluation of the information provided by the sensors and (2) adaptability of the filtering. By carefully analyzing these factors we accomplish fault detection in different sources of information and in filtering. This allows us to apply corrections whenever the system requires it. Hence, our methodology consists of two stages. In the first stage, the evaluation is conducted. We apply the principles of causal diagnosis using possibility theory by defining states for normal behavior and for fault states. When a fault occurs, corrective measures are applied according to empirical knowledge. In the second stage, the consistency test of the filtering is performed. If this is inconsistent, principles of adaptive Kalman filtering are applied, which means the process and measurement noise matrices are tuned. Our results indicate a reasonable improvement of the trajectory obtained. At the same time, we can achieve consistent filtering, to obtain a more robust system and reliable information.}
}
@article{BABALOLA2023106214,
title = {Applications of immersive technologies for occupational safety and health training and education: A systematic review},
journal = {Safety Science},
volume = {166},
pages = {106214},
year = {2023},
issn = {0925-7535},
doi = {https://doi.org/10.1016/j.ssci.2023.106214},
url = {https://www.sciencedirect.com/science/article/pii/S092575352300156X},
author = {Akinloluwa Babalola and Patrick Manu and Clara Cheung and Akilu Yunusa-Kaltungo and Paulo Bartolo},
keywords = {Augmented reality, Mixed reality, Training and education, Immersive technologies, Virtual reality},
abstract = {Immersive technologies (ImTs) have emerged as a viable pathway to address poor occupational safety and health (OSH) performance through training and education of workers. This study aimed to gain a holistic view of the applications of ImTs for OSH training and education. A review of the application of ImTs for OSH training and education is conducted using the preferred reporting items for systematic reviews and meta-analysis (PRISMA) approach and bibliometric analysis. This resulted in the evaluation of 67 relevant journal articles collected from Scopus, Web of Science, and Engineering Village. The review revealed that ImTs have been applied for OSH training and education in various industries including transportation, construction, mining, and healthcare. It was also revealed that the OSH hazards addressed by ImT-based training and education include but are not limited to fire, fall, electrical and chemical hazards in order to prevent or reduce injuries, illnesses and fatalities. In addition, it was revealed that one of the benefits of ImTs for OSH training and education is better retention of concepts when compared to conventional training and education. Challenges associated with the use of ImTs for OSH training and education include insufficient display brightness for users to effectively see virtual objects in a brightly luminated environment. Among the recommendations for future work is research into how to develop effective communication methods between trainers and trainees immersed in a virtual environment for trainers to fully understand the difficulties trainees experience in operating the developed ImT-based platform and provide solutions to such difficulties.}
}
@article{GINTERS2019167,
title = {Augmented reality use for cycling quality improvement},
journal = {Procedia Computer Science},
volume = {149},
pages = {167-176},
year = {2019},
note = {ICTE in Transportation and Logistics 2018 (ICTE 2018)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2019.01.120},
url = {https://www.sciencedirect.com/science/article/pii/S1877050919301279},
author = {Egils Ginters},
keywords = {Augmented reality, Green transport, Bicycle routes simulation},
abstract = {The impact of air pollution on the health of the population and the greenhouse effect determine the development of green transport modes. One is cycling. The developed a dual-use cycling route planning and management tool VeloRouter provides agent-based routing load simulation and allows each user to choose the most attractive travel time. However, during the trip, the cyclists want to get real-time information not only about the weather, but also about the terrain that would improve travel safety. One of the possible solutions is augmented reality (AR) smart glasses. It is important to develop an appropriate and sustainable AR solution, which is not possible without careful prior analysis.}
}
@article{ABDELHAKEEM20222419,
title = {Vision and research directions of 6G technologies and applications},
journal = {Journal of King Saud University - Computer and Information Sciences},
volume = {34},
number = {6, Part A},
pages = {2419-2442},
year = {2022},
issn = {1319-1578},
doi = {https://doi.org/10.1016/j.jksuci.2022.03.019},
url = {https://www.sciencedirect.com/science/article/pii/S1319157822001033},
author = {Shimaa A. {Abdel Hakeem} and Hanan H. Hussein and HyungWon Kim},
keywords = {Cellular communication, 6G drivers, Standardization, 6G requirements, Research activities, E-health, UAV networks, Factory of the future, Localization, CAV networks, HW-SW divide, B5G projects, 5G advanced},
abstract = {Fifth-generation (5G) mobile communication technology is now widely available in several countries, with millions of 5G customers. Therefore, it's time for academia and business to focus on the next generation. This paper will overview the sixth-generation (6G) mobile network, including motivations, use case scenarios, requirements, supported research projects, and technologies. We discuss the Beyond 5G (B5G) evolution and advanced 5G features to predict the critical 6G requirements and highlight the 6G capabilities. We also introduce the 6G scenarios, requirements, and technological components compared to 5G. Moreover, the current status of 6G research is discussed, and a rough roadmap for specification and regulation is explored. Then we describe a few prospective applications, their benefits, concepts, and research directions. We explore the business direction for 6G by introducing the most recently 6G projects in the vertical markets. We also propose a network architectural vision and the evolution of hardware-software designs to satisfy the higher requirements of 6G applications. This paper also presents a comprehensive survey of existing 6G trends, technologies, applications, industrial markets, and network structures for the most promising 6G applications.}
}
@article{BELLALOUNA2021554,
title = {Digitization of industrial engineering processes using the augmented reality technology: industrial case studies},
journal = {Procedia CIRP},
volume = {100},
pages = {554-559},
year = {2021},
note = {31st CIRP Design Conference 2021 (CIRP Design 2021)},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2021.05.120},
url = {https://www.sciencedirect.com/science/article/pii/S2212827121005941},
author = {Fahmi Bellalouna},
keywords = {Augmented Reality (AR), Product Configuration Management, Production Planning, Assembly Assistance, Industrial Digitization},
abstract = {Augmented Reality Technology is one of the key technologies of digital transformation in industrial and non-industrial areas. Due to the rapid development of display hardware and tracking systems, virtual and augmented reality applications are being developed today that would only have been possible in large research laboratories with huge efforts a few years ago. This paper presents the application of the augmented reality technology (AR) in the industrial field. Based on industrial case studies the implementation of two AR applications and their potential to digitize the product lifecycle processes will be discussed. The use cases were developed within cooperation projects between the University of Applied Sciences Karlsruhe and a fire truck manufacturer. The case studies focus on the following topics: digital product configuration management and production planning and assistance. The objective of the case studies is the investigation of the AR application in the industrial environment and its capability as digital transformation technology along the product lifecycle. The presented case studies deliver experiences and suggestions in terms of praxis-oriented development and deployment of the AR technology in the engineering field, which can be used for future AR research works.}
}
@article{REZAZADEH2011289,
title = {Using affective human–machine interface to increase the operation performance in virtual construction crane training system: A novel approach},
journal = {Automation in Construction},
volume = {20},
number = {3},
pages = {289-298},
year = {2011},
note = {Augmented and Virtual Reality in Architecture, Engineering and Construction (CONVR2009)},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2010.10.005},
url = {https://www.sciencedirect.com/science/article/pii/S092658051000169X},
author = {Iman Mohammad Rezazadeh and Xiangyu Wang and Mohammad Firoozabadi and Mohammad Reza {Hashemi Golpayegani}},
keywords = {Virtual Reality, Facial bioelectric-signals, Affective computing, Affective measures, Construction training},
abstract = {In the construction industry, some progress have been achieved by researchers to design and implement environments for task training using VR technology and its derivatives such as Augmented and Mixed Reality. Although, these developments have been well recognized at the application level, however crucial to the virtual training system is the effective and reliable measurement of training performance of the particular skill and handling the experiment for long-run. It is known that motor skills cannot be measured directly, but only inferred by observing behaviour or performance measures. The typical way of measuring performance is through measuring task completion time and accuracy, but can be supported by indirect measurement of some other factors. In this paper, a virtual crane training system has been developed which can be controlled using control commands extracted from facial gestures and is capable to lift up loads/materials in the virtual construction sites. Then, we integrate affective computing concept into the conventional VR training platform for measuring the cognitive load and level of satisfaction during performance using human's forehead bioelectric-signals. By employing the affective measures and our novel control scheme, the designed interface could be adapted to user's affective status during the performance in real-time. This adaptable user interface approach helps the trainee to cope with the training for long-run performance, leads to gaining more expertise and provides more effective transfer of learning to other operation environments. The detailed methodology of the affective control is presented in the paper. The results and future applications of the proposed method for disabled users, especially from neck down are discussed.}
}
@article{LU2023137412,
title = {Digital twin-enabled human-robot collaborative teaming towards sustainable and healthy built environments},
journal = {Journal of Cleaner Production},
volume = {412},
pages = {137412},
year = {2023},
issn = {0959-6526},
doi = {https://doi.org/10.1016/j.jclepro.2023.137412},
url = {https://www.sciencedirect.com/science/article/pii/S0959652623015706},
author = {Weisheng Lu and Junjie Chen and Yonglin Fu and Yipeng Pan and Frank Ato Ghansah},
keywords = {Sustainability, Green building, Human–robot teaming, Human–robot interaction, Digital twin},
abstract = {Development of sustainable and healthy built environments (SHBE) is highly advocated to achieve collective societal good. Part of the pathway to SHBE is the engagement of robots to manage the ever-complex facilities for tasks such as inspection and disinfection. However, despite the increasing advancements of robot intelligence, it is still “mission impossible” for robots to independently undertake such open-ended problems as facility management, calling for a need to “team up” the robots with humans. Leveraging digital twin's ability to capture real-time data and inform decision-making via dynamic simulation, this study aims to develop a human-robot teaming framework for facility management to achieve sustainability and healthiness in the built environments. A digital twin-enabled prototype system is developed based on the framework. Case studies showed that the framework can safely and efficiently incorporate robotics into facility management tasks (e.g., patrolling, inspection, and cleaning) by allowing humans to plan, oversee, manage, and cooperate with the robot via the digital twin's bi-directional mechanism. The study lays out a high-level framework, under which purposeful efforts can be made to unlock digital twin's full potential in collaborating humans and robots in facility management towards SHBE.}
}
@article{FRAUNE2021102573,
title = {Developing Future Wearable Interfaces for Human-Drone Teams through a Virtual Drone Search Game},
journal = {International Journal of Human-Computer Studies},
volume = {147},
pages = {102573},
year = {2021},
issn = {1071-5819},
doi = {https://doi.org/10.1016/j.ijhcs.2020.102573},
url = {https://www.sciencedirect.com/science/article/pii/S1071581920301750},
author = {Marlena R. Fraune and Ahmed S. Khalaf and Mahlet Zemedie and Poom Pianpak and Zahra NaminiMianji and Sultan A. Alharthi and Igor Dolgov and Bill Hamilton and Son Tran and Z.O. Toups},
keywords = {Human-drone teams, Drones, Wearables, Mixed reality, HMD, Gesture interface, Empirical study},
abstract = {Autonomous robotic vehicles (i.e., drones) are potentially transformative for search and rescue (SAR). This paper works toward wearable interfaces, through which humans team with multiple drones. We introduce the Virtual Drone Search Game as a first step in creating a mixed reality simulation for humans to practice drone teaming and SAR techniques. Our goals are to (1) evaluate input modalities for the drones, derived from an iterative narrowing of the design space, (2) improve our mixed reality system for designing input modalities and training operators, and (3) collect data on how participants socially experience the virtual drones with which they work. In our study, 17 participants played the game with two input modalities (Gesture condition, Tap condition) in counterbalanced order. Results indicated that participants performed best with the Gesture condition. Participants found the multiple controls challenging, and future studies might include more training of the devices and game. Participants felt like a team with the drones and found them moderately agentic. In our future work, we will extend this testing to a more externally valid mixed reality game.}
}
@article{AMBROGIO2022108158,
title = {Workforce and supply chain disruption as a digital and technological innovation opportunity for resilient manufacturing systems in the COVID-19 pandemic},
journal = {Computers & Industrial Engineering},
volume = {169},
pages = {108158},
year = {2022},
issn = {0360-8352},
doi = {https://doi.org/10.1016/j.cie.2022.108158},
url = {https://www.sciencedirect.com/science/article/pii/S0360835222002285},
author = {Giuseppina Ambrogio and Luigino Filice and Francesco Longo and Antonio Padovano},
keywords = {COVID-19 pandemic, Resilience, Manufacturing systems, Supply chain disruption, Digitalization, Industry 4.0, Additive manufacturing, Operator 4.0},
abstract = {During the SARS-CoV-2 pandemic (also known as COVID-19), workforce downsizing needs, safety requirements, supply chain breaks and inventory shortages affected manufacturing systems’ and supply chain’s responsiveness and resilience. Companies wandered in a disrupted scenario because recommended actions/strategies to survive – and thrive – were not available an improvised actions to keep their operations up and running. This paper analyzes the COVID-19 impacts on the workforce and supply resilience in a holistic manner. The following research questions are discussed: (i) how can manufacturing firms cope with urgent staff deficiencies while sustaining at the same time a healthy and safe workforce in the perspective of socially sustainable and human-centric cyber-physical production systems?; (ii) is remote working (cf. smart working) applicable to shop-floor workers?; (iii) is it possible to overcome supply chain breaks without stopping production? In the first part, we propose three Industry 4.0-driven solutions that would increase the workforce resilience, namely: (i) the Plug-and-Play worker; (ii) the Remote Operator 4.0; (iii) the Predictive Health of the Operational Staff. In the second part, the concepts of (i) Digital & Unconventional Sourcing, i.e. Additive Manufacturing, and (ii) Product/Process Innovation are investigated from a novel business continuity and integration perspective. We ultimately argue that forward-looking manufacturing companies should turn a disruptive event like a pandemic in an opportunity for digital and technological innovation of the workplace inspired by the principles of harmonic digital innovation (that places the human well-being at the center). These aspects are discussed with use cases, system prototypes and results from research projects carried out by the authors and real-world examples arising lessons learned and insights useful for scientists, researchers and managers.}
}
@article{HOCRAFFER201766,
title = {A meta-analysis of human-system interfaces in unmanned aerial vehicle (UAV) swarm management},
journal = {Applied Ergonomics},
volume = {58},
pages = {66-80},
year = {2017},
issn = {0003-6870},
doi = {https://doi.org/10.1016/j.apergo.2016.05.011},
url = {https://www.sciencedirect.com/science/article/pii/S0003687016300989},
author = {Amy Hocraffer and Chang S. Nam},
keywords = {Unmanned aerial vehicle (UAV), Swarm, Multi-robot systems, Human factors, Human-system interface, Human-robot interaction, Human-swarm interaction},
abstract = {A meta-analysis was conducted to systematically evaluate the current state of research on human-system interfaces for users controlling semi-autonomous swarms composed of groups of drones or unmanned aerial vehicles (UAVs). UAV swarms pose several human factors challenges, such as high cognitive demands, non-intuitive behavior, and serious consequences for errors. This article presents findings from a meta-analysis of 27 UAV swarm management papers focused on the human-system interface and human factors concerns, providing an overview of the advantages, challenges, and limitations of current UAV management interfaces, as well as information on how these interfaces are currently evaluated. In general allowing user and mission-specific customization to user interfaces and raising the swarm’s level of autonomy to reduce operator cognitive workload are beneficial and improve situation awareness (SA). It is clear more research is needed in this rapidly evolving field.}
}
@article{HU2019100974,
title = {Detecting, locating, and characterizing voids in disaster rubble for search and rescue},
journal = {Advanced Engineering Informatics},
volume = {42},
pages = {100974},
year = {2019},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2019.100974},
url = {https://www.sciencedirect.com/science/article/pii/S1474034619305476},
author = {Da Hu and Shuai Li and Junjie Chen and Vineet R. Kamat},
keywords = {First responders, Search and rescue, Disaster, Void, Ground penetrating radar, Detection and localization},
abstract = {After natural and man-made disasters such as earthquakes, hurricanes, and explosions, victims may survive in voids that are formed naturally in collapsed structures. First responders need to identify and locate these critical voids for rapid search and rescue operations. Due to the complex and unstructured occlusions in disaster areas, visual and manual search is time-consuming and error-prone. In this study, we proposed a novel method to automatically detect, locate, and characterize voids buried in disaster rubble using ground penetrating radar (GPR). After preprocessing the collected radargrams, the boundaries of potential voids are segmented based on radar signal patterns, and the 95% confidence intervals are constructed around the segmented boundaries to account for uncertainties. To improve the detection accuracy, the geometric relations of the detected boundaries and their signal characteristics are examined to confirm the void existence. Then, the void location and dimension are estimated based on calibrated velocity of radar wave and its travel time. The effectiveness and efficiency of the proposed method were manifested by its performance in laboratory and field experiments. The contribution of this study is twofold. First, the feasibility of using GPR to detect, locate, and characterize voids in collapsed structures is experimentally tested, innovatively extending the application of GPR to search and rescue operations. Second, algorithms are developed to process non-intuitive radargrams to provide first responders actionable information.}
}
@article{KOSAKA2023103807,
title = {Decision-making support utilizing real-time tsunami inundation and damage forecast},
journal = {International Journal of Disaster Risk Reduction},
volume = {94},
pages = {103807},
year = {2023},
issn = {2212-4209},
doi = {https://doi.org/10.1016/j.ijdrr.2023.103807},
url = {https://www.sciencedirect.com/science/article/pii/S221242092300287X},
author = {Naoko Kosaka and Shunichi Koshimura and Kenjiro Terada and Yoichi Murashima and Tsuneko Kura and Akira Koyama and Hiroshi Matsubara},
keywords = {Decision-making, Real-time tsunami inundation and damage forecast, Hazard map, Emergency operations center (EOC), Crisis management, Disaster resilience},
abstract = {In the Great East Japan Earthquake of 2011, tsunami inundation caused devastating damage over a wide area along the coast of the Tohoku region. Since then, hazard maps for tsunami flooding have been prepared or updated nationwide. These maps assume flooding in the event of a tsunami of the extreme class (L2) with a recurrence interval of 1000 years, in which the top priority is to protect lives. However, once an earthquake occurs, the situation of inundation differs depending on the earthquake rupture mechanisms and its magnitude, so the area of unexpected damage needs to be grasped as soon as possible. Therefore, a forecast of tsunami inundation and damage needs to be provided immediately after the disaster to support disaster responders’ decisions. In this paper, we propose a framework to utilize a tsunami inundation and damage forecast. Specifically, we introduce “recovery levels”, which allow areas that need immediate response to be more easily recognized to allocate human and physical resources. We evaluated their usefulness from the viewpoint of disaster responders by surveying users in a local government through a disaster response drill and an explanatory meeting. Consequently, it was found that the recognition and understanding of the tsunami forecast advanced, and many positive opinions were obtained about utilizing the forecast in the initial activity of disaster response.}
}
@article{DWYER202041,
title = {The Data Visualisation and Immersive Analytics Research Lab at Monash University},
journal = {Visual Informatics},
volume = {4},
number = {4},
pages = {41-49},
year = {2020},
issn = {2468-502X},
doi = {https://doi.org/10.1016/j.visinf.2020.11.001},
url = {https://www.sciencedirect.com/science/article/pii/S2468502X2030067X},
author = {Tim Dwyer and Maxime Cordeil and Tobias Czauderna and Pari {Delir Haghighi} and Barrett Ens and Sarah Goodwin and Bernhard Jenny and Kim Marriott and Michael Wybrow},
keywords = {Immersive Analytics, Data Visualisation, Network visualisation, Cartographic visualisation, Interactive optimisation},
abstract = {This article reviews two decades of research in topics in Information Visualisation emerging from the Data Visualisation and Immersive Analytics Lab at Monash University Australia (Monash IA Lab). The lab has been influential with contributions in algorithms, interaction techniques and experimental results in Network Visualisation, Interactive Optimisation and Geographic and Cartographic visualisation. It has also been a leader in the emerging topic of Immersive Analytics, which explores natural interactions and immersive display technologies in support of data analytics. We reflect on advances in these areas but also sketch our vision for future research and developments in data visualisation more broadly.}
}
@article{HUANG2021101578,
title = {Regulatory compliance and socio-demographic analyses of civil Unmanned Aircraft Systems users},
journal = {Technology in Society},
volume = {65},
pages = {101578},
year = {2021},
issn = {0160-791X},
doi = {https://doi.org/10.1016/j.techsoc.2021.101578},
url = {https://www.sciencedirect.com/science/article/pii/S0160791X21000531},
author = {Chenyu Huang and Yu-Che Chen and Joseph Harris},
keywords = {UAS, Drone, Regulatory compliance, Logistic regression},
abstract = {To safely integrate the emerging Unmanned Aircraft Systems (UAS) technology into the national airspace system and a variety of application fields, the Federal Aviation Administration (FAA) is in charge of publishing rules to regulate and oversee UAS activities in the U.S. However, incompliance with rules undermines the effectiveness of such regulations. This study focuses on investigating the status of UAS regulatory compliance in the U.S. from the perspectives of UAS ownership registration and maximum flight altitude limitation, analyzing the socio-demographic factors of UAS users and their relationship with regulatory compliance. A U.S. national representative survey was performed for data collection. Descriptive statistics illustrate the overall status of UAS regulatory compliance and the demographic characteristics of the adult UAS users. Canonical correlation analysis was adopted to explore the pattern between variables of regulatory compliance and socio-demographic factors. Logistic regression was used to identify influencing socio-demographic factors for compliance behavior of UAS users on two specific rules. Results present 1) the demographic features of the adult UAS users in the U.S., 2) the overall status of UAS regulatory compliance in terms of ownership registration and maximum flight altitude limitation, and 3) the relationship between UAS regulatory compliance and influencing socio-demographic factors. Findings of this study provide aviation regulation authorities and UAS law enforcement important insights into UAS regulatory compliance to further develop more effective policies and strategies to safely and sustainably regulate UAS activities.}
}
@article{MENIN2022402,
title = {The effects of VR in training simulators: Exploring perception and knowledge gain},
journal = {Computers & Graphics},
volume = {102},
pages = {402-412},
year = {2022},
issn = {0097-8493},
doi = {https://doi.org/10.1016/j.cag.2021.09.015},
url = {https://www.sciencedirect.com/science/article/pii/S0097849321002119},
author = {Aline Menin and Rafael Torchelsen and Luciana Nedel},
keywords = {Virtual reality, Immersion, Training simulators, User perception, Knowledge gain},
abstract = {Although immersive virtual environments have been used for years for training and learning purposes (e.g., flight and surgery simulators), the effects of using VR devices on simulation sessions are yet to be understood. In this work, we explore the effects of different VR devices on virtual environments developed for training, focusing on perception and knowledge gain aspects. We performed two user studies to investigate the influence of these devices on users’ workload, motion sickness, and performance in the domain of work safety training. The first experiment included 61 participants and sought to understand whether and how VR displays providing different fields of view affects the users’ ability to search for risks in an office-like virtual environment (focus on user perception). Subsequently, we conducted a second experiment involving 46 subjects, where we assess whether and how interaction techniques providing different degrees-of-freedom influence users’ ability to learn procedural tasks (focus on knowledge gain). From our results, we learned that users’ knowledge on the simulation’s topic (i.e. work safety) and gaming experience play an important role in VR simulations, and that cybersickness symptoms such as disorientation are likely caused by unawareness of one’s surroundings instead of VR content.}
}
@article{LI2022117459,
title = {Immersive technology-enabled digital transformation in transportation fields: A literature overview},
journal = {Expert Systems with Applications},
volume = {202},
pages = {117459},
year = {2022},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2022.117459},
url = {https://www.sciencedirect.com/science/article/pii/S0957417422007928},
author = {Fan Li and Amy J.C. Trappey and Ching-Hung Lee and Li Li},
keywords = {Immersive technology, Digital transformation, Transportation, Virtual reality (VR), Augmented reality (AR)},
abstract = {Immersive technology is rapidly emerging as a powerful tool for enhancing the digital transformation in transportation to deal with the complexity, high cost, and uncertainty in the dynamic traffic environment. In this study, we investigate the innovations induced by immersive technologies for transportation fields. The literature (153 articles) published over the past five years were collected and analyzed systematically, pertaining to the lifecycle model of the product–service system, i.e., design, development, evaluation, and applications. The review indicated that immersive systems and scenarios have been developed and applied in various transportation areas, such as air traffic management, autonomous vehicles, railways, highways, and vehicle maintenance. Additionally, the review indicated that immersive technology brings significant benefits to the transportation field and induces significant changes in the interactions between humans and the physical world. These changes are expected to induce digital transformation in several aspects, e.g., digital testbeds for theoretical models and algorithms, immersive and safe digital environments for user studies, and digital training. Based on the review, a novel framework and conceptual lifecycle model of developing immersive technology-enabled digital transformation in transportation is proposed, a novel evaluation matrix for measuring the immersive experience level is established. The results provide essential references for practitioners to apply immersive technology and guidance regarding potential future research directions.}
}
@article{MUSTAK2023113368,
title = {Deepfakes: Deceptions, mitigations, and opportunities},
journal = {Journal of Business Research},
volume = {154},
pages = {113368},
year = {2023},
issn = {0148-2963},
doi = {https://doi.org/10.1016/j.jbusres.2022.113368},
url = {https://www.sciencedirect.com/science/article/pii/S0148296322008335},
author = {Mekhail Mustak and Joni Salminen and Matti Mäntymäki and Arafat Rahman and Yogesh K. Dwivedi},
keywords = {Deepfake, Fake photo, Fake video, Artificial intelligence, Machine learning, Deception, Opportunities, Threats, Challenges, Protection, Marketing},
abstract = {Deepfakes—artificial but hyper-realistic video, audio, and images created by algorithms—are one of the latest technological developments in artificial intelligence. Amplified by the speed and scope of social media, they can quickly reach millions of people and result in a wide range of marketplace deceptions. However, extant understandings of deepfakes’ implications in the marketplace are limited and fragmented. Against this background, we develop insights into the significance of deepfakes for firms and consumers—the threats they pose, how to mitigate those threats, and the opportunities they present. Our findings indicate that the main risks to firms include damage to image, reputation, and trustworthiness and the rapid obsolescence of existing technologies. However, consumers may also suffer blackmail, bullying, defamation, harassment, identity theft, intimidation, and revenge porn. We then accumulate and present knowledge on the strategies and mechanisms to safeguard against deepfake-based marketplace deception. Furthermore, we uncover and report the various legitimate opportunities offered by this new technology. Finally, we present an agenda for future research in this emergent and highly critical area.}
}
@article{ALSABBAG2022101473,
title = {Interactive defect quantification through extended reality},
journal = {Advanced Engineering Informatics},
volume = {51},
pages = {101473},
year = {2022},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2021.101473},
url = {https://www.sciencedirect.com/science/article/pii/S1474034621002238},
author = {Zaid Abbas Al-Sabbag and Chul Min Yeum and Sriram Narasimhan},
keywords = {Visual inspection, Extended reality, Augmented reality, Damage detection},
abstract = {In this study, a new visual inspection method that can interactively detect and quantify structural defects using an Extended Reality (XR) device (headset) is proposed. The XR device, which is at the core of this method, supports an interactive environment using a holographic overlay of graphical information on the spatial environment and physical objects being inspected. By leveraging this capability, a novel XR-supported inspection pipeline, called eXtended Reality-based Inspection and Visualization (XRIV), is developed. Key tasks supported by this method include detecting visual damage from sensory data acquired by the XR device, estimating its size, and visualizing (overlaying) information on the spatial environment. The crucial step of real-time interactive segmentation—detection and pixel-wise damage boundary refinement—is achieved using a feature Back-propagating Refinement Scheme (f-BRS) algorithm. Then, a ray-casting algorithm is applied to back-project the 2D image pixel coordinates of the damage region to their 3D world coordinates for damage area quantification in real-world (physical) units. Finally, the area information is overlaid and anchored to the scene containing damage for visualization and documentation. The performance of XRIV is experimentally demonstrated by measuring surface structural damage of an in-service concrete bridge with less than 10% errors for two different test cases, and image processing latency of 2–3 s (or 0.5 s per seed point) from f-BRS. The proposed XRIV pipeline underscores the advantages of real-time interaction between expert users and the XR device through immersive visualization so that a human–machine collaborative workflow can be established to obtain better inspection outcomes in terms of accuracy and robustness.}
}
@article{MACKENZIE20223575,
title = {Virtual reality and haptic interfaces for civilian and military open trauma surgery training: A systematic review},
journal = {Injury},
volume = {53},
number = {11},
pages = {3575-3585},
year = {2022},
issn = {0020-1383},
doi = {https://doi.org/10.1016/j.injury.2022.08.003},
url = {https://www.sciencedirect.com/science/article/pii/S0020138322005344},
author = {Colin F. Mackenzie and Tyler E. Harris and Andrea G. Shipper and Eric Elster and Mark W. Bowyer},
keywords = {Virtual, Augmented, Mixed reality, Haptics, ASSET, ASSET+, Haemorrhage Control Skill, Open vascular surgical procedures, Competence benchmark, Simulation of open surgery, Benefit to patient outcomes},
abstract = {Objective
Virtual (VR), augmented (AR), mixed reality (MR) and haptic interfaces make additional avenues available for surgeon assessment, guidance and training. We evaluated applications for open trauma and emergency surgery to address the question: Have new computer-supported interface developments occurred that could improve trauma training for civilian and military surgeons performing open, emergency, non-laparoscopic surgery?
Design
Systematic literature review.
Setting and Participants
Faculty, University of Maryland School of Medicine, Baltimore., Maryland; Womack Army Medical Center, Fort Bragg, North Carolina; Temple University, Philadelphia, Pennsylvania; Uniformed Services University of Health Sciences, and Walter Reed National Military Medical Center, Bethesda, Maryland.
Methods
Structured literature searches identified studies using terms for virtual, augmented, mixed reality and haptics, as well as specific procedures in trauma training courses. Reporting bias was assessed. Study quality was evaluated by the Kirkpatrick's Level of evidence and the Machine Learning to Asses Surgical Expertise (MLASE) score.
Results
Of 422 papers identified, 14 met inclusion criteria, included 282 enrolled subjects, 20% were surgeons, the remainder students, medics and non-surgeon physicians. Study design was poor and sample sizes were low. No data analyses were beyond descriptive and the highest outcome types were procedural success, subjective self-reports, except three studies used validated metrics. Among the 14 studies, Kirkpatrick's level of evidence was level zero in five studies, level 1 in 8 and level 2 in one. Only one study had MLASE Score greater than 9/20. There was a high risk of bias in 6 studies, uncertain bias in 5 studies and low risk of bias in 3 studies.
Conclusions
There was inadequate evidence that VR,MR,AR or haptic interfaces can facilitate training for open trauma surgery or replace cadavers. Because of limited testing in surgeons, deficient study and technology design, risk of reporting bias, no current well-designed studies of computer-supported technologies have shown benefit for open trauma, emergency surgery nor has their use shown improved patient outcomes. Larger more rigorously designed studies and evaluations by experienced surgeons are required for a greater variety of procedures and skills.
Competencies
Medical Knowledge, Practice Based Learning and Improvement, Patient Care, Systems-Based Practice.}
}
@article{PRINGLE2022696,
title = {Extended reality (XR) virtual practical and educational eGaming to provide effective immersive environments for learning and teaching in forensic science},
journal = {Science & Justice},
volume = {62},
number = {6},
pages = {696-707},
year = {2022},
note = {The Future of Teaching, Training and Learning in Forensic and Crime Sciences},
issn = {1355-0306},
doi = {https://doi.org/10.1016/j.scijus.2022.04.004},
url = {https://www.sciencedirect.com/science/article/pii/S135503062200051X},
author = {Jamie K. Pringle and Ian G. Stimpson and Adam J. Jeffery and Kristopher D. Wisniewski and Timothy Grossey and Luke Hobson and Vivienne Heaton and Vladimir Zholobenko and Steven L. Rogers},
keywords = {Search, Educational eGaming, Virtual practicals, Geophysics, Flexible learning, XR},
abstract = {Online virtual learning resources have been available for learning and teaching in forensic science for some years now, but the recent global COVID-19 related periods of irregular lockdown have necessitated the rapid development of these for teaching, learning and CPD activities. However, these resources do need to be carefully constructed and grounded in pedagogic theory to be effective. This article details eXtended Reality (XR) learning and teaching environments to facilitate effective online teaching and learning for forensic geoscientists. The first two case studies discussed in this article make use of Thinglink software to produce virtual learning and teaching XR resources through an internet system, which was delivered to undergraduate students in 2021. Case one details a range of XR virtual laboratory-based equipment resources, providing a consistent, reliable and asynchronous learning and teaching experience, whilst the second case study presents an XR virtual learning applied geophysics resource developed for a 12-week CPD training programme. This programme involves recorded equipment video resources, accompanying datasets and worksheets for users to work through. Both case studies were positively received by learners, but there were issues encountered by learners with poor internet connections or computer skills, or who do not engage well with online learning. A third case study showcases an XR educational forensic geoscience eGame that was developed to take the user through a cold case search investigation, from desktop study through to field reconnaissance and multi-staged site investigations. Pedagogic research was undertaken with user questionnaires and interviews, providing evidence that the eGame was an effective learning and teaching tool. eGame users highly rated the eGame and reported that they raised awareness and understanding of the use of geophysics equipment and best practice of forensic geoscience search phased investigations. These types of XR virtual learning digital resources, whilst costly to produce in terms of development time and staff resource, provide a complementary virtual learning experience to in-situ practical sessions, and allow learners to asynchronously familiarise themselves with equipment, environments and techniques resulting in more efficient use of in situ time. The XR resources also allow learners to reinforce learning post in-situ sessions. Finally, XR resources can provide a more inclusive and authentic experience for learners who cannot attend or complete work synchronously.}
}
@article{YIN2020381,
title = {VR and AR in human performance research―An NUS experience},
journal = {Virtual Reality & Intelligent Hardware},
volume = {2},
number = {5},
pages = {381-393},
year = {2020},
issn = {2096-5796},
doi = {https://doi.org/10.1016/j.vrih.2020.07.009},
url = {https://www.sciencedirect.com/science/article/pii/S2096579620300723},
author = {Jun-Hao Yin and Chin-Boon Chng and Pooi-Mun Wong and Nicholas Ho and Matthew Chua and Chee-Kong Chui},
keywords = {Human computer interaction, Virtual environment, Human performance},
abstract = {With the mindset of constant improvement in efficiency and safety in the workspace and training in Singapore, there is a need to explore varying technologies and their capabilities to fulfil this need. The ability of Virtual Reality (VR) and Augmented Reality (AR) to create an immersive experience of tying the virtual and physical environments coupled with information filtering capabilities brings a possibility of introducing this technology into the training process and workspace. This paper surveys current research trends, findings and limitation of VR and AR in its effect on human performance, specifically in Singapore, and our experience in the National University of Singapore (NUS).}
}
@article{DING2021125168,
title = {State-of-the-art high-rise building emergency evacuation behavior},
journal = {Physica A: Statistical Mechanics and its Applications},
volume = {561},
pages = {125168},
year = {2021},
issn = {0378-4371},
doi = {https://doi.org/10.1016/j.physa.2020.125168},
url = {https://www.sciencedirect.com/science/article/pii/S0378437120306105},
author = {Ning Ding and Tao Chen and Yu Zhu and Yang Lu},
keywords = {High-rise building evacuation, Evacuation experiment, Evacuation behavior, Fire evacuation},
abstract = {Emergency evacuation in case of an emergency is a crucial problem in high-rise buildings, as many occupants are in a limited amount of space. To improve building safety design and evacuation strategies, it is essential to understand how individuals behave during an evacuation in high-rise buildings. This paper surveys the recently available literature on evacuation in high-rise buildings with the following objectives: (1) to review the high-rise building evacuation experiment methods; (2) to review the wayfinding and impact factors in horizontal evacuation; and (3) to review the individual and crowd behaviors in vertical evacuation. The review highlights the application of the virtual reality technology in evacuation experiments and the two-side effect of the group behavior in high-rise buildings. Future research should focus on quantitative pre-evacuation behavior study, the elevator’s assistant function, and the impact of group relations on evacuation. As the height of high-rise buildings continues to increase, individual characteristics, such as mobility issues and fatigue, warrant further study.}
}
@article{LOVREGLIO2022103283,
title = {Prototyping and testing a virtual reality counterterrorism serious game for active shooting},
journal = {International Journal of Disaster Risk Reduction},
volume = {82},
pages = {103283},
year = {2022},
issn = {2212-4209},
doi = {https://doi.org/10.1016/j.ijdrr.2022.103283},
url = {https://www.sciencedirect.com/science/article/pii/S2212420922005027},
author = {Ruggiero Lovreglio and Daphney-Chloe Ngassa and Anass Rahouti and Daniel Paes and Zhenan Feng and Alastair Shipman},
keywords = {Virtual reality, Counterterrorism, Training, Active shooting, Serious games},
abstract = {An active shooting emergency requires an effective strategy to increase the chances of survival of the attacked population. Educational environments are one of the most common locations of such events. To reduce the impact of these disasters, several emergency plans have been developed and put in place. Traditionally, these emergency plans are taught to occupants using non-interactive videos, drills, etc. However, these conventional methods present many limitations regarding trainees' knowledge acquisition, engagement and self-efficacy. To overcome them, this paper presents the prototype of an immersive Virtual Reality (VR) Serious Game (SG) for counterterrorism training. A user-centred evaluation of the proposed training SG was conducted with 32 participants. The experiment aimed to investigate the impact of the proposed tool on participants' knowledge regarding the safest actions to take in case of an active shooter attack. Participants' intrinsic motivation and self-efficacy levels were also assessed before and after the VR-based training. Findings indicate that participants’ knowledge, intrinsic motivation, and self-efficacy significantly increased immediately after the training.}
}
@article{BRUNS200433,
title = {Ubiquitous Computing and New Frontiers of Automation},
journal = {IFAC Proceedings Volumes},
volume = {37},
number = {5},
pages = {33-42},
year = {2004},
note = {7th IFAC Symposium on Cost-Oriented Automation (COA 2004), Gatineau, Québec, Canada, 6-9 June 2004},
issn = {1474-6670},
doi = {https://doi.org/10.1016/S1474-6670(17)32340-6},
url = {https://www.sciencedirect.com/science/article/pii/S1474667017323406},
author = {Wilhelm Bruns},
keywords = {ubiquitous computing, intelligent environments, invisible computing, pervasive computing},
abstract = {Abstract
Ubiquitous Computing, a vision of invisible computing integrated in our everyday surroundings, first introduced by M. Weiser and his group at Xerox PARC in 1988, is still in its early infancy and far from leaving the laboratory stage. Nevertheless there are foreseeable applications in specific areas like automotive automation, health care, home automation, advanced manufacturing. Some aspects of Ubiquitous Computing from an automatic control perspective and its relation to mixed reality, augmented reality and pervasive computing will be covered. Several problems like geometric representation, extensible computing, scalability, movable interactions, integration of various network-technologies, user interface design for multi-modality, design methodologies and evaluation techniques, security/privacy issues and enabling software concepts are touched and it will be speculated about how Ubiquitous Computing might influence Low Cost Advanced Manufacturing and how experiences from the automation and control field might influence the emerging community.}
}
@incollection{2018863,
title = {Subject Index},
editor = {William R. Sherman and Alan B. Craig},
booktitle = {Understanding Virtual Reality (Second Edition)},
publisher = {Morgan Kaufmann},
edition = {Second Edition},
address = {Boston},
pages = {863-901},
year = {2018},
series = {The Morgan Kaufmann Series in Computer Graphics},
isbn = {978-0-12-800965-9},
doi = {https://doi.org/10.1016/B978-0-12-800965-9.18001-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780128009659180018}
}
@article{ZEREIK2018350,
title = {Challenges and future trends in marine robotics},
journal = {Annual Reviews in Control},
volume = {46},
pages = {350-368},
year = {2018},
issn = {1367-5788},
doi = {https://doi.org/10.1016/j.arcontrol.2018.10.002},
url = {https://www.sciencedirect.com/science/article/pii/S1367578818300038},
author = {Enrica Zereik and Marco Bibuli and Nikola Mišković and Pere Ridao and António Pascoal},
keywords = {Marine robotics, Field applications, Future trends},
abstract = {Spawned by fast paced progress in marine science and technology, the past two decades have witnessed growing interest in ocean exploration and exploitation for scientific and commercial purposes, the development of technological products for the maritime and offshore industries, and a host of other activities in which the marine environment takes center stage. In this context, marine robotics has steadily emerged as a key enabling technology for the execution of increasingly complex and challenging missions at sea. Intensive research and development in this field have led to major advances and shown unequivocally the effectiveness and reliability of marine robotics solutions in several domains. This progress goes hand in hand with the availability of increasingly sophisticated acoustic networks for multiple, cooperative missions involving surface and underwater robots. At the root of this trend is the fruitful dialogue between robotic systems developers and end-users with the capacity to convert general mission objectives into functional and technical specifications that serve as application-driven requirements for engineering development. The result is the tremendous progress observed in the consolidated methodologies and procedures adopted and the consequent impact on science, industry, and the society at large. In spite of the progress in the area, however many challenges must still be faced and novel applications will continue to set further requirements for future generations of marine robots and their enabling systems. The time is therefore appropriate to overview recent trends in the field of marine robotics and assess their impact on several important application domains. With these objectives in mind, in the present paper we highlight key technological achievements in the field, analyze some of the shortcomings encountered, and indicate specific issues that warrant further research and development effort. To this end, we review a number of highly representative projects in the field, with due account for the theoretical frameworks upon which technological developments build upon. Finally, the paper concludes with an outlook on the future of marine robotics, both from a theoretical and practical standpoint, and describes recently initiated projects that hold promise for the development of advanced tools and systems for ocean exploration and exploitation.}
}
@article{SANTAMARIABONFIL2020103871,
title = {Learning analytics for student modeling in virtual reality training systems: Lineworkers case},
journal = {Computers & Education},
volume = {151},
pages = {103871},
year = {2020},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2020.103871},
url = {https://www.sciencedirect.com/science/article/pii/S0360131520300701},
author = {Guillermo Santamaría-Bonfil and María Blanca Ibáñez and Miguel Pérez-Ramírez and Gustavo Arroyo-Figueroa and Francisco Martínez-Álvarez},
keywords = {Learning analytics, Performance prediction, Feature importance analysis, Exploratory data analysis, Virtual reality},
abstract = {Live-line maintenance is a high risk activity. Hence, lineworkers require effective and safe training. Virtual Reality Training Systems (VRTS) provide an affordable and safe alternative for training in such high risk environments. However, their effectiveness relies mainly on having meaningful activities for supporting learning and on their ability to detect untrained students. This study builds a student model based on Learning Analytics (LA), using data collected from 1399 students that used a VRTS for the maintenance training of lineworkers in 329 courses carried out from 2008 to 2016. By employing several classifiers, the model allows discriminating between trained and untrained students in different maneuvers using three minimum evaluation proficiency scores. Using the best classifier, a Feature Importance Analysis is carried out to understand the impact of the variables regarding the trainees’ final performances. The model also involves the exploration of the trainees’ trace data through a visualization tool to pose non-observable behavioral variables related to displayed errors. The results show that the model can discriminate between trained and untrained students, the Random Forest algorithm standing out. The feature importance analysis revealed that the most relevant features regarding the trainees’ final performance were profile and course variables along with specific maneuver steps. Finally, using the visual tool, and with human expert aid, several error patterns in trace data associated with misconceptions and confusion were identified. In the light of these, LA enables disassembling the data jigsaw quandary from VRTS to enhance the human-in-the-loop evaluation.}
}
@article{RADIANTI2015312,
title = {Fire simulation-based adaptation of SmartRescue App for serious game: Design, setup and user experience},
journal = {Engineering Applications of Artificial Intelligence},
volume = {46},
pages = {312-325},
year = {2015},
note = {Innovative Artificial Intelligence Solutions for Crisis Management},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2015.06.012},
url = {https://www.sciencedirect.com/science/article/pii/S0952197615001347},
author = {Jaziar Radianti and Mehdi Ben Lazreg and Ole-Christoffer Granmo},
keywords = {Fire simulations, Sensors, Game app, Serious game, Disaster management, Bayesian network},
abstract = {Managing the crisis by embracing game and simulation elements and human participation into an interactive system is a mean to learn about responding to unexpected events. This so-called serious game approach is adopted in a summer school for crisis management attended by doctoral students and practitioners, as a part of its learning curriculum. The participants took part in the Disaster in my Backyard serious game, designed as a realistic crisis environment. A smartphone app encompassing fire simulations of a five-story apartment, showing how the flame, smoke and temperature of the fire developed over time from floor to floor, was tested in this serious game scenario. The color-coding of smoke and temperature information indicating the danger levels was used as a guide and decision support for the rescue team to evacuate victims out of the burning apartment. In this paper, we elaborate the underlying technology, design, and setup of the app. Finally, we discuss the evaluation of the user experience, and the merits and shortcomings of the app for search and rescue activity in a serious game fire situation.}
}
@article{APPLIN2021100010,
title = {Facebook's Project Aria indicates problems for responsible innovation when broadly deploying AR and other pervasive technology in the Commons},
journal = {Journal of Responsible Technology},
volume = {5},
pages = {100010},
year = {2021},
issn = {2666-6596},
doi = {https://doi.org/10.1016/j.jrt.2021.100010},
url = {https://www.sciencedirect.com/science/article/pii/S2666659621000032},
author = {Sally A. Applin and Catherine Flick},
keywords = {Ethics, Responsible innovation, Augmented reality, Pervasive technology, Social media, Surveillance, Anthropology},
abstract = {Nearly every week, a technology company is introducing a new surveillance technology, varying from applying facial recognition to observing and cataloguing behaviours of the public in the Commons and private spaces, to listening and recording what we say, or mapping what we do, where we go, and who we're with—or as much of these facets of our lives as can be accessed. As such, the general public writ-large has had to wrestle with the colonization of publicly funded space, and the outcomes to each of our personal lives as a result of the massive harvesting and storing of our data, and the potential machine learning and processing applied to that data. Facebook, once content to harvest our data through its website, cookies, and apps on mobile phones and computers, has now planned to follow us more deeply into the Commons by developing new mapping technology combined with smart camera equipped Augmented Reality (AR) eyeglasses, that will track, render and record the Commons—and us with it. The resulting data will privately benefit Facebook's continued goal to expand its worldwide reach and growth. In this paper, we examine the ethical implications of Facebook's Project Aria research pilot through the perspectives of Responsible Innovation, comparing both existing understandings of Responsible Research and Innovation and Facebook's own Responsible Innovation Principles; we contextualise Project Aria within the Commons through applying current social multi-dimensional communications theory to understand the extensive socio-technological implications of Project Aria within society and culture; and we address the potentially serious consequences of the Facebook Project Aria experiment, inspiring countless other companies to shift their focus to compete with Project Aria, or beat it to the consumer marketplace.}
}
@article{MONDRAGONSOLIS201421,
title = {Critical evaluation of cognitive analysis techniques for construction field management},
journal = {Automation in Construction},
volume = {40},
pages = {21-32},
year = {2014},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2013.12.012},
url = {https://www.sciencedirect.com/science/article/pii/S0926580513002331},
author = {Fernando A. {Mondragon Solis} and William J. O'Brien},
keywords = {Cognitive analysis, Construction management, Knowledge elicitation, Knowledge representation},
abstract = {Cognitive analysis techniques to document field personnel's knowledge have been a recent topic of interest in construction. However, the decision to utilize such techniques remains a difficult one, given their perceived complexity, their variety of scopes and means and their expected limitations for utilization in jobsites. This paper presents a critical review of cognitive analysis techniques to analyze their value for construction management research. The evaluation is geared towards identifying the function of different types of techniques as well as constraints for their implementation in construction environments. In the evaluation, the components of techniques are dissected to uncover their individual capabilities and applications, while also providing insight into the actual difficulties to collect and represent knowledge. This analysis is complemented by the authors' experience in previous cognitive analysis studies, which helps produce a set of recommendations about the practical challenges and implications of deploying specific techniques in construction jobsites.}
}
@article{MURPHY2022103922,
title = {An analysis of international use of robots for COVID-19},
journal = {Robotics and Autonomous Systems},
volume = {148},
pages = {103922},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103922},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021002074},
author = {Robin R. Murphy and Vignesh B.M. Gandudi and Trisha Amin and Angela Clendenin and Jason Moats},
keywords = {Robotics and society, Field robotics, Disaster robotics, Medical robotics, Unmanned systems},
abstract = {This article analyses data collected from press reports, social media, and the scientific literature on 338 instances of robots used explicitly in response to COVID-19 from 24 Jan, 2020, to 23 Jan, 2021, in 48 countries. The analysis was guided by four overarching questions: (1) What were robots used for in the COVID-19 response? (2) When were they used? (3) How did different countries innovate? and 4) Did having a national policy on robotics influence a country’s innovation and insertion of robotics for COVID-19? The findings indicate that robots were used for six different sociotechnical work domains and 29 discrete use cases. When robots were used varied greatly on the country; although many countries did report an increase at the beginning of their first surge. To understand the findings of how innovation occurred, the data was examined through the lens of the technology’s maturity according to NASA’s Technical Readiness Assessment metrics. Through this lens, findings note that existing robots were used for more than 78% of the instances; slightly modified robots made up 10%; and truly novel robots or novel use cases constituted 12% of the instances. The findings clearly indicate that countries with a national robotics initiative were more likely to use robotics more often and for broader purposes. Finally, the dataset and analysis produces a broad set of implications that warrant further study and investigation. The results from this analysis are expected to be of value to the robotics and robotics policy community in preparing robots for rapid insertion into future disasters.}
}
@article{FILLATREAU20131253,
title = {Using virtual reality and 3D industrial numerical models for immersive interactive checklists},
journal = {Computers in Industry},
volume = {64},
number = {9},
pages = {1253-1262},
year = {2013},
note = {Special Issue: 3D Imaging in Industry},
issn = {0166-3615},
doi = {https://doi.org/10.1016/j.compind.2013.03.018},
url = {https://www.sciencedirect.com/science/article/pii/S0166361513000717},
author = {P. Fillatreau and J.-Y. Fourquet and R. {Le Bolloc’h} and S. Cailhol and A. Datas and B. Puel},
keywords = {Virtual reality, 3D industrial inspection, Quality and control processes, 3D visualization, Sensorimotor interfaces},
abstract = {At the different stages of the PLM, companies develop numerous checklist-based procedures involving prototype inspection and testing. Besides, techniques from CAD, 3D imaging, animation and virtual reality now form a mature set of tools for industrial applications. The work presented in this article develops a unique framework for immersive checklist-based project reviews that applies to all steps of the PLM. It combines immersive navigation in the checklist, virtual experiments when needed and multimedia update of the checklist. It provides a generic tool, independent of the considered checklist, relies on the integration of various VR tools and concepts, in a modular way, and uses an original gesture recognition. Feasibility experiments are presented, validating the benefits of the approach.}
}
@article{DURMUSOGLU2022351,
title = {Emerging research questions for new journey development in industrial markets},
journal = {Industrial Marketing Management},
volume = {106},
pages = {351-362},
year = {2022},
issn = {0019-8501},
doi = {https://doi.org/10.1016/j.indmarman.2022.08.014},
url = {https://www.sciencedirect.com/science/article/pii/S0019850122001997},
author = {Serdar S. Durmusoglu and Regina C. McNally and Junsong Chen},
keywords = {New journey development, Customer journey, Solutions marketing, Dynamic capability, Industrial solutions},
abstract = {In consumer markets, customer experiences and their associated capabilities are supplanting prior focus on goods and services. The view of experiences has even been expanded to bundling them into a customer journey that is the entirety of a customer's experiences across multiple touchpoints, multiple channels, and over time. Increasingly, industrial firms are also recognizing the importance of customer journeys and moving toward reconfiguring their market approach to align with a focus on customer journey. In this article, we delineate ensuing emerging B2B research challenges and identify key research questions moving forward with respect to new journey development. We also discuss some contextual factors that researchers should pay attention to when conducting research on the topics highlighted. We end with some concluding thoughts regarding the research methods and theories that can be used for impactful research in this research stream.}
}
@article{BUHALIS2023104724,
title = {Metaverse as a disruptive technology revolutionising tourism management and marketing},
journal = {Tourism Management},
volume = {97},
pages = {104724},
year = {2023},
issn = {0261-5177},
doi = {https://doi.org/10.1016/j.tourman.2023.104724},
url = {https://www.sciencedirect.com/science/article/pii/S0261517723000067},
author = {Dimitrios Buhalis and Daniel Leung and Michael Lin},
keywords = {Metaverse, Immersive experience, Virtual experience, Information communication technologies},
abstract = {Metaverse is the next disruptive technology that will impact society in the coming decades, by enabling immersive experiences in both virtual and physical environments. Although still conceptual, Metaverse converges the physical and digital universe, allowing users to seamlessly traverse between them. Digital immersion offers opportunities for people to travel in time, supporting users to experience virtually ancient encounters, space explorations or dangerous natural phenomena, such as volcano eruptions. Users can explore immersive environments for working, learning, transacting, exploring interests and socialising with others. This is already evident in gaming ecosystems, where gamers effectively interact in the metaverse. Although still experimental, Metaverse is expected to revolutionize travel and tourism management and marketing. It empowers destination awareness, positioning and branding, as well as coordination and management, through digital twins. Metaverse provides opportunities to support trip planning, interaction and engagement, effectively transforming consumer behaviour. Visiting and engaging with destinations virtually is expected to motivate real travel, rather than replace it. This paper provides a vision of how Metaverse can revolutionize tourism experiences and transform tourism management and marketing. Drawing on a systematic review of scholarly works, articles from media and industry reports, this study defines and conceptualizes the Metaverse ecosystem for tourism and travel. It explores the foundations of the disruptions that Metaverse brings to tourism destinations and organisations and identifies the building blocks of Metaverse tourism. The study outlines research directions so that the tourism industry can take full advantage of the Metaverse capabilities and opportunities emerging as well as identify challenges for the future.}
}
@article{HERINK202232,
title = {Opportunities of experiential education in chemical technology and engineering},
journal = {Education for Chemical Engineers},
volume = {41},
pages = {32-41},
year = {2022},
issn = {1749-7728},
doi = {https://doi.org/10.1016/j.ece.2022.08.003},
url = {https://www.sciencedirect.com/science/article/pii/S1749772822000203},
author = {Tomáš Herink and Vojtěch Bělohlav and Tomáš Jirout and Zdeněk Bělohlav},
keywords = {Experiential education, Training simulator, Virtual reality, Pilot distillation},
abstract = {The University of Chemistry and Technology Prague, the Czech Technical University in Prague and ORLEN Unipetrol have established a common University center in the production facility of the refinery-petrochemical complex in Litvínov, Czech Republic. The university center offers higher education to more than 50 students in bachelor and master programs. The connection between the chemical industry and the academic environment has created a unique opportunity to apply experiential learning in many areas of teaching. The University center uses a newly built Training facility, which is equipped with several modules for training operators, engineers and, currently, students. Thanks to the attractiveness of the environment of the training facility premises, the target group of students has been extended to secondary and even primary schools. The University center organizes regular practice for secondary and primary schools at the training facility. The aim of these activities is to practice systematically modern methods of education through experience and to make technical disciplines as popular as possible among young students. Regionally, this experiential education system has achieved high popularity and, in addition to the University center own students, more than 500 students from around 30 secondary and primary schools go through the program every year.}
}
@article{JOZWIAK2017202,
title = {Advanced mobile and wearable systems},
journal = {Microprocessors and Microsystems},
volume = {50},
pages = {202-221},
year = {2017},
issn = {0141-9331},
doi = {https://doi.org/10.1016/j.micpro.2017.03.008},
url = {https://www.sciencedirect.com/science/article/pii/S0141933117300741},
author = {Lech Jóźwiak},
keywords = {Cyber-physical systems, Mobile systems, Heterogeneous systems, Massively parallel systems, Multi-processor systems on a chip, Automated design technology},
abstract = {The recent spectacular progress in the microelectronic, information, communication, material and sensor technologies created a big stimulus towards development of smart communicating cyber-physical systems (CPS) and Internet of Things (IoT). CPS and IoT are undergoing an explosive growth to a large degree related to advanced mobile systems like smart automotive and avionic systems, mobile robots and wearable devices. The huge and rapidly developing markets of sophisticated mobile cyber-physical systems represent great opportunities, but these opportunities come with a price of unusual system complexity, as well as, stringent and difficult to satisfy requirements of many modern applications. Specifically, smart cars and various wearable systems to a growing degree involve big instant data from multiple complex sensors or other systems, and are required to provide continuous autonomous service in a long time. In consequence, they demand a guaranteed (ultra-)high performance and/or (ultra-)low energy consumption, while requiring a high reliability, safety and security. To adequately address these demands, sophisticated embedded computing and embedded design technologies are needed. After an introduction to modern mobile systems, this paper discusses the huge heterogeneous area of these systems, and considers serious issues and challenges in their design. Subsequently, it discusses the embedded computing and design technologies needed to adequately address the issues and overcome the challenges in order to satisfy the stringent requirements of the modern mobile systems.}
}
@article{ZHU2020125156,
title = {Follow the evacuation signs or surrounding people during building evacuation, an experimental study},
journal = {Physica A: Statistical Mechanics and its Applications},
volume = {560},
pages = {125156},
year = {2020},
issn = {0378-4371},
doi = {https://doi.org/10.1016/j.physa.2020.125156},
url = {https://www.sciencedirect.com/science/article/pii/S037843712030604X},
author = {Yu Zhu and Tao Chen and Ning Ding and Mohcine Chraibi and Wei-Cheng Fan},
keywords = {Pedestrian evacuation, Wayfinding, Evacuation signage, Surrounding pedestrians, Eye tracking device},
abstract = {Evacuation signage plays a vital role in building evacuation. In order to test the efficiency of evacuation signage, the traditional methods are video analysis and after-drill questionnaires and the human factors are rarely considered. This paper investigates the impact of surrounding pedestrians on the sign guidance efficiency during building emergency evacuation, replacing the traditional ways with eye tracking device method. More than 500 participants were involved in the series of experiments to test the influence of surrounding people on detecting and following signages. It is found that (a) the subjective ignorance and objective ignorance of signs exist obviously and are affected by surrounding people number; (b) strangers and acquaintances have similar effect on the sign detection probability and direction choosing probability in the safe and quick evacuation experiments, contrary to general belief; (c) One surrounding person has an important influence on the sign guidance effect, especially on the following probability, while three surrounding people not. Based on the results of the experiments, a new logic of wayfinding within rooms was put forward and simulated to compared with the original logic. It is shown that the average right direction choosing percentage decreases by 30% after considering the effect of surrounding pedestrians, proving that the impact of surrounding pedestrians must be considered in evacuation modeling and evacuation route design.}
}
@article{CINNAMON2023102044,
title = {360-degree video for virtual place-based research: A review and research agenda},
journal = {Computers, Environment and Urban Systems},
volume = {106},
pages = {102044},
year = {2023},
issn = {0198-9715},
doi = {https://doi.org/10.1016/j.compenvurbsys.2023.102044},
url = {https://www.sciencedirect.com/science/article/pii/S0198971523001072},
author = {Jonathan Cinnamon and Lindi Jahiu},
keywords = {360 video, Virtual reality, Place-based research, Visualization, Panoramic, Virtual geography},
abstract = {360-degree video is an immersive technology used in research across academic disciplines. This paper provides the first comprehensive review on the use of 360-degree video for virtual place-based research, highlighting its use in experimental, experiential, and environmental observation studies. Five key research domains for 360-degree video are described: tourism and cultural heritage; built environment and land use; natural environment; health and wellbeing; and transportation and safety. 360-degree video offers considerable advantages compared to unidirectional video, computer-generated virtual reality, and map-based geographic representation. Benefits include ease of use, low-cost, interactivity, sense of immersive realism, remote accessibility, and the ability to capture and analyze places in a fully panoramic field of view. Limitations include additional costs associated with virtual reality viewing technologies, simulation sickness and discomfort, and viewer distraction due to the technology's novelty and immersive affordances. This paper also outlines a future research agenda, including the possibility of moving beyond the ‘testing and trialling’ of 360-degree video since it provides novel research opportunities distinct from either ‘real’ experience or conventional forms of visual and spatial representation. Overall, this paper provides detailed evidence for researchers interested in using 360-degree video for virtual research on built, social, and natural environments and human-environment interactions.}
}
@article{ZHU20211,
title = {Virtual and augmented reality technologies for emergency management in the built environments: A state-of-the-art review},
journal = {Journal of Safety Science and Resilience},
volume = {2},
number = {1},
pages = {1-10},
year = {2021},
issn = {2666-4496},
doi = {https://doi.org/10.1016/j.jnlssr.2020.11.004},
url = {https://www.sciencedirect.com/science/article/pii/S266644962030030X},
author = {Yiqing Zhu and Nan Li},
keywords = {Virtual reality, Augmented reality, Emergency management, Built environment, Literature review},
abstract = {With the rapid technological advancements in recent decades, virtual reality (VR) and augmented reality (AR) technologies have been increasingly adopted to address various challenges in emergency management in the built environments. This paper presents a review of state-of-the-art applications in this rapidly evolving area. A total of 84 relevant articles are identified based on searching in the Web of Science Core Collection and snowballing. These papers are then organized based on a taxonomy developed in this study. Next, a range of VR/AR applications presented in these papers that are aimed to enhance various processes associated with pre-emergency preparedness, responses during emergency and post-emergency recovery are reviewed in detail. The existing VR/AR applications are also described from a human-computer interaction perspective. Finally, current research trends, knowledge gaps and directions for future research are discussed. The findings presented in this paper are expected to provide a synthetic and critical review of state-of-the-art VR/AR applications for emergency management in the built environment and facilitate further advancements in both research and practice in this area.}
}
@article{ROOPA20213860,
title = {Revolutionizing education system with interactive augmented reality for quality education},
journal = {Materials Today: Proceedings},
volume = {46},
pages = {3860-3863},
year = {2021},
note = {International Conference on Materials, Manufacturing and Mechanical Engineering for Sustainable Developments-2020 (ICMSD 2020)},
issn = {2214-7853},
doi = {https://doi.org/10.1016/j.matpr.2021.02.294},
url = {https://www.sciencedirect.com/science/article/pii/S2214785321013936},
author = {D. Roopa and R. Prabha and G.A. Senthil},
keywords = {Augmented reality, Vuforia, Blender, 60-degree view, Transformative learning, Experimental learning},
abstract = {Augmented reality would soon impact the modern learning cycle in education. AR has the ability to alter research location and timing, adding new and additional forms and methods. Augmented Reality technology’s capabilities will make classes more interactive and knowledgeable. We all are 3D creatures. Our brain is the most powerful 3D computer technology in the world. All of us have evolved to think and store memory in 3-dimensions i.e when we look at the information in a flat piece of paper or computer screen, our brain takes its own time to translate it back to a 2D visual and store it. This is how our education system is, it started with textbook material and recently educators have started encouraging the use of smart classes which again shows videos. As a result, there is no practical exposure that lags us a step behind. This is where a promising technology of the future called Augmented Reality holds for us. Learners will have a 360-degree view of the real-world entities, interacting with those entities by touching them which will eventually make them have better insight about the concepts. Hence our learning curve decreases increasing the brain's productivity. With the development of smartphones, Augmented Reality is applied to a broader range. Augmented reality can turn an ordinary classroom into an engaging experience. The aim is to implement an interactive Augmented Reality Experience using Vuforia, Unity 3D and Blender. The purpose is to promote situational learning, experimental learning, transformative learning as the learning theory basis of mobile Augmented Reality.}
}
@article{BRAUN2022406,
title = {Virtual Reality for Immersive Multi-User Firefighter Training Scenarios},
journal = {Virtual Reality & Intelligent Hardware},
volume = {4},
number = {5},
pages = {406-417},
year = {2022},
issn = {2096-5796},
doi = {https://doi.org/10.1016/j.vrih.2022.08.006},
url = {https://www.sciencedirect.com/science/article/pii/S209657962200081X},
author = {Philipp Braun and Michaela Grafelmann and Felix Gill and Hauke Stolz and Johannes Hinckeldeyn and Ann-Kathrin Lange},
keywords = {Virtual reality, Multi-user, Motion capture, Training, Firefighting},
abstract = {Virtual Reality (VR) applications are tools used to provide comprehensive training scenarios that are difficult or impossible to represent in physical configurations. This includes team training for emergency services, e.g. in firefighting. To achieve effective virtual training, creating a high level of immersion is essential. In that respect, motion capture systems offer the possibility to create highly immersive multi-user training experiences including full-body avatars. This work presents a preliminary prototype that enables the extinguishing of a fire on a container ship as a VR training scenario. The prototype provides a full-body and multi-user VR experience, based on the synthesis of position data provided by the motion capture system and orientation data from the VR headsets. As a consequence, the prototype allows an initial evaluation of results. The results confirm the value of using VR to train procedures that are difficult to train in the real world. Furthermore, the results show that motion capture based VR technologies are particularly useful for firefighting training, in which participants can collaborate in otherwise difficult-to-access environments. However, the work also illustrates that increasing the immersion of such training remains a challenge.}
}
@article{ZHANG2017717,
title = {Head-mounted display-based intuitive virtual reality training system for the mining industry},
journal = {International Journal of Mining Science and Technology},
volume = {27},
number = {4},
pages = {717-722},
year = {2017},
note = {Special Issue on Advances in Mine Safety Science and Engineering},
issn = {2095-2686},
doi = {https://doi.org/10.1016/j.ijmst.2017.05.005},
url = {https://www.sciencedirect.com/science/article/pii/S2095268617303439},
author = {Hui Zhang},
keywords = {Virtual reality, Training, Head-mounted display, High immersive, Intuitive, Mining industry},
abstract = {Virtual reality (VR) training technology in the mining industry is a new field of research and utilization. The successful application of VR training system is critical to mine safety and production. Through the statistics of the current research and applications of VR training systems in mining industry, all the input/output devices are classified. Based on the classifications of the input/output devices that are used in the VR system, the current VR training systems for the mining industry could be divided into three types: screen-based general type, projector-based customized type, and head-mounted display (HMD)-based intuitive type. By employing a VR headset, a smartphone and a leap motion device, an HMD-based intuitive type VR training system prototype for drilling in underground mines has been developed. Ten trainees tried both the HMD-based intuitive system and the screen-based general control system to compare the experiences and training effects. The results show that the HMD-based system can give a much better user experience and is easy to use. Three of the five components of a VR training system, namely, the user, the tasks, and software and database should be given more attention in future research. With more available technologies of input and output devices, VR engines, and system software, the VR training system will eventually yield much better training results, and will play a more important role in as a training tool for mine safety.}
}
@article{2023A3,
title = {Research Forum Educational Program 2023},
journal = {Annals of Emergency Medicine},
volume = {82},
number = {4, Supplement },
pages = {A3-A19},
year = {2023},
issn = {0196-0644},
doi = {https://doi.org/10.1016/S0196-0644(23)01219-2},
url = {https://www.sciencedirect.com/science/article/pii/S0196064423012192}
}
@article{KOSTAVELIS201586,
title = {Semantic mapping for mobile robotics tasks: A survey},
journal = {Robotics and Autonomous Systems},
volume = {66},
pages = {86-103},
year = {2015},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2014.12.006},
url = {https://www.sciencedirect.com/science/article/pii/S0921889014003030},
author = {Ioannis Kostavelis and Antonios Gasteratos},
keywords = {Mobile robots, Semantic map, Topological map, Temporal coherence, Object recognition, Place recognition, Human–robot interaction, Knowledge representation, Planning},
abstract = {The evolution of contemporary mobile robotics has given thrust to a series of additional conjunct technologies. Of such is the semantic mapping, which provides an abstraction of space and a means for human–robot communication. The recent introduction and evolution of semantic mapping motivated this survey, in which an explicit analysis of the existing methods is sought. The several algorithms are categorized according to their primary characteristics, namely scalability, inference model, temporal coherence and topological map usage. The applications involving semantic maps are also outlined in the work at hand, emphasizing on human interaction, knowledge representation and planning. The existence of publicly available validation datasets and benchmarking, suitable for the evaluation of semantic mapping techniques is also discussed in detail. Last, an attempt to address open issues and questions is also made.}
}
@article{KIM2023301608,
title = {Digital forensic approaches for metaverse ecosystems},
journal = {Forensic Science International: Digital Investigation},
volume = {46},
pages = {301608},
year = {2023},
issn = {2666-2817},
doi = {https://doi.org/10.1016/j.fsidi.2023.301608},
url = {https://www.sciencedirect.com/science/article/pii/S2666281723001208},
author = {Donghyun Kim and Subin Oh and Taeshik Shon},
keywords = {Digital Forensics, Metaverse, Augmented Reality (AR), Virtual Reality (VR), Ecosystem, Meta, Meta Quest},
abstract = {The accelerating pace of digital transformation has given rise to metaverses that can participate freely in contactless environments. More than just game content, metaverses are driving everyday innovation across industries. However, threats are also prevalent, with crimes such as child sexual exploitation and privacy violations occurring in metaverses that mimic reality, making digital forensics for metaverse threats essential. Nevertheless, technical standards for different types of metaverses have yet to be defined, making investigation difficult. Furthermore, even though metaverses are complex forms that combine multiple hardware devices and software applications, existing studies have either focused on a single component or not analyzed the real-world environment. In this study, we derived a metaverse ecosystem with common components that comprise a metaverse and analyzed the hardware and software used throughout the user's metaverse lifecycle from a digital forensics perspective. In particular, we applied real-case-based scenario to the metaverse environment of the most popular Meta's currently in use to identify various artifacts that can be used across the ecosystem and validate the effectiveness of the process. We also developed a metaverse digital forensics tool for the first time in the current situation where open-source and commercial tools do not support metaverse investigations.}
}
@article{ALTAN2022103022,
title = {Developing serious games for CBRN-e training in mixed reality, virtual reality, and computer-based environments},
journal = {International Journal of Disaster Risk Reduction},
volume = {77},
pages = {103022},
year = {2022},
issn = {2212-4209},
doi = {https://doi.org/10.1016/j.ijdrr.2022.103022},
url = {https://www.sciencedirect.com/science/article/pii/S2212420922002412},
author = {Burak Altan and Servet Gürer and Ali Alsamarei and Damla Kıvılcım Demir and H. Şebnem Düzgün and Mustafa Erkayaoğlu and Elif Surer},
keywords = {Serious games, Training, Virtual reality, Mixed reality, CBRN-e, Mining},
abstract = {In the last decade, chemical, biological, radioactive, nuclear, and explosive (CBRN-e) attacks have become severe risks to countries, prompting connected parties to prioritize CBRN-e training. CBRN-e training is typically performed as physical exercises, and although such training is necessary and beneficial, repeating the same training program can be time-consuming and costly. In this study, newly developed versions of two previous serious games—Hospital and Biogarden— and a new mining serious game were developed for training purposes in Virtual Reality (VR), Mixed Reality (MR), and personal computer (PC) environments. The Hospital and Biogarden games’ scenarios were based on the joint activities held in 2018 in France and Belgium as part of the EU H2020 European Network Of CBRN Training CEnters (eNOTICE) project, while the mining game was created over a replica of a training mine at a university in Turkey. Sixteen CBRN-e experts from the eNOTICE project, who took part in the physical training programs in France and Belgium, evaluated the games. For evaluation and extensive feedback, presence, system usability scale, technology acceptance model questionnaires, and open-ended questions were conducted. The findings revealed that serious games have a vast potential in CBRN-e training, and the comparisons of different environments provided invaluable testbeds giving hindsight to develop a future training program.}
}
@article{BRUNZINI2023100505,
title = {Human-centred data-driven redesign of simulation-based training: a qualitative study applied on two use cases of the healthcare and industrial domains},
journal = {Journal of Industrial Information Integration},
volume = {35},
pages = {100505},
year = {2023},
issn = {2452-414X},
doi = {https://doi.org/10.1016/j.jii.2023.100505},
url = {https://www.sciencedirect.com/science/article/pii/S2452414X2300078X},
author = {Agnese BRUNZINI and Margherita PERUZZINI and Pamela BARBADORO},
keywords = { Healthcare 4.0, Industry 4.0, Simulation-based training, Design optimization, Human Factors, Ergonomics},
abstract = {Among the main features of Industry 4.0, digitization and the evolution of the human-machine interaction occupy a central role. These concepts are transferring even in the health domain, moving toward Healthcare 4.0. The new concept of Industry 5.0 further promotes the human-centric perspective focusing on the consideration of human factors. In this context, training for workers, both in the industry and in the healthcare sectors, needs to be strongly human-centred to be efficient and effective. This paper refers to simulation-based training and aims to provide a transdisciplinary framework for the simulation assessment from the learners’ perspective. The final scope is to outline a set of data-driven guidelines for the simulation optimization and redesign, throughout a human-centred approach, aiming to improve the workers’ performance and the overall learning process, considering the physical, cognitive, and emotional conditions. The proposed method is suitable for each kind of training (both traditional and with the use of virtual reality/augmented reality systems) and relevant for every sector. Two different use cases are presented, respectively referring to the healthcare and industry fields, proposing a unique assessment protocol. The healthcare use case considered the low-fidelity simulation of lumbar puncture, while the industrial use case referred to the replacement of the engine oil filter on tractors. Although the great differences between the content of the use cases, the results obtained about performance as well as cognitive and emotional states are close enough to define a common set of guidelines to redesign and optimize the simulation-based training.}
}
@article{MORELOT2021104145,
title = {Virtual reality for fire safety training: Influence of immersion and sense of presence on conceptual and procedural acquisition},
journal = {Computers & Education},
volume = {166},
pages = {104145},
year = {2021},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2021.104145},
url = {https://www.sciencedirect.com/science/article/pii/S0360131521000221},
author = {Sarah Morélot and Alain Garrigou and Julie Dedieu and Bernard N'Kaoua},
keywords = {Augmented and virtual reality, Human-computer interface, Media in education, Pedagogical issues},
abstract = {A fire can have serious economic and human consequences. However, in many cases, rapid intervention and appropriate behavior can significantly reduce this threat. For this it is important that people are properly trained. Faced with the economic, ecological and organizational requirements and constraints linked to fire safety training, virtual training environments appear to be a judicious alternative to traditional training. However, before committing companies to invest in expensive devices, it is necessary to ensure the effectiveness of such devices. The literature is rich and divided on this subject, and it appears that certain characteristics of the system and of the learners are decisive. In this context, the objective of our work was to study the effects of immersion, the feeling of presence as well as the interaction between these 2 factors on the performance of conceptual and procedural learning. Certain variables were also controlled such as gender, tendency to immersion, previous experience in computers and video games. Our work shows that immersion promotes procedural but not conceptual learning, and that neither the sense of presence, nor the interaction between immersion and the sense of presence affect these two types of learning in our training task. Apart from the knowledge of fire which potentiates the effect of immersion on procedural learning, the variables considered in our study (computer experience, video game experience and genre) had no impact on performance. Understanding the impact of the technical device or the characteristics of users on conceptual and procedural learning is a major challenge in helping trainers to develop pedagogical devices in order to better exploit the opportunities offered by new technological approaches.}
}
@article{DRIEWER2007113,
title = {DESIGN AND EVALUATION OF A TELEOPERATION INTERFACE FOR HETEROGENEOUS HUMAN-ROBOT TEAMS},
journal = {IFAC Proceedings Volumes},
volume = {40},
number = {16},
pages = {113-118},
year = {2007},
note = {10th IFAC,IFIP,IFORS,IEA Symposium on Analysis, Design, and Evaluation of Human-Machine Systems},
issn = {1474-6670},
doi = {https://doi.org/10.3182/20070904-3-KR-2922.00020},
url = {https://www.sciencedirect.com/science/article/pii/S1474667015327695},
author = {Frauke Driewer and Markus Sauer and Klaus Schilling},
keywords = {robotics, mobile robots, teleoperation, human-machine interface, supervisory control, virtual reality, telematics},
abstract = {Mobile robots can significantly support human teams in dangerous environments in order to reduce risks. Joint teams of humans and robots take advantage of complementary capabilities in navigation, search and planning. Remote coordination of such teams needs efficient teleoperation interfaces. Mixed reality approaches for remote coordination for human-robot teams are investigated. Evaluation results are presented from first experiments.}
}
@article{SYAMIMI2020409,
title = {VR industrial applications―A singapore perspective},
journal = {Virtual Reality & Intelligent Hardware},
volume = {2},
number = {5},
pages = {409-420},
year = {2020},
issn = {2096-5796},
doi = {https://doi.org/10.1016/j.vrih.2020.06.001},
url = {https://www.sciencedirect.com/science/article/pii/S209657962030070X},
author = {Athirah Syamimi and Yiwei Gong and Ryan Liew},
keywords = {Virtual reality, VR applications, Building information modeling},
abstract = {Virtual Reality (VR) has been around for a long time but has come into the spotlight only recently. From an industrial perspective, this article serves as a proverbial scalpel to dissect the different use cases and commercial applications of VR in Singapore. Before researching the Singapore market, we examine how VR has evolved. At the moment, the global annual budget for VR (and augmented reality) is at an upward trend with a leading growth in market value for the training sector. VR in Singapore has also seen a rapid development in recent years. We discuss some of the Singapore government's initiatives to promote the commercial adoption of VR for the digital economy of the nation. To address the mass adoption of VR, we present VRcollab's business solutions for the construction and building industry. 2020 is one of the most important years for VR in history.}
}
@article{CHNG2009458,
title = {Experiential archaeology: Is virtual time travel possible?},
journal = {Journal of Cultural Heritage},
volume = {10},
number = {4},
pages = {458-470},
year = {2009},
issn = {1296-2074},
doi = {https://doi.org/10.1016/j.culher.2009.02.001},
url = {https://www.sciencedirect.com/science/article/pii/S1296207409000831},
author = {Eugene Ch’ng},
keywords = {Virtual Time Travel, Experiential Archaeology, Virtual Reality, Mixed Reality, Artificial Life, Artificial Intelligence, Presence},
abstract = {Advances in computing hardware coupled with its software counterparts have, for the past decades, influenced to a greater extent both the workflow of archaeologists and their interpretation of archaeological data. On the leisurely periphery, the synergy that arises between entertainment demands and commercial driven developments of interactive 3D (i3D) computer games has pushed these technologies beyond the expectations of the Virtual Reality (VR) community. This phenomenal growth in useable technology and its proportionate decrease in price have benefited the applicability of VR which in turn, have made it more accessible for researchers wishing to harness its benefits. The last 10 years have seen a steady increase in the use of VR technology to restore, preserve, reconstruct, recreate, and visualise ancient sites, monuments and artefacts. But, is technology ready for virtual time travel (VTT)? This article examines the possibility of experiential archaeology in voltage and silicon with the aim of formulating a strategy for VTT.}
}
@article{BELLALOUNA2021400,
title = {The Augmented Reality Technology as Enabler for the Digitization of Industrial Business Processes: Case Studies},
journal = {Procedia CIRP},
volume = {98},
pages = {400-405},
year = {2021},
note = {The 28th CIRP Conference on Life Cycle Engineering, March 10 – 12, 2021, Jaipur, India},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2021.01.124},
url = {https://www.sciencedirect.com/science/article/pii/S2212827121001542},
author = {Fahmi Bellalouna},
keywords = {Augmented Reality (AR), Product Configuration Management, Production Planning, Assembly Assistance, Idustrial Digitization},
abstract = {Augmented Reality Technology Augmented Reality Technology (AR) is one of the key technologies of digital transformation in industrial and non-industrial areas. Due to the rapid development of display hardware and tracking systems, virtual and augmented reality applications are being developed today that would only have been possible in large research laboratories with huge efforts a few years ago. This paper presents the application of the augmented reality technology in the industrial field. Based on industrial case studies the implementation of two AR applications and their potential to digitize the product lifecycle processes will be discussed. The case studies were developed within cooperation projects between the University of Applied Sciences Karlsruhe and a fire truck manufacturer with the focus on the following topics: product configuration management and assembly assistance. The objective of this work is the investigation of the AR application in the industrial environment and its capability as digital transformation technology along the product lifecycle. The presented paper delivers experiences and suggestions in terms of praxis-oriented development and deployment of the AR technology in the engineering field, which can be used for future AR research works.}
}
@article{HSIAO2023105913,
title = {Real-time fire protection system architecture for building safety},
journal = {Journal of Building Engineering},
volume = {67},
pages = {105913},
year = {2023},
issn = {2352-7102},
doi = {https://doi.org/10.1016/j.jobe.2023.105913},
url = {https://www.sciencedirect.com/science/article/pii/S235271022300092X},
author = {Chung-Jung Hsiao and Shang-Hsien Hsieh},
keywords = {Prevention level, Building information modeling, Quality management system, Simulated reality},
abstract = {Regardless of the type of disaster a building undergoes, personal safety, property preservation, and attribution of responsibility are the three assessment indicators that summarize the effectiveness of disaster prevention, evacuation, and rescue operations when the area of a building affected by a disaster endangers personal safety. The only possible response under these conditions is for people to immediately leave the dangerous area and escape to a safe and secure area. Therefore, both the timeliness of evacuation and rescue advice directly determine the outcome of the disaster. This study reflects on current fire protection systems and puts forward the approaches of Prevention Level for Deployment in Advance and Spatial Transformation by Human–Machine Collaboration to deal with disasters and promote building safety. A real-time fire protection system architecture for disaster prevention, evacuation, and rescue operations in buildings is proposed and prototyped for a proof of concept. The architecture promotes simulated verification of the effectiveness of disaster prevention, evacuation, and rescue operations at the building planning and design stage.}
}
@article{QADIR2023296,
title = {Towards 6G Internet of Things: Recent advances, use cases, and open challenges},
journal = {ICT Express},
volume = {9},
number = {3},
pages = {296-312},
year = {2023},
issn = {2405-9595},
doi = {https://doi.org/10.1016/j.icte.2022.06.006},
url = {https://www.sciencedirect.com/science/article/pii/S2405959522000959},
author = {Zakria Qadir and Khoa N. Le and Nasir Saeed and Hafiz Suliman Munawar},
keywords = {6G, Wireless communication, Internet of Everything, Smart cities},
abstract = {Smart services based on the Internet of Everything (IoE) are gaining considerable popularity due to the ever-increasing demands of wireless networks. This demands the appraisal of the wireless networks with enhanced properties as next-generation communication systems. Although 5G networks show great potential to support numerous IoE based services, it is not adequate to meet the complete requirements of the new smart applications. Therefore, there is an increased demand for envisioning the 6G wireless communication systems to overcome the major limitations in the existing 5G networks. Moreover, incorporating artificial intelligence in 6G will provide solutions for very complex problems relevant to network optimization. Furthermore, to add further value to the future 6G networks, researchers are investigating new technologies, such as THz and quantum communications. The requirements of future 6G wireless communications demand to support massive data-driven applications and the increasing number of users. Unlike existing works, this paper highlights the recent activities and trends toward 6G technology, network requirement, essential enabling technologies for 6G networks, and a detailed use case analysis between 5G and 6G networks. Moreover, this paper surveys emerging 6G connectivity solutions, such as holographic beamforming, artificial intelligence-enabled IoT networks, edge computing, and backscatter communications to serve smart communities. Furthermore, several future research directions to accomplish 6G-based IoT networks are also highlighted.}
}
@article{HASSAN2020101461,
title = {Gameful civic engagement: A review of the literature on gamification of e-participation},
journal = {Government Information Quarterly},
volume = {37},
number = {3},
pages = {101461},
year = {2020},
issn = {0740-624X},
doi = {https://doi.org/10.1016/j.giq.2020.101461},
url = {https://www.sciencedirect.com/science/article/pii/S0740624X19302606},
author = {Lobna Hassan and Juho Hamari},
keywords = {Gamification, Games, E-participation, Governance, Civic engagement, Policy-making},
abstract = {With increased digitalization, governments and public institutes became potentially better able to practice fuller and wider ranges of democratic governance through e.g., e-participation. E-participation, as any means of engagement with the common good, is, however, a difficult area of human motivation as it can be seen to exist outside the common hurdles of the everyday life and where the effects of participation are often invisible or take a long time to materialize. Recent trends of digitalization, such as gamification; a popular approach for stimulating motivation, have been proposed as remedies to foster e-participation. A plethora of applications and research has emerged related to gamified e-participation. However, there is currently a dearth in our knowledge of how gamification is being applied, researched or what its possible positive and negative outcomes can be. This study employed a systematic literature review approach in order to summarize research and findings on gamified e-participation. 66 papers were reviewed, the majority of which indicated that gamified e-participation is linked to increased engagement, motivation, civic learning and enjoyment amongst other outcomes. Nonetheless, question remains as to ethical and inclusive gamification, for which, this research provides directions for future research.}
}
@article{IQBAL2023100961,
title = {Cognitive D2D communication: A comprehensive survey, research challenges, and future directions},
journal = {Internet of Things},
volume = {24},
pages = {100961},
year = {2023},
issn = {2542-6605},
doi = {https://doi.org/10.1016/j.iot.2023.100961},
url = {https://www.sciencedirect.com/science/article/pii/S2542660523002846},
author = {Adeel Iqbal and Ali Nauman and Riaz Hussain and Muhammad Bilal},
keywords = {Cognitive D2D, Energy efficiency, Spectrum efficiency, Security, QoS, 5G, 6G},
abstract = {The integration of cognitive radio and device-to-device (D2D) communication gives rise to Cognitive D2D (cD2D) communication, which offers numerous advantages, such as improved spectrum and energy efficiency, increased network throughput, and enhanced coverage. Although there are existing survey papers on cognitive networks and D2D communications, the topic of integrated cD2D communication has received limited attention. To bridge this gap in the literature, this paper presents a comprehensive survey of cD2D communication. We commence by introducing cD2D communication and highlighting the key research challenges in this field. Subsequently, we categorize the recent advancements in cD2D communications into eight major types of techniques and provide an in-depth review of the existing literature. Furthermore, we address several significant challenges associated with cD2D communications and discuss future applications that can benefit from this technology. Through our analysis, we aim to contribute to a deeper understanding of cD2D communication and provide insights into its potential for various domains.}
}
@incollection{2023311,
title = {Index},
editor = {Surbhi {Bhatia Khan} and Suyel Namasudra and Swati Chandna and Arwa Mashat and Fatos Xhafa},
booktitle = {Innovations in Artificial Intelligence and Human-Computer Interaction in the Digital Era},
publisher = {Academic Press},
pages = {311-321},
year = {2023},
series = {Intelligent Data-Centric Systems},
isbn = {978-0-323-99891-8},
doi = {https://doi.org/10.1016/B978-0-323-99891-8.20001-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780323998918200016}
}
@article{KIYAK2023107578,
title = {The efficacy of cue exposure therapy on alcohol use disorders: A quantitative meta-analysis and systematic review},
journal = {Addictive Behaviors},
volume = {139},
pages = {107578},
year = {2023},
issn = {0306-4603},
doi = {https://doi.org/10.1016/j.addbeh.2022.107578},
url = {https://www.sciencedirect.com/science/article/pii/S0306460322003446},
author = {Ceyda Kiyak and Matilde E. Simonetti and Sam Norton and Paolo Deluca},
abstract = {Background
Cue exposure therapy (CET) techniques involves repeated and controlled exposures to alcohol stimuli which rest upon the well-established principles of Pavlovian extinction (Byrne et al., 2019). However, the efficacy of CET while treating alcohol use disorders (AUDs) is still a matter of debate. Therefore, we aimed to investigate the efficacy of CET on AUDs by using previous meta-analysis study on the same topic from Mellentin et al. (2017) as a base.
Methods
A computer-assisted search of relevant articles identified 879 studies in Medline, PsycInfo and Embase, of which 11 studies (published between 1992 and 2019) were selected. Three outcome measures were extracted: alcohol consumption defined as drinks per day (drinking intensity) and alcohol reduction defined as drinking days and relapse (drinking frequency). This study is registered with PROSPERO (Registration no: #CRD42021259077).
Results
The present meta-analytical review found small to medium effect on drinks per day (g = -0.35; 95 %CI -0.72 to 0.03), drinking days (g = -0.30; 95 %CI -0.54 to -0.06) and relapse (OR = -0.58; 95 %CI 0.29 to 1.15) while investigating the efficacy of CET on AUDs. GRADE assessment was used to evaluate the overall quality, and it was assessed as low. Regarding Risk of Bias, the studies in this systematic review were evaluated with “some concerns”.
Conclusion
The present meta-analysis demonstrated that CET has small to medium effect on drinks per day, drinking days and relapse. Future research should strive to conduct larger scale multi-site CET trials with additional methodological innovations and increase retention.}
}
@article{MITHOO2023110450,
title = {Social network analysis for crime rate detection using Spizella swarm optimization based BiLSTM classifier},
journal = {Knowledge-Based Systems},
volume = {269},
pages = {110450},
year = {2023},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2023.110450},
url = {https://www.sciencedirect.com/science/article/pii/S0950705123002009},
author = {Pooja Mithoo and Manoj Kumar},
keywords = {BiLSTM, Spizella swarm optimization, Criminal activities, Crime rate, Performance metrics},
abstract = {Technical advancements initiated a rapid increase in criminal activity over time. For the prevention of these criminal activities, preventive measures are needed. In order to monitor these illicit activities and enhance public safety, crime rate detection is essential. Social media can be used to identify crime rates in various parts of any nation, which can dramatically lower crime rates. Social media are a source of information as well as a tool for communication. Twitter, which has a user base of more than 300 million, makes a suitable choice for data analysis. The Spizella swarm based BiLSTM classifier is used for the detection of crime rate in this research. While performing social network analysis using the BiLSTM classifier for the determination of crime rate providing faster convergence is a crucial factor and this faster convergence is achieved by the proposed Spizella swarm optimization. BiLSTM classifier effectively identified the crime rate and the BiLSTM performance is boosted by the Spizella swarm optimization where the escaping characteristics of Spizella improve the convergence and help in attaining desired results Additional training is given by the BiLSTM classifier by traversing the outputs and this BiLSTM classifier are more efficient in the text classification. Measuring the metrics values for accuracy, sensitivity, and specificity demonstrates the effectiveness of the proposed method and the proposed Spizella swarm optimization achieved an improvement of 0.5 %, 1.16 %, and 1.08 %, which is more efficient.}
}
@article{ATTARAN2023100165,
title = {Digital Twin: Benefits, use cases, challenges, and opportunities},
journal = {Decision Analytics Journal},
volume = {6},
pages = {100165},
year = {2023},
issn = {2772-6622},
doi = {https://doi.org/10.1016/j.dajour.2023.100165},
url = {https://www.sciencedirect.com/science/article/pii/S277266222300005X},
author = {Mohsen Attaran and Bilge Gokhan Celik},
keywords = {Digital Twins, Digital Twin Technologies, Digital Twin Drivers, Healthcare and Life Sciences, Automotive and Aerospace Industry, Construction and Real Estate},
abstract = {Applications of Digital Twin technology have been growing at an exponential rate, and it is transforming the way businesses operate. In the past few years, Digital Twins leveraged vital business applications, and it is predicted that the technology will expand to more applications, use cases, and industries. The purpose of this paper is to do a literature review and explore how Digital Twins streamline intelligent automation in different industries. This paper defines the concept, highlights the evolution and development of Digital Twins, reviews its key enabling technologies, examines its trends and challenges, and explores its applications in different industries.}
}
@article{DELORENZIS2023103785,
title = {Immersive Virtual Reality for procedural training: Comparing traditional and learning by teaching approaches},
journal = {Computers in Industry},
volume = {144},
pages = {103785},
year = {2023},
issn = {0166-3615},
doi = {https://doi.org/10.1016/j.compind.2022.103785},
url = {https://www.sciencedirect.com/science/article/pii/S0166361522001816},
author = {Federico {De Lorenzis} and Filippo Gabriele Pratticò and Maurizio Repetto and Enrico Pons and Fabrizio Lamberti},
keywords = {Virtual reality, Learning by teaching, Procedural training},
abstract = {Virtual Reality (VR) has been widely adopted for the creation of training experiences, since it appears to allow overcoming, especially for practical training, some of the limitations of real exercises. Many previous works focused on investigating the effectiveness of VR Training Systems (VRTS) in a variety of fields, but the efficacy of these systems is very task-dependent, and the best way to integrate them into existing learning paths has yet to be thoroughly investigated. The goal of the present paper is to explore the latter aspects considering a case study in the context of energy management in industry, and focusing on a measuring procedure that is part, e.g., of energy audit inspections. To this aim, a VRTS was developed and used to conduct two user studies: a first study designed to investigate the effectiveness of the devised system when used as an alternative or in combination with lecture and laboratory-based teaching experiences, and a second study aimed to compare two different approaches (traditional learning, TL, and learning by teaching, LBT) for exploiting the provided VR-based functionalities in a learning path. Experimental results showed that the use of the VRTS alone improved the participants’ performance compared to traditional experiences, and that LBT proved to be more effective that TL for practical learning purposes.}
}
@article{STEFANOU2022102729,
title = {Training and exercises for Critical Infrastructure – A Hellenic computer-assisted exercise use case analysis},
journal = {International Journal of Disaster Risk Reduction},
volume = {69},
pages = {102729},
year = {2022},
issn = {2212-4209},
doi = {https://doi.org/10.1016/j.ijdrr.2021.102729},
url = {https://www.sciencedirect.com/science/article/pii/S2212420921006907},
author = {N. Stefanou and D. {Kazantzidou – Firtinidou} and G. Sakkas and G. Theodoridis and V. Rousakis},
keywords = {Critical infrastructures, Exercises, Training, Computer assisted exercises, IT tools},
abstract = {This paper aims to highlight the importance of emerging tools and technologies in the exercises and training of Critical Infrastructure (CI) operators. Computer-assisted exercises (CAX) may offer multiple advantages in designing and conducting exercises (e.g. cost-effectiveness, distance/remote learning), yet, customized platforms need to be designed and employed to meet the particular needs of CI protection. In this context, the paper analyses training and exercises of the Hellenic program for Critical Infrastructure Protection (CIP). A brief description of the current framework for the protection of CI in Greece encompassing the European directive is also presented. A CAX use case analysis is described with the pioneer implementation of the Joint Research Centre (JRC - E.2 Unit), Platform-based Operational System Events and Injects Distribution Online (POSEIDON) web-based IT platform, that was customised for the needs of the exercise under the code name EYZS-3, focusing on the transportation sector. Advanced training approaches, such as EYZS-3, seem to gain ground, as opposed to typical discussion-based exercises (tabletop), indicating valuable findings for future exploitation for planning training and exercises in CI protection.}
}
@article{BROOKFIELD2021103427,
title = {“It Just Kind of Cascades”: A critical ethnography of methamphetamine-related pleasure among people in recovery},
journal = {International Journal of Drug Policy},
volume = {98},
pages = {103427},
year = {2021},
issn = {0955-3959},
doi = {https://doi.org/10.1016/j.drugpo.2021.103427},
url = {https://www.sciencedirect.com/science/article/pii/S0955395921003327},
author = {Samuel J Brookfield and Linda Selvey and Lisa Maher and Lisa Fitzgerald},
keywords = {Methamphetamine, Ethnography, Recovery, Pleasure, Critical},
abstract = {Background
Despite its well documented risks and harms, methamphetamine use can also be experienced as a pleasurable, purposeful, and productive activity. Drug use discourse has historically deemphasised the pleasures of drug use, as they can contradict the expectations of neoliberalism that individuals be moderate, rational consumers. The purpose of this study was to explore the experiences of people trying to reduce or control their methamphetamine use, utilising a critical interactionist approach to excavate the subjugated knowledge of methamphetamine-related pleasure, and construct an understanding of methamphetamine use that incorporated these positive experiences.
Methods
Qualitative interviews and ethnographic observation were conducted over an eight-month period with a group of twelve people using methamphetamine and accessing recovery services. Transcripts and fieldnotes were analysed thematically with a critical interactionist lens.
Results
The pleasures of methamphetamine use were differentiated into pursuing the rush, exploring sociality, self-medication, and desiring productivity. The interwoven nature of these themes presents a multidimensional understanding of methamphetamine use resulting from a cascade of interacting causes and effects, rather than a linear product of individual choice or structural forces. These findings also highlight the complex symbiotic relationship between pleasure, productivity, and risk for people using methamphetamine which can be traced to the broader cultural and economic context in which use occurs.
Conclusion
Interventions and policies responding to harmful methamphetamine use must address the content and nature of the methamphetamine use cascade, acknowledging the diverse needs methamphetamine can meet for contemporary neoliberal citizens, and the sometimes complex and sophisticated purposes for which people may utilise its effects.}
}
@article{BAKHTIARI2023104958,
title = {A critical review for the application of cutting-edge digital visualisation technologies for effective urban flood risk management},
journal = {Sustainable Cities and Society},
volume = {99},
pages = {104958},
year = {2023},
issn = {2210-6707},
doi = {https://doi.org/10.1016/j.scs.2023.104958},
url = {https://www.sciencedirect.com/science/article/pii/S2210670723005693},
author = {Vahid Bakhtiari and Farzad Piadeh and Kourosh Behzadian and Zoran Kapelan},
keywords = {Augmented reality, Digital twin, Digital visualisation, Flood risk management, Systematic review, Virtual reality},
abstract = {Cutting-edge digital visualisation tools (CDVT) are playing an increasingly important role in improving urban flood risk management. However, there is a paucity of comprehensive research examining their role across all stages of urban flood risk management. To address, this study conducts an integrated critical review to identify the application of CDVT and assess their contribution to the prevention, mitigation, preparation, response, and recovery stages of flood risk management. The results show that virtual reality, augmented reality, and digital twin technologies are the primary CDVT used in urban flood visualisation, with virtual reality being the most frequently used. The focus of urban flood visualisation studies has been primarily on preparation and mitigation stages. However, there is a need to investigate the application of these technologies in the entire urban water cycle. Furthermore, there is potential for greater adoption of digital twin, especially in simulating urban flood inundation and flood evacuation routes. Integrating real-time data, data-driven modeling, and CDVT can significantly improve real-time flood forecasting. This benefits stakeholders and the public by enhancing early warning systems, preparedness, and flood resilience, leading to more effective flood risk management and reduced impacts on communities.}
}
@article{MITCHELL2022100146,
title = {A review: Challenges and opportunities for artificial intelligence and robotics in the offshore wind sector},
journal = {Energy and AI},
volume = {8},
pages = {100146},
year = {2022},
issn = {2666-5468},
doi = {https://doi.org/10.1016/j.egyai.2022.100146},
url = {https://www.sciencedirect.com/science/article/pii/S2666546822000088},
author = {Daniel Mitchell and Jamie Blanche and Sam Harper and Theodore Lim and Ranjeetkumar Gupta and Osama Zaki and Wenshuo Tang and Valentin Robu and Simon Watson and David Flynn},
keywords = {Artificial intelligence, Autonomous systems, Digitalization, Offshore renewable energy, Offshore wind farms, Robotics},
abstract = {The UK has set plans to increase offshore wind capacity from 22GW to 154GW by 2030. With such tremendous growth, the sector is now looking to Robotics and Artificial Intelligence (RAI) in order to tackle lifecycle service barriers as to support sustainable and profitable offshore wind energy production. Today, RAI applications are predominately being used to support short term objectives in operation and maintenance. However, moving forward, RAI has the potential to play a critical role throughout the full lifecycle of offshore wind infrastructure, from surveying, planning, design, logistics, operational support, training and decommissioning. This paper presents one of the first systematic reviews of RAI for the offshore renewable energy sector. The state-of-the-art in RAI is analyzed with respect to offshore energy requirements, from both industry and academia, in terms of current and future requirements. Our review also includes a detailed evaluation of investment, regulation and skills development required to support the adoption of RAI. The key trends identified through a detailed analysis of patent and academic publication databases provide insights to barriers such as certification of autonomous platforms for safety compliance and reliability, the need for digital architectures for scalability in autonomous fleets, adaptive mission planning for resilient resident operations and optimization of human machine interaction for trusted partnerships between people and autonomous assistants. Our study concludes with identification of technological priorities and outlines their integration into a new ‘symbiotic digital architecture’ to deliver the future of offshore wind farm lifecycle management.}
}
@article{STRANGMAN201945,
title = {Deep-space applications for point-of-care technologies},
journal = {Current Opinion in Biomedical Engineering},
volume = {11},
pages = {45-50},
year = {2019},
note = {Biomechanics and Mechanobiology: multiscale modeling ●Novel Biomedical Technologies: Medical devices > point of care (LMIC)},
issn = {2468-4511},
doi = {https://doi.org/10.1016/j.cobme.2019.08.014},
url = {https://www.sciencedirect.com/science/article/pii/S2468451119300340},
author = {Gary E. Strangman and Aenor Sawyer and Kristin M. Fabre and Emmanuel Urquieta and James Hury and Jimmy Wu and Andrew Peterman and Jeff Hoffman and Dorit Donoviel},
keywords = {Space medicine, Spaceflight medical risks, Biomedical engineering, Technology development, Machine learning},
abstract = {Deep-space missions — such as a crewed voyage to Mars — will require a comprehensive medical care system to treat and maintain astronaut health. This system must address many of the same medical conditions that occur on Earth, as well as several that are unique to spaceflight environments. Hardware constraints are numerous, including mass, volume, usability by nonspecialists, and minimal need for consumable supplies, all of which are also relevant to medical care in remote-, ambulatory-, or home-care settings on Earth. This review describes the expected medical needs on deep-space missions, outlines the current state of the art of onboard medical capabilities, and highlights approaches and technologies that will likely be necessary to achieve autonomous health care for astronauts.}
}
@article{WANG2020119852,
title = {Safety informatics as a new, promising and sustainable area of safety science in the information age},
journal = {Journal of Cleaner Production},
volume = {252},
pages = {119852},
year = {2020},
issn = {0959-6526},
doi = {https://doi.org/10.1016/j.jclepro.2019.119852},
url = {https://www.sciencedirect.com/science/article/pii/S0959652619347225},
author = {Bing Wang and Chao Wu},
keywords = {Safety science, Information science, Safety information, Safety informatics, Safety 4.0},
abstract = {Safety is a central dimension in contemporary debates on human health, loss prevention, environmental protection, sustainability, and cleaner production. In the information age, especially in the era of big data, safety information is an essential strategy for safety, and safety informatics has become a major research interest and a popular issue in the field of safety science. In recent years, safety informatics—a new area of safety science—has received increasing attention, developing greatly with successful research on the subject. The three key purposes of this paper are: (i) to analyze the historical development of safety informatics, (ii) to review the research progress of safety informatics, and (iii) to review limitations and propose future directions in the field of safety informatics. First, the development process of safety informatics is divided into four typical stages: (i) the embryonic stage (1940–1980), (ii) the initial stage (1980–1990), (iii) the formation stage (1990–2010), and (iv) the deepening stage (2010–present). Then, a review of safety informatics research is provided from seven aspects, including: (i) the discipline construction of safety informatics, (ii) theoretical safety information model, (iii) accident causation model from a safety information perspective, (iv) safety management based on safety information, (v) safety big data, (vi) safety intelligence, and (vii) safety information technology. Finally, limitations and future research directions in the safety informatics area are briefly discussed.}
}
@article{ULLAH2021101527,
title = {Barriers to the digitalisation and innovation of Australian Smart Real Estate: A managerial perspective on the technology non-adoption},
journal = {Environmental Technology & Innovation},
volume = {22},
pages = {101527},
year = {2021},
issn = {2352-1864},
doi = {https://doi.org/10.1016/j.eti.2021.101527},
url = {https://www.sciencedirect.com/science/article/pii/S2352186421001759},
author = {Fahim Ullah and Samad M.E. Sepasgozar and Muhammad Jamaluddin Thaheem and Fadi Al-Turjman},
keywords = {Technology adoption barriers, Innovation, Non-adoption, Smart real estate, Disruptive digital technologies (DDTs), Managerial perspective},
abstract = {The real estate sector brings a fortune to the global economy. But, presently, this sector is regressive and uses traditional methods and approaches. Therefore, it needs a technological transformation and innovation in line with the Industry 4.0 requirements to transform into smart real estate. However, it faces the barriers of disruptive digital technology (DDT) adoption and innovation that need effective management to enable such transformation. These barriers present managerial challenges that affect DDT adoption and innovation in smart real estate. The current study assesses these DDTs adoption and innovation barriers facing the Australian real estate sector from a managerial perspective. Based on a comprehensive review of 72 systematically retrieved and shortlisted articles, we identify 21 key barriers to digitalisation and innovation. The barriers are grouped into the technology-organisation-external environment (TOE) categories using a Fault tree. Data is collected from 102 real estate and property managers to rate and rank the identified barriers. The results show that most of the respondents are aware of the DDTs and reported AI (22.5% of respondents), big data (12.75%) and VR (12.75%) as the most critical technologies not adopted so far due to costs, organisation policies, awareness, reluctance, user demand, tech integration, government support and funding. Overall, the highest barrier (risk) scores are observed for high costs of software and hardware (T1), high complexity of the selected technology dissemination system (T2) and lack of government incentives, R&D support, policies, regulations and standards (E1). Among the TOE categories, as evident from the fault tree analysis, the highest percentage of failure to adopt the DDT is attributed to E1 in the environmental group. For the technological group, the highest failure reason is attributed to T2. And for the organisational group, the barrier with the highest failure chances for DDT adoption is the lack of organisational willingness to invest in digital marketing (O4). These barriers must be addressed to pave the way for DDT adoption and innovation in the Australian real estate sector and move towards smart real estate.}
}
@article{CAO20208,
title = {Examining the use of narrative constructs in data videos},
journal = {Visual Informatics},
volume = {4},
number = {1},
pages = {8-22},
year = {2020},
issn = {2468-502X},
doi = {https://doi.org/10.1016/j.visinf.2019.12.002},
url = {https://www.sciencedirect.com/science/article/pii/S2468502X1930066X},
author = {Ruochen Cao and Subrata Dey and Andrew Cunningham and James Walsh and Ross T. Smith and Joanne E. Zucco and Bruce H. Thomas},
keywords = {Narrative visualization, Data videos, Taxonomy, Narrative approaches},
abstract = {Data videos are a highly impactful method of communication and are becoming a prevalent medium for communicating information. While the majority of current research focuses on the cinematic aspects of data videos, very little is known about the narrative methodologies involved. This paper presents our insights derived from an initial exploration of this area. We present a taxonomy based on the analysis of 70 existing data videos examining their narrative and visual approaches. We propose that our taxonomy can be used to explain the characteristics or design of data videos. Applying this taxonomy, we present our observations, including the trend of popular technologies applied in current data videos, the under-utilization of promising methods, and highlight research opportunities in the field.}
}
@article{BAILONRUIZ2022104071,
title = {Real-time wildfire monitoring with a fleet of UAVs},
journal = {Robotics and Autonomous Systems},
volume = {152},
pages = {104071},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2022.104071},
url = {https://www.sciencedirect.com/science/article/pii/S0921889022000355},
author = {Rafael Bailon-Ruiz and Arthur Bit-Monnot and Simon Lacroix},
keywords = {UAV, Remote sensing, Wildfire monitoring, Multi-robot planning},
abstract = {This paper introduces a wildfire monitoring system based on a fleet of Unmanned Aerial Vehicles (UAVs) to provide firefighters with precise and up-to-date information about a propagating wildfire, so that they can devise efficient suppression actions. We present an approach to plan trajectories for a fleet of fixed-wing UAVs to observe a wildfire evolving over time by tailoring the Variable Neighborhood Search metaheuristic to the problem characteristics. Realistic models of the terrain, of the fire propagation process, and of the UAVs are exploited, together with a model of the wind, to predict wildfire spread and plan accordingly the UAVs motions. Algorithms and models are integrated within a software architecture allowing tests with real and simulated UAVs flying over synthetic wildfires. Results of a mixed-reality test campaign show the ability of the proposed system to effectively map wildfire propagation.}
}
@article{MILLERRUSHING2021109038,
title = {COVID-19 pandemic impacts on conservation research, management, and public engagement in US national parks},
journal = {Biological Conservation},
volume = {257},
pages = {109038},
year = {2021},
issn = {0006-3207},
doi = {https://doi.org/10.1016/j.biocon.2021.109038},
url = {https://www.sciencedirect.com/science/article/pii/S0006320721000902},
author = {Abraham J. Miller-Rushing and Nicole Athearn and Tami Blackford and Christy Brigham and Laura Cohen and Rebecca Cole-Will and Todd Edgar and Elizabeth R. Ellwood and Nicholas Fisichelli and Colleen Flanagan Pritz and Amanda S. Gallinat and Adam Gibson and Andy Hubbard and Sierra McLane and Koren Nydick and Richard B. Primack and Susan Sachs and Paul E. Super},
keywords = {Early-career, Informal education, Protected areas, Remote engagement, US National Park Service, Visitation, Wildlife},
abstract = {The COVID-19 pandemic has disrupted the timing and substance of conservation research, management, and public engagement in protected areas around the world. This disruption is evident in US national parks, which play a key role in protecting natural and cultural resources and providing outdoor experiences for the public. Collectively, US national parks protect 34 million ha, host more than 300 million visits annually, and serve as one of the world's largest informal education organizations. The pandemic has altered park conditions and operations in a variety of ways. Shifts in operational conditions related to safety issues, reduced staffing, and decreased park revenues have forced managers to make difficult trade-offs among competing priorities. Long-term research and monitoring of the health of ecosystems and wildlife populations have been interrupted. Time-sensitive management practices, such as control of invasive plants and restoration of degraded habitat, have been delayed. And public engagement has largely shifted from in-person experiences to virtual engagement through social media and other online interactions. These changes pose challenges for accomplishing important science, management, and public engagement goals, but they also create opportunities for developing more flexible monitoring programs and inclusive methods of public engagement. The COVID-19 pandemic reinforces the need for strategic science, management planning, flexible operations, and online public engagement to help managers address rapid and unpredictable challenges.}
}
@article{MUNSINGER2023103368,
title = {Virtual reality for improving cyber situational awareness in security operations centers},
journal = {Computers & Security},
volume = {132},
pages = {103368},
year = {2023},
issn = {0167-4048},
doi = {https://doi.org/10.1016/j.cose.2023.103368},
url = {https://www.sciencedirect.com/science/article/pii/S016740482300278X},
author = {Brita Munsinger and Nicole Beebe and Turquoise Richardson},
keywords = {Cyber situational awareness, Virtual reality, Security operations centers, Network monitoring},
abstract = {Security operations centers (SOCs) are the 911 centers of many organizational networks, except they not only respond, but also monitor. SOC operators are charged with detection, response, and mitigation. This is a tall task when one considers the volume, velocity, and variety of both internal and external organizational network and system data. SOC operations are truly a big data problem. Security orchestration, incident event management, data fusion, and anomaly detection systems help, but more is needed. This study examines the impact virtual reality (VR) can have on SOC operator performance and perceived task load. We developed a VR based network monitoring tool and assigned human subjects to one of three conditions – VR only, traditional tool only, or both. Our results, though small in scale, provide very promising indication that VR based technology may be beneficial for improving cyber situational awareness (SA), particularly with overall data perception involving novice SOC operators. The results are promising, but the sample size is small, so future research should validate this pilot study. Given the workforce challenges in the cybersecurity space, and the need to perceive large quantities of data, VR may be a very good addition to SOCs.}
}
@article{QAMAR2023103127,
title = {A systematic threat analysis and defense strategies for the metaverse and extended reality systems},
journal = {Computers & Security},
volume = {128},
pages = {103127},
year = {2023},
issn = {0167-4048},
doi = {https://doi.org/10.1016/j.cose.2023.103127},
url = {https://www.sciencedirect.com/science/article/pii/S0167404823000378},
author = {Sara Qamar and Zahid Anwar and Mehreen Afzal},
keywords = {Extended reality (XR), Metaverse, Cyber defense, Privacy, Cyber threats, Cyberstalking, Physical safety, XR commerce, Virtual reality, Augmented reality, Mixed reality, Blockchain, Cybersickness, Currency scams},
abstract = {With the rapid development and evolution of immersive technologies there are growing concerns of security and privacy threats to the metaverse and extended reality (XR) systems. Immersive reality solutions are a combination of multiple vulnerable technologies allowing attackers to easily undermine security. Furthermore the deployment of appropriate security controls and defensive mechanisms for resource constrained proprietary XR products has been limited. In this paper, we provide a comprehensive overview of extended reality systems and the metaverse with emphasis on technology weaknesses, cyber security challenges and users’ safety concerns. Five major taxonomies have been presented in this research with an aim of identifying privacy inference vectors and potential cyber threats; determining the impact on human health and the extent to which cyberstalking, and digital currency scam activities proliferate when using XR. This research also proposes strategies for primary lines of defense and provides recommendations on the adoption of safety measures.}
}
@article{TONGUZ2010531,
title = {Multiplayer games over Vehicular Ad Hoc Networks: A new application},
journal = {Ad Hoc Networks},
volume = {8},
number = {5},
pages = {531-543},
year = {2010},
note = {Vehicular Networks},
issn = {1570-8705},
doi = {https://doi.org/10.1016/j.adhoc.2009.12.009},
url = {https://www.sciencedirect.com/science/article/pii/S1570870509001334},
author = {Ozan K. Tonguz and Mate Boban},
keywords = {Multiplayer games, VANET, Vehicular networks, Real-time applications, Commercial applications},
abstract = {In this paper we investigate the possibility of a new type of application, namely multiplayer games, in a Vehicular Ad Hoc Network (VANET) environment. First, we analyze the available empirical data on travel and traffic volume in the United States, and point out the most important challenges that have to be met in order to enable multiplayer games over VANET. We then propose a new paradigm of multiplayer games over VANET, one which utilizes the new, interactive and dynamic VANET environment, while adapting to its inherent constraints.}
}
@article{2010i,
title = {The Second IFAC Symposium on Telematics Applications (TA 2010)},
journal = {IFAC Proceedings Volumes},
volume = {43},
number = {23},
pages = {i-iv},
year = {2010},
note = {2nd IFAC Symposium on Telematics Applications},
issn = {1474-6670},
doi = {https://doi.org/10.3182/20101005-4-RO-2018.90001},
url = {https://www.sciencedirect.com/science/article/pii/S1474667015343512}
}
@article{ESFAHLANI201942,
title = {Mixed reality and remote sensing application of unmanned aerial vehicle in fire and smoke detection},
journal = {Journal of Industrial Information Integration},
volume = {15},
pages = {42-49},
year = {2019},
issn = {2452-414X},
doi = {https://doi.org/10.1016/j.jii.2019.04.006},
url = {https://www.sciencedirect.com/science/article/pii/S2452414X18300773},
author = {Shabnam Sadeghi Esfahlani},
keywords = {Fire detection, Autonomous flight, Crazyflie 2.0, Monocular camera, Computer vision},
abstract = {This paper proposes the development of a system incorporating inertial measurement unit (IMU), a consumer-grade digital camera and a fire detection algorithm simultaneously with a nano Unmanned Aerial Vehicle (UAV) for inspection purposes. The video streams are collected through the monocular camera and navigation relied on the state-of-the-art indoor/outdoor Simultaneous Localisation and Mapping (SLAM) system. It implements the robotic operating system (ROS) and computer vision algorithm to provide a robust, accurate and unique inter-frame motion estimation. The collected onboard data are communicated to the ground station and used the SLAM system to generate a map of the environment. A robust and efficient re-localization was performed to recover from tracking failure, motion blur, and frame lost in the data received. The fire detection algorithm was deployed based on the color, movement attributes, temporal variation of fire intensity and its accumulation around a point. The cumulative time derivative matrix was utilized to analyze the frame-by-frame changes and to detect areas with high-frequency luminance flicker (random characteristic). Color, surface coarseness, boundary roughness, and skewness features were perceived as the quadrotor flew autonomously within the clutter and congested area. Mixed Reality system was adopted to visualize and test the proposed system in a physical environment, and the virtual simulation was conducted through the Unity game engine. The results showed that the UAV could successfully detect fire and flame, autonomously fly towards and hover around it, communicate with the ground station and simultaneously generate a map of the environment. There was a slight error between the real and virtual UAV calibration due to the ground truth data and the correlation complexity of tracking real and virtual camera coordinate frames.}
}
@article{HALEEM202242,
title = {Holography and its applications for industry 4.0: An overview},
journal = {Internet of Things and Cyber-Physical Systems},
volume = {2},
pages = {42-48},
year = {2022},
issn = {2667-3452},
doi = {https://doi.org/10.1016/j.iotcps.2022.05.004},
url = {https://www.sciencedirect.com/science/article/pii/S2667345222000141},
author = {Abid Haleem and Mohd Javaid and Ravi Pratap Singh and Rajiv Suman and Shanay Rab},
keywords = {Holography, Industry 4.0, Technology, 3D modelling, Virtual reality, Augmented reality},
abstract = {Industry 4.0 is a new stage in the organisation and control of the industrial value chain, interchangeably with the fourth industrial revolution. It has a broad vision with well-defined frameworks and reference designs, focusing on bridging physical infrastructure and digital technology in so-called cyber-physical systems. Apart from the other essential technologies, Holography is considered a new innovative technology that can completely transform the vision of Industry 4.0. In industrial applications, holographic technology is used for quality control in manufacturing and fracture testing, such as holographic nondestructive testing. Holography has a wide range of applications in medicine, the military, weather forecasting, virtual reality, digital art, and security. The fourth industrial revolution aims to provide automated asset monitoring, decision-making for corporate operations, and real-time network connectivity. This paper explores holography and its significant benefits through various development processes, features, and applications, where the focus is on ‘holography for Industry 4.0'. Hologram technology is a new industry trend and can impact multiple domains of Industry 4.0. Furthermore, the adoption of holographic technologies may improve the efficiency of existing products and services in other technology sectors such as architecture, 3D modelling, mechatronics, robotics, and healthcare and medical engineering.}
}
@article{DRIEWER2006267,
title = {MIXED REALITY FOR TELEOPERATION OF MOBILE ROBOTS IN SEARCH AND RESCUE SCENARIOS},
journal = {IFAC Proceedings Volumes},
volume = {39},
number = {3},
pages = {267-272},
year = {2006},
note = {12th IFAC Symposium on Information Control Problems in Manufacturing},
issn = {1474-6670},
doi = {https://doi.org/10.3182/20060517-3-FR-2903.00148},
url = {https://www.sciencedirect.com/science/article/pii/S1474667015358687},
author = {Frauke Driewer and Markus Sauer and Klaus Schilling},
keywords = {human-robot interaction, multi-modal interaction, mobile robots, telerobotic, multi-entity teams, mixed reality, search and rescue},
abstract = {Mobile robots can support human rescue workers to accomplish tasks in dangerous areas and locations of difficult access. The remotely operated rovers characterize the environment with their sensors. Telepresence methods are employed to present collected information and a-priori known information efficiently to an operator, who controls multiple mobile robots. In this paper, a user interface that combines two-dimensional and three-dimensional stereo visualization of related information from the remote environment using a mixed reality approach is presented. The implemented system architecture and system features are described.}
}
@article{LI2022109017,
title = {From traffic classes to content: A hierarchical approach for encrypted traffic classification},
journal = {Computer Networks},
volume = {212},
pages = {109017},
year = {2022},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2022.109017},
url = {https://www.sciencedirect.com/science/article/pii/S138912862200175X},
author = {Ying Li and Yi Huang and Suranga Seneviratne and Kanchana Thilakarathna and Adriel Cheng and Guillaume Jourjon and Darren Webb and David B. Smith and Richard Yi Da Xu},
keywords = {Traffic classification, Network security, Encrypted traffic},
abstract = {The vast majority of Internet traffic is now end-to-end encrypted, and while encryption provides user privacy and security, it has made network surveillance an impossible task. Various parties are using this limitation to distribute problematic content such as fake news, copy-righted material, and propaganda videos. Recent advances in machine learning techniques have shown great promise in extracting content fingerprints from encrypted traffic captured at the various points in IP core networks. Nonetheless, content fingerprinting from listening to encrypted wireless traffic remains a challenging task due to the difficulty in distinguishing re-transmissions and multiple flows on the same link. In this paper, we show the potential of fingerprinting internet traffic by passively sniffing WiFi frames in air, without connecting to the WiFi network by leveraging deep learning methods. First, we show the possibility of building a generic traffic classifier using a hierarchical approach that is able to identity most common traffic types in the Internet and reveal fine-granular details such as identifying the exact content of the traffic. Second, we demonstrate the possibility of using Multi-Layer Perceptron (MLP) and Recurrent Neural Networks (RNNs) to identify streaming traffic, such as video and music, from a closed set, by sniffing WiFi traffic that is encrypted at both Media Access Control (MAC) and Transport layers. Overall, our results demonstrate that we can achieve over 95% accuracy in identifying traffic types such as web, video streaming, and audio streaming as well as identifying the exact content consumed by the user.}
}
@article{TABONE2021100293,
title = {Vulnerable road users and the coming wave of automated vehicles: Expert perspectives},
journal = {Transportation Research Interdisciplinary Perspectives},
volume = {9},
pages = {100293},
year = {2021},
issn = {2590-1982},
doi = {https://doi.org/10.1016/j.trip.2020.100293},
url = {https://www.sciencedirect.com/science/article/pii/S2590198220302049},
author = {Wilbert Tabone and Joost {de Winter} and Claudia Ackermann and Jonas Bärgman and Martin Baumann and Shuchisnigdha Deb and Colleen Emmenegger and Azra Habibovic and Marjan Hagenzieker and P.A. Hancock and Riender Happee and Josef Krems and John D. Lee and Marieke Martens and Natasha Merat and Don Norman and Thomas B. Sheridan and Neville A. Stanton},
keywords = {Automated vehicles, External human-machine interfaces, Smart infrastructure, Augmented reality, Virtual reality, Position paper},
abstract = {Automated driving research over the past decades has mostly focused on highway environments. Recent technological developments have drawn researchers and manufacturers to look ahead at introducing automated driving in cities. The current position paper examines this challenge from the viewpoint of scientific experts. Sixteen Human Factors researchers were interviewed about their personal perspectives on automated vehicles (AVs) and the interaction with VRUs in the future urban environment. Aspects such as smart infrastructure, external human-machine interfaces (eHMIs), and the potential of augmented reality (AR) were addressed during the interviews. The interviews showed that the researchers believed that fully autonomous vehicles will not be introduced in the coming decades and that intermediate levels of automation, specific AV services, or shared control will be used instead. The researchers foresaw a large role of smart infrastructure and expressed a need for AV-VRU segregation, but were concerned about corresponding costs and maintenance requirements. The majority indicated that eHMIs will enhance future AV-VRU interaction, but they noted that implicit communication will remain dominant and advised against text-based and instructive eHMIs. AR was commended for its potential in assisting VRUs, but given the technological challenges, its use, for the time being, was believed to be limited to scientific experiments. The present expert perspectives may be instrumental to various stakeholders and researchers concerned with the relationship between VRUs and AVs in future urban traffic.}
}
@article{CAPUTO201962,
title = {Validation of the return of spontaneous circulation after cardiac arrest (RACA) score in two different national territories},
journal = {Resuscitation},
volume = {134},
pages = {62-68},
year = {2019},
issn = {0300-9572},
doi = {https://doi.org/10.1016/j.resuscitation.2018.11.012},
url = {https://www.sciencedirect.com/science/article/pii/S0300957218310918},
author = {Maria Luce Caputo and Enrico Baldi and Simone Savastano and Roman Burkart and Claudio Benvenuti and Catherine Klersy and Roberto Cianella and Luciano Anselmi and Tiziano Moccetti and Romano Mauri and Gaetano M. {De Ferrari} and Angelo Auricchio},
keywords = {Out-of-hospital cardiac arrest, ROSC, Prediction},
abstract = {Background
The likelihood of return of spontaneous circulation (ROSC) after out-of-hospital cardiac arrest (OHCA) is influenced by unmodifiable (gender, aetiology, location, the presence of witnesses and initial rhythm) and modifiable factors (bystander CPR and the time to EMS arrival). All of these have been included in the ROSC After Cardiac Arrest (RACA) score.
Purpose
To test the ability of the RACA score to predict the probability of ROSC in two different regions with different local resuscitation networks: the Swiss Canton Ticino and the Italian Province of Pavia.
Methods and Results
All OHCAs occurred between January 1st 2015 and December 31st 2017 were included. The original regression coefficients for all RACA score variables were applied. The probability to obtain the ROSC as measured with the RACA score was divided in tertiles. Overall, 2041 OHCAs were included in the analysis. The RACA score showed good discrimination for ROSC (AUC 0.76) and calibration, without interaction (p 0.28) between the region and the probability of ROSC. The probability of ROSC was 15% for RACA scores <0.28, 20% for RACA scores between 0.28 and 0.42, increasing to 55% for RACA scores >0.42.
Conclusions
The application of the RACA score reliably assess the probability to obtain the ROSC, with equal effectiveness in the two regions, despite different organization of the resuscitation network. Patients with a RACA score >0.42 had more than 50% probability to obtain ROSC.}
}
@article{LOWELL2023100017,
title = {Authentic learning and fidelity in virtual reality learning experiences for self-efficacy and transfer},
journal = {Computers & Education: X Reality},
volume = {2},
pages = {100017},
year = {2023},
issn = {2949-6780},
doi = {https://doi.org/10.1016/j.cexr.2023.100017},
url = {https://www.sciencedirect.com/science/article/pii/S2949678023000119},
author = {Victoria Lynn Lowell and Deepti Tagare},
keywords = {Authentic learning, Authenticity, Fidelity, Virtual reality, Learning experience, VRLE, Collaborative learning, Self-efficacy, Transfer},
abstract = {Authentic learning is an instructional approach that best occurs when the learning activities are set in real-world contexts. The authenticity of the learning experience increases when learning is situated in a context akin to the real world, and realistic learning experiences are created by carefully designing the learning tasks, context, and environment. The fidelity of a learning task's psychological, physical, functional, and social aspects and environment is the design attributes that contribute to the authenticity of the learning experience. The social context, or the social environment during learning, is essential in engaging learners in authentic learning tasks. In this mixed-method study, we investigate whether the collaborative nature of the learning activities, the authentic design of the learning experience and tasks, and the social environment impact the learner's perceptions of their learning experience and confidence in learning transfer. Two instruments were used to collect quantitative and qualitative data. The quantitative and qualitative data were analyzed separately and then together through triangulation. The findings of this study suggest that learners perceived the tasks and environment as realistic and the learning activities' collaborative aspect as helpful. The authentic learning environment did not significantly impact learners' confidence to transfer. However, the experience led to valuable metacognitive reflection and change in self-efficacy beliefs about their learning and practice needs. This experience may result in better self-regulation in long-term learning. This paper presents the findings of this study and discusses future research implications.}
}
@article{2023e1,
title = {PDF of Full Issue},
journal = {Annals of Emergency Medicine},
volume = {82},
number = {4, Supplement },
pages = {e1-e215},
year = {2023},
issn = {0196-0644},
doi = {https://doi.org/10.1016/S0196-0644(23)01222-2},
url = {https://www.sciencedirect.com/science/article/pii/S0196064423012222}
}
@article{YUAN2021132,
title = {Immersive sketch-based tree modeling in virtual reality},
journal = {Computers & Graphics},
volume = {94},
pages = {132-143},
year = {2021},
issn = {0097-8493},
doi = {https://doi.org/10.1016/j.cag.2020.12.001},
url = {https://www.sciencedirect.com/science/article/pii/S0097849320301813},
author = {Qi Yuan and Yongjian Huai},
keywords = {Tree modeling, Virtual reality, 3D sketching, Immersive modeling, Twigs generation},
abstract = {Tree modeling has been a widely-discussed topic in computer graphics. However, with existing methods, the modeling process is occupied with complex data collection and tedious parameter adjustment, lacking a rich sensory modeling experience. In this paper, we propose an approach to sketch-based tree modeling in an immersive virtual reality environment, aiming to lower the difficulty of modeling and enhance the immersion in the designing process. We first present a sketch sampling and points optimization algorithm to obtain the skeleton of the branch in 3D space. As generating geometry along the skeleton, we apply a vector-projection method to fix the branch polygon twisting. Then, we introduce a bidirectional ray-hit algorithm to determine the branch radius as real-time sketching. To generate random twigs on branches, we introduce a twigs generation algorithm based on Perlin noise and the parent branch direction. Finally, we design a series of interactive methods for users to create tree models in a 3D virtual scene with the VR HMD and controller. Experimental results indicate that our approach can accomplish creating realistic tree models in real-time. The interactive and immersive modeling experience enables users to readily convey their ideas on tree structures in a simple and direct way of sketching. Visualizing and modifying the real-time generated branch results can contribute to provoking the inspiration for creation.}
}
@article{CRIDER2020102579,
title = {Digital Daimons: Algorithmic Rhetorics of Augmented Reality},
journal = {Computers and Composition},
volume = {57},
pages = {102579},
year = {2020},
note = {Composing Algorithms: Writing (with) Rhetorical Machines},
issn = {8755-4615},
doi = {https://doi.org/10.1016/j.compcom.2020.102579},
url = {https://www.sciencedirect.com/science/article/pii/S8755461520300402},
author = {Jason Crider and Jacob Greene and Sean Morey},
keywords = {Algorithms, augmented reality, Daimon, GPS, writing studies, digital rhetoric, Mixed-Reality, Location-Based Writing, Electracy},
abstract = {This article develops a theoretical framework for studying the algorithmic underpinnings of contemporary augmented reality technologies. We delineate this framework through the rhetorical figure of the “daimon,” a greek mythological entity as well as a technical concept within computer science, to articulate an approach to AR algorithms as emergent, material processes that can create unpredicted, unintended effects. Ultimately, we argue that the conceptual framework of the “daimon” provides an interface through which writing and rhetoric scholars can better discern the algorithmic effects of emerging AR composing platforms.}
}
@article{SOTOVERGEL2023104094,
title = {Transforming ground disaster response: Recent technological advances, challenges, and future trends for rapid and accurate real-world applications of survivor detection},
journal = {International Journal of Disaster Risk Reduction},
volume = {98},
pages = {104094},
year = {2023},
issn = {2212-4209},
doi = {https://doi.org/10.1016/j.ijdrr.2023.104094},
url = {https://www.sciencedirect.com/science/article/pii/S2212420923005745},
author = {Angelo J. Soto-Vergel and Juan C. Velez and Rene Amaya-Mier and Mauricio Pardo},
keywords = {Ground disaster, Survivor, Life detection, Response phase, Technology, Real-world application},
abstract = {Recent technological advancements, encompassing cutting-edge sensors, drones, and AI systems, present novel prospects for enhancing survivor detection in disaster scenarios. This article systematically reviews sixty-seven studies spanning 2009 to 2023, concentrating on technologies for locating survivors within land-based disaster contexts. Adhering to PRISMA guidelines, the review delineates the literature landscape, unveiling unmanned vehicles, radars, wireless sensors, smartphones, and Wi-Fi as prominent modalities. Significant challenges include limited actual-physical world validation, on-site deployment logistics, reliance on communication infrastructure, and power consumption. Nevertheless, innovative strategies such as multi-sensory integration and on-site processing using TinyML, exhibit the potential to reduce these limitations, signifying promising opportunities for future research. The conclusions take a practical perspective, excluding less mature technologies unsuited for early physical world implementation, given the prevalence of studies based on unrealistic assumptions—a major criticism of the literature. In terms of contributions, a conceptual framework, the Ground Disaster Information Management System, is introduced. This framework accentuates the importance of emerging technologies and communication protocols for efficient deployment and standardized data exchange. Ultimately, by synthesizing merits, constraints, and knowledge gaps, this review discerns challenges in survivor detection while underscoring technology-driven resolutions to enhance rescue operations. These encompass pragmatic paradigms for sensing, computation, communication, and coordination, targeting device deployment, in-situ sensors, communication systems, multi-sensory modalities, and augmented autonomy.}
}
@article{PETERSON2020173,
title = {Mixed-Reality Simulation for a Pediatric Transport Team: A Pilot Study},
journal = {Air Medical Journal},
volume = {39},
number = {3},
pages = {173-177},
year = {2020},
issn = {1067-991X},
doi = {https://doi.org/10.1016/j.amj.2020.03.001},
url = {https://www.sciencedirect.com/science/article/pii/S1067991X20300560},
author = {Eleanor Peterson and Melissa Porter and Aaron Calhoun},
abstract = {Objective
Transport medicine requires a complex set of skills including fast-paced medical decision making, in-depth medical knowledge, procedural competence, interpersonal and communication skills, leadership, and professionalism. There has been a call for more training in these areas. Simulation-based training can be a way to acquire these necessary skills and bridge the gap to higher-quality transport care. The purpose of this study was to develop a novel mixed-reality simulation program to enhance medical and communication skills for a pediatric transport team.
Methods
A mixed-reality simulation program using standardized patients portraying family members and high-fidelity manikins to simulate a medical emergency was developed and implemented for a pediatric transport team. Ten nurses, 9 respiratory therapists, and 8 emergency medical technicians participated. Pre-post self-perceptions of skill and program quality were assessed prospectively.
Results
Team members rated the overall program quality highly, with a median 5 on a 5-point Likert scale. There was a statistically significant change in pre- versus postprogram self-perceptions of skill in the areas of communication (premedian = 3 vs. postmedian = 4, 5-point Likert scale, P < .001).
Conclusion
Mixed-reality simulation programs can enhance standard technical skills training by providing an additional relational element. Such programs are translatable to other institutions.}
}
@article{KHAN2023955,
title = {Technology-enhanced trauma training in low-resource settings: A scoping review and feasibility analysis of educational technologies},
journal = {Journal of Pediatric Surgery},
volume = {58},
number = {5},
pages = {955-963},
year = {2023},
issn = {0022-3468},
doi = {https://doi.org/10.1016/j.jpedsurg.2023.01.039},
url = {https://www.sciencedirect.com/science/article/pii/S0022346823000581},
author = {Minahil Khan and Fabio Botelho and Laura Pinkham and Elena Guadagno and Dan Poenaru},
keywords = {Virtual reality, Advanced Trauma Life Support, Education, Medical, Simulation training, High fidelity simulation training},
abstract = {Background
Lack of training contributes to the burden of trauma-related mortality and morbidity in low- and lower-middle-income countries (LMICs). Educational technologies present a unique opportunity to enhance the quality of trauma training. Therefore, this study reviews current technologies used in trauma courses and evaluates their feasibility for LMICs.
Methods
We conducted a scoping review evaluating the learning outcomes of technology-enhanced training in general trauma assessment, team skills or any procedures covered in the 2020 Advanced Trauma Life Support® program. Based on the Technology-Enhanced Learning criteria, we created and applied a feasibility analysis tool to evaluate the technologies for use in LMICs.
Results
We screened 6471 articles and included 64. Thirty-four (45%) articles explored training in general trauma assessment, 28 (37%) in team skills, and 24 (32%) in procedures. The most common technologies were high-fidelity mannequins (60%), video-assisted debriefing (19%), and low-fidelity mannequins (13%). Despite their effectiveness, high-fidelity mannequins ranked poorly in production, maintenance, cost, and reusability categories, therefore being poorly suited for LMICs. Virtual simulation and digital courses had the best feasibility scores, but still represented a minority of articles in our review.
Conclusion
To our knowledge, this is the first study to perform a feasibility analysis of trauma training technologies in the LMIC context. We identified that the majority of trauma courses in the literature use technologies which are less suitable for LMICs. Given the urgent need for pediatric trauma training, educators must use technologies that optimize learning outcomes and remain feasible for low-resource settings.
Level of Evidence
IV.}
}
@article{SPAULDING201038,
title = {How can virtual communities create value for business?},
journal = {Electronic Commerce Research and Applications},
volume = {9},
number = {1},
pages = {38-49},
year = {2010},
note = {Special Issue: Social Networks and Web 2.0},
issn = {1567-4223},
doi = {https://doi.org/10.1016/j.elerap.2009.07.004},
url = {https://www.sciencedirect.com/science/article/pii/S156742230900043X},
author = {Trent J. Spaulding},
keywords = {Business value, Information technology, Online community, Social contracts, Trust theory, Virtual community},
abstract = {Virtual communities include everything from discussion boards to massive multiplayer online role-playing games and virtual realities such as Second Life. The business world has assumed that virtual communities can be leveraged to provide access to consumers and consumer data. The benefits of this assumption have not always been realized. The purpose of this article is to understand why some business ventures into virtual communities fail and others succeed. Why do virtual communities support certain types of business activities and not others? Which firm activities are the best candidates to benefit from being positioned in virtual communities? The theories of social contracts and trust explain how firms can successfully participate in virtual communities. The theories have implications in the context of transaction-oriented, interest-oriented, relationship-oriented, and fantasy-oriented communities. The value chain provides an instructive background to understand which firm activities are candidates for being included in virtual communities. Success in virtual communities depends on an attitude of contribution, dedication of resources, building a critical mass, and matching community and business needs. Because many social technologies are in the disillusionment stage of the hype cycle, further research in the business use of virtual communities is needed to guide business practices as we move to full adoption.}
}
@article{BACEVICIUTE2021104122,
title = {Remediating learning from non-immersive to immersive media: Using EEG to investigate the effects of environmental embeddedness on reading in Virtual Reality},
journal = {Computers & Education},
volume = {164},
pages = {104122},
year = {2021},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2020.104122},
url = {https://www.sciencedirect.com/science/article/pii/S0360131520303201},
author = {Sarune Baceviciute and Thomas Terkildsen and Guido Makransky},
keywords = {Virtual reality environments, Learning, Embeddedness, Remediation, EEG},
abstract = {Virtual Reality (VR) has the potential to enrich education but little is known about how unique affordances of immersive technology might influence leaning and cognition. This study investigates one particular affordance of VR, namely environmental embeddedness, which enables learners to be situated in simulated or imagined settings that contextualize their learning. A sample of 51 university students were administered written learning material in a between-subjects design study, wherein one group read text about sarcoma cancer on a physical pamphlet in the real world, and the other group read identical text on a virtual pamphlet embedded in an immersive VR environment which resembled a hospital room. The study combined advanced EEG measurement techniques, learning tests, and cognitive load measures to compare conditions. Results show that the VR group performed significantly better on a knowledge transfer post-test. However, reading in VR was found to be more cognitively effortful and less time-efficient. Findings suggest the significance of environmental embeddedness for learning, and provide important considerations for the design of educational VR environments, as we remediate learning content from non-immersive to immersive media.}
}
@article{LOUIE20181229,
title = {Recent Advances in Technology and Its Applications to Pediatric Emergency Care},
journal = {Pediatric Clinics of North America},
volume = {65},
number = {6},
pages = {1229-1246},
year = {2018},
note = {Pediatric Emergency Medicine},
issn = {0031-3955},
doi = {https://doi.org/10.1016/j.pcl.2018.07.013},
url = {https://www.sciencedirect.com/science/article/pii/S003139551830110X},
author = {Marisa C. Louie and Todd P. Chang and Robert W. Grundmeier},
keywords = {Pediatric emergency medicine, Ultrasonography, Electronic health records, Clinical decision support, Simulation-based training, Clinical competence, Free open access medical education}
}