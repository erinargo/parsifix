@article{ODEN20154052,
title = {Embedding Emotional Intelligence into Military Training Contexts},
journal = {Procedia Manufacturing},
volume = {3},
pages = {4052-4059},
year = {2015},
note = {6th International Conference on Applied Human Factors and Ergonomics (AHFE 2015) and the Affiliated Conferences, AHFE 2015},
issn = {2351-9789},
doi = {https://doi.org/10.1016/j.promfg.2015.07.976},
url = {https://www.sciencedirect.com/science/article/pii/S2351978915009774},
author = {Kevin B. Oden and Monika Lohani and Marissa McCoy and James Crutchfield and Susan Rivers},
keywords = {Emotional intelligence, Immersion training, Virtual characters},
abstract = {Even the most junior Warfighters must effectively interact and negotiate with locals from communities that do not share their religious beliefs, social perspectives or customs. These cultural differences introduce a layer of uncertainty into chaotic operational contexts that are marked by moments of intense stress, and often contribute to strong emotional responses such as anxiety or anger. Unchecked, these emotional responses can escalate and lead Warfighters to make judgments and decisions they might not otherwise make. In high stakes situations, even the slightest mistake may have tragic consequences; thus, a need exists to equip Warfighters with skills that allow them to recognize/regulate their emotions. Emotional Intelligence (EI) “is the ability to monitor one's own and other's feelings and emotions, to discriminate among them and to use this information to guide one's thinking and actions” [1]. Learning effective strategies to manage our emotions is critical for laying a strong foundation for the development of positive relationships [2], [3]. Being able to effectively build positive relationships in diverse settings is a key attribute of cross cultural competence that may be improved through EI training. By practicing emotion recognition/regulation strategies, individuals will begin to replace ineffective decision-making with productive responses to challenging situations. In order to understand how emotions can influence decision making and social judgment, various moderating factors need to be considered, including cultural, group, and individual differences in emotional recognition/regulation [4]. We provide a brief overview of the operational need, define the basic tenets of EI, and describe how this approach could be implemented within an existing military training setting. We describe how emotion recognition and regulation skills would be exercised and evaluated and list potential benefits of using immersive training for skill development. Finally, we conclude with recommendations for future research and development in this area.}
}
@article{SASTRY1997305,
title = {Milli-robotics for remote, minimally invasive surgery},
journal = {Robotics and Autonomous Systems},
volume = {21},
number = {3},
pages = {305-316},
year = {1997},
note = {Critical Issues in Robotics},
issn = {0921-8890},
doi = {https://doi.org/10.1016/S0921-8890(96)00082-6},
url = {https://www.sciencedirect.com/science/article/pii/S0921889096000826},
author = {S.S Sastry and M Cohn and F Tendick},
keywords = {Minimally invasive surgery, Endoscopy, Milli-robotics, MEMS (micro-electro mechanical systems)},
abstract = {In this paper, we describe an ongoing collaborative research project between the Universities of California at Berkeley and San Francisco with Endorobotics Corporation to develop milli-robotic tools for remote, minimally invasive surgery. We describe the limitations of current surgical practice and then describe the technological and scientific issues involved in building a telesurgical workstation. We describe the novel techniques that we have adapted from MEMS for the design of the milli-robots, their actuators, tactile sensors and displays. We also discuss the need for modeling compliant tissue for telepresent manipulation and training. We, then, describe a test bed telesurgical workstation that has been set up at Berkeley. Animal trials are ready to commence on this surgical workstation. Finally, we do a brief review of related projects. In this paper, we describe our research program for developing tools for minimally invasive remote surgery. Key to this paper is the use of minimally invasive surgery. For urgent remote care, it is usually advisable not to cause additional trauma by an invasive operating procedure and also to keep low the possibility of infection in an incompletely sterile environment. Thus, the need for milli-robotics for this surgery and the need for new kinds of robots, tactile and visual sensors, and human-machine interfaces. While we talk primarily about general surgery in this white paper, we have the goal of eventually being able to do coronary procedures, through minimally invasive thoracoscopes.}
}
@article{MARSH201161,
title = {Serious games continuum: Between games for purpose and experiential environments for purpose},
journal = {Entertainment Computing},
volume = {2},
number = {2},
pages = {61-68},
year = {2011},
note = {Serious Games Development and Applications},
issn = {1875-9521},
doi = {https://doi.org/10.1016/j.entcom.2010.12.004},
url = {https://www.sciencedirect.com/science/article/pii/S1875952110000224},
author = {Tim Marsh},
keywords = {Serious games, Definition, Categorization, Continuum},
abstract = {While many categorizations and definitions have attempted to elucidate the elusive term serious games, we are still some way off formulating an agreed understanding of what serious games are and can be. This article argues that the term serious games challenges our understanding of generally accepted characteristics such as, challenge, play and fun, which are largely associated with and borrowed from video games. It is argued that key to understanding what serious games encapsulate is to look beyond these characteristics. This article proposes a definition and way to frame serious games technologies, applications and environments along a continuum of gaming characteristics or gameness. From those with traditional gaming activities and characteristics (challenge, play, fun, etc.) at one end to those with minimal traditional gaming characteristics at the other end, whose main purpose is to provide experience and emotion to convey meaning. The main advantages of the definition and continuum are to establish a shared understanding and arena for current and emerging serious games, frame and connect currently fragmented groups into a cohesive serious games movement and community and open opportunities for future collaborative research and development. In addition, it helps in identifying characteristics for the design and assessment of serious games.}
}
@article{GAO2022100075,
title = {High fusion computers: The IoTs, edges, data centers, and humans-in-the-loop as a computer},
journal = {BenchCouncil Transactions on Benchmarks, Standards and Evaluations},
volume = {2},
number = {3},
pages = {100075},
year = {2022},
issn = {2772-4859},
doi = {https://doi.org/10.1016/j.tbench.2022.100075},
url = {https://www.sciencedirect.com/science/article/pii/S277248592200062X},
author = {Wanling Gao and Lei Wang and Mingyu Chen and Jin Xiong and Chunjie Luo and Wenli Zhang and Yunyou Huang and Weiping Li and Guoxin Kang and Chen Zheng and Biwei Xie and Shaopeng Dai and Qian He and Hainan Ye and Yungang Bao and Jianfeng Zhan},
keywords = {Emerging and future applications, Safety-critical, Mission-critical, IoT, Edge, Data center, Humans-in-the-loop, Open-source computer systems, High Fusion Computers, HFC},
abstract = {Emerging and future applications rely heavily upon systems consisting of Internet of Things (IoT), edges, data centers, and humans-in-the-loop. Significantly different from warehouse-scale computers that serve independent concurrent user requests, this new class of computer systems directly interacts with the physical world, considering humans an essential part and performing safety-critical and mission-critical operations; their computations have intertwined dependencies between not only adjacent execution loops but also actions or decisions triggered by IoTs, edge, datacenters, or humans-in-the-loop; the systems must first satisfy the accuracy metric in predicting, interpreting, or taking action before meeting the performance goal under different cases. This article argues we need a paradigm shift to reconstruct the IoTs, edges, data centers, and humans-in-the-loop as a computer rather than a distributed system. We coin a new term, high fusion computers (HFCs), to describe this class of systems. The fusion in the term has two implications: fusing IoTs, edges, data centers, and humans-in-the-loop as a computer, fusing the physical and digital worlds through HFC systems. HFC is a pivotal case of the open-source computer systems initiative. We laid out the challenges, plan, and call for uniting our community’s wisdom and actions to address the HFC challenges. Everything, including the source code, will be publicly available from the project homepage: https://www.computercouncil.org/HFC/.}
}
@article{2022iii,
title = {Contents},
journal = {Procedia Computer Science},
volume = {207},
pages = {iii-xxviii},
year = {2022},
note = {Knowledge-Based and Intelligent Information & Engineering Systems: Proceedings of the 26th International Conference KES2022},
issn = {1877-0509},
doi = {https://doi.org/10.1016/S1877-0509(22)01439-9},
url = {https://www.sciencedirect.com/science/article/pii/S1877050922014399}
}
@article{HAGHANI2020104745,
title = {Optimising crowd evacuations: Mathematical, architectural and behavioural approaches},
journal = {Safety Science},
volume = {128},
pages = {104745},
year = {2020},
issn = {0925-7535},
doi = {https://doi.org/10.1016/j.ssci.2020.104745},
url = {https://www.sciencedirect.com/science/article/pii/S0925753520301429},
author = {Milad Haghani},
keywords = {Evacuation preparedness, Disaster preparedness, Crowd management, Evacuation time, Evacuation planning},
abstract = {This work is a systematic review of optimisation methods for pedestrian evacuations. The focus is on interventional approaches that seek to improve evacuation efficiency rather than efforts to purely describe/predict evacuations. Three major evacuation optimisation approaches are identified: (a) architectural design and infrastructure adjustment, (b) mathematical programming and optimisation of path/departure-schedule planning, (c) behavioural modification, training and active instructions. The reviewed literature is dominated by architectural solutions, while the evidence on their effectiveness is largely mixed and inconclusive. They also pose practical challenges: major design interventions in previously-built infrastructure may not always be readily feasible. Furthermore, the effectiveness of architectural solutions is often suggested to be geometry/context dependant rather than universal. Complex path/schedule optimisation solutions also pose their own implementation and enforcement challenges. They often require that an entire crowd be controlled and directed by a central body. They also do not address microscopic aspects of individual behaviour. The behavioural modification method used to be the least studied approach until recently, but it is gaining increasing traction as a promising method in terms of both effectiveness and practicality. Its underexplored potential constitutes a major knowledge gap in evacuation dynamics literature. The first important step to address this gap is to (i) identify possible and most effective areas of behavioural intervention; and (ii) employ reliable experimental or numerical methods to discover optimum strategies, and (iii) determine how behavioural interventions can be effectively conveyed to people. Establishing the relative effectiveness of the three optimisation approaches also constitutes another important question to be explored.}
}
@article{CAO201937,
title = {A virtual reality based study of indoor fire evacuation after active or passive spatial exploration},
journal = {Computers in Human Behavior},
volume = {90},
pages = {37-45},
year = {2019},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2018.08.041},
url = {https://www.sciencedirect.com/science/article/pii/S0747563218304163},
author = {Lijun Cao and Jing Lin and Nan Li},
keywords = {Fire evacuation, Spatial learning, Virtual reality (VR), Emergency, Active exploration, Passive exploration},
abstract = {Here we report a study designed to examine the influence of spatial exploration mode on people's wayfinding performance during a building fire emergency. Using immersive virtual environments, we asked the participants to actively or passively explore a virtual museum to look for hidden treasure keys and then a treasure point. Half of the participants were asked to exit from a virtual museum during a virtual fire emergency after they had actively or passively explored the museum, whereas the other half of the participants were asked to complete the same task under the control condition without the virtual fire. Importantly, both the active and passive exploration conditions allowed the participants to control their own movement, whereas only those under the active exploration condition had the opportunity to make route decisions. Compared to those who explored the virtual museum passively, the participants did it actively traveled longer in completing the egress task. The results also revealed that participants under the fire emergency condition spent more time in finding their way to exit the museum than those under the control condition, and rated the evacuation task to be more difficult. The underlying mechanisms of these findings were discussed.}
}
@incollection{1994489,
title = {APPENDIX F - BIBLIOGRAPHY},
editor = {Christopher D. Watkins and Stephen R. Marenka},
booktitle = {Virtual Reality Excursions with Programs in C},
publisher = {Academic Press},
pages = {489-495},
year = {1994},
isbn = {978-0-12-737865-7},
doi = {https://doi.org/10.1016/B978-0-12-737865-7.50019-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780127378657500195}
}
@article{DASILVA2016192,
title = {Review study of virtual reality techniques used at nuclear issues with emphasis on Brazilian research},
journal = {Annals of Nuclear Energy},
volume = {87},
pages = {192-197},
year = {2016},
issn = {0306-4549},
doi = {https://doi.org/10.1016/j.anucene.2015.08.017},
url = {https://www.sciencedirect.com/science/article/pii/S0306454915004302},
author = {Márcio Henrique {da Silva} and Ana Paula Legey and Antônio Carlos de A. Mól},
keywords = {Virtual reality, Nuclear engineering, 3D modeling},
abstract = {Some of the procedures referred to nuclear issues like evacuation training, waste management and radioactive dose assessment evaluation are related to dangerous situations where the health of the involved personnel can be compromised. For this reason, several researchers have been proposing the use of virtual reality techniques to help on performing this kind of task. Moreover, there are other applications using this type of tool which allow not only the achievement of better results in comparison to the already available procedures but also provide the development of new technologies. Therefore this work proposes to make a review study concerning to some of the applications of virtual reality techniques and concepts at nuclear issues highlighting some of the works developed in Brazil. To do so, the analyzed researches were organized according to its similarities, objectives and applicability. The goal of this survey is to provide a brief glance concerning to the information about the chronological evolution of this practice describing some of its results besides of showing prospects for further works.}
}
@article{FU2021103644,
title = {Do people follow neighbors? An immersive virtual reality experimental study of social influence on individual risky decisions during evacuations},
journal = {Automation in Construction},
volume = {126},
pages = {103644},
year = {2021},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2021.103644},
url = {https://www.sciencedirect.com/science/article/pii/S0926580521000959},
author = {Meiqing Fu and Rui Liu and Yu Zhang},
keywords = {Building evacuations, Risky decisions, Social influence, Immersive virtual reality},
abstract = {This study examined social influence on individual risk-taking decisions during evacuations through an immersive virtual reality (VR)-based experiment. Participants were asked to evacuate in the case of a virtual building fire. The results suggested that participants' route choices during evacuations were affected by their neighbors' behaviors. In particular, if a risky route was less preferred due to dense smoke, the effect of neighbor behavior was strongest when enticing participants to take the risky route. Nonetheless, the number of virtual neighbors did not significantly change the degree of social influence on participants' route choices. Moreover, an increase in smoke density significantly reduced the number of participants making risky decisions. The results also indicated that individuals had a tendency to follow others when making risky decisions, but they were not blindly following others. Individuals made their evacuation route decisions by engaging in comprehensive consideration of various types of environmental information.}
}
@article{SINGH2011739,
title = {Accelerating urban fast response Lagrangian dispersion simulations using inexpensive graphics processor parallelism},
journal = {Environmental Modelling & Software},
volume = {26},
number = {6},
pages = {739-750},
year = {2011},
issn = {1364-8152},
doi = {https://doi.org/10.1016/j.envsoft.2010.12.011},
url = {https://www.sciencedirect.com/science/article/pii/S1364815210003452},
author = {B. Singh and E.R. Pardyjak and A. Norgren and P. Willemsen},
keywords = {GPU, Parallel simulation, Urban dispersion modeling, Virtual environment, Visualization},
abstract = {Owing to the potential consequences associated with accidental or deliberate releases of chemical or biological agents in urban areas, fast response urban dispersion models must rapidly provide solutions that can be easily analyzed by researchers and emergency responders. In this paper, we describe a novel application of an existing Lagrangian dispersion modeling system to achieve real-time simulation and visualization of an urban plume that a user can interact with in a virtual environment (VE) through the utilization of commodity graphics hardware, utilizing the highly parallel computational capabilities available on graphics processing units (GPU). GPUs have quickly developed from video game technology to open up new avenues for enhancing simulation performance and visualization of engineering and science applications. For computer graphics applications, GPUs provide highly parallel and inexpensive data paths for processing geometry and pixels, but for simulation these parallel paths are exploited for solving general problems. In this paper, a newly developed dispersion model (GPU Plume) is tested against an analytical solution, a CPU implementation of the Lagrangian dispersion model and wind tunnel data for dispersion around a single building. GPU Plume is shown to provide results that are similar in accuracy to the CPU model, but with computation times that are up to two orders magnitude smaller. In addition, challenges associated with the implementation of Lagrangian dispersion models onto the GPU architecture are discussed in this paper.}
}
@article{CUKOR2009715,
title = {Emerging treatments for PTSD},
journal = {Clinical Psychology Review},
volume = {29},
number = {8},
pages = {715-726},
year = {2009},
note = {Posttraumatic Stress Disorder and the Wars in Afghanistan and Iraq},
issn = {0272-7358},
doi = {https://doi.org/10.1016/j.cpr.2009.09.001},
url = {https://www.sciencedirect.com/science/article/pii/S0272735809001184},
author = {Judith Cukor and Josh Spitalnick and JoAnn Difede and Albert Rizzo and Barbara O. Rothbaum},
keywords = {Posttraumatic stress disorder, Review, Novel treatments, Emerging treatments, Virtual reality, D-cycloserine},
abstract = {Recent innovations in posttraumatic stress disorder (PTSD) research have identified new treatments with significant potential, as well as novel enhancements to empirically-validated treatments. This paper reviews emerging psychotherapeutic and pharmacologic interventions for the treatment of PTSD. It examines the evidence for a range of interventions, from social and family-based treatments to technological-based treatments. It describes recent findings regarding novel pharmacologic approaches including propranolol, ketamine, prazosin, and methylenedioxymethamphetamine. Special emphasis is given to the description of virtual reality and D-cycloserine as enhancements to prolonged exposure therapy.}
}
@article{MAROCCO2021103917,
title = {Integrating disruptive technologies with facilities management: A literature review and future research directions},
journal = {Automation in Construction},
volume = {131},
pages = {103917},
year = {2021},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2021.103917},
url = {https://www.sciencedirect.com/science/article/pii/S092658052100368X},
author = {Marco Marocco and Ilaria Garofolo},
keywords = {Building information modelling (BIM), Digital twin (DT), Facilities management (FM), Operation & maintenance (O&M), Literature review},
abstract = {Facilities Management (FM) has received increasing attention from the Architecture, Engineering, Construction and Operation (AECO) industry over the last decade. Disruptive technologies have the potential to advance the Operation and Maintenance (O&M) phase in different application fields. With the increasing industry interest, there is a need to review the current status of research developments in FM. In this review, 70 journal articles published from 2011 to 2020 were reviewed. This paper aims to provide a comprehensive review of the applications of disruptive technologies for FM, analyse research trends and identify research gaps and potential future research directions. This article focuses on only academic articles including topics, such as operations and maintenance, information management, emergency management and energy management. Eventually, it is hoped that this review will provide researchers with clarity of where research endeavours are most needed and helpful insights to address FM challenges.}
}
@article{WEN2021101411,
title = {VR-Electricians: Immersive storytelling for attracting students to the electrical construction industry},
journal = {Advanced Engineering Informatics},
volume = {50},
pages = {101411},
year = {2021},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2021.101411},
url = {https://www.sciencedirect.com/science/article/pii/S1474034621001634},
author = {Jing Wen and Masoud Gheisari},
keywords = {Immersive storytelling, Virtual Reality (VR), 360-degree VR, Student recruitment, Virtual storyteller, Workforce shortage},
abstract = {Although it is projected to have significant employment growth in the electrical construction industry, there are not enough young people to join the workforce. It is indispensable for the future of work in construction to explore emerging technologies and effectively attract the younger generation to the construction industry. This paper explores the innovative use of 360-degree immersive environments powered by virtual electricians to tell success stories of the electrical construction trades on the field (VR-Electricians) and understand how such an immersive storytelling approach can attract young people to join the industry. A pretest-posttest design was used for the VR-Electricians assessment. VR-Electricians was found to significantly enhance several aspects of students’ attitude towards the electrical construction industry. VR-Electricians was also rated as a highly usable and easy-to-use system. The outcomes of this study provide construction researchers and practitioners an understanding of how immersive storytelling can be used as a powerful technology-mediated method for attracting students to their field.}
}
@article{ZHU2022101718,
title = {Identifying uncertainty states during wayfinding in indoor environments: An EEG classification study},
journal = {Advanced Engineering Informatics},
volume = {54},
pages = {101718},
year = {2022},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2022.101718},
url = {https://www.sciencedirect.com/science/article/pii/S1474034622001768},
author = {Bingzhao Zhu and Jesus G. Cruz-Garza and Qi Yang and Mahsa Shoaran and Saleh Kalantari},
keywords = {Wayfinding, Uncertainty, Mobile brain/body imaging, Architectural design, Classification},
abstract = {The researchers used a machine-learning classification approach to better understand neurological features associated with periods of wayfinding uncertainty. The participants (n = 30) were asked to complete wayfinding tasks of varying difficulty in a virtual reality (VR) hospital environment. Time segments when participants experienced navigational uncertainty were first identified using a combination of objective measurements (frequency of inputs into the VR controller) and behavioral annotations from two independent observers. Uncertainty time-segments during navigation were ranked on a scale from 1 (low) to 5 (high). The machine-learning model, a Random Forest classifier implemented using scikit-learn in Python, was used to evaluate common spatial patterns of EEG spectral power across the theta, alpha, and beta bands associated with the researcher-identified uncertainty states. The overall predictive power of the resulting model was 0.70 in terms of the area under the Receiver Operating Characteristics curve (ROC-AUC). These findings indicate that EEG data can potentially be used as a metric for identifying navigational uncertainty states, which may provide greater rigor and efficiency in studies of human responses to architectural design variables and wayfinding cues.}
}
@article{FENG2022105573,
title = {Development and evaluation of a VR research tool to study wayfinding behaviour in a multi-story building},
journal = {Safety Science},
volume = {147},
pages = {105573},
year = {2022},
issn = {0925-7535},
doi = {https://doi.org/10.1016/j.ssci.2021.105573},
url = {https://www.sciencedirect.com/science/article/pii/S092575352100415X},
author = {Yan Feng and Dorine C. Duives and Serge P. Hoogendoorn},
keywords = {Virtual reality, Pedestrian wayfinding, Multi-story building, Evacuation, Validity, Route and exit choice},
abstract = {Although understanding wayfinding behaviour in complex buildings is important to ensure pedestrian safety, the state of the art predominantly investigated pedestrian movement in simplified environments. This paper presents a Virtual Reality tool – WayR, that is designed to investigate pedestrian wayfinding behaviour in a multi-story building under both normal and emergency situations. WayR supports free navigation and collects pedestrian walking trajectories, head movements and gaze points automatically. To evaluate WayR, a VR experiment consists of four wayfinding assignments were conducted. The validity and usability of WayR are evaluated using objective measures (i.e., route choice, evacuation exit choice, wayfinding performance, and observation behaviour) and subjective measures (i.e., realism, feeling of presence, system usability, and simulation sickness). Analysis of the objective measures indicates that participants’ wayfinding behaviour in VR matches with findings in the literature. Moreover, we found that overall participants behaved significantly different across wayfinding assignments with increasing complexity. Furthermore, the results of subjective measures indicate a high degree of realism, immersion, usability, and low level of sickness of WayR. Overall, the results demonstrated the face validity, content validity, construct validity and usability of WayR as a research tool to study wayfinding behaviour in a complex multi-story building.}
}
@article{JAHID2022103311,
title = {A contemporary survey on free space optical communication: Potentials, technical challenges, recent advances and research direction},
journal = {Journal of Network and Computer Applications},
volume = {200},
pages = {103311},
year = {2022},
issn = {1084-8045},
doi = {https://doi.org/10.1016/j.jnca.2021.103311},
url = {https://www.sciencedirect.com/science/article/pii/S108480452100299X},
author = {Abu Jahid and Mohammed H. Alsharif and Trevor J. Hall},
keywords = {Optical wireless communication, 5G/B5G, IoT/IoE, Free space optical communication, MIMO FSO, Multi-user FSO},
abstract = {Due to the unprecedented growth of high speed multimedia services and diversified applications initiated from the massive connectivity of IoT devices, 5G and beyond 5G (B5G) cellular communications, the existing electromagnetic spectrum under RF ranges is incapable to tackle the enormous future data rate demands. Free space optical (FSO) communication systems covering an ultra-wide range of unlicensed spectrum have emerged as a promising solution to mitigate conventional RF spectrum scarcity ranging of communication distances from nm to several kilometers. The implication of hybrid FSO, radio over FSO (RoFSO), MIMO FSO systems support ultra high speed 5G/B5G demand by eliminating the limitations of individual technology. FSO offers a broad range of applications both in outdoor and indoor services, for instance, wireless video surveillance, data centers, terrestrial transmission, LAN connectivity, mobile cellular networks, last mile solution, space communications, radio astronomy, remote sensing, and so on. Despite the potential benefits of FSO technology, its link reliability deteriorates due to atmospheric turbulence, cloud induced fading, some other environmental factors such as fog, aerosol, temperature variations, storms, heavy rain, pointing error, and scintillation. This survey presents the overview of several key technologies, significance, demonstration, recent development, and implications of state-of-the-art criteria in terms of spectrum reuse, classification, architecture, physical layer security, and future applications for understanding FSO system among different appealing optical wireless technologies. In addition, the adaptive modulation, channel modeling schemes, relay-aided transmission, cooperative diversity, potential challenges, numerous mitigation techniques, and opportunities in the near future are also outlined to realize the successful deployment of FSO systems.}
}
@article{2021S1,
title = {NCSBN’s Environmental Scan COVID-19 and Its Impact on Nursing and Regulation},
journal = {Journal of Nursing Regulation},
volume = {11},
number = {4, Supplement },
pages = {S1-S36},
year = {2021},
note = {NCSBN’s Environmental Scan COVID-19 and Its Impact on Nursing and Regulation},
issn = {2155-8256},
doi = {https://doi.org/10.1016/S2155-8256(21)00002-8},
url = {https://www.sciencedirect.com/science/article/pii/S2155825621000028},
keywords = {COVID-19, nursing workforce, nursing education, healthcare delivery, public policy}
}
@article{REZAZADEH2011289,
title = {Using affective human–machine interface to increase the operation performance in virtual construction crane training system: A novel approach},
journal = {Automation in Construction},
volume = {20},
number = {3},
pages = {289-298},
year = {2011},
note = {Augmented and Virtual Reality in Architecture, Engineering and Construction (CONVR2009)},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2010.10.005},
url = {https://www.sciencedirect.com/science/article/pii/S092658051000169X},
author = {Iman Mohammad Rezazadeh and Xiangyu Wang and Mohammad Firoozabadi and Mohammad Reza {Hashemi Golpayegani}},
keywords = {Virtual Reality, Facial bioelectric-signals, Affective computing, Affective measures, Construction training},
abstract = {In the construction industry, some progress have been achieved by researchers to design and implement environments for task training using VR technology and its derivatives such as Augmented and Mixed Reality. Although, these developments have been well recognized at the application level, however crucial to the virtual training system is the effective and reliable measurement of training performance of the particular skill and handling the experiment for long-run. It is known that motor skills cannot be measured directly, but only inferred by observing behaviour or performance measures. The typical way of measuring performance is through measuring task completion time and accuracy, but can be supported by indirect measurement of some other factors. In this paper, a virtual crane training system has been developed which can be controlled using control commands extracted from facial gestures and is capable to lift up loads/materials in the virtual construction sites. Then, we integrate affective computing concept into the conventional VR training platform for measuring the cognitive load and level of satisfaction during performance using human's forehead bioelectric-signals. By employing the affective measures and our novel control scheme, the designed interface could be adapted to user's affective status during the performance in real-time. This adaptable user interface approach helps the trainee to cope with the training for long-run performance, leads to gaining more expertise and provides more effective transfer of learning to other operation environments. The detailed methodology of the affective control is presented in the paper. The results and future applications of the proposed method for disabled users, especially from neck down are discussed.}
}
@article{FRAUNE2021102573,
title = {Developing Future Wearable Interfaces for Human-Drone Teams through a Virtual Drone Search Game},
journal = {International Journal of Human-Computer Studies},
volume = {147},
pages = {102573},
year = {2021},
issn = {1071-5819},
doi = {https://doi.org/10.1016/j.ijhcs.2020.102573},
url = {https://www.sciencedirect.com/science/article/pii/S1071581920301750},
author = {Marlena R. Fraune and Ahmed S. Khalaf and Mahlet Zemedie and Poom Pianpak and Zahra NaminiMianji and Sultan A. Alharthi and Igor Dolgov and Bill Hamilton and Son Tran and Z.O. Toups},
keywords = {Human-drone teams, Drones, Wearables, Mixed reality, HMD, Gesture interface, Empirical study},
abstract = {Autonomous robotic vehicles (i.e., drones) are potentially transformative for search and rescue (SAR). This paper works toward wearable interfaces, through which humans team with multiple drones. We introduce the Virtual Drone Search Game as a first step in creating a mixed reality simulation for humans to practice drone teaming and SAR techniques. Our goals are to (1) evaluate input modalities for the drones, derived from an iterative narrowing of the design space, (2) improve our mixed reality system for designing input modalities and training operators, and (3) collect data on how participants socially experience the virtual drones with which they work. In our study, 17 participants played the game with two input modalities (Gesture condition, Tap condition) in counterbalanced order. Results indicated that participants performed best with the Gesture condition. Participants found the multiple controls challenging, and future studies might include more training of the devices and game. Participants felt like a team with the drones and found them moderately agentic. In our future work, we will extend this testing to a more externally valid mixed reality game.}
}
@article{KIM2019102960,
title = {Participatory sensing-based geospatial localization of distant objects for disaster preparedness in urban built environments},
journal = {Automation in Construction},
volume = {107},
pages = {102960},
year = {2019},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2019.102960},
url = {https://www.sciencedirect.com/science/article/pii/S0926580518312378},
author = {Hongjo Kim and Youngjib Ham},
keywords = {Geospatial localization, Participatory sensing, Urban built environments},
abstract = {Although the benefit of participatory sensing for collecting local data over large areas has long been recognized, it has not been widely used for various applications such as disaster preparation due to a lack of geospatial localization capability with respect to a distant object. In such applications, objects of interest need to be robustly localized and documented for supporting data-driven decision-making in site inspection and resource mobilization. However, participatory sensing is inappropriate to localize a distant object due to the absence of ranging sensors in citizens' mobile devices; thus, the localization accuracy varies to a large extent. To address this issue, this study presents a novel geospatial localization method for distant objects based on participatory sensing. The proposed geospatial localization process consists of multiple computational modules—a geographic coordinate conversion, mean-shift clustering, deep learning-based object detection, magnetic declination adjustment, line of sight equation formulation, and the Moore-Penrose generalized inverse method—to improve the localization accuracy in participatory sensing environments. The experiments were conducted in Houston and College Station in Texas to evaluate the proposed method, and the experimental results demonstrated a reasonable localization accuracy, recording the distance errors of 1.5 m to 27.8 m when the distance from observers to the objects of interest were 17 m to 296 m. The proposed method is expected to contribute to rapid data collection over large urban areas, thereby facilitating disaster preparedness that needs to identify locations of distant objects at risk.}
}
@incollection{2019295,
title = {Index},
editor = {Mohammad Jawaid and Mohamed Thariq and Naheed Saba},
booktitle = {Structural Health Monitoring of Biocomposites, Fibre-Reinforced Composites and Hybrid Composites},
publisher = {Woodhead Publishing},
pages = {295-308},
year = {2019},
series = {Woodhead Publishing Series in Composites Science and Engineering},
isbn = {978-0-08-102291-7},
doi = {https://doi.org/10.1016/B978-0-08-102291-7.18001-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780081022917180013}
}
@article{COSTIN2018257,
title = {Building Information Modeling (BIM) for transportation infrastructure – Literature review, applications, challenges, and recommendations},
journal = {Automation in Construction},
volume = {94},
pages = {257-281},
year = {2018},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2018.07.001},
url = {https://www.sciencedirect.com/science/article/pii/S0926580517309470},
author = {Aaron Costin and Alireza Adibfar and Hanjin Hu and Stuart S. Chen},
keywords = {Building Information Modeling (BIM), Bridge Information Modeling (BrIM), Civil Integrated Management (CIM), Civil information Modeling (CiM), Industry Foundation Classes (IFC), Transportation infrastructure, Emerging technologies, Literature review},
abstract = {Transportation infrastructure is a critical component to a nation’s economy, security, and wellbeing. In order to keep up with the rising population, there is a great need for more efficient and cost-effective technologies and techniques to not only repair the infrastructure, but also to advance and expand the transportation infrastructure to sustain the growing population. Building Information Modeling (BIM) has been widely adopted in the building industry, and its established methods and technologies show enormous potential in benefiting the transportation industry. The purpose of this paper is to present a literature review and critical analysis of BIM for transportation infrastructure. A total of 189 publications in the area of BIM for transportation infrastructure were reviewed, including journal articles, conference proceedings, and published reports. Additionally, schemas and file formats from 9 main categories and 34 areas related to transportation infrastructure were reviewed. An application was developed to collect, store, and analyze the publications. Various algorithms were developed and implemented to help in the automation and analysis of the review. The goal of this paper is to provide a comprehensive, up-to-date literature review and critical analysis of research areas regarding BIM for transportation infrastructure to further facilitate research and applications in this domain. Based on the results of the analysis, current topics and trends, applications and uses, emerging technologies, benefits, challenges and limitations, research gaps, and future needs are discussed. Significantly, the contribution of this paper is providing the foundation of current research, gaps, and emerging technologies needed to facilitate further research and applications for both academia and industry stakeholders to develop more efficient and cost-effective techniques necessary to repair, advance, and expand the transportation infrastructure. Furthermore, the results show that the use of BIM for transportation infrastructure has been increasing, although the research has mainly been focusing on roads, highways, and bridges. The results also reveal a major need for a standard neutral exchange format and schema to promote interoperability. Most importantly, the continuing collaboration between academia and industry is required to mitigate most challenges and to realize the full potential of BIM for transportation infrastructure.}
}
@article{MITSUHARA20191670,
title = {Failure-enhanced evacuation training using a VR-based disaster simulator: A comparative experiment with simulated evacuees},
journal = {Procedia Computer Science},
volume = {159},
pages = {1670-1679},
year = {2019},
note = {Knowledge-Based and Intelligent Information & Engineering Systems: Proceedings of the 23rd International Conference KES2019},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2019.09.337},
url = {https://www.sciencedirect.com/science/article/pii/S1877050919315388},
author = {Hiroyuki Mitsuhara and Chie Tanimura and Junko Nemoto and Masami Shishibori},
keywords = {Evacuation training, failure, conformity bias, inactive evacuees, disaster simulator, virtual reality},
abstract = {Evacuation training is an important component of disaster education and survival. Evacuation training using a virtual reality (VR)-based disaster simulator that provides a highly immersive simulated evacuation experience (SEE) has attracted significant attention. To improve the training effect, we propose a failure-enhanced evacuation training model based on Kolb’s experiential learning theory. Our model aims to purposefully induce participants to succumb to conformity bias and fail to evacuate during the first SEE because inactive evacuees (i.e., people who are not evacuating speedily or not starting their evacuation) are simulated in a VR-based disaster simulator. The participants are expected to overcome failure in the second SEE via reflection and conceptualization. A preliminary comparative experiment focused on how simulated evacuees influence the SEE of participants in a VR-based disaster simulator. Results indicated that failure-enhanced evacuation training can successfully improve the training effect.}
}
@article{AMBROGIO2022108158,
title = {Workforce and supply chain disruption as a digital and technological innovation opportunity for resilient manufacturing systems in the COVID-19 pandemic},
journal = {Computers & Industrial Engineering},
volume = {169},
pages = {108158},
year = {2022},
issn = {0360-8352},
doi = {https://doi.org/10.1016/j.cie.2022.108158},
url = {https://www.sciencedirect.com/science/article/pii/S0360835222002285},
author = {Giuseppina Ambrogio and Luigino Filice and Francesco Longo and Antonio Padovano},
keywords = {COVID-19 pandemic, Resilience, Manufacturing systems, Supply chain disruption, Digitalization, Industry 4.0, Additive manufacturing, Operator 4.0},
abstract = {During the SARS-CoV-2 pandemic (also known as COVID-19), workforce downsizing needs, safety requirements, supply chain breaks and inventory shortages affected manufacturing systems’ and supply chain’s responsiveness and resilience. Companies wandered in a disrupted scenario because recommended actions/strategies to survive – and thrive – were not available an improvised actions to keep their operations up and running. This paper analyzes the COVID-19 impacts on the workforce and supply resilience in a holistic manner. The following research questions are discussed: (i) how can manufacturing firms cope with urgent staff deficiencies while sustaining at the same time a healthy and safe workforce in the perspective of socially sustainable and human-centric cyber-physical production systems?; (ii) is remote working (cf. smart working) applicable to shop-floor workers?; (iii) is it possible to overcome supply chain breaks without stopping production? In the first part, we propose three Industry 4.0-driven solutions that would increase the workforce resilience, namely: (i) the Plug-and-Play worker; (ii) the Remote Operator 4.0; (iii) the Predictive Health of the Operational Staff. In the second part, the concepts of (i) Digital & Unconventional Sourcing, i.e. Additive Manufacturing, and (ii) Product/Process Innovation are investigated from a novel business continuity and integration perspective. We ultimately argue that forward-looking manufacturing companies should turn a disruptive event like a pandemic in an opportunity for digital and technological innovation of the workplace inspired by the principles of harmonic digital innovation (that places the human well-being at the center). These aspects are discussed with use cases, system prototypes and results from research projects carried out by the authors and real-world examples arising lessons learned and insights useful for scientists, researchers and managers.}
}
@article{SMETS201139,
title = {Effects of mobile support on situation awareness and navigation in a field and game environment},
journal = {Entertainment Computing},
volume = {2},
number = {1},
pages = {39-46},
year = {2011},
note = {Video Games as Research Instruments},
issn = {1875-9521},
doi = {https://doi.org/10.1016/j.entcom.2011.03.004},
url = {https://www.sciencedirect.com/science/article/pii/S1875952111000140},
author = {Nanja Smets and Guido {te Brake} and Thijs Buurman and Mark Neerincx and Herre {van Oostendorp}},
keywords = {Virtual environment, Mobile support, Field test, Game-based evaluation, Tactile, Unreal engine, Unreal tournament},
abstract = {For surveillance and rescue operations, human navigation and situation awareness should be well-supported. However, proper testing of new and innovative mobile support is hard for such operations. Evaluations in field settings are expensive, difficult to control, potentially dangerous, and may sometimes be impossible to execute. Using a virtual environment may solve these disadvantages of testing in the field. But how well does the performance with mobile support in a virtual environment predict the performance with the same mobile support in the real environment? To establish validity, patterns found in situation awareness, attention and performance in the virtual environment must match with patterns found in the field. This paper describes an experiment that compares these patterns for participants who search for objects in a virtual or field (real) environment. The virtual environment seemed to be sufficient in providing the prominent cues of the field environment that people use to navigate, but navigation itself proved to be far more easy in the field so that navigation support effects differed for both environments.}
}
@article{LI2022117459,
title = {Immersive technology-enabled digital transformation in transportation fields: A literature overview},
journal = {Expert Systems with Applications},
volume = {202},
pages = {117459},
year = {2022},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2022.117459},
url = {https://www.sciencedirect.com/science/article/pii/S0957417422007928},
author = {Fan Li and Amy J.C. Trappey and Ching-Hung Lee and Li Li},
keywords = {Immersive technology, Digital transformation, Transportation, Virtual reality (VR), Augmented reality (AR)},
abstract = {Immersive technology is rapidly emerging as a powerful tool for enhancing the digital transformation in transportation to deal with the complexity, high cost, and uncertainty in the dynamic traffic environment. In this study, we investigate the innovations induced by immersive technologies for transportation fields. The literature (153 articles) published over the past five years were collected and analyzed systematically, pertaining to the lifecycle model of the product–service system, i.e., design, development, evaluation, and applications. The review indicated that immersive systems and scenarios have been developed and applied in various transportation areas, such as air traffic management, autonomous vehicles, railways, highways, and vehicle maintenance. Additionally, the review indicated that immersive technology brings significant benefits to the transportation field and induces significant changes in the interactions between humans and the physical world. These changes are expected to induce digital transformation in several aspects, e.g., digital testbeds for theoretical models and algorithms, immersive and safe digital environments for user studies, and digital training. Based on the review, a novel framework and conceptual lifecycle model of developing immersive technology-enabled digital transformation in transportation is proposed, a novel evaluation matrix for measuring the immersive experience level is established. The results provide essential references for practitioners to apply immersive technology and guidance regarding potential future research directions.}
}
@article{CHLAMTAC200313,
title = {Mobile ad hoc networking: imperatives and challenges},
journal = {Ad Hoc Networks},
volume = {1},
number = {1},
pages = {13-64},
year = {2003},
issn = {1570-8705},
doi = {https://doi.org/10.1016/S1570-8705(03)00013-1},
url = {https://www.sciencedirect.com/science/article/pii/S1570870503000131},
author = {Imrich Chlamtac and Marco Conti and Jennifer J.-N. Liu},
keywords = {MAC, Routing, Energy saving, Security, Performance evaluation},
abstract = {Mobile ad hoc networks (MANETs) represent complex distributed systems that comprise wireless mobile nodes that can freely and dynamically self-organize into arbitrary and temporary, “ad-hoc” network topologies, allowing people and devices to seamlessly internetwork in areas with no pre-existing communication infrastructure, e.g., disaster recovery environments. Ad hoc networking concept is not a new one, having been around in various forms for over 20 years. Traditionally, tactical networks have been the only communication networking application that followed the ad hoc paradigm. Recently, the introduction of new technologies such as the Bluetooth, IEEE 802.11 and Hyperlan are helping enable eventual commercial MANET deployments outside the military domain. These recent evolutions have been generating a renewed and growing interest in the research and development of MANET. This paper attempts to provide a comprehensive overview of this dynamic field. It first explains the important role that mobile ad hoc networks play in the evolution of future wireless technologies. Then, it reviews the latest research activities in these areas, including a summary of MANET’s characteristics, capabilities, applications, and design constraints. The paper concludes by presenting a set of challenges and problems requiring further research in the future.}
}
@article{LAKE201513,
title = {The integrative management of PTSD: A review of conventional and CAM approaches used to prevent and treat PTSD with emphasis on military personnel},
journal = {Advances in Integrative Medicine},
volume = {2},
number = {1},
pages = {13-23},
year = {2015},
note = {Special Issue: Integrative Mental Health},
issn = {2212-9588},
doi = {https://doi.org/10.1016/j.aimed.2014.10.002},
url = {https://www.sciencedirect.com/science/article/pii/S2212962614000480},
author = {James Lake},
keywords = {Alternative, Complementary, Integrative, Military, Trauma, PTSD, Post-traumatic stress disorder, Veterans},
abstract = {Post-traumatic stress disorder (PTSD) may be the most urgent problem the U.S. military is facing today. Pharmacological and psychological interventions reduce the severity of some PTSD symptoms however these conventional approaches have limited efficacy. This issue is compounded by the high rate of co-morbid traumatic brain injury (TBI) and other medical and psychiatric disorders in veterans diagnosed with PTSD and unresolved system-level problems within the Veterans Administration and Department of Defense healthcare services that interfere with adequate and prompt care for veterans and active duty military personnel. This paper is offered as a framework for interdisciplinary dialogue and collaboration between experts in biomedicine and CAM addressing three primary areas of need: resiliency training in high risk military populations, prevention of PTSD following exposure to combat-related trauma, and treatment of established cases of PTSD. The evidence for widely used conventional pharmacological and psychological interventions used in the VA/DOD healthcare systems to treat PTSD is reviewed. Challenges and barriers to adequate assessment and treatment of PTSD in military personnel are discussed. A narrative review of promising CAM modalities used to prevent or treat PTSD emphasizes interventions that are not widely used in VA/DOD clinics and programmes. Interventions reviewed include virtual reality graded exposure therapy (VRGET), brain–computer interface (BCI), EEG biofeedback, cardiac coherence training, EMDR, acupuncture, omega-3 fatty acids and other natural products, lucid dreaming training, and energy therapies. As meditation and mind-body practices are widely offered within VA/DOD programmes and services addressing PTSD the evidence for these modalities is only briefly reviewed. Sources included mainstream medical databases and journals not currently indexed in the mainstream medical databases. Although most interventions discussed are applicable to both civilian and military populations the emphasis is on military personnel. Provisional integrative guidelines are offered with the goal of providing a flexible and open framework when planning interventions aimed at preventing or treating PTSD based on the best available evidence for both conventional and CAM approaches. The paper concludes with recommendations on research and policy within the VA and DOD healthcare systems addressing urgent unmet needs associated with PTSD.}
}
@article{MACKENZIE20223575,
title = {Virtual reality and haptic interfaces for civilian and military open trauma surgery training: A systematic review},
journal = {Injury},
volume = {53},
number = {11},
pages = {3575-3585},
year = {2022},
issn = {0020-1383},
doi = {https://doi.org/10.1016/j.injury.2022.08.003},
url = {https://www.sciencedirect.com/science/article/pii/S0020138322005344},
author = {Colin F. Mackenzie and Tyler E. Harris and Andrea G. Shipper and Eric Elster and Mark W. Bowyer},
keywords = {Virtual, Augmented, Mixed reality, Haptics, ASSET, ASSET+, Haemorrhage Control Skill, Open vascular surgical procedures, Competence benchmark, Simulation of open surgery, Benefit to patient outcomes},
abstract = {Objective
Virtual (VR), augmented (AR), mixed reality (MR) and haptic interfaces make additional avenues available for surgeon assessment, guidance and training. We evaluated applications for open trauma and emergency surgery to address the question: Have new computer-supported interface developments occurred that could improve trauma training for civilian and military surgeons performing open, emergency, non-laparoscopic surgery?
Design
Systematic literature review.
Setting and Participants
Faculty, University of Maryland School of Medicine, Baltimore., Maryland; Womack Army Medical Center, Fort Bragg, North Carolina; Temple University, Philadelphia, Pennsylvania; Uniformed Services University of Health Sciences, and Walter Reed National Military Medical Center, Bethesda, Maryland.
Methods
Structured literature searches identified studies using terms for virtual, augmented, mixed reality and haptics, as well as specific procedures in trauma training courses. Reporting bias was assessed. Study quality was evaluated by the Kirkpatrick's Level of evidence and the Machine Learning to Asses Surgical Expertise (MLASE) score.
Results
Of 422 papers identified, 14 met inclusion criteria, included 282 enrolled subjects, 20% were surgeons, the remainder students, medics and non-surgeon physicians. Study design was poor and sample sizes were low. No data analyses were beyond descriptive and the highest outcome types were procedural success, subjective self-reports, except three studies used validated metrics. Among the 14 studies, Kirkpatrick's level of evidence was level zero in five studies, level 1 in 8 and level 2 in one. Only one study had MLASE Score greater than 9/20. There was a high risk of bias in 6 studies, uncertain bias in 5 studies and low risk of bias in 3 studies.
Conclusions
There was inadequate evidence that VR,MR,AR or haptic interfaces can facilitate training for open trauma surgery or replace cadavers. Because of limited testing in surgeons, deficient study and technology design, risk of reporting bias, no current well-designed studies of computer-supported technologies have shown benefit for open trauma, emergency surgery nor has their use shown improved patient outcomes. Larger more rigorously designed studies and evaluations by experienced surgeons are required for a greater variety of procedures and skills.
Competencies
Medical Knowledge, Practice Based Learning and Improvement, Patient Care, Systems-Based Practice.}
}
@article{BUN2015173,
title = {Application of Professional and Low-cost Head Mounted Devices in Immersive Educational Application},
journal = {Procedia Computer Science},
volume = {75},
pages = {173-181},
year = {2015},
note = {2015 International Conference Virtual and Augmented Reality in Education},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2015.12.235},
url = {https://www.sciencedirect.com/science/article/pii/S1877050915036960},
author = {Paweł Buń and Filip Górski and Radosław Wichniarek and Wiesław Kuczko and Adam Hamrol and Przemysław Zawadzki},
keywords = {virtual reality, low – cost devices, medical application},
abstract = {The paper presents a process of adaptation of the Oculus Rift and Samsung Gear VR devices for needs of immersive training application. The process was described on the example of virtual 3D human body atlas, created using EON Studio software. The aim of this application is to facilitate and make it more attractive to learn anatomy for students of medical disciplines. Possibilities of the application are, among others: selection of visibility level of certain organs or groups of organs, creation of complex sections in 3 planes and launching animations of selected organs. Application of each selected device required additional programming work. The work included both adaptation of Graphical User Interface for different display resolutions, as well as preparation of communication between integrated orientation tracking systems and the application, because none of the selected low-cost HMDs has a position tracking system, to allow navigation in the virtual space, two low-cost solutions were proposed, as well as traditional approach in form of a professional tracking system. First of the proposed low-cost solutions is application of a dedicated, customized controller built in the PUT VR Laboratory using commercial electronics and 3D printing technologies. The second solution is controlling the navigation via specific gestures recognized by the Kinect low-cost tracking device. After application was developed, a group of students tested all possibilities of interaction with the virtual environment using a professional HMD and both low-cost display and tracking solutions. During the evaluation performed by the test group, features like field of view, weight of devices and general impressions and feeling after prolonged use were taken into consideration. Intuitiveness of the proposed navigation solutions was evaluated separately. The evaluation performed by the test group can be used during work on subsequent versions of the medical educational application and design of new peripheral devices.}
}
@article{RAO2022104099,
title = {Real-time monitoring of construction sites: Sensors, methods, and applications},
journal = {Automation in Construction},
volume = {136},
pages = {104099},
year = {2022},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2021.104099},
url = {https://www.sciencedirect.com/science/article/pii/S0926580521005501},
author = {Aravinda S. Rao and Marko Radanovic and Yuguang Liu and Songbo Hu and Yihai Fang and Kourosh Khoshelham and Marimuthu Palaniswami and Tuan Ngo},
keywords = {Real-time monitoring, Construction Site, Sensors, Internet of Things (IoT), Automation},
abstract = {The construction industry is one of the world's largest industries, with an annual budget of $10 trillion globally. Despite its size, the efficiency and growth in labour productivity in the construction industry have been relatively low compared to other sectors, such as manufacturing and agriculture. To this extent, many studies have recognised the role of automation in improving the efficiency and safety of construction projects. In particular, automated monitoring of construction sites is a significant research challenge. This paper provides a comprehensive review of recent research on the real-time monitoring of construction projects. The review focuses on sensor technologies and methodologies for real-time mapping, scene understanding, positioning, and tracking of construction activities in indoor and outdoor environments. The review also covers various case studies of applying these technologies and methodologies for real-time hazard identification, monitoring workers’ behaviour, workers’ health, and monitoring static and dynamic construction environments.}
}
@article{NICHOLS2002251,
title = {Health and safety implications of virtual reality: a review of empirical evidence},
journal = {Applied Ergonomics},
volume = {33},
number = {3},
pages = {251-271},
year = {2002},
note = {Fundamental Reviews in Applied Ergonomics 2002},
issn = {0003-6870},
doi = {https://doi.org/10.1016/S0003-6870(02)00020-0},
url = {https://www.sciencedirect.com/science/article/pii/S0003687002000200},
author = {Sarah Nichols and Harshada Patel},
abstract = {For the last 10 years a number of papers have been written that discuss human factors issues associated with virtual reality (VR). The nature of these papers has gradually evolved from speculation and anecdotal report to empirical research. Despite developments in VR technology, some participants still experience health and safety problems associated with VR use-termed VR-induced symptoms and effects (VRISE). The key concern from the literature is VR-induced sickness, experienced by a large proportion of VR participants, but for the majority these effects are mild and subside quickly. This paper makes a number of recommendations regarding the future direction of research into health and safety implications of VR, including the need to take into account the way in which VR is being used when conducting empirical research: first, to ensure that studies consider both effects and their consequences; second, to ensure that empirical trials reflect the actual likely context of VR use; third, to consider interactions between effects; and finally, to consider ways in which effects can be managed.}
}
@article{LIU2022112403,
title = {A survey of crowd evacuation on passenger ships: Recent advances and future challenges},
journal = {Ocean Engineering},
volume = {263},
pages = {112403},
year = {2022},
issn = {0029-8018},
doi = {https://doi.org/10.1016/j.oceaneng.2022.112403},
url = {https://www.sciencedirect.com/science/article/pii/S0029801822016924},
author = {Kezhong Liu and Yuting Ma and Mozi Chen and Kehao Wang and Kai Zheng},
keywords = {Building evacuation, Ship passenger evacuation, Passenger evacuation behavior, Passenger evacuation optimization, Passenger evacuation assessment},
abstract = {During ship emergencies, a reliable and efficient evacuation system is able to guide passengers to the appropriate muster stations as quickly as possible. The majority of the existing indoor evacuation systems provide emergency guidance for people trapped in general buildings. However, those systems fail to consider the unique challenges of ship passenger evacuation, such as the effect of ship motion on pedestrian motion and the feedback of pedestrian motion on ship inclination state. Consequently, evacuation guidance provided by these schemes may not always be optimal or may even make the evacuation worse due to the differences in the critical factors influencing emergency guiding between land-based buildings and passenger ships. This paper presents a systematic literature overview of recent advances in building evacuation, followed by a description of the challenges unique to evacuating passengers on vessels. Furthermore, the existing ship evacuation research is reviewed from three aspects, i.e., passenger behavior study, ship evacuation optimization, and evaluation of evacuation on passenger ships. A discussion of land-based evacuation schemes and prospects for ship evacuation is also presented.}
}
@article{SCHWEIZER201842,
title = {Psychophysiological reactivity, coping behaviour and intrusive memories upon multisensory Virtual Reality and Script-Driven Imagery analogue trauma: A randomised controlled crossover study},
journal = {Journal of Anxiety Disorders},
volume = {59},
pages = {42-52},
year = {2018},
issn = {0887-6185},
doi = {https://doi.org/10.1016/j.janxdis.2018.08.005},
url = {https://www.sciencedirect.com/science/article/pii/S0887618517306096},
author = {Tina Schweizer and Fritz Renner and Dali Sun and Birgit Kleim and Emily A. Holmes and Brunna Tuschen-Caffier},
keywords = {Risk factors, Psychopathology, Post-traumatic stress, Stress and coping measures, Guided mental imagery, Virtual Reality},
abstract = {Background
Peri- and post-traumatic factors predict the differential development of stress-associated mental disorders. Prospective designs assessing these risk factors in real-time under controlled experimental conditions can overcome limitations of retrospective designs. Therefore, we aimed to investigate multi-sensory, experimental analogues of a traumatic experience delivered in Virtual Reality (VR) or Script-Driven Imagery (SDI).
Methods
In a randomised controlled crossover design, differences in the induced analogue trauma symptoms between multi-sensory analogue trauma by either VR or SDI versus a neutral condition were assessed in 127 non-clinical participants.
Results
Analogue symptoms (psychophysiological responses, coping behaviour and intrusive memories of the experimental trauma) increased following analogue trauma in both VR and SDI, with more analogue symptoms for VR. Psychophysiological arousal was in general higher in VR.
Limitations
The analogue trauma situation of a car park fire that was used may be infrequent in real life.
Conclusions
Multisensory (vision, olfaction, hearing) analogue trauma in VR and SDI offers a useful tool for the induction and real-time assessment of peri- and post-traumatic risk factors for analogue stress-associated psychopathology. VR was more effective in inducing analogue symptoms than SDI, even though the latter might be more personalised. New experimental models for studying trauma exposure and responses may contribute to a better understanding of risk factors and help to identify and protect individuals at risk.}
}
@article{REINA202012,
title = {The moving target of visualization software for an increasingly complex world},
journal = {Computers & Graphics},
volume = {87},
pages = {12-29},
year = {2020},
issn = {0097-8493},
doi = {https://doi.org/10.1016/j.cag.2020.01.005},
url = {https://www.sciencedirect.com/science/article/pii/S0097849320300078},
author = {Guido Reina and Hank Childs and Krešimir Matković and Katja Bühler and Manuela Waldner and David Pugmire and Barbora Kozlíková and Timo Ropinski and Patric Ljung and Takayuki Itoh and Eduard Gröller and Michael Krone},
keywords = {Software engineering, Visualization, Visualization community, Visualization research, Visualization software},
abstract = {Visualization has evolved into a mature scientific field and it has also become widely accepted as a standard approach in diverse fields, including physics, life sciences, and business intelligence. However, despite its successful development, there are still many open research questions that require customized implementations in order to explore and establish concepts, and to perform experiments and take measurements. Many methods and tools have been developed and published but most are stand-alone prototypes and have not reached a mature state that can be used in a reliable manner by collaborating domain scientists or a wider audience. In this study, we discuss the challenges, solutions, and open research questions that affect the development of sophisticated, relevant, and novel scientific visualization solutions with minimum overheads. We summarize and discuss the results of a recent National Institute of Informatics Shonan seminar on these topics.}
}
@incollection{2018863,
title = {Subject Index},
editor = {William R. Sherman and Alan B. Craig},
booktitle = {Understanding Virtual Reality (Second Edition)},
publisher = {Morgan Kaufmann},
edition = {Second Edition},
address = {Boston},
pages = {863-901},
year = {2018},
series = {The Morgan Kaufmann Series in Computer Graphics},
isbn = {978-0-12-800965-9},
doi = {https://doi.org/10.1016/B978-0-12-800965-9.18001-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780128009659180018}
}
@article{TONGUZ2010531,
title = {Multiplayer games over Vehicular Ad Hoc Networks: A new application},
journal = {Ad Hoc Networks},
volume = {8},
number = {5},
pages = {531-543},
year = {2010},
note = {Vehicular Networks},
issn = {1570-8705},
doi = {https://doi.org/10.1016/j.adhoc.2009.12.009},
url = {https://www.sciencedirect.com/science/article/pii/S1570870509001334},
author = {Ozan K. Tonguz and Mate Boban},
keywords = {Multiplayer games, VANET, Vehicular networks, Real-time applications, Commercial applications},
abstract = {In this paper we investigate the possibility of a new type of application, namely multiplayer games, in a Vehicular Ad Hoc Network (VANET) environment. First, we analyze the available empirical data on travel and traffic volume in the United States, and point out the most important challenges that have to be met in order to enable multiplayer games over VANET. We then propose a new paradigm of multiplayer games over VANET, one which utilizes the new, interactive and dynamic VANET environment, while adapting to its inherent constraints.}
}
@article{FU2021105245,
title = {Why do people make risky decisions during a fire evacuation? Study on the effect of smoke level, individual risk preference, and neighbor behavior},
journal = {Safety Science},
volume = {140},
pages = {105245},
year = {2021},
issn = {0925-7535},
doi = {https://doi.org/10.1016/j.ssci.2021.105245},
url = {https://www.sciencedirect.com/science/article/pii/S0925753521000904},
author = {Meiqing Fu and Rui Liu and Yu Zhang},
keywords = {Evacuation, Risk-taking behavior, Route selection, Smoke, Risk preference},
abstract = {People make risky decisions during fire evacuations such as moving through smoke. However, the reasons behind such risk-taking decisions have not been investigated in controlled experiments. Using an immersive virtual reality (VR)-based controlled experiment, this study investigated the effect of smoke level, individual risk preference, and neighbor behavior on individual risky decisions to take a smoky shortcut for evacuations. In the present experiment, participants’ risk tolerance was measured using questionnaires, and their route choices were recorded when they evacuated from a virtual building under different smoke scenarios. A high density of smoke reduced the use of a smoky shortcut but did not prevent some participants from using the shortcut. Participants with high-risk tolerance were more likely to take a risky shortcut. However, individual attitude towards risk is unstable; hence, the risk preference revealed in daily behaviors under a low-danger context may not reveal individual risky decisions in face of high hazards. Moreover, neighbor behavior also had a significant impact on participants’ risky decisions. The implications of our findings on evacuation training and management and evacuation simulation models were also discussed.}
}
@article{MEINER2019445,
title = {Combining virtual reality and mobile eye tracking to provide a naturalistic experimental environment for shopper research},
journal = {Journal of Business Research},
volume = {100},
pages = {445-458},
year = {2019},
issn = {0148-2963},
doi = {https://doi.org/10.1016/j.jbusres.2017.09.028},
url = {https://www.sciencedirect.com/science/article/pii/S0148296317303478},
author = {Martin Meißner and Jella Pfeiffer and Thies Pfeiffer and Harmen Oppewal},
keywords = {Eye tracking, Visual attention, Virtual reality, Augmented reality, Assistance system, Shopper behavior},
abstract = {Technological advances in eye tracking methodology have made it possible to unobtrusively measure consumer visual attention during the shopping process. Mobile eye tracking in field settings however has several limitations, including a highly cumbersome data coding process. In addition, field settings allow only limited control of important interfering variables. The present paper argues that virtual reality can provide an alternative setting that combines the benefits of mobile eye tracking with the flexibility and control provided by lab experiments. The paper first reviews key advantages of different eye tracking technologies as available for desktop, natural and virtual environments. It then explains how combining virtual reality settings with eye tracking provides a unique opportunity for shopper research in particular regarding the use of augmented reality to provide shopper assistance.}
}
@article{SANTAMARIABONFIL2020103871,
title = {Learning analytics for student modeling in virtual reality training systems: Lineworkers case},
journal = {Computers & Education},
volume = {151},
pages = {103871},
year = {2020},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2020.103871},
url = {https://www.sciencedirect.com/science/article/pii/S0360131520300701},
author = {Guillermo Santamaría-Bonfil and María Blanca Ibáñez and Miguel Pérez-Ramírez and Gustavo Arroyo-Figueroa and Francisco Martínez-Álvarez},
keywords = {Learning analytics, Performance prediction, Feature importance analysis, Exploratory data analysis, Virtual reality},
abstract = {Live-line maintenance is a high risk activity. Hence, lineworkers require effective and safe training. Virtual Reality Training Systems (VRTS) provide an affordable and safe alternative for training in such high risk environments. However, their effectiveness relies mainly on having meaningful activities for supporting learning and on their ability to detect untrained students. This study builds a student model based on Learning Analytics (LA), using data collected from 1399 students that used a VRTS for the maintenance training of lineworkers in 329 courses carried out from 2008 to 2016. By employing several classifiers, the model allows discriminating between trained and untrained students in different maneuvers using three minimum evaluation proficiency scores. Using the best classifier, a Feature Importance Analysis is carried out to understand the impact of the variables regarding the trainees’ final performances. The model also involves the exploration of the trainees’ trace data through a visualization tool to pose non-observable behavioral variables related to displayed errors. The results show that the model can discriminate between trained and untrained students, the Random Forest algorithm standing out. The feature importance analysis revealed that the most relevant features regarding the trainees’ final performance were profile and course variables along with specific maneuver steps. Finally, using the visual tool, and with human expert aid, several error patterns in trace data associated with misconceptions and confusion were identified. In the light of these, LA enables disassembling the data jigsaw quandary from VRTS to enhance the human-in-the-loop evaluation.}
}
@article{MAANI201283,
title = {Battlefield Pain Control: Forging Ahead by Building on the Past},
journal = {Perioperative Nursing Clinics},
volume = {7},
number = {1},
pages = {83-88},
year = {2012},
note = {Burn Care Update},
issn = {1556-7931},
doi = {https://doi.org/10.1016/j.cpen.2011.12.001},
url = {https://www.sciencedirect.com/science/article/pii/S1556793111000866},
author = {Christopher V. Maani},
keywords = {Pain management, Combat casualties, Battlefield medicine, Analgesics}
}
@article{TABONE2021100293,
title = {Vulnerable road users and the coming wave of automated vehicles: Expert perspectives},
journal = {Transportation Research Interdisciplinary Perspectives},
volume = {9},
pages = {100293},
year = {2021},
issn = {2590-1982},
doi = {https://doi.org/10.1016/j.trip.2020.100293},
url = {https://www.sciencedirect.com/science/article/pii/S2590198220302049},
author = {Wilbert Tabone and Joost {de Winter} and Claudia Ackermann and Jonas Bärgman and Martin Baumann and Shuchisnigdha Deb and Colleen Emmenegger and Azra Habibovic and Marjan Hagenzieker and P.A. Hancock and Riender Happee and Josef Krems and John D. Lee and Marieke Martens and Natasha Merat and Don Norman and Thomas B. Sheridan and Neville A. Stanton},
keywords = {Automated vehicles, External human-machine interfaces, Smart infrastructure, Augmented reality, Virtual reality, Position paper},
abstract = {Automated driving research over the past decades has mostly focused on highway environments. Recent technological developments have drawn researchers and manufacturers to look ahead at introducing automated driving in cities. The current position paper examines this challenge from the viewpoint of scientific experts. Sixteen Human Factors researchers were interviewed about their personal perspectives on automated vehicles (AVs) and the interaction with VRUs in the future urban environment. Aspects such as smart infrastructure, external human-machine interfaces (eHMIs), and the potential of augmented reality (AR) were addressed during the interviews. The interviews showed that the researchers believed that fully autonomous vehicles will not be introduced in the coming decades and that intermediate levels of automation, specific AV services, or shared control will be used instead. The researchers foresaw a large role of smart infrastructure and expressed a need for AV-VRU segregation, but were concerned about corresponding costs and maintenance requirements. The majority indicated that eHMIs will enhance future AV-VRU interaction, but they noted that implicit communication will remain dominant and advised against text-based and instructive eHMIs. AR was commended for its potential in assisting VRUs, but given the technological challenges, its use, for the time being, was believed to be limited to scientific experiments. The present expert perspectives may be instrumental to various stakeholders and researchers concerned with the relationship between VRUs and AVs in future urban traffic.}
}
@article{DUGGAL2021101791,
title = {Infrastructure, mobility and safety 4.0: Modernization in road transportation},
journal = {Technology in Society},
volume = {67},
pages = {101791},
year = {2021},
issn = {0160-791X},
doi = {https://doi.org/10.1016/j.techsoc.2021.101791},
url = {https://www.sciencedirect.com/science/article/pii/S0160791X21002669},
author = {Angel Swastik Duggal and Rajesh Singh and Anita Gehlot and Lovi Raj Gupta and Sheik Vaseem Akram and Chander Prakash and Sunpreet Singh and Raman Kumar},
keywords = {Artificial intelligence (AI), Big data, Electric vehicles (EV), Digitalization, Sustainability, Machine learning (ML), Mobility},
abstract = {This study explores the modernization of road-based technologies for the enhancement of mobility while also implementing safer transportation. Mobility plays a critical role in everyday life on a micro and a macro scale combined. Modernization in mobility would enable establishment of a sustainable, digitalized and informed society. The inclusion of AI/ML to enhance road environment, curbing driver distraction, adopting electric vehicles, and integrating low power computing units in vehicular networks are among the potential recommendations for strengthening the evolving digital road architecture. The current ecosystem surrounding road safety and mobility can be boosted even further upon integrating products of modern technology into the classical elements of transportation. Modern technologies are classified and perceptually investigated by realizing the current challenges and proposing seamless potential extensions to the existing infrastructure from each domain. Techno-administrative concepts like the regulation of individual risk profiles for achieving a safer road environment are addressed.}
}
@article{HUANG2022104593,
title = {Technological solutions for promoting employees' knowledge levels and practical skills: An SVVR-based blended learning approach for professional training},
journal = {Computers & Education},
volume = {189},
pages = {104593},
year = {2022},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2022.104593},
url = {https://www.sciencedirect.com/science/article/pii/S0360131522001646},
author = {Hsin Huang and Gwo-Jen Hwang and Morris Siu-Yung Jong},
keywords = {Teaching/learning strategies, Improving classroom teaching, Pedagogical issues, Interactive learning environments},
abstract = {In professional training programs, how to help learners fully understand the contexts and problem-solving procedure in the workplace is a crucial and challenging issue. Due to the advancements of computer and multimedia technology, many professional training programs have applied technology to provide richer learning content. Blended learning is a learning approach combining online and physical courses. In the blended learning mode, learners can not only learn through multimedia teaching materials, but also interact and practice with teachers and students in online and physical classrooms. However, the conventional blended learning (C-BL) mode mainly presents teaching content through online videos and physical courses. In such a learning environment with one-way information transmission and without experience, it is not easy for most learners to experience the actual situations encountered in the professional training process, which affects their judgment and actual handling performance. In order to tackle this problem, this research adopted spherical video-based virtual reality (SVVR) technology and applied it in a general registered nurse (RN) training program via a blended learning mode. To verify the effects of this teaching approach, a quasi-experimental study was conducted in a RN training program in a large-scale hospital. The experimental group employed the SVVR-BL mode while the control group employed the C-BL mode. The results indicated that the SVVR-BL mode could not only improve learners' learning achievement, but also enhance their problem-solving tendency, meta-cognition tendency, and classroom engagement. The practical skills test results in the workplace further implied that, compared to the learners who adopted the C-BL mode, learners who adopted the SVVR-BL mode had better judgment, analysis, and overall performance of the handling process when encountering practical problems. As a result, SVVR-BL not only helped learners gain knowledge and improve their higher order thinking, but also assisted them in applying what they had learned to solve real problems. This result can serve as an important reference for SVVR-BL studies and the design of professional training programs in the future.}
}
@article{YUAN2021132,
title = {Immersive sketch-based tree modeling in virtual reality},
journal = {Computers & Graphics},
volume = {94},
pages = {132-143},
year = {2021},
issn = {0097-8493},
doi = {https://doi.org/10.1016/j.cag.2020.12.001},
url = {https://www.sciencedirect.com/science/article/pii/S0097849320301813},
author = {Qi Yuan and Yongjian Huai},
keywords = {Tree modeling, Virtual reality, 3D sketching, Immersive modeling, Twigs generation},
abstract = {Tree modeling has been a widely-discussed topic in computer graphics. However, with existing methods, the modeling process is occupied with complex data collection and tedious parameter adjustment, lacking a rich sensory modeling experience. In this paper, we propose an approach to sketch-based tree modeling in an immersive virtual reality environment, aiming to lower the difficulty of modeling and enhance the immersion in the designing process. We first present a sketch sampling and points optimization algorithm to obtain the skeleton of the branch in 3D space. As generating geometry along the skeleton, we apply a vector-projection method to fix the branch polygon twisting. Then, we introduce a bidirectional ray-hit algorithm to determine the branch radius as real-time sketching. To generate random twigs on branches, we introduce a twigs generation algorithm based on Perlin noise and the parent branch direction. Finally, we design a series of interactive methods for users to create tree models in a 3D virtual scene with the VR HMD and controller. Experimental results indicate that our approach can accomplish creating realistic tree models in real-time. The interactive and immersive modeling experience enables users to readily convey their ideas on tree structures in a simple and direct way of sketching. Visualizing and modifying the real-time generated branch results can contribute to provoking the inspiration for creation.}
}
@article{CROFTON2019102178,
title = {Potential applications for virtual and augmented reality technologies in sensory science},
journal = {Innovative Food Science & Emerging Technologies},
volume = {56},
pages = {102178},
year = {2019},
issn = {1466-8564},
doi = {https://doi.org/10.1016/j.ifset.2019.102178},
url = {https://www.sciencedirect.com/science/article/pii/S1466856418314449},
author = {E.C. Crofton and C. Botinestean and M. Fenelon and E. Gallagher},
keywords = {Virtual reality, Augmented reality, Emerging technologies, Sensory science},
abstract = {Sensory science has advanced significantly in the past decade and is quickly evolving to become a key tool for predicting food product success in the marketplace. Increasingly, sensory data techniques are moving towards more dynamic aspects of sensory perception, taking account of the various stages of user-product interactions. Recent technological advancements in virtual reality and augmented reality have unlocked the potential for new immersive and interactive systems which could be applied as powerful tools for capturing and deciphering the complexities of human sensory perception. This paper reviews recent advancements in virtual and augmented reality technologies and identifies and explores their potential application within the field of sensory science. The paper also considers the possible benefits for the food industry as well as key challenges posed for widespread adoption. The findings indicate that these technologies have the potential to alter the research landscape in sensory science by facilitating promising innovations in five principal areas: consumption context, biometrics, food structure and texture, sensory marketing and augmenting sensory perception. Although the advent of augmented and virtual reality in sensory science offers new exciting developments, the exploitation of these technologies is in its infancy and future research will understand how they can be fully integrated with food and human responses.
Industrial relevance
The need for sensory evaluation within the food industry is becoming increasingly complex as companies continuously compete for consumer product acceptance in today's highly innovative and global food environment. Recent technological developments in virtual and augmented reality offer the food industry new opportunities for generating more reliable insights into consumer sensory perceptions of food and beverages, contributing to the design and development of new products with optimised consumer benefits. These technologies also hold significant potential for improving the predictive validity of newly launched products within the marketplace.}
}
@article{SHERIDAN1989487,
title = {Telerobotics},
journal = {Automatica},
volume = {25},
number = {4},
pages = {487-507},
year = {1989},
issn = {0005-1098},
doi = {https://doi.org/10.1016/0005-1098(89)90093-9},
url = {https://www.sciencedirect.com/science/article/pii/0005109889900939},
author = {T.B. Sheridan},
keywords = {Robots, manipulation, man-machine systems, artificial intelligence, telecontrol},
abstract = {The concepts of telerobotics, and more generally teleoperation—extension of human sensing and manipulating capability by coupling through communication means to artificial sensors and actuators—are discussed, along with related concepts of telepresence, robotics and supervisory control. Relevant historical developments are reviewed. Current and future applications to space, undersea, nuclear power, the handicapped, surgery, terrestrial mining, construction and maintenance, warehousing, firefighting, policing and military operations are briefly described. Current and new research problems are presented in telesensing, teleactuating, computer-aided supervisory control, and the interactions between the human, computer, teleoperator and task. Finally, some future social implications are discussed. The emphasis throughout is on human-machine interaction rather than on teleoperator hardware or software.}
}
@article{JOZWIAK2017202,
title = {Advanced mobile and wearable systems},
journal = {Microprocessors and Microsystems},
volume = {50},
pages = {202-221},
year = {2017},
issn = {0141-9331},
doi = {https://doi.org/10.1016/j.micpro.2017.03.008},
url = {https://www.sciencedirect.com/science/article/pii/S0141933117300741},
author = {Lech Jóźwiak},
keywords = {Cyber-physical systems, Mobile systems, Heterogeneous systems, Massively parallel systems, Multi-processor systems on a chip, Automated design technology},
abstract = {The recent spectacular progress in the microelectronic, information, communication, material and sensor technologies created a big stimulus towards development of smart communicating cyber-physical systems (CPS) and Internet of Things (IoT). CPS and IoT are undergoing an explosive growth to a large degree related to advanced mobile systems like smart automotive and avionic systems, mobile robots and wearable devices. The huge and rapidly developing markets of sophisticated mobile cyber-physical systems represent great opportunities, but these opportunities come with a price of unusual system complexity, as well as, stringent and difficult to satisfy requirements of many modern applications. Specifically, smart cars and various wearable systems to a growing degree involve big instant data from multiple complex sensors or other systems, and are required to provide continuous autonomous service in a long time. In consequence, they demand a guaranteed (ultra-)high performance and/or (ultra-)low energy consumption, while requiring a high reliability, safety and security. To adequately address these demands, sophisticated embedded computing and embedded design technologies are needed. After an introduction to modern mobile systems, this paper discusses the huge heterogeneous area of these systems, and considers serious issues and challenges in their design. Subsequently, it discusses the embedded computing and design technologies needed to adequately address the issues and overcome the challenges in order to satisfy the stringent requirements of the modern mobile systems.}
}
@article{SCHMUNTZSCH201370,
title = {The Warning Glove: Wearable Computing Technology for Maintenance Assistance in IPS2},
journal = {IFAC Proceedings Volumes},
volume = {46},
number = {15},
pages = {70-75},
year = {2013},
note = {12th IFAC Symposium on Analysis, Design, and Evaluation of Human-Machine Systems},
issn = {1474-6670},
doi = {https://doi.org/10.3182/20130811-5-US-2037.00007},
url = {https://www.sciencedirect.com/science/article/pii/S1474667016330476},
author = {Ulrike Schmuntzsch and Lea Henrike Feldhaus},
keywords = {action-specific warning glove, wearable computing technology, smart clothing, multimodality, maintenance assistance, human error, Industrial Product-Service Systems (IPS)},
abstract = {This paper presents an approach on how multimodality and wearable technology can be used to design an innovative device for maintenance assistance of human operators in Industrial Product-Service Systems (IPS2). Based on findings from wearable computing technology and multimodality in warning design, the concept and prototypic realization of a multimodal action-specific warning glove is introduced. This glove provides visual, auditory and haptic feedback. To test the glove's usability the maintenance scenario “changing a spindle” was used. The results of the short version of the ISONORM 9241/110 questionnaire encourage further improvements of the warning glove.}
}
@article{VOIGT2024104161,
title = {Testing the hormesis hypothesis on motor behavior under stress},
journal = {Applied Ergonomics},
volume = {115},
pages = {104161},
year = {2024},
issn = {0003-6870},
doi = {https://doi.org/10.1016/j.apergo.2023.104161},
url = {https://www.sciencedirect.com/science/article/pii/S0003687023001990},
author = {Laura Voigt and Yannick Hill and Marie Ottilie Frenkel},
keywords = {Antifragility, Yerkes-Dodson law, Curvilinear association, Virtual reality, Police},
abstract = {While much research has focused on the deleterious effects of stress on goal-directed behavior in recent decades, current views increasingly discuss growth under stress, often assuming dose-dependent effects of stress in a curvilinear association. This is based on the concept of hormesis, which postulates a strengthening effect of stress at low-to-moderate doses. Leveraging this approach, hormetic curves indicate under which stress dose an individual is able to maintain or even increase goal-directed behavior. The present study aimed to test the hormetic effect of low-to-moderate stress on tactical movement performance in the context of police operational scenarios in virtual reality. In teams of three to four, 37 riot police officers had to search a building for a potentially aggressive perpetrator in three scenarios with escalating stress potential (i.e., increasing weapon violence and number of civilians). Tactical movement performance as behavioral response was quantified by the sample entropy of each officer's velocity derived from positional data. To account for inter-individuality in response to the scenarios, we assessed self-reported stress, anxiety, mental effort, and vagally mediated heart rate variability. Specifically, we tested the quadratic associations between tactical movement performance and stress parameters, respectively. Random-intercept-random-slope regressions revealed neither significant linear nor quadratic associations between any of the stress parameters and performance. While we did not find evidence for hormesis in the present study, it stimulates theoretical discussions about the definition of “baseline” functioning and how the understanding of hormesis can move from psychological to behavioral adaptations to stressors.}
}
@article{YORK2004771,
title = {Human–computer interaction issues for mobile computing in a variable work context},
journal = {International Journal of Human-Computer Studies},
volume = {60},
number = {5},
pages = {771-797},
year = {2004},
note = {HCI Issues in Mobile Computing},
issn = {1071-5819},
doi = {https://doi.org/10.1016/j.ijhcs.2003.07.004},
url = {https://www.sciencedirect.com/science/article/pii/S1071581904000035},
author = {Judy York and Parag C Pendharkar},
abstract = {The current paper takes an introspective look at the human–computer interaction (HCI) issues for mobile computing in a variable work context. We catalogue the current research in four major categories. The major findings of our study are following. (1) A majority of HCI issues, about 58%, fall under the category of computer systems and interface architecture implications. (2) 23% of the articles focus on development and implementation issues. (3) 13% of the articles focus on use and context of computer issues. (4) 6% of the articles focus on human characteristics issues. Further, the literature indicates that the field services is a main application of mobile computing (46%) followed by sales force (21%), health care (17%), fieldwork (8%), insurance claims (4%) and journalism (4%).}
}
@article{DHOKE202368,
title = {Is there a relationship between time pressure and pedestrian non-compliance? A systematic review},
journal = {Transportation Research Part F: Traffic Psychology and Behaviour},
volume = {93},
pages = {68-89},
year = {2023},
issn = {1369-8478},
doi = {https://doi.org/10.1016/j.trf.2023.01.001},
url = {https://www.sciencedirect.com/science/article/pii/S1369847823000025},
author = {Apurwa Dhoke and Pushpa Choudhary},
keywords = {Intersections, Non-compliance Behaviour, Time pressure, Pedestrians},
abstract = {Pedestrians are usually referred to as the most vulnerable road users because they lack sound protection against crashes. The danger of collisions for pedestrians increases at intersection crosswalks due to the non-compliance behaviour of pedestrians at such multi-directional traffic locations. To acquire a greater comprehension, it is indeed imperative to understand pedestrian behaviour at such sites. Therefore, this systematic review aims to assess the risk associated with non-compliance behaviour and the primary causes of non-compliance behaviour at intersections. The study also explored the relationship between time pressure and non-compliance road crossing behaviour. The authors searched the Web of Science, Google Scholar, Scopus, and Semantic to identify the required studies. After excluding books, review papers, non-English research, proceedings, duplicates, and irrelevant studies, 73 pieces of literature were identified for the review process. The current study enlisted all the elements that influence the non-compliance behaviour of pedestrians. Many factors, such as time of day, weather conditions, land use, etc., have a substantial effect on non-compliance but have not been sufficiently studied to establish broad conclusions. Consequently, in exploring the fundamental reasons for non-compliance behaviour, it was found that time--saving or being in a hurry is one of the strong influencers for non-compliance behaviour. Hence, these findings indicate a positive correlation between time pressure and the non-compliance behaviour of pedestrians. However, even though time pressure is a primary source of non-compliance, studies illustrating the impact of time pressure on pedestrian decision-making behaviour are extremely limited. Furthermore, because all time pressure studies have been limited to midblock crossings, it is worthwhile to assess the role of time pressure in pedestrian safety in complex intersection scenarios.}
}
@article{CINNAMON2023102044,
title = {360-degree video for virtual place-based research: A review and research agenda},
journal = {Computers, Environment and Urban Systems},
volume = {106},
pages = {102044},
year = {2023},
issn = {0198-9715},
doi = {https://doi.org/10.1016/j.compenvurbsys.2023.102044},
url = {https://www.sciencedirect.com/science/article/pii/S0198971523001072},
author = {Jonathan Cinnamon and Lindi Jahiu},
keywords = {360 video, Virtual reality, Place-based research, Visualization, Panoramic, Virtual geography},
abstract = {360-degree video is an immersive technology used in research across academic disciplines. This paper provides the first comprehensive review on the use of 360-degree video for virtual place-based research, highlighting its use in experimental, experiential, and environmental observation studies. Five key research domains for 360-degree video are described: tourism and cultural heritage; built environment and land use; natural environment; health and wellbeing; and transportation and safety. 360-degree video offers considerable advantages compared to unidirectional video, computer-generated virtual reality, and map-based geographic representation. Benefits include ease of use, low-cost, interactivity, sense of immersive realism, remote accessibility, and the ability to capture and analyze places in a fully panoramic field of view. Limitations include additional costs associated with virtual reality viewing technologies, simulation sickness and discomfort, and viewer distraction due to the technology's novelty and immersive affordances. This paper also outlines a future research agenda, including the possibility of moving beyond the ‘testing and trialling’ of 360-degree video since it provides novel research opportunities distinct from either ‘real’ experience or conventional forms of visual and spatial representation. Overall, this paper provides detailed evidence for researchers interested in using 360-degree video for virtual research on built, social, and natural environments and human-environment interactions.}
}
@article{TUCKER20181,
title = {The effects of information and hazard on evacuee behavior in virtual reality},
journal = {Fire Safety Journal},
volume = {99},
pages = {1-11},
year = {2018},
issn = {0379-7112},
doi = {https://doi.org/10.1016/j.firesaf.2018.04.011},
url = {https://www.sciencedirect.com/science/article/pii/S0379711217300152},
author = {A. Tucker and K.L. Marsh and T. Gifford and X. Lu and P.B. Luh and R.S. Astur},
keywords = {Virtual reality, Evacuation, Anxiety, Information, Hazard, Navigation},
abstract = {Many contextual factors can influence evacuees' choice of egress route during an emergency. Anxiety caused by the emergency situation may lead to suboptimal choices, resulting in slower evacuation and greater risk of injury or death. The present pilot study tests the influence of hazard level (presence of visible fire and smoke) and information about an obstacle (delivered verbally or through signage) on evacuees' anxiety levels and choice of egress route in a virtual reality (VR) simulation of a fire evacuation with multiple possible exits. Physiological measures were recorded and used to validate the efficacy of VR in inducing anxiety germane to the situation of interest. Consistent with our expectations, providing information about the obstacle was shown to decrease total evacuation time. Contrary to our predictions, it did not significantly impact evacuees' choice of exit. Information also had a marginally significant effect on participants' self-reported anxiety. Providing more targeted information may further reduce anxiety and evacuation time. More generally, VR appears well-suited to assessing individual and psychological factors in evacuations.}
}
@article{MITSUHARA20212105,
title = {Expressing Disaster Situations for Evacuation Training Using Markerless Augmented Reality},
journal = {Procedia Computer Science},
volume = {192},
pages = {2105-2114},
year = {2021},
note = {Knowledge-Based and Intelligent Information & Engineering Systems: Proceedings of the 25th International Conference KES2021},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2021.08.218},
url = {https://www.sciencedirect.com/science/article/pii/S1877050921017142},
author = {Hiroyuki Mitsuhara and Chie Tanimura and Junko Nemoto and Masami Shishibori},
keywords = {Augmented reality, disaster education, evacuation training, smartphone application},
abstract = {Evacuation training is crucial for protecting human lives from natural and man-made disasters, but it should be more realistic to achieve training effects. In this study, we focused on expressing disaster situations using markerless augmented reality to achieve realistic evacuation training. We prototyped a scenario-based evacuation training system that superimposed three-dimensional computer graphics of disaster situations (e.g. fire and debris) onto real-time vision (captured by Android tablets or smartphones) using ARCore and Unity3D. Through preliminary experiments, we found that the prototype system can provide realistic expression and potentially be used for evacuation training, but we have not yet clarified the training results and how the expressions influenced participants’ emotions.}
}
@article{BURIGAT201692,
title = {Passive and active navigation of virtual environments vs. traditional printed evacuation maps: A comparative evaluation in the aviation domain},
journal = {International Journal of Human-Computer Studies},
volume = {87},
pages = {92-105},
year = {2016},
issn = {1071-5819},
doi = {https://doi.org/10.1016/j.ijhcs.2015.11.004},
url = {https://www.sciencedirect.com/science/article/pii/S1071581915001809},
author = {Stefano Burigat and Luca Chittaro},
keywords = {Virtual environments, Navigation, Maps, Evacuation, Safety, Education, Training, Aviation},
abstract = {Printed maps are the most common tool to prepare people for emergency evacuation in contexts such as public buildings or transportation. Unfortunately, they are poorly understood and often ignored by people. Virtual environments (VEs) could be a more effective method to support people in acquiring spatial knowledge about the real-world environment to evacuate. This paper pursues three main goals. First, we propose a VE-based tool to support spatial knowledge acquisition for evacuation purposes, using aviation as a real-world domain in which such knowledge is crucial for passengers’ safety. Second, we study in detail one of the VE design choices (active or passive navigation), comparing a version of our tool in which users navigate by actively controlling their position with another version in which users are passively led along pre-defined routes. Third, we contrast the two versions of the tool with the traditional, printed diagrammatic map provided to passengers by airlines. Results of our study show that the VE-based approach produces objectively better spatial knowledge when users are asked to pinpoint their assigned position in the environment, and that active navigation produces a performance improvement in a subsequent virtual evacuation. Moreover, the VE-based approach is perceived as more enjoyable, easier to comprehend and more effective than printed maps when active navigation is available.}
}
@article{KHAN2023955,
title = {Technology-enhanced trauma training in low-resource settings: A scoping review and feasibility analysis of educational technologies},
journal = {Journal of Pediatric Surgery},
volume = {58},
number = {5},
pages = {955-963},
year = {2023},
issn = {0022-3468},
doi = {https://doi.org/10.1016/j.jpedsurg.2023.01.039},
url = {https://www.sciencedirect.com/science/article/pii/S0022346823000581},
author = {Minahil Khan and Fabio Botelho and Laura Pinkham and Elena Guadagno and Dan Poenaru},
keywords = {Virtual reality, Advanced Trauma Life Support, Education, Medical, Simulation training, High fidelity simulation training},
abstract = {Background
Lack of training contributes to the burden of trauma-related mortality and morbidity in low- and lower-middle-income countries (LMICs). Educational technologies present a unique opportunity to enhance the quality of trauma training. Therefore, this study reviews current technologies used in trauma courses and evaluates their feasibility for LMICs.
Methods
We conducted a scoping review evaluating the learning outcomes of technology-enhanced training in general trauma assessment, team skills or any procedures covered in the 2020 Advanced Trauma Life Support® program. Based on the Technology-Enhanced Learning criteria, we created and applied a feasibility analysis tool to evaluate the technologies for use in LMICs.
Results
We screened 6471 articles and included 64. Thirty-four (45%) articles explored training in general trauma assessment, 28 (37%) in team skills, and 24 (32%) in procedures. The most common technologies were high-fidelity mannequins (60%), video-assisted debriefing (19%), and low-fidelity mannequins (13%). Despite their effectiveness, high-fidelity mannequins ranked poorly in production, maintenance, cost, and reusability categories, therefore being poorly suited for LMICs. Virtual simulation and digital courses had the best feasibility scores, but still represented a minority of articles in our review.
Conclusion
To our knowledge, this is the first study to perform a feasibility analysis of trauma training technologies in the LMIC context. We identified that the majority of trauma courses in the literature use technologies which are less suitable for LMICs. Given the urgent need for pediatric trauma training, educators must use technologies that optimize learning outcomes and remain feasible for low-resource settings.
Level of Evidence
IV.}
}
@article{PARK2018177,
title = {A Dual-cable Hand Exoskeleton System for Virtual Reality},
journal = {Mechatronics},
volume = {49},
pages = {177-186},
year = {2018},
issn = {0957-4158},
doi = {https://doi.org/10.1016/j.mechatronics.2017.12.008},
url = {https://www.sciencedirect.com/science/article/pii/S095741581730185X},
author = {Yeongyu Park and Inseong Jo and Jeongsoo Lee and Joonbum Bae},
keywords = {Wearable system, Hand exoskeleton, Force feedback, Haptic interface, Virtual reality},
abstract = {In this paper, a hand exoskeleton system for virtual reality is proposed. As a virtual reality interface for the hand, a wearable system should be able to measure the finger joint angles and apply force feedback to the fingers at the same time with a simple and light structure. In the proposed system, two different cable mechanisms are applied to achieve such requirements; three finger joint angles in the direction of the flexion/extension (F/E) motion are measured by a tendon-inspired cable mechanism and another cable is used for force feedback to the finger for one degree of freedom (DOF) actuation per finger. As two different types of cables are used, the system is termed a dual-cable hand exoskeleton system. Using the measured finger joint angles and motor current, the cable-driven actuation system applies the desired force to the fingers. That is, when the desired force is zero, the motor position is controlled to follow the finger posture while maintaining the appropriate cable slack; when the desired force needs to be applied, the motor current is controlled to generate the desired force. To achieve a smooth transition between the two control strategies, the control inputs were linearly integrated; and the desired motor position was generated to prevent a sudden motor rotation. A prototype of the proposed system was manufactured with a weight of 320g, a volume of 13 × 23 × 8cm3, maximum force up to 5 N. The proposed control algorithms were verified by experiments with virtual reality applications.}
}
@article{BLASCH20131999,
title = {Dynamic Data Driven Applications System Concept for Information Fusion},
journal = {Procedia Computer Science},
volume = {18},
pages = {1999-2007},
year = {2013},
note = {2013 International Conference on Computational Science},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2013.05.369},
url = {https://www.sciencedirect.com/science/article/pii/S1877050913005127},
author = {Erik Blasch and Guna Seetharaman and Kitt Reinhardt},
keywords = {Information Fusion, DDDAS, Cooperaive Sensing, Wide-Area Motion Imagery, target tracking, situation awareness},
abstract = {We present a framework of Information Fusion (IF) using the Dynamic Data Driven Applications Systems (DDDAS) concept. Existing literature at the intersection of these two topics supports environmental modeling (e.g., terrain understanding) for context enhanced applications. Taking advantage of sensor models, statistical methods, and situation- specific spatio-temporal fusion products derived from wide area sensor networks, DDDAS demonstrates robust multi-scale and multi-resolution geographical terrain computations. We highlight the complementary nature of these seemingly parallel approaches and propose a more integrated analytical framework in the context of a cooperative multimodal sensing application. In particular, we use a Wide-Area Motion Imagery (WAMI) application to draw parallels and contrasts between IF and DDDAS systems that warrants an integrated perspective. This elementary work is aimed at triggering a sequence of deeper insightful research towards exploiting sparsely sampled piecewise dense WAMI measurements – an application where the challenges of big-data with regards to mathematical fusion relationships and high-performance computations remain significant and will persist. Dynamic data-driven adaptive computations are required to effectively handle the challenges with exponentially increasing data volume for advanced information fusion systems solutions such as simultaneous target tracking and identification.}
}
@article{SHERIDAN198767,
title = {Telerobotics},
journal = {IFAC Proceedings Volumes},
volume = {20},
number = {5, Part 1},
pages = {67-81},
year = {1987},
note = {10th Triennial IFAC Congress on Automatic Control - 1987 Volume 1, Munich, Germany, 27-31 July},
issn = {1474-6670},
doi = {https://doi.org/10.1016/S1474-6670(17)55536-6},
url = {https://www.sciencedirect.com/science/article/pii/S1474667017555366},
author = {T.B. Sheridan},
keywords = {Robots, manipulators, man-machine systems, artificial intelligence},
abstract = {The concepts of telerobotics, and more generally teleoperation - extension of human sensing and manipulating capability by coupling through communication means to artificial sensors and actuators - are discussed, along with related concepts of telepresence, robotics and supervisory control. Relevant historical developments are reviewed. Current and future applications to space, undersea, nuclear power, the handicapped, surgery, terrestrial mining, construction and maintenance, warehousing, firefighting, policing and military operations are described. Current and new research problems are presented in telesensing, teleactuating, computer-aided supervisory control, and meta-analysis of human/computer/teleoperator/task interaction. Finally, some future social implications are discussed.}
}
@incollection{2007305,
title = {Index},
editor = {Robert D. Christ and Robert L. {Wernli Sr}},
booktitle = {The ROV Manual},
publisher = {Butterworth-Heinemann},
address = {Oxford},
pages = {305-308},
year = {2007},
isbn = {978-0-7506-8148-3},
doi = {https://doi.org/10.1016/B978-075068148-3/50021-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780750681483500219}
}
@article{BACEVICIUTE2021104122,
title = {Remediating learning from non-immersive to immersive media: Using EEG to investigate the effects of environmental embeddedness on reading in Virtual Reality},
journal = {Computers & Education},
volume = {164},
pages = {104122},
year = {2021},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2020.104122},
url = {https://www.sciencedirect.com/science/article/pii/S0360131520303201},
author = {Sarune Baceviciute and Thomas Terkildsen and Guido Makransky},
keywords = {Virtual reality environments, Learning, Embeddedness, Remediation, EEG},
abstract = {Virtual Reality (VR) has the potential to enrich education but little is known about how unique affordances of immersive technology might influence leaning and cognition. This study investigates one particular affordance of VR, namely environmental embeddedness, which enables learners to be situated in simulated or imagined settings that contextualize their learning. A sample of 51 university students were administered written learning material in a between-subjects design study, wherein one group read text about sarcoma cancer on a physical pamphlet in the real world, and the other group read identical text on a virtual pamphlet embedded in an immersive VR environment which resembled a hospital room. The study combined advanced EEG measurement techniques, learning tests, and cognitive load measures to compare conditions. Results show that the VR group performed significantly better on a knowledge transfer post-test. However, reading in VR was found to be more cognitively effortful and less time-efficient. Findings suggest the significance of environmental embeddedness for learning, and provide important considerations for the design of educational VR environments, as we remediate learning content from non-immersive to immersive media.}
}