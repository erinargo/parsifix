@article{GRABOWSKI2021103440,
title = {Practical skills training in enclosure fires: An experimental study with cadets and firefighters using CAVE and HMD-based virtual training simulators},
journal = {Fire Safety Journal},
volume = {125},
pages = {103440},
year = {2021},
issn = {0379-7112},
doi = {https://doi.org/10.1016/j.firesaf.2021.103440},
url = {https://www.sciencedirect.com/science/article/pii/S0379711221001818},
author = {Andrzej Grabowski},
keywords = {Firefighting, Enclosure fires, Virtual training, Technology acceptance, Multisensory experiences, Multi-user interaction fidelity, Passive haptic},
abstract = {Training in enclosure fires is essential because it is one of the most dangerous tasks for firefighters. The training simulators should consider the specificity of the tasks performed to achieve the best training outcomes. Additionally, the end-users may not accept even the best technical solutions. Due to the availability of many different interfaces and methods (e.g., for image presentation), end-users' opinions are essential in choosing the best possible technologies. In this research, the aim is to create and compare two realistic virtual training systems for fighting enclosure fires, CAVE (Cave Automated Virtual Environment) with projectors and VR (Virtual Reality) with HMD (Head Mounted Display). Both focused on nozzle person training to fill the gap between theoretical training and real-life training with fires (e.g., drills with class A fuels). Efforts were made to minimize the disadvantages of training simulators while maintaining high simulation realism and low simulator cost. The study was conducted with the participation of 67 cadets and seven active firefighters. The method of reducing the limitations of VR training simulators while maintaining relatively low costs is discussed. The simulator enables multisensory experience with passive haptic and multi-user interaction considering the sense of touch. The VR simulator was rated better than the CAVE simulator, but both were accepted and rated as very useful. The paper also discusses the issues of simulation sickness symptoms, simulation realism (spatial presence), usability, acceptance of technology, and stress associated with using a training simulator.}
}
@article{RINK2020124507,
title = {A virtual geographic environment for multi-compartment water and solute dynamics in large catchments},
journal = {Journal of Hydrology},
volume = {582},
pages = {124507},
year = {2020},
issn = {0022-1694},
doi = {https://doi.org/10.1016/j.jhydrol.2019.124507},
url = {https://www.sciencedirect.com/science/article/pii/S0022169419312429},
author = {Karsten Rink and Erik Nixdorf and Chengzi Zhou and Markus Hillmann and Lars Bilke},
keywords = {Environmental information system, Virtual reality, OpenGeoSys, Water resources management, Poyang Lake},
abstract = {We propose a visualisation framework for data exploration, analysis and presentation of complex hydrological studies in large catchments. This furthers a deeper understanding of the interrelations between the included datasets, allows for discussions among researchers from different disciplines and is the basis for illustrating complex phenomena to stakeholders or the interested public. Based on the 162,000 km2 catchment of Poyang Lake, the largest freshwater lake in China, we developed a Virtual Geographic Environment that combines a wide range of 2D and 3D observation data sets with simulation results from both an OpenGeoSys groundwater model and a COAST2D hydrodynamic model visualising water and solute dynamics within and across hydrologic reservoirs. The system aims for a realistic presentation of the investigation area and implements approaches of scientific visualisation to illustrate interesting aspects of multi-variate data in intuitive ways. It employs easy-to-learn interaction techniques for navigation, animation, and access to linked data sets from external sources, such as time series data or websites, to function as an environmental information system for any region of interest.}
}
@article{VERGARA2022155,
title = {Educational trends post COVID-19 in engineering: Virtual laboratories},
journal = {Materials Today: Proceedings},
volume = {49},
pages = {155-160},
year = {2022},
note = {Advances in Mechanical Engineering Trends},
issn = {2214-7853},
doi = {https://doi.org/10.1016/j.matpr.2021.07.494},
url = {https://www.sciencedirect.com/science/article/pii/S2214785321054006},
author = {Diego Vergara and Pablo Fernández-Arias and Jamil Extremera and Lilian P. Dávila and Manuel P. Rubio},
keywords = {Virtual laboratories, Virtual reality, COVID-19, Engineering, Hybrid education, Didactic tools},
abstract = {The rapid advance of Information and Communication Technology (ICT) in recent times and the current pandemic caused by COVID-19 have profoundly transformed society and the economy in most of the world. The education sector has benefited from this ICT-driven revolution, which has provided and expanded multiple new tools and teaching methods that did not exist just a few decades ago. In light of this technological change, virtual laboratories (VLs) based on the use of virtual reality (VR) have emerged, which are increasingly used to facilitate the teaching–learning process in a wide range of training activities, both academic and professional types. The set of advantages offered by this type of VL, the main of which are listed in this article, has made its use increasingly common as support for engineering classes at universities. This paper presents a study involving 420 engineering students from Spanish and Portuguese universities and associated analyses on the assessment of different parameters in various VLs designed by the authors. The results obtained indicate that, in general, VR-based VLs are widely accepted and demanded by students, who likewise consider real laboratories (RLs) necessary in face-to-face teaching. In the current post-COVID-19 educational scenario, VLs and RLs will coexist within the new hybrid models that combine face-to-face and online teaching and learning.}
}
@article{SUN2023108715,
title = {Requirements, challenges, and novel ideas for wearables on power supply and energy harvesting},
journal = {Nano Energy},
volume = {115},
pages = {108715},
year = {2023},
issn = {2211-2855},
doi = {https://doi.org/10.1016/j.nanoen.2023.108715},
url = {https://www.sciencedirect.com/science/article/pii/S2211285523005529},
author = {Yuehang Sun and Yun-Ze Li and Man Yuan},
keywords = {Smart wearables, Energy harvesting method, Micro-supercapacitor, Power consumption, Energy supply},
abstract = {Smart wearables are receiving increasing attention. Different forms of wearables have a wide range of power requirements, and lithium-ion batteries are now the most popular energy storage option. This paper discusses the trends and challenges of smart wearables. Future wearable technology will be more compact and integrated. For the specificity of future wearables, new energy harvesting technologies that are more practical, durable, and ecologically beneficial are needed. This paper summarizes the research on the human body and environment based energy harvesting techniques, including solar, thermal, Radio frequency (RF) energy, kinetic energy, and biomass energy. We deeply analyze the application potential and limitations of each new energy harvesting technology and summarize the relationship between the energy required by wearables and the new energy harvesting systems. Solar and kinetic energy generation technologies have higher energy density and are suitable for application in outdoor sports wearables. RF energy, thermal energy, and biomass energy have less energy dense and can be used as auxiliary power sources for small wearables. The combination of the energy harvesting system and the micro energy storage unit enables the continuous power supply of wearables in different circumstances of daytime, nighttime, indoor and outdoor. The significance of this work stems from providing guidance for future energy supply methods of wearables.}
}
@article{FANFAROVA2017160,
title = {Simulation tool for fire and rescue services},
journal = {Procedia Engineering},
volume = {192},
pages = {160-165},
year = {2017},
note = {12th international scientific conference of young scientists on sustainable, modern and safe transport},
issn = {1877-7058},
doi = {https://doi.org/10.1016/j.proeng.2017.06.028},
url = {https://www.sciencedirect.com/science/article/pii/S1877705817325742},
author = {Adelaida Fanfarová and Ladislav Mariš},
keywords = {simulation tool, fire and rescue services, serious games, software, model},
abstract = {The authors of the contribution present the possibility of using modern simulation tools based on computer software - applications for the needs of emergency responders, especially for fire fighters. They point out different features of simulation technologies and recommend their implementation in the process of lifelong preparation, training and education of the members of Fire and Rescue Services as the new trend for the comprehensive improvement of preparedness and safety of fire fighters and rescuers. The contribution also presents basic research supported by institutional grant project of the University of Žilina. In agreement with research results, the authors propose a new simulation model design. This model can be used for designing and programming serious games and software for education of fire fighters. It is the first time the simulation model has been designed with active cooperation and support of the Fire and Rescue Services in Slovakia.}
}
@article{DENG2023102034,
title = {A clarity-intensity model for evacuation behaviour: A VR study and comparison with a real-world case},
journal = {Journal of Environmental Psychology},
volume = {88},
pages = {102034},
year = {2023},
issn = {0272-4944},
doi = {https://doi.org/10.1016/j.jenvp.2023.102034},
url = {https://www.sciencedirect.com/science/article/pii/S0272494423000828},
author = {Kaifeng Deng and Shizhi Xing and Guanning Wang and Xiangmin Hu and Tao Chen},
keywords = {Public safety, Evacuation, Virtual reality, Delay time, Speed preference, Statistical analysis},
abstract = {It is previously discovered that evacuees’ mental state involves two key elements: the awareness of the situation, namely the clarity; and the intensity of the stimulation (Deng et al., 2022). In this paper, we aim to construct a clarity-intensity model for the delay time and the speed preference through a VR experiment, and to compare the model with real-world cases. 15 disaster stimuli are designed to build a clarity-intensity plane, and are applied in the virtual environment (VE). The VE is made walkable with an omni-directional treadmill, and the behaviours are videotaped for later analysis. The analysed behaviours are quadratically regressed on the clarity-intensity plane, and it is discovered 1) that the delay time is effectively reduced with high clarity, and appears an inverted U-shape on the intensity dimension, and 2) that the stride frequency ratio, which represents the speed preference, rises with both clarity and intensity. The results on the delay time are further compared with a dormitory building fire case, and consistency is concluded.}
}
@article{MOLAN2023103444,
title = {Understanding the intention to stay and defend during a bushfire: An application of virtual reality to improve awareness of predictors associated with behavioural response},
journal = {International Journal of Disaster Risk Reduction},
volume = {84},
pages = {103444},
year = {2023},
issn = {2212-4209},
doi = {https://doi.org/10.1016/j.ijdrr.2022.103444},
url = {https://www.sciencedirect.com/science/article/pii/S221242092200663X},
author = {Safa Molan and Delene Weber and Matin Kor},
keywords = {Bushfire threat, Wildfires, Protective action decision model (PADM), Structural equation modelling, Stay and defend, Virtual reality (VR)},
abstract = {Encouraging residents of bushfire-prone areas to make wise protective action decisions in response to bushfire threats is a challenging task. Despite the emphasis on early evacuation as the safest option, there are circumstances when staying and defending a property is a rational decision. Using the protective action decision model (PADM), this study aimed to: (1) increase understanding of the relative importance of bushfire risk perception, protective action perception, and stakeholder perception in predicting the intention to ‘stay and defend’ and (2) analyse the effect of a virtual reality (VR) intervention on these factors among South Australian residents (n = 299). Prior to the VR intervention, participants were grouped into three cohorts of ‘stay and defend’, ‘leave early’ and ‘wait and see’ based on their preferred protective action on a day forecast as a day of severe fire danger. The participants who either indicated they would ‘stay and defend’ or ‘wait and see’ experienced the intervention which challenged their capacity to ‘stay and defend’ using a virtual bushfire threat. Structural equation modelling (SEM) analysis of data showed that protective action perception was the strongest predictor of the intention to stay and defend for all cohorts. Self-efficacy was found to have a mediating role between risk perception and the intention to stay and defend. For those intending to ‘stay and defend’, stakeholder perception was not a significant predictor, however, its importance amongst all three groups significantly increased after exposure to the virtual bushfire experience. Understanding the differences in the decision-making process of the three cohorts and the way they were influenced by the virtual scenario provides valuable insights that could contribute to the design of more effective bushfire risk communication strategies.}
}
@article{WILSON201824,
title = {3D digital documentation for disaster management in historic buildings: Applications following fire damage at the Mackintosh building, The Glasgow School of Art},
journal = {Journal of Cultural Heritage},
volume = {31},
pages = {24-32},
year = {2018},
issn = {1296-2074},
doi = {https://doi.org/10.1016/j.culher.2017.11.012},
url = {https://www.sciencedirect.com/science/article/pii/S1296207417304685},
author = {Lyn Wilson and Alastair Rawlinson and Adam Frost and James Hepher},
keywords = {Mackintosh, 3D digital documentation, Laser scanning, Disaster management, Conservation, Condition monitoring},
abstract = {3D digital documentation generates accurate spatial data. This data can be processed and developed for use in a range of different applications. Within the cultural heritage sector, the use of 3D data is becoming more established to aid conservation. However, little work has been done to investigate the role of scanning surveys for postfire inspection of historic buildings with timber components. The Glasgow School of Art and Historic Environment Scotland have been working collaboratively on digital heritage projects for almost a decade. When the fire at the Mackintosh building occurred on 23rd May 2014, the joint team immediately began a programme of emergency 3D digital documentation in the fire-affected areas. Prior to this, The Glasgow School of Art had undertaken a laser scan survey of the exterior of the Mackintosh building in 2008. Subsequently, comprehensive laser scanning has been carried out throughout the whole building. This paper outlines how and why 3D digital documentation was carried out, highlighting the immediate benefits for disaster management and immediate decision making in an emergency situation and additionally, demonstrates the ongoing research benefits for the longer-term conservation and restoration of the Mackintosh. The results of the documentation produced an accurate and high-resolution 3D spatial record of a significant historic building despite the challenging material properties of the postfire interior environment. Analysis of the data provided conservation teams and building control with valuable metrics for building access, health and safety and structural deformation.}
}
@article{LIU2023106175,
title = {Effectiveness of VR-based training on improving occupants’ response and preparedness for active shooter incidents},
journal = {Safety Science},
volume = {164},
pages = {106175},
year = {2023},
issn = {0925-7535},
doi = {https://doi.org/10.1016/j.ssci.2023.106175},
url = {https://www.sciencedirect.com/science/article/pii/S0925753523001170},
author = {Ruying Liu and Burcin Becerik-Gerber and Gale M. Lucas},
keywords = {Virtual reality, Video, Training, Active shooter incidents, Occupants, Simulation},
abstract = {Effective training for preparing building occupants for active shooter incidents is essential to reduce harm and fatalities. Virtual Reality (VR) technology has been increasingly used as a promising training method in many applications including emergency preparedness. However, previous studies for active shooter incidents have mainly focused on developing VR-based training prototypes. Thus, the effectiveness of VR-based training for active shooter incidents has yet to be rigorously studied. This study focuses on the effectiveness of VR-based training for active shooter preparedness compared to traditional training methods and investigates the factors behind the improved performance. To study the effectiveness of VR-based training, a total of 108 participants were recruited to experience video-based training, VR-based training with low interactivity, and VR-based training with high interactivity. Both objective and subjective measures were assessed. The results show that VR-based training is more effective than video-based training in improving participants’ response performance and perceived preparedness for active shooter incidents. The immersion and interactivity of the VR-based training contribute to performance. Participants without previous training experience benefit more from VR-based training than participants who previously had received some training to prepare for active shooter incidents.}
}
@article{VANSINTEMAARTENSDIJK2022111712,
title = {Personality and burglary: A virtual reality study},
journal = {Personality and Individual Differences},
volume = {196},
pages = {111712},
year = {2022},
issn = {0191-8869},
doi = {https://doi.org/10.1016/j.paid.2022.111712},
url = {https://www.sciencedirect.com/science/article/pii/S0191886922002173},
author = {Iris {van Sintemaartensdijk} and Jan-Willem {van Prooijen} and Claire Nee and Marco Otte and Paul {van Lange}},
keywords = {Virtual reality, Personality, Burglary, Expertise},
abstract = {Personality traits are robust predictors of the likelihood of involvement in criminal behaviour, but how such traits predict behaviour while committing a crime is unclear. This study investigates associations between HEXACO personality traits and burglars' scouting process, as well as how burglars differ in this respect from non-offenders due to their unique burglary expertise. In a virtual reality experiment, 181 incarcerated burglars and 172 non-offenders (university students) were asked to scout two virtual neighbourhoods for potential targets. For burglars, two main findings were observed: (1) lower honesty-humility was associated with increased perceived neighbourhood deterrence and the perceived likelihood of residents intervening, and (2) higher honesty-humility and self-control, but lower conscientiousness were all associated with taking less time scouting and travelling less distance in the virtual neighbourhood as well as target selection (e.g., selecting corner houses). For non-offenders, only extraversion emerged as a trait associated with increased efficiency in scouting the neighbourhood. We conclude that honesty-humility, conscientiousness, and self-control are primarily associated with the burglar scouting process, and suggest that burglary expertise is key to explaining why these effects were only observed for burglars rather than non-offenders.}
}
@article{ARIAS2019102861,
title = {Forensic virtual reality: Investigating individual behavior in the MGM Grand fire},
journal = {Fire Safety Journal},
volume = {109},
pages = {102861},
year = {2019},
issn = {0379-7112},
doi = {https://doi.org/10.1016/j.firesaf.2019.102861},
url = {https://www.sciencedirect.com/science/article/pii/S0379711218305320},
author = {Silvia Arias and Rita Fahy and Enrico Ronchi and Daniel Nilsson and Håkan Frantzich and Jonathan Wahlqvist},
keywords = {Evacuation, Egress, Virtual reality, Fire, Safety, Human behavior, Hotel fire, Forensic},
abstract = {The forensic investigation of human behavior in fires can benefit from a first-hand perspective of what happened during the fire. Complementing the on-site investigation and the witnesses’ accounts with a virtual reality replication of the real fire, forensic investigators could gather valuable data from having non-victims experiencing it. This paper aims to introduce and develop the forensic virtual reality method as a tool to provide a better understanding of the behavior of the building occupants. To assess the method, a virtual reality scenario based on the conditions in a hotel room during the MGM Grand fire in 1980 was created, and 55 naïve participants were exposed to it. Their behavior was later compared to that of the survivors of the real fire. The results show that the virtual environment made approximately 50% of the participants feel urgency due to the emergency and act on it. A comparison to the data from the MGM Grand fire confirmed that real life behavior can be observed in the virtual environment, although the frequencies of actions performed were lower in the virtual reality experiments.}
}
@article{BHAUMIK2023488,
title = {An Intelligent Virtual Environment for Designers with Reduced Motor Abilities},
journal = {Procedia Computer Science},
volume = {218},
pages = {488-503},
year = {2023},
note = {International Conference on Machine Learning and Data Engineering},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2023.01.031},
url = {https://www.sciencedirect.com/science/article/pii/S1877050923000315},
author = {Rahul Bhaumik and Tarun Kumar and Unais Sait},
keywords = {Virtual Reality, design tool, intelligent interface, gaze-based input, artificial intelligence},
abstract = {Conventional CAD modelling software demands substantial utilisation of input modalities like the keyboard and mouse for creating 3-dimensional (3D) models. The dexterity measures involved in controlling input modalities could pose challenges to users with motor disabilities—including the inability to move their limbs, particularly their upper and lower arms, and fingers, due to traumatic damage or congenital problems. In order to meet these challenges, this paper proposes a virtual reality (VR)-based medium to help users with motor disabilities build simple 3D models for architectural design. The concept of operating buttons using head-gaze in the VR environment has been utilised to perform scaling—a 3D object manipulation method—to create simplified building models. Moreover, navigation in the VR space using tilting of the head has been employed with the user seated on a revolving chair, thus eliminating the need for any limbic movement. Unity game engine was used to develop two variations of the VR model with a different button layout for creating simple cuboidal volumes mimicking buildings in the virtual environment. Both variations have been tested with 32 individuals against a specific performance indicator (i.e., task completion time) and self-reported metrics, such as the perception of effort applied and degree of visual clutter, followed by retrospective participant feedback sessions. One of the VR application's variants (i.e., variant 1) produced promising results regarding overall usability and effort demand. This paper also proposes a methodological framework for an AI-based, intelligent, and adaptive VR application interface that caters to the user's abilities and pain points in real-time. In the future, this framework could be instrumental in creating a comprehensive gaze-based VR tool for 3D modelling having multiple functions to help users with motor disabilities.}
}
@article{CAKIROGLU201956,
title = {Development of fire safety behavioral skills via virtual reality},
journal = {Computers & Education},
volume = {133},
pages = {56-68},
year = {2019},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2019.01.014},
url = {https://www.sciencedirect.com/science/article/pii/S036013151930020X},
author = {Ünal Çakiroğlu and Seyfullah Gökoğlu},
keywords = {Virtual reality-based behavioral skills training (VR-BST), Fire safety training, Virtual reality},
abstract = {In recent years, virtual reality has become prevalent in many educational settings. In this study, virtual reality-based behavioral skills training (VR-BST) approach is proposed to teach basic behavioral skills for fire safety. A virtual reality-based environment was designed and implemented in the context of the design-based research. A group of ten primary school students received a basic fire safety training package through this environment and in situ training was implemented when needed. The results indicated that students’ fire safety behavioral skills significantly improved with the use of virtual reality based training and the majority of the students could transfer their behavioral skills to real environments. The way of modelling the behaviors in this study and integrating in situ training into the learning environment positively contributed to the development of behavioral skills. The study concludes with suggestions for practitioners and researchers in the field of virtual reality for behavioral skills training.}
}
@article{BABALOLA2023106214,
title = {Applications of immersive technologies for occupational safety and health training and education: A systematic review},
journal = {Safety Science},
volume = {166},
pages = {106214},
year = {2023},
issn = {0925-7535},
doi = {https://doi.org/10.1016/j.ssci.2023.106214},
url = {https://www.sciencedirect.com/science/article/pii/S092575352300156X},
author = {Akinloluwa Babalola and Patrick Manu and Clara Cheung and Akilu Yunusa-Kaltungo and Paulo Bartolo},
keywords = {Augmented reality, Mixed reality, Training and education, Immersive technologies, Virtual reality},
abstract = {Immersive technologies (ImTs) have emerged as a viable pathway to address poor occupational safety and health (OSH) performance through training and education of workers. This study aimed to gain a holistic view of the applications of ImTs for OSH training and education. A review of the application of ImTs for OSH training and education is conducted using the preferred reporting items for systematic reviews and meta-analysis (PRISMA) approach and bibliometric analysis. This resulted in the evaluation of 67 relevant journal articles collected from Scopus, Web of Science, and Engineering Village. The review revealed that ImTs have been applied for OSH training and education in various industries including transportation, construction, mining, and healthcare. It was also revealed that the OSH hazards addressed by ImT-based training and education include but are not limited to fire, fall, electrical and chemical hazards in order to prevent or reduce injuries, illnesses and fatalities. In addition, it was revealed that one of the benefits of ImTs for OSH training and education is better retention of concepts when compared to conventional training and education. Challenges associated with the use of ImTs for OSH training and education include insufficient display brightness for users to effectively see virtual objects in a brightly luminated environment. Among the recommendations for future work is research into how to develop effective communication methods between trainers and trainees immersed in a virtual environment for trainers to fully understand the difficulties trainees experience in operating the developed ImT-based platform and provide solutions to such difficulties.}
}
@article{MORCOS20111049,
title = {An information-theoretic framework for field monitoring using autonomously mobile sensors},
journal = {Ad Hoc Networks},
volume = {9},
number = {6},
pages = {1049-1058},
year = {2011},
note = {Distributed Computing in Sensor Systems},
issn = {1570-8705},
doi = {https://doi.org/10.1016/j.adhoc.2010.07.016},
url = {https://www.sciencedirect.com/science/article/pii/S1570870510000958},
author = {Hany Morcos and George Atia and Azer Bestavros and Ibrahim Matta},
keywords = {Mobile sensors, Data management, Information theory, Simulation},
abstract = {We consider a mobile sensor network monitoring a spatio-temporal field. Given limited caches at the sensor nodes, the goal is to develop a distributed cache management algorithm to efficiently answer queries with a known probability distribution over the spatial dimension. First, we propose a novel distributed information theoretic approach assuming knowledge of the distribution of the monitored phenomenon. Under this scheme, nodes minimize an entropic utility function that captures the average amount of uncertainty in queries given the probability distribution of query locations. Second, we propose a correlation-based technique, which only requires knowledge of the second-order statistics, relaxing the stringent constraint of a priori knowledge of the query distribution, while significantly reducing the computational overhead. We show that the proposed approaches considerably improve the average field estimation error. Further, we show that the correlation-based technique is robust to model mismatch in case of imperfect knowledge of the underlying generative correlation structure.}
}
@article{AWADA2021101227,
title = {An integrated emotional and physiological assessment for VR-based active shooter incident experiments},
journal = {Advanced Engineering Informatics},
volume = {47},
pages = {101227},
year = {2021},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2020.101227},
url = {https://www.sciencedirect.com/science/article/pii/S1474034620301968},
author = {Mohamad Awada and Runhe Zhu and Burcin Becerik-Gerber and Gale Lucas and Erroll Southers},
keywords = {Active shooter incidents, Virtual reality, Emotional response, Physiological response, Locomotion technique},
abstract = {Unfortunately, active shooter incidents are on the rise in the United States. With the recent technological advancements, virtual reality (VR) experiments could serve as an effective method to prepare civilians and law enforcement personnel for such scenarios. However, for VR experiments to be effective for active shooter training and research, such experiments must be able to evoke emotional and physiological responses as live active shooter drills and events do. The objective of this study is thus to test the effectiveness of an active shooter VR experiment on emotional and physiological responses. Additionally, we consider different locomotion techniques (i.e., walk-in-place and controller) and explore their impact on users’ sense of presence. The results suggest that the VR active shooter experiment in this study can induce emotional arousal and increase heart rate of the participants immersed in the virtual environment. Furthermore, compared to the controller, the walk-in-place technique resulted in a higher emotional arousal in terms of negative emotions and a stronger sense of presence. The study presents a foundation for future active shooter experiments as it supports the ecological validity using VR for active shooter incident related work for the purposes of training or research.}
}
@article{SIEBERTH2023111602,
title = {Identification parade in immersive virtual reality - A technical setup},
journal = {Forensic Science International},
volume = {348},
pages = {111602},
year = {2023},
issn = {0379-0738},
doi = {https://doi.org/10.1016/j.forsciint.2023.111602},
url = {https://www.sciencedirect.com/science/article/pii/S037907382300052X},
author = {Till Sieberth and Dilan Seckiner},
keywords = {Virtual Reality, Line-up, Identification Parade, Photobox},
abstract = {Virtual Reality (VR) has sparked interest within the forensic community, where it is currently used for training purposes and in variety of forensic scenarios. In combination with efficient and user friendly full body 3-Dimensional (3D) documentation methods, VR visualisations present a viable tool for suspect witness identification. The well-known procedure of placing several persons in a room with a one-way-mirror, along with a witness on the other side of the mirror has practical disadvantages. The primary concern implicates the witness(s) and person(s) of interest coming face-to-face prior to the line-up, combined with finding sufficient persons to include within the line-up. Although image identification using printed paper partially resolved this problem, features such as body stature also marks an issue for the recognition and identification process. To test whether VR provides the technical capabilities to perform an identification parade, a total of 15 subjects were 3D documented using the multi-camera device “Photobox”. From this group, one of the documented persons then interrupted a lecture, where consequently, the students were asked afterwards to identify the same person in VR and paper identification sets. It was found that the participating students were able to identify the “suspect” in both datasets. The results imply that VR technology allow users to identify persons. However, as this is a preliminary study the similarity problem was not analysed in this paper and requires further investigation to demonstrate the robustness of this approach.}
}
@incollection{2009361,
editor = {Alan B. Craig and William R. Sherman and Jeffrey D. Will},
booktitle = {Developing Virtual Reality Applications},
publisher = {Morgan Kaufmann},
address = {Boston},
pages = {361-382},
year = {2009},
isbn = {978-0-12-374943-7},
doi = {https://doi.org/10.1016/B978-0-12-374943-7.00020-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780123749437000203}
}
@article{MENIN2022402,
title = {The effects of VR in training simulators: Exploring perception and knowledge gain},
journal = {Computers & Graphics},
volume = {102},
pages = {402-412},
year = {2022},
issn = {0097-8493},
doi = {https://doi.org/10.1016/j.cag.2021.09.015},
url = {https://www.sciencedirect.com/science/article/pii/S0097849321002119},
author = {Aline Menin and Rafael Torchelsen and Luciana Nedel},
keywords = {Virtual reality, Immersion, Training simulators, User perception, Knowledge gain},
abstract = {Although immersive virtual environments have been used for years for training and learning purposes (e.g., flight and surgery simulators), the effects of using VR devices on simulation sessions are yet to be understood. In this work, we explore the effects of different VR devices on virtual environments developed for training, focusing on perception and knowledge gain aspects. We performed two user studies to investigate the influence of these devices on users’ workload, motion sickness, and performance in the domain of work safety training. The first experiment included 61 participants and sought to understand whether and how VR displays providing different fields of view affects the users’ ability to search for risks in an office-like virtual environment (focus on user perception). Subsequently, we conducted a second experiment involving 46 subjects, where we assess whether and how interaction techniques providing different degrees-of-freedom influence users’ ability to learn procedural tasks (focus on knowledge gain). From our results, we learned that users’ knowledge on the simulation’s topic (i.e. work safety) and gaming experience play an important role in VR simulations, and that cybersickness symptoms such as disorientation are likely caused by unawareness of one’s surroundings instead of VR content.}
}
@article{GLADSTONE2000106,
title = {Virtual reality for dermatologic surgery: Virtually a reality in the 21st century},
journal = {Journal of the American Academy of Dermatology},
volume = {42},
number = {1, Part 1},
pages = {106-112},
year = {2000},
issn = {0190-9622},
doi = {https://doi.org/10.1016/S0190-9622(00)90017-3},
url = {https://www.sciencedirect.com/science/article/pii/S0190962200900173},
author = {Hayes B. Gladstone and Gregory J. Raugi and Daniel Berg and Jeff Berkley and Suzanne Weghorst and Mark Ganter},
abstract = {In the 20th century, virtual reality has predominantly played a role in training pilots and in the entertainment industry. Despite much publicity, virtual reality did not live up to its perceived potential. During the past decade, it has also been applied for medical uses, particularly as training simulators, for minimally invasive surgery. Because of advances in computer technology, virtual reality is on the cusp of becoming an effective medical educational tool. At the University of Washington, we are developing a virtual reality soft tissue surgery simulator. Based on fast finite element modeling and using a personal computer, this device can simulate three-dimensional human skin deformations with real-time tactile feedback. Although there are many cutaneous biomechanical challenges to solve, it will eventually provide more realistic dermatologic surgery training for medical students and residents than the currently used models. (J Am Acad Dermatol 2000;42:106-12.)}
}
@article{SHARMA2023103583,
title = {Periocular biometrics and its relevance to partially masked faces: A survey},
journal = {Computer Vision and Image Understanding},
volume = {226},
pages = {103583},
year = {2023},
issn = {1077-3142},
doi = {https://doi.org/10.1016/j.cviu.2022.103583},
url = {https://www.sciencedirect.com/science/article/pii/S1077314222001618},
author = {Renu Sharma and Arun Ross},
keywords = {Periocular, Ocular, Biometrics},
abstract = {Periocular is one of the promising biometric traits for human recognition. It encompasses a surrounding area of eyes that includes eyebrows, eyelids, eyelashes, eye-folds, eyebrows, eye shape, and skin texture. Its relevance is more emphasize during the COVID-19 pandemic due to the masked faces. So, this article presents a detailed review of periocular biometrics to understand its current state. The paper first discusses the various face and periocular techniques, specially designed to recognize humans wearing a face mask. Then, different aspects of periocular biometrics are reviewed: (a) the anatomical cues present in the periocular region useful for recognition, (b) the various feature extraction and matching techniques developed, (c) recognition across different spectra, (d) fusion with other biometric modalities (face or iris), (e) recognition on mobile devices, (f) its usefulness in other applications, (g) periocular datasets, and (h) competitions organized for evaluating the efficacy of this biometric modality. Finally, various challenges and future directions in the field of periocular biometrics are presented.}
}
@article{FERRANDINIPRICE201848,
title = {Comparative study of a simulated incident with multiple victims and immersive virtual reality},
journal = {Nurse Education Today},
volume = {71},
pages = {48-53},
year = {2018},
issn = {0260-6917},
doi = {https://doi.org/10.1016/j.nedt.2018.09.006},
url = {https://www.sciencedirect.com/science/article/pii/S0260691718305999},
author = {Mariana {Ferrandini Price} and Damián {Escribano Tortosa} and Antonio {Nieto Fernandez-Pacheco} and Nuria {Perez Alonso} and José Joaquín {Cerón Madrigal} and Rafael Melendreras-Ruiz and Ángel Joaquín García-Collado and Manuel {Pardo Rios} and Laura {Juguera Rodriguez}},
keywords = {Emergency medical services, Alpha amylase, Simulation, Virtual reality},
abstract = {Objectives
The main objective of the study is to determine the efficiency in the execution of the START (Simple Triage and Rapid Treatment) triage, comparing Virtual Reality (VR) to Clinical Simulation (CS) in a Mass Casualty Incident (MCI). The secondary objective is to determine the stress produced in the health professionals in the two situations described.
Materials
A comparative study on the efficiency and the stress during triage in a MSI was conducted. The basal and post levels of salivary α-amylase (sAA) activity were measured in all the participants before and after the simulation.
Results
The percentage of victims that were triaged correctly was 87.65% (SD = 8.3); 88.3% (SD = 9.65) for the Clinical Simulation with Actors (CSA) group and 87.2% (SD = 7.2) for the Virtual Reality Simulation (VRG) group, without any significant differences (p = 0.612) between both groups. The basal sAA was 103.26 (SD = 79.13) U/L with a significant increase (p < 0.001) with respect to the post-simulation levels (182.22, SD = 148.65 U/L). The increase of sAA was 80.70 (SD = 109.67) U/mL, being greater for the CSA group than the VRG group.
Conclusion
The results show that virtual reality method is as efficient as clinical simulation for training on the execution of basic triage (START model). Also, based on the sAA results, we can attest that clinical simulation creates a more stressful training experience for the student, so that is should not be substituted by the use of virtual reality, although the latter could be used as a complementary activity.}
}
@article{LI2019699,
title = {A collaborative simulation in shipbuilding and the offshore installation based on the integration of the dynamic analysis, virtual reality, and control devices},
journal = {International Journal of Naval Architecture and Ocean Engineering},
volume = {11},
number = {2},
pages = {699-722},
year = {2019},
issn = {2092-6782},
doi = {https://doi.org/10.1016/j.ijnaoe.2019.02.010},
url = {https://www.sciencedirect.com/science/article/pii/S2092678218300220},
author = {Xing Li and Myung-Il Roh and Seung-Ho Ham},
keywords = {Collaborative simulation, Integrated simulation interface, HLA, Virtual reality, Block turn-over, Offshore module installation},
abstract = {It is difficult to observe the potential risks of lifting or turn-over operations in the early stages before a real operation. Therefore, many dynamic simulations have been designed to predict the risks and to reduce the possibility of accidents. These simulations, however, have usually been performed for predetermined and fixed scenarios, so they do not reflect the real-time control of an operator that is one of the most important influential factors in an operation; additionally, lifting or turn-over operations should be a collaboration involving more than two operators. Therefore, this study presents an integrated method for a collaborative simulation that allows multiple workers to operate together in the virtual world. The proposed method is composed of four components. The first component is a dynamic analysis that is based on multibody-system dynamics. The second component is VR (virtual reality) for the generation of realistic views for the operators. The third component comprises the control devices and the scenario generator to handle the crane in the virtual environment. Lastly, the fourth component is the HLA (high-level architecture)-based integrated simulation interface for the convenient and efficient exchange of the data through the middleware. To show the applicability of the proposed method, it has been applied to a block turn-over simulation for which one floating crane and two crawler cranes were used, and an offshore module installation for which a DCR (dual-crane rig) was used. In conclusion, the execution of the proposed method of this study is successful regarding the above two applications for which multiple workers were involved.}
}
@article{BELLALOUNA2020636,
title = {Industrial Case Studies for Digital Transformation of Engineering Processes using the Virtual Reality Technology},
journal = {Procedia CIRP},
volume = {90},
pages = {636-641},
year = {2020},
note = {27th CIRP Life Cycle Engineering Conference (LCE2020) Advancing Life Cycle Engineering : from technological eco-efficiency to technology that supports a world that meets the development goals and the absolute sustainability},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2020.01.082},
url = {https://www.sciencedirect.com/science/article/pii/S2212827120301803},
author = {Fahmi Bellalouna},
keywords = {Virtual Reality, Cognitive Approach, VR-based Product Lifecyle, CAD},
abstract = {The virtual reality technology (VR) has undergone a rapid development in recent years. The VR software and hardware have become powerful and affordable. Therefore, the VR counts to the key technologies for enabling the digital transformation. However, this significant technology has not achieved the expected breakthrough in the industrial engineering area yet. The potential of the VR to digitize and to improve the engineering process of industrial companies especially for SMEs is still undiscovered. This has led to a poor implementation and use of the VR applications with an engineering scope compared with other business sectors e.g. gaming, entertainments. This paper presents and discusses two case studies achieved within cooperation project between the University of Applied Sciences Karlsruhe and German manufacturers for fire trucks and systems for firefighting and disaster protection. The aim of the case studies is the implementation of VR applications and their evaluation in terms of using in the business processes of the involved industrial partner. Based on the experiences gathered during this cooperation project a CAD Data transformation process for an industrial VR application as best-practice approach will be outlined and discussed in this paper. © 2020 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/3.0/). Peer-review under responsibility of the scientific committee of the 27th CIRP Life Cycle Engineering (LCE) Conference.}
}
@article{LOVREGLIO2022103283,
title = {Prototyping and testing a virtual reality counterterrorism serious game for active shooting},
journal = {International Journal of Disaster Risk Reduction},
volume = {82},
pages = {103283},
year = {2022},
issn = {2212-4209},
doi = {https://doi.org/10.1016/j.ijdrr.2022.103283},
url = {https://www.sciencedirect.com/science/article/pii/S2212420922005027},
author = {Ruggiero Lovreglio and Daphney-Chloe Ngassa and Anass Rahouti and Daniel Paes and Zhenan Feng and Alastair Shipman},
keywords = {Virtual reality, Counterterrorism, Training, Active shooting, Serious games},
abstract = {An active shooting emergency requires an effective strategy to increase the chances of survival of the attacked population. Educational environments are one of the most common locations of such events. To reduce the impact of these disasters, several emergency plans have been developed and put in place. Traditionally, these emergency plans are taught to occupants using non-interactive videos, drills, etc. However, these conventional methods present many limitations regarding trainees' knowledge acquisition, engagement and self-efficacy. To overcome them, this paper presents the prototype of an immersive Virtual Reality (VR) Serious Game (SG) for counterterrorism training. A user-centred evaluation of the proposed training SG was conducted with 32 participants. The experiment aimed to investigate the impact of the proposed tool on participants' knowledge regarding the safest actions to take in case of an active shooter attack. Participants' intrinsic motivation and self-efficacy levels were also assessed before and after the VR-based training. Findings indicate that participants’ knowledge, intrinsic motivation, and self-efficacy significantly increased immediately after the training.}
}
@article{RUDDLE2004299,
title = {Effects of proprioceptive feedback and environmental characteristics on spatial learning in virtual environments},
journal = {International Journal of Human-Computer Studies},
volume = {60},
number = {3},
pages = {299-326},
year = {2004},
issn = {1071-5819},
doi = {https://doi.org/10.1016/j.ijhcs.2003.10.001},
url = {https://www.sciencedirect.com/science/article/pii/S1071581903001733},
author = {Roy A Ruddle and Patrick Péruch},
abstract = {The effect of proprioceptive information and environmental characteristics on spatial learning was investigated when participants repeatedly navigated complex three-dimensional virtual mazes. Proprioceptive information, provided by viewing the mazes using a head-mounted display, was found to have little effect. The primary environmental characteristics were layout orthogonality (using paths that intersected at either oblique or 90° angles), lines of sight (controlled using computer-generated “fog”), a visually defined perimeter and global landmarks. Participants travelled less far in orthogonal than oblique environments, even when fog was used to make the distance that participants could see equivalent. The removal of fog caused a further, substantial reduction in the distance participants travelled, indicating the importance of extended lines of sight, as predicted by the architectural theory of space syntax. Global landmarks promoted a similar rate of spatial learning to a visual perimeter.}
}
@article{KWEGYIRAFFUL2022102681,
title = {Effects of an engaging maintenance task on fire evacuation delays and presence in virtual reality},
journal = {International Journal of Disaster Risk Reduction},
volume = {67},
pages = {102681},
year = {2022},
issn = {2212-4209},
doi = {https://doi.org/10.1016/j.ijdrr.2021.102681},
url = {https://www.sciencedirect.com/science/article/pii/S2212420921006427},
author = {Ebo Kwegyir-Afful},
keywords = {Fire evacuation, Safety, Pre-movement time, 3D simulation, Virtual reality, Presence},
abstract = {The current study aims to investigate the capability of occupants of a powerhouse simulation to sense a fire and initiate evacuation while engaged with a task. For this reason, the study involved the maintenance task of replacing the air filter of a gas-powered engine through a series of instructions. The virtual reality-based accident causation model (VR-ACM) consisting of 3D modeling and simulation, accident causation, and safety training was adapted to address the study's aims. Two groups of participants were immersed in the virtual realm as occupants of the powerhouse to determine the pre-movement time and the evacuation duration under distinct scenarios. The first scenario constituted the experimental group (n = 26), who were assigned to replace the filters, while the second scenario (control n = 26) performed no task before the fire outbreak. An independent samples t-test revealed a significant difference in the pre-movement time of the groups, which suggested a decline in the perception of the experimental group due to the task. Further assessment revealed a consequential transfer of the delay at the pre-movement phase to the evacuation delay of the experimental group from the powerhouse. Secondly, the differences in interactivity implied that the experimental group exhibited a higher level of involvement and distraction in the Presence measurement than the control group. To this end, a virtual reality (VR) environment's performance and real-time functionality during a maintenance task simulation have been experimented with in an emergency fire evacuation scenario to ascertain safety concerns.}
}
@article{TUFO2021100006,
title = {Application of HPC and big data in post-pandemic times},
journal = {Earthquake Research Advances},
volume = {1},
number = {3},
pages = {100006},
year = {2021},
issn = {2772-4670},
doi = {https://doi.org/10.1016/j.eqrea.2021.100006},
url = {https://www.sciencedirect.com/science/article/pii/S2772467021000063},
author = {Henry M. Tufo and David A. Yuen and Gabriele Morra and Matthew G. Knepley and Bei Zhang and Shi Chen},
keywords = {Geophysics, High-performance computing, Higher education, Post-pandemic era},
abstract = {We lay out the ramifications of the 2020 pandemic for all people in geosciences, especially the young, and argue for significant changes on training and career development. We focus primarily on its devastating impact in USA and compare with that in other countries especially China. We review the potential effect for the next four years or so on the aspirations of an academic career versus more realistic career goals. We urge people in mid-career about the need to reassess previous goals. We stress the need for students or researchers to acquire technical skills in high-performance computing (HPC), data analytics, artificial intelligence, and/or visualization along with a broad set of technical skills in applied computer science and mathematics. We give advice about hot prospects in several areas that have great potential for advancement in the coming decade, such as visualization, deep learning, quantum computing and information, and cloud computing, all of which lie within the aegis of HPC. Our forecast is that the pandemic will significantly reshape the job landscape and career paths for both young and established researchers and we discuss bluntly the dire situation facing junior people in geosciences in the aftermath of the pandemic around the world until 2024.}
}
@article{KOEPNICK2010665,
title = {RIST: Radiological Immersive Survey Training for two simultaneous users},
journal = {Computers & Graphics},
volume = {34},
number = {6},
pages = {665-676},
year = {2010},
note = {Graphics for Serious Games Computer Graphics in Spain: a Selection of Papers from CEIG 2009 Selected Papers from the SIGGRAPH Asia Education Program},
issn = {0097-8493},
doi = {https://doi.org/10.1016/j.cag.2010.09.008},
url = {https://www.sciencedirect.com/science/article/pii/S009784931000141X},
author = {Steven Koepnick and Roger V. Hoang and Matthew R. Sgambati and Daniel S. Coming and Evan A. Suma and William R. Sherman},
keywords = {Virtual reality, Computer-based training, Human factors, Collaborative virtual environment},
abstract = {National Guard Civil Support Teams (CST) respond to a variety of situations involving dangerous materials. Many of these situations can be safely simulated for training purposes in the real world. Radiological threats, however, are difficult to simulate due to the lack of materials that can mimic radiation sources without the danger of the real radiation. To address the need for a system to train CSTs to respond to radiological threats, we have developed the Radiological Immersive Survey Training (RIST) system. RIST simulates radiological threats from multiple sources using a realistic real-time shielding model based on ray casting and allows users to practice surveying the threat using simulated representations of the world and equipment. We have developed an after action review tool to allow a trainer to show trainees a recording of their survey and how they can improve. We also created a scenario design tool to allow the trainer to create complex environments with radiological threats. We developed novel multi-user interaction techniques to enable simultaneous training for two CST members in an immersive virtual environment. We also introduced a novel multi-perspective rendering technique for two users based on each user's task rather than field of view. Finally, we conducted a preliminary user study with several pairs of expert users to measure user preferences and the effects of using this technique, in conjunction with how altering which user navigated, on user performance. CST survey teams from two states have now used the system for training.}
}
@article{CHEN2023103486,
title = {Cross-cultural assessment of the effect of spatial information on firefighters’ wayfinding performance: A virtual reality-based study},
journal = {International Journal of Disaster Risk Reduction},
volume = {84},
pages = {103486},
year = {2023},
issn = {2212-4209},
doi = {https://doi.org/10.1016/j.ijdrr.2022.103486},
url = {https://www.sciencedirect.com/science/article/pii/S2212420922007051},
author = {Jieyu Chen and Nan Li and Yangming Shi and Jing Du},
keywords = {Spatial information, Culture, Virtual reality, Wayfinding, Firefighter, Search and rescue},
abstract = {When firefighters conduct search and rescue operations during building fire emergencies, effective wayfinding plays a critical role in protecting them from disorientation and improving the efficiency of their operations. However, whether and how different cultural backgrounds affect firefighters' acquisition and utilization of spatial knowledge during wayfinding tasks has not been comprehensively explored. To narrow this knowledge gap, we conducted a virtual reality-based search and rescue experiment with a 4 (spatial information type: control, landmark, route, and survey condition) × 2 (culture: the US and China) mixed factorial design. For each trial, firefighters were required to find three trapped victims in a virtual office maze within 3 min after a 3-min review of a certain type of spatial information. The wayfinding performance metrics (number of victims found, rescue score, distance to the goal path), direction decision-making strategy, and cognitive load of 62 firefighter participants were measured and analyzed. The results indicated that spatial information type, culture, and the interaction influence between them all significantly affected the firefighters' wayfinding performance. We found that the route and survey information contributed to firefighters' wayfinding performance with different degrees of influence on the US and Chinese firefighters; whereas the landmark information increased firefighters’ cognitive load and impaired their wayfinding performance. We also found that the acquisition and utilization process of spatial information for navigation varied among different cultures. The findings of this study are expected to help develop better training strategies for firefighters, as well as improve their safety and efficiency during search and rescue operations.}
}
@article{ZHOU2023106100,
title = {Cognition-driven navigation assistive system for emergency indoor wayfinding (CogDNA): Proof of concept and evidence},
journal = {Safety Science},
volume = {162},
pages = {106100},
year = {2023},
issn = {0925-7535},
doi = {https://doi.org/10.1016/j.ssci.2023.106100},
url = {https://www.sciencedirect.com/science/article/pii/S0925753523000425},
author = {Tianyu Zhou and Pengxiang Xia and Qi Zhu and Jing Du},
keywords = {User Interface, Emergency Wayfinding, Cognition-Driven Adaptive System, Human factors},
abstract = {Attributed to the advances in sensing and visualization technologies, novel wayfinding assistive systems are becoming more accessible such as the augmented reality (AR)-based wayfinding guidance that provides immersive information about the space and environments. However, the excessive information provided by these new methods results in cognitive overload, leading to subpar performance. Especially for emergency wayfinding where responders need to process a large amount of information while performing search and hazard identification tasks, an overdesigned wayfinding user interface and excessive information can cause confusion or disorientation among responders. This study proposes and tests a real-time cognition-driven navigation assistive system for emergency wayfinding called CogDNA. CogDNA measures responders’ real-time cognitive load and mental status based on the high-frequent pupillometer and gazes tracking data. Then the elements and formats of the primary wayfinding information are adjusted based on the individualized cognitive load models and the mental fatigue status measured by the pupillometer data including gaze movement entropy and blink rate. To test the efficacy of CogDNA, a human-subject experiment (n = 31) was performed with local firefighters in a simulated emergency wayfinding task. Three conditions were presented including the control condition with a static wayfinding system, a self-adaption condition where responders could adjust information with gesture controls, and the auto-adaption condition that tailored information based on real-time cognitive load and mental status measures. The result shows that the proposed method reduces the workload and improves the performance of the responders during the wayfinding task. The self-reported assessments also indicate benefits of the proposed method in cognitive load. The findings prove the efficacy of adaptive wayfinding information systems based on real-time cognitive load measures for future emergency wayfinding tasks.}
}
@article{LONGO201999,
title = {Emergency preparedness in industrial plants: A forward-looking solution based on industry 4.0 enabling technologies},
journal = {Computers in Industry},
volume = {105},
pages = {99-122},
year = {2019},
issn = {0166-3615},
doi = {https://doi.org/10.1016/j.compind.2018.12.003},
url = {https://www.sciencedirect.com/science/article/pii/S0166361518302756},
author = {Francesco Longo and Letizia Nicoletti and Antonio Padovano},
keywords = {Emergency management, Emergency preparedness, Training, Virtual reality, Simulation},
abstract = {The need for effective response systems is widely acknowledged from industry managers as well as from academic communities that have invested a great deal of time and effort to detect methodologies and approaches to enhance response systems performances. With this in mind, the proposed research work recognizes the crucial role of training activities in implementing high performing response systems in industrial sites and takes a step forward proposing an Industry 4.0-driven solution for emergency staff training. The proposed solution seamlessly combines a teaching strategy defined as Cooperative, Experiential and Differentiated Learning along with industry 4.0 enabling technologies and approaches such as simulation, virtual reality, immersive and interactive technologies. This way, leveraging on the user experience and on the capabilities to provide a comprehensive as well as realistic set of training scenarios, the proposed training system has been critically investigated to ascertain: •How the performances of Emergency Managers and Emergency Team Members evolve along training sessions.•To which extent the proposed solution is effective in delivering procedural knowledge to Emergency Managers and Emergency Team Members;•Whether it is realistic enough to produce psychological stress in those people that are trained with it. After an experimental campaign, data have been collected and statistically analyzed to answer to the research questions stated above based on scientific evidence.}
}
@article{WARD2022103720,
title = {More or less? Improving monocular head mounted display assisted visual search by reducing guidance precision},
journal = {Applied Ergonomics},
volume = {102},
pages = {103720},
year = {2022},
issn = {0003-6870},
doi = {https://doi.org/10.1016/j.apergo.2022.103720},
url = {https://www.sciencedirect.com/science/article/pii/S0003687022000436},
author = {Matthew Ward and William S. Helton},
keywords = {Attention, Head-mounted display, Mobile devices, Visual search, Wearable devices},
abstract = {Objective
To test six different methods of directing a user's attention in a peripheral head mounted display assisted visual search task.
Background
Each time a user needs to shift their attention between virtual information and their environment has a cost. The faster a user can process a guiding cue and the fewer times they need to return to it, the more efficient that cue will be at directing a user's attention. The most effective method, creating a visual effect at the location of the target, is not suitable for peripheral head mounted displays. This study tests alternative guiding cues better suited to these devices.
Method
Participants searched for a singleton target hidden among 299 distractors while directed with one of six device-delivered guiding cues. Search times were recorded.
Results
A static region map was the most efficient and most preferred cue. Static and dynamic directional cues were also effective in comparison to non-guided search. Cues designed to work solely within the participants’ peripheral vision were relatively ineffective
Conclusion
Guidance cues that direct a user's attention to targets within the real environment do not need to precisely lead to the target. It is instead more efficient to lead a user to the general vicinity of the target quickly and then have the user revert to their natural visual search behaviour.
Application
This finding is broadly useful when assisting visual search tasks with handheld or worn devices which do not cover the user's full field of view.
Précis
This study tested six different methods of guiding attention in a peripheral head-mounted display assisted visual search task. This study compared static, dynamic and peripheral-vision endogenous cues to targets and found a static simple map cue both fastest and most preferred by users.}
}
@article{GAMBERINI2015104,
title = {Psychological response to an emergency in virtual reality: Effects of victim ethnicity and emergency type on helping behavior and navigation},
journal = {Computers in Human Behavior},
volume = {48},
pages = {104-113},
year = {2015},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2015.01.040},
url = {https://www.sciencedirect.com/science/article/pii/S0747563215000540},
author = {Luciano Gamberini and Luca Chittaro and Anna Spagnolli and Claudio Carlesso},
keywords = {Emergency, Virtual reality, Helping behavior, Navigation behavior, Racial discrimination, Validation},
abstract = {Virtual environments are increasingly used for emergency training, but tend to focus mainly on teaching prescribed emergency procedures. However, social psychology literature highlights several factors that can bias individual response to an emergency in the real world, and would be worth considering in virtual training systems. In this paper, we focus on withdrawal of help due to racial discrimination and explore the potential of virtual environments to trigger this bias in emergency situations. We also test if a virtual emergency is actually reacted to as an emergency. We use an immersive virtual environment (IVE) where a victim issues help requests during two different emergency situations (time pressure or fire). While experiencing the emergency, white participants (N=96) receive a request for help from a black or white virtual human. The results show a psychological response to the virtual experience consistent with an emergency situation (increased state anxiety and increased frequency of collisions with objects in the environment) and biased by racial discrimination in help provision. In addition, racial discrimination increases under time pressure, but not in a fire. The implications for virtual training are discussed.}
}
@article{SCHMIDT20089180,
title = {Kinesthetic Telepresent Control with Application to Defusing of Mines - Concepts, Implementation and Evaluation},
journal = {IFAC Proceedings Volumes},
volume = {41},
number = {2},
pages = {9180-9185},
year = {2008},
note = {17th IFAC World Congress},
issn = {1474-6670},
doi = {https://doi.org/10.3182/20080706-5-KR-1001.01552},
url = {https://www.sciencedirect.com/science/article/pii/S1474667016404295},
author = {G. Schmidt and A. Kron},
abstract = {This paper presents a novel approach to support disposal of explosive ordnances by application of bimanual haptic telepresent control techniques. For improved task execution the proposed system enables an operator to perceive multimodal feedback, in particular detailed kinesthetic and tactile feedback, from a remote task environment. Details of the developed experimental setup, comprising stereo vision, a two-handed human system interface and a corresponding two-arm teleoperator, are presented. Furthermore a novel structure adapting scheme for control of the force feedback display and the manipulator arms is introduced. The usability and effectiveness of the bimanual telepresent control system are demonstrated by focusing and evaluating as a most relevant task scenario, the execution of defusing operations in a remote task environment.}
}
@article{ALEKSEEVA2022100494,
title = {The future of computing paradigms for medical and emergency applications},
journal = {Computer Science Review},
volume = {45},
pages = {100494},
year = {2022},
issn = {1574-0137},
doi = {https://doi.org/10.1016/j.cosrev.2022.100494},
url = {https://www.sciencedirect.com/science/article/pii/S1574013722000326},
author = {Daria Alekseeva and Aleksandr Ometov and Otso Arponen and Elena Simona Lohan},
keywords = {Computing paradigms, Medical and emergency services, Wireless communications, Electronic healthcare, Smart healthcare, Standardization},
abstract = {Healthcare is of particular importance in everyone’s life, and keeping the advancement of it on a good pace is a priority of any country, as it highly influences the overall well-being of its citizens. Each government strives to build a modern, intelligent medical system that provides maximum population coverage with high-quality medical services. The development of Information and Communication Technologies (ICT) significantly improves the accessibility and effectiveness of the healthcare system by forming the eHealth environment, thus, providing an opportunity to enhance the quality of patient care and significantly speed up the work of medical experts and reduce costs for medical services. Shifting medical services to digital and remote operations requires a lot of computational capabilities. Implementing new computing paradigms is prominent — remote services face new requirements due to the increasing data and demand for new computing solutions. Computing paradigms, e.g., Cloud, Edge, Mobile Edge Computing, besides others, are used to process the collected medical data, improving patient healthcare quality. This paper focuses on computing solutions for medical use cases by offering a comprehensive survey on standardization aspects, use cases, applicable computing paradigms, security limitations, and design considerations within the ICT usages for medical applications. Finally, it outlines the most critical integration challenges and solutions from the literature.}
}
@article{KHOURY2009483,
title = {High-precision identification of contextual information in location-aware engineering applications},
journal = {Advanced Engineering Informatics},
volume = {23},
number = {4},
pages = {483-496},
year = {2009},
note = {Civil Engineering Informatics},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2009.04.002},
url = {https://www.sciencedirect.com/science/article/pii/S1474034609000184},
author = {Hiam M. Khoury and Vineet R. Kamat},
abstract = {This paper presents research that investigated algorithms for high-precision identification of contextual information in location-aware engineering applications. The primary contribution of the presented work is the design and implementation of a dynamic user-viewpoint tracking scheme in which mobile users’ spatial context is defined not only by their position (i.e., location), but also by their three-dimensional head orientation (i.e., line of sight). This allows the identification of objects and artifacts visible in a mobile user’s field of view with much higher accuracy than was possible by tracking position alone. For outdoor applications, a georeferencing based algorithm has been developed using the Global Positioning System (GPS) and magnetic orientation tracking devices [5] to track a user’s dynamic viewpoint. For indoor applications, this study explored the applicability of wireless technologies, in particular Indoor GPS, for dynamic user position tracking in situations where GPS is unavailable. The objectives of this paper are to describe the details of the three-stage-algorithm that has been designed and implemented, and to demonstrate the extent to which positioning technologies such as GPS and Indoor GPS can be used together with high-precision orientation trackers to accurately interpret the fully-qualified spatial context of a mobile user in challenging environments such as those found on construction sites. The obtained results highlight the potential of using location-aware technologies for rapidly identifying and retrieving contextual information in engineering applications.}
}
@article{RAYMER2023301658,
title = {Virtual reality forensics: Forensic analysis of Meta Quest 2},
journal = {Forensic Science International: Digital Investigation},
volume = {47},
pages = {301658},
year = {2023},
issn = {2666-2817},
doi = {https://doi.org/10.1016/j.fsidi.2023.301658},
url = {https://www.sciencedirect.com/science/article/pii/S2666281723001774},
author = {Emma Raymer and Áine MacDermott and Alex Akinbi},
keywords = {Virtual reality, Meta Quest 2, VR Forensics, Digital forensics},
abstract = {The Meta Quest 2 is one of the most popular Virtual Reality (VR) entertainment headsets to date. The headset, developed by Meta Platforms Inc., immerses the user in a completely simulated environment. Some VR environments can be shared over the Internet to allow users to communicate and interact with one another and share their experiences. Unfortunately, the safety of these VR environments cannot always be guaranteed, generating a risk that users may be exposed to illicit online behaviour in the form of online harassment, grooming, and cyberbullying. Therefore, forensic examiners must be able to conduct sound forensic analysis of VR headsets to investigate these criminal investigations. In this study, we conduct digital forensic acquisition and analysis of the Meta Quest 2 VR headset. Analysis of the forensic image exemplified that there were several digital artefacts relating to user activities, device information and stored digital artefacts that can be extracted in a forensically sound manner. The main contributions of this study include a detailed description of the forensic acquisition process, identification of internal file storage locations, and recovery and analysis of digital artefacts that can be used to aid VR forensic investigations.}
}
@article{ZHU20211,
title = {Virtual and augmented reality technologies for emergency management in the built environments: A state-of-the-art review},
journal = {Journal of Safety Science and Resilience},
volume = {2},
number = {1},
pages = {1-10},
year = {2021},
issn = {2666-4496},
doi = {https://doi.org/10.1016/j.jnlssr.2020.11.004},
url = {https://www.sciencedirect.com/science/article/pii/S266644962030030X},
author = {Yiqing Zhu and Nan Li},
keywords = {Virtual reality, Augmented reality, Emergency management, Built environment, Literature review},
abstract = {With the rapid technological advancements in recent decades, virtual reality (VR) and augmented reality (AR) technologies have been increasingly adopted to address various challenges in emergency management in the built environments. This paper presents a review of state-of-the-art applications in this rapidly evolving area. A total of 84 relevant articles are identified based on searching in the Web of Science Core Collection and snowballing. These papers are then organized based on a taxonomy developed in this study. Next, a range of VR/AR applications presented in these papers that are aimed to enhance various processes associated with pre-emergency preparedness, responses during emergency and post-emergency recovery are reviewed in detail. The existing VR/AR applications are also described from a human-computer interaction perspective. Finally, current research trends, knowledge gaps and directions for future research are discussed. The findings presented in this paper are expected to provide a synthetic and critical review of state-of-the-art VR/AR applications for emergency management in the built environment and facilitate further advancements in both research and practice in this area.}
}
@article{ZHANG2019341,
title = {Fuzzy comprehensive evaluation of virtual reality mine safety training system},
journal = {Safety Science},
volume = {120},
pages = {341-351},
year = {2019},
issn = {0925-7535},
doi = {https://doi.org/10.1016/j.ssci.2019.07.009},
url = {https://www.sciencedirect.com/science/article/pii/S0925753518318903},
author = {Hui Zhang and Xueqiu He and Hani Mitri},
keywords = {Mine safety, Safety training, Virtual reality, AHP, Fuzzy comprehensive evaluation},
abstract = {Effective safety training is an indispensable means to ensure mine safety. Virtual Reality (VR) technology is a promising method to improve training efficiency. At present, research on VR mine safety training is limited; it focuses mainly on the implementation of a VR training system rather than the evaluation of the techniques and methods employed, which is far more important. The evaluation of a VR safety training system mainly includes the selection of indicators, calculation of weights, and a comprehensive evaluation of the system components. This paper presents a comprehensive evaluation of the VR mine safety training system with the analytic hierarchy process and the fuzzy logic technology. Firstly, by analyzing the components of the VR system, the weights of the system components and the main elements of each part are determined; the most important part is the software, which has a weight of 49.62%. Secondly, the fuzzy logic of each element will give a comprehensive evaluation result of the system. An existing VR training system is evaluated, and the result appears to be moderate. The main disadvantage of the system is the lack of realism, the absence of user data record, and the limited degree of freedom of the VR scene. Through this method, the VR training system can be scientifically and efficiently evaluated, and the system shortcomings can be derived from the evaluation results, so that the system can be improved in future, thereby ensuring the effectiveness of the system itself, and laying a solid foundation for safety training.}
}
@article{WEI2019290,
title = {Virtual fire drill system supporting co-located collaboration},
journal = {Virtual Reality & Intelligent Hardware},
volume = {1},
number = {3},
pages = {290-302},
year = {2019},
issn = {2096-5796},
doi = {https://doi.org/10.3724/SP.J.2096-5796.2019.0012},
url = {https://www.sciencedirect.com/science/article/pii/S2096579619300245},
author = {Yuan WEI and Dongdong GUAN and Qiuchen WANG and Xiangxian LI and Yulong BIAN and Pu QIN and Yanning XU and Chenglei YANG},
keywords = {Virtual reality, Co-located collaboration, Multi-view display, Ultra wideband, Simulated firefighting water-gun},
abstract = {Background Due to the restriction of display mode, in most of the virtual reality systems with multiple people in the same physical space, the program renders the scene based on the position and perspective of the one user, so that other users just see the same scene, resulting in vision disorder. Methods To improve experience of multi-user co-located collaboration, in this study, we propose a fire drill system supporting co-located collaboration, in which three co-located users can collaborate to complete the virtual firefighting mission. Firstly, with multi-view stereoscopic projective display technology and ultra wideband (UWB) technology, co-located users can roam independently and watch virtual scenes through the correct perspective view based on their own position by wearing dedicated shutter glasses, thus carrying out different virtual tasks, which improves the flexibility of co-located collaboration. Secondly, we design simulated firefighting water-gun using the micro-electromechanical system sensor, through which users can interact with virtual environment, and thus provide a better interactive experience. Finally, we develop a workbench including a holographic display module and multi-touch operation module for virtual scene assembly and virtual environment control. Results The controller can use the workbench to adjust the virtual layout in real time, and control the virtual task process to increase the flexibility and playability of system. Conclusions Our work can be employed in a wide range of related virtual reality applications.}
}
@article{HINCAPIE2021107289,
title = {Educational applications of augmented reality: A bibliometric study},
journal = {Computers & Electrical Engineering},
volume = {93},
pages = {107289},
year = {2021},
issn = {0045-7906},
doi = {https://doi.org/10.1016/j.compeleceng.2021.107289},
url = {https://www.sciencedirect.com/science/article/pii/S0045790621002706},
author = {Mauricio Hincapie and Christian Diaz and Alejandro Valencia and Manuel Contero and David Güemes-Castorena},
keywords = {Augmented reality, Educational innovation, Educational technology, Human-computer interaction, Simulation, higher education},
abstract = {Augmented Reality (AR) has been used successfully in several industries; one of these is education. A systematic understanding of how AR contributes to education still lacks studies about the content type and its effects on learning outcomes. This article systematically analyzes the AR state-of-the-art in education, determines productivity and publication indicators in this field, and identifies research works that have studied how content type affects the learning outcomes. The methodology was performed through a bibliometric analysis using the Scopus database, focusing on AR's educational uses. Engineering education is the primary research trend, followed by simulation, tracking, and virtual reality. Education and e-learning also have leading roles within this analysis, along with gamification and human-computer interaction, whose impacts are further explored. There is no preferred design methodology for creating AR content. In its absence, most of the works suggest a design based on the developers' and researchers' experience.}
}
@article{ARIAS2021103067,
title = {A virtual reality study of behavioral sequences in residential fires},
journal = {Fire Safety Journal},
volume = {120},
pages = {103067},
year = {2021},
note = {Fire Safety Science: Proceedings of the 13th International Symposium},
issn = {0379-7112},
doi = {https://doi.org/10.1016/j.firesaf.2020.103067},
url = {https://www.sciencedirect.com/science/article/pii/S0379711220300618},
author = {Silvia Arias and Daniel Nilsson and Jonathan Wahlqvist},
keywords = {Human behavior, Virtual reality, Egress, Residential fires},
abstract = {Decision-making in residential fires can be difficult to study in an experimental setup. Virtual reality could be a way to expose participants to a residential fire scenario and collect data on their behavior. However, the validity of the data obtained needs to be assessed. To explore that, the data collected in two virtual reality residential fire scenarios in form of sequences of behavior was compared to the general model developed by Canter, Breaux and Sime. Two scenarios were developed, one with and one without a smoke alarm. Two samples of 20 participants each were exposed to a fire in a virtual house. The participants were residents of houses with the same layout as the virtual one, making them familiar with the building. The sequence of actions they performed were recorded and decomposition diagrams were drafted based on them, to then be compared to the general model. The results show that the participants’ sequences of behavior did not only fit those predicted by the general model, but also that the participants followed many different sequences, covering most of the possible patterns indicated in the general model, as it is expected in a real world fire.}
}
@article{DRIEWER200459,
title = {Robot/Human Interfaces for Rescue Teams},
journal = {IFAC Proceedings Volumes},
volume = {37},
number = {7},
pages = {59-64},
year = {2004},
note = {1st IFAC Symposium on Telematics Applications in Automation and Robotics (TA 2004), Espoo, Finland, 21-23 June 2004},
issn = {1474-6670},
doi = {https://doi.org/10.1016/S1474-6670(17)32124-9},
url = {https://www.sciencedirect.com/science/article/pii/S1474667017321249},
author = {Frauke Driewer and Herbert Baier and Klaus Schilling},
keywords = {teleoperation, telepresence, mobile robots, user interfaces, man-machine interaction, cooperation},
abstract = {Mobile robots can be of significant support for human teams in search and rescue situations. A user requirement analysis on basis of questionnaires distributed to fire fighters and emergency support people expresses notable interest in sending teleoperated robots into dangerous areas instead of risking human life. This paper summarises the requirements and the consequences for a telematic system with an intuitive user interface, which supports quick reaction capabilities. Design and implementation of an infrastructure addressing data flow in joint teams of humans and robots for data sharing, teleoperations and remote coordination are presented. Furthermore, robot vehicles used in that context and test scenarios are described.}
}
@article{KAPHINGST2009224,
title = {Testing the effects of educational strategies on comprehension of a genomic concept using virtual reality technology},
journal = {Patient Education and Counseling},
volume = {77},
number = {2},
pages = {224-230},
year = {2009},
issn = {0738-3991},
doi = {https://doi.org/10.1016/j.pec.2009.03.029},
url = {https://www.sciencedirect.com/science/article/pii/S0738399109001499},
author = {Kimberly A. Kaphingst and Susan Persky and Cade McCall and Christina Lachance and Johanna Loewenstein and Andrew C. Beall and Jim Blascovich},
keywords = {Patient education, Learning approaches, Genetics, Genetic communication},
abstract = {Objective
Applying genetic susceptibility information to improve health will likely require educating patients about abstract concepts, for which there is little existing research. This experimental study examined the effect of learning mode on comprehension of a genomic concept.
Methods
156 individuals aged 18–40 without specialized knowledge were randomly assigned to either a virtual reality active learning or didactic learning condition. The outcome was comprehension (recall, transfer, mental models).
Results
Change in recall was greater for didactic learning than for active learning (p<0.001). Mean transfer and change in mental models were also higher for didactic learning (p<0.0001 and p<0.05, respectively). Believability was higher for didactic learning (p<0.05), while ratings for motivation (p<0.05), interest (p<0.0001), and enjoyment (p<0.0001) were higher for active learning, but these variables did not mediate the association between learning mode and comprehension.
Conclusion
These results show that learning mode affects comprehension, but additional research is needed regarding how and in what contexts different approaches are best for educating patients about abstract concepts.
Practice implications
Didactic, interpersonal health education approaches may be more effective than interactive games in educating patients about abstract, unfamiliar concepts. These findings indicate the importance of traditional health education approaches in emerging areas like genomics.}
}
@article{SONG2014173,
title = {Robust nose tip localization based on two-stage subclass discriminant analysis},
journal = {Neurocomputing},
volume = {137},
pages = {173-179},
year = {2014},
note = {Advanced Intelligent Computing Theories and Methodologies},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2013.02.055},
url = {https://www.sciencedirect.com/science/article/pii/S0925231214002306},
author = {Jiatao Song and Lihua Jia and Wei Wang and Hongwei Ying},
keywords = {Nose tip localization, Subclass discriminant analysis (SDA), Illumination variation, Facial expression change},
abstract = {Nose is one of the salient features in a human face, and its localization is important for face recognition, face pose recognition, 3D face reconstruction, etc. In this paper, a novel nose tip localization method is proposed, which is based on two-stage subclass discriminant analysis (SDA). At the first stage, some randomly selected image patches are used as negative samples for the training of SDA classifier, and nose is detected from the whole face image. The second stage refines nose tip position by using some nose context patches as negative samples for the training of SDA classifier. The proposed method detects nose from the whole face image and no a priori knowledge about the layout of face components is used. Experimental results on AR images show that the proposed method can achieve high nose tip localization rates, and is robust to changes of illumination and facial expression.}
}
@article{ZHANG2017717,
title = {Head-mounted display-based intuitive virtual reality training system for the mining industry},
journal = {International Journal of Mining Science and Technology},
volume = {27},
number = {4},
pages = {717-722},
year = {2017},
note = {Special Issue on Advances in Mine Safety Science and Engineering},
issn = {2095-2686},
doi = {https://doi.org/10.1016/j.ijmst.2017.05.005},
url = {https://www.sciencedirect.com/science/article/pii/S2095268617303439},
author = {Hui Zhang},
keywords = {Virtual reality, Training, Head-mounted display, High immersive, Intuitive, Mining industry},
abstract = {Virtual reality (VR) training technology in the mining industry is a new field of research and utilization. The successful application of VR training system is critical to mine safety and production. Through the statistics of the current research and applications of VR training systems in mining industry, all the input/output devices are classified. Based on the classifications of the input/output devices that are used in the VR system, the current VR training systems for the mining industry could be divided into three types: screen-based general type, projector-based customized type, and head-mounted display (HMD)-based intuitive type. By employing a VR headset, a smartphone and a leap motion device, an HMD-based intuitive type VR training system prototype for drilling in underground mines has been developed. Ten trainees tried both the HMD-based intuitive system and the screen-based general control system to compare the experiences and training effects. The results show that the HMD-based system can give a much better user experience and is easy to use. Three of the five components of a VR training system, namely, the user, the tasks, and software and database should be given more attention in future research. With more available technologies of input and output devices, VR engines, and system software, the VR training system will eventually yield much better training results, and will play a more important role in as a training tool for mine safety.}
}
@article{SALADIN20061881,
title = {A preliminary report on the use of virtual reality technology to elicit craving and cue reactivity in cocaine dependent individuals},
journal = {Addictive Behaviors},
volume = {31},
number = {10},
pages = {1881-1894},
year = {2006},
issn = {0306-4603},
doi = {https://doi.org/10.1016/j.addbeh.2006.01.004},
url = {https://www.sciencedirect.com/science/article/pii/S0306460306000153},
author = {Michael E. Saladin and Kathleen T. Brady and Ken Graap and Barbara Olasov Rothbaum},
keywords = {Virtual reality, Craving, Cue reactivity, Cocaine dependence},
abstract = {In the present feasibility study, we developed a 3-dimensional virtual “crack” cocaine environment and evaluated the environment's ability to elicit subjective craving and cue reactivity (i.e., subjective emotional responding, heart rate and skin conductance) in 11 crack cocaine dependent individuals. Each of the seven 3-D crack cocaine scenes in the cocaine environment depicted actors engaging in a range of using-related behaviors (i.e., smoking crack) whereas the neutral environment contained scenes depicted 3-D aquariums with active aquatic life (baseline measures were obtained following immersion in the neutral environment). Results indicated that craving was significantly elevated during the cocaine-related scenes as compared to baseline. Craving varied by scene content, with scenes depicting active cocaine use eliciting the highest levels of craving. Heart rate was significantly higher in four of the scenes with drug use content and positive affect (i.e., happiness) ratings were significantly lower during cocaine scenes as compared to baseline. Overall, the results suggest that a standardized and stimulus rich virtual reality environment effectively elicits craving and physiologic reactivity. Such technology has potential utility in the development and refinement of exposure-based behavioral and pharmacological interventions for substance use disorders.}
}
@article{GAGLIARDI2023106141,
title = {Characterization and future perspectives of Virtual Reality Evacuation Drills for safe built environments: A Systematic Literature Review},
journal = {Safety Science},
volume = {163},
pages = {106141},
year = {2023},
issn = {0925-7535},
doi = {https://doi.org/10.1016/j.ssci.2023.106141},
url = {https://www.sciencedirect.com/science/article/pii/S0925753523000838},
author = {Emanuele Gagliardi and Gabriele Bernardini and Enrico Quagliarini and Michael Schumacher and Davide Calvaresi},
keywords = {Immersive Virtual Reality, Drills, Evacuation, Emergency simulation, User behavior},
abstract = {Physical evacuation drills are pre-planned activities to train building occupants in facing emergencies and evaluate safety performances. Nowadays, technologies including Virtual Reality (VR) and Immersive Virtual Reality (IVR) are shifting from the physical to the virtual paradigm. AR enables just to extend real-world environment, while VR and IVR allow to (re)create and manipulate digital environments. VR and IVR simulation systems have been observed to guarantee higher involvement and long-term information retention — leveraging more attractive experiences and psychological arousal. However, efforts should be provided to improve end-user training while assessing occupants’ behaviors and the effectiveness of the emergency plan. This paper proposes a systematic literature review of VR and IVR evacuation solutions. To support and guide such effort, we formulated thirteen structured research questions investigating scenarios, recipients, requirements, objectives, methods, and technologies. The results mainly show that VR and IVR drills almost entirely tackle a single hazard, considers occupants as sole system recipients, and lack systems formalization. Among the most relevant outcomes, the paper analyzes the need for enhancing the modeling of emergency systems (e.g., signage, alarms), user inclusiveness (i.e., impaired individuals), devices, non-player characters, and additional effects (e.g., heat reproduction, sounds, and smells). These measures can improve the level of realism experienced by the user of IVR simulators and pave the way to more reliable outcomes.}
}
@article{KIM2023301608,
title = {Digital forensic approaches for metaverse ecosystems},
journal = {Forensic Science International: Digital Investigation},
volume = {46},
pages = {301608},
year = {2023},
issn = {2666-2817},
doi = {https://doi.org/10.1016/j.fsidi.2023.301608},
url = {https://www.sciencedirect.com/science/article/pii/S2666281723001208},
author = {Donghyun Kim and Subin Oh and Taeshik Shon},
keywords = {Digital Forensics, Metaverse, Augmented Reality (AR), Virtual Reality (VR), Ecosystem, Meta, Meta Quest},
abstract = {The accelerating pace of digital transformation has given rise to metaverses that can participate freely in contactless environments. More than just game content, metaverses are driving everyday innovation across industries. However, threats are also prevalent, with crimes such as child sexual exploitation and privacy violations occurring in metaverses that mimic reality, making digital forensics for metaverse threats essential. Nevertheless, technical standards for different types of metaverses have yet to be defined, making investigation difficult. Furthermore, even though metaverses are complex forms that combine multiple hardware devices and software applications, existing studies have either focused on a single component or not analyzed the real-world environment. In this study, we derived a metaverse ecosystem with common components that comprise a metaverse and analyzed the hardware and software used throughout the user's metaverse lifecycle from a digital forensics perspective. In particular, we applied real-case-based scenario to the metaverse environment of the most popular Meta's currently in use to identify various artifacts that can be used across the ecosystem and validate the effectiveness of the process. We also developed a metaverse digital forensics tool for the first time in the current situation where open-source and commercial tools do not support metaverse investigations.}
}
@article{ALTAN2022103022,
title = {Developing serious games for CBRN-e training in mixed reality, virtual reality, and computer-based environments},
journal = {International Journal of Disaster Risk Reduction},
volume = {77},
pages = {103022},
year = {2022},
issn = {2212-4209},
doi = {https://doi.org/10.1016/j.ijdrr.2022.103022},
url = {https://www.sciencedirect.com/science/article/pii/S2212420922002412},
author = {Burak Altan and Servet Gürer and Ali Alsamarei and Damla Kıvılcım Demir and H. Şebnem Düzgün and Mustafa Erkayaoğlu and Elif Surer},
keywords = {Serious games, Training, Virtual reality, Mixed reality, CBRN-e, Mining},
abstract = {In the last decade, chemical, biological, radioactive, nuclear, and explosive (CBRN-e) attacks have become severe risks to countries, prompting connected parties to prioritize CBRN-e training. CBRN-e training is typically performed as physical exercises, and although such training is necessary and beneficial, repeating the same training program can be time-consuming and costly. In this study, newly developed versions of two previous serious games—Hospital and Biogarden— and a new mining serious game were developed for training purposes in Virtual Reality (VR), Mixed Reality (MR), and personal computer (PC) environments. The Hospital and Biogarden games’ scenarios were based on the joint activities held in 2018 in France and Belgium as part of the EU H2020 European Network Of CBRN Training CEnters (eNOTICE) project, while the mining game was created over a replica of a training mine at a university in Turkey. Sixteen CBRN-e experts from the eNOTICE project, who took part in the physical training programs in France and Belgium, evaluated the games. For evaluation and extensive feedback, presence, system usability scale, technology acceptance model questionnaires, and open-ended questions were conducted. The findings revealed that serious games have a vast potential in CBRN-e training, and the comparisons of different environments provided invaluable testbeds giving hindsight to develop a future training program.}
}
@article{JOHNSON2006121,
title = {Simulation Education in Emergency Medical Services for Children},
journal = {Clinical Pediatric Emergency Medicine},
volume = {7},
number = {2},
pages = {121-127},
year = {2006},
issn = {1522-8401},
doi = {https://doi.org/10.1016/j.cpem.2006.03.005},
url = {https://www.sciencedirect.com/science/article/pii/S1522840106000267},
author = {Laurie Johnson and Mary D. Patterson},
keywords = {patient simulator, patient simulation},
abstract = {Simulation has been utilized as a training method for nearly 80 years by the aviation industry to improve pilots' skills and enhance the teamwork of the flight crew. Within the medical profession, simulation techniques have been used extensively by anesthesiologists for individual and teamwork training tasks. Following the example in anesthesiology, simulation curricula are being developed for teaching and evaluating core competencies for surgical and emergency medicine residents, prehospital personnel, and medical students. Simulation models can be as simple as static mannequins for procedural skills or as complex as high-fidelity human patient simulators that react physiologically to administered medications and provider actions. As this technology continues to mature, benefits of incorporating such safe and valuable education to trainees across all medical disciplines and training levels must be considered in light of the expense of such endeavors. Benefits of simulation training within the medical field include learning and perfecting procedural skills before patient interaction, participating in rare or complicated case scenarios which might otherwise not be encountered in traditional training, and nonprocedural training such as teamwork training and disaster management skills. As efforts continue to emerge to increase patient safety and reduce medical errors, simulation has become more popular in promoting patient autonomy while allowing trainees to experience positive and negative outcomes with the opportunity for constructive feedback, or debriefing, afterward.}
}
@article{CHOWDHURY2017301,
title = {The Need for Casualty Care Decision Support in Civilian and Defense Sectors},
journal = {Procedia Engineering},
volume = {188},
pages = {301-308},
year = {2017},
note = {Structural Health Monitoring - From Sensing to Diagnosis and Prognosis},
issn = {1877-7058},
doi = {https://doi.org/10.1016/j.proeng.2017.04.488},
url = {https://www.sciencedirect.com/science/article/pii/S1877705817320404},
author = {Nabil M. Chowdhury and Peter Finnegan and Mark Fitzgerald and Wing Kong Chiu},
keywords = {trauma, smartglass, decision support system},
abstract = {Trauma effects the lives of many people around the world; cases may include people involved in a car crash right through to military personnel injured on the battle field. Each situation requires different levels of care and the diagnosis and treatments administered play a large role in the recovery of the trauma victims. In such events it is vital to provide the correct level of care with high efficiency and with minimal errors. However these fast paced situations lead to stressful environments contributing to errors in patient care leading to detrimental consequences of morbidity. Computerized decision support systems have been introduced into the medical industry which have greatly improved patient recovery in trauma care, however such systems are primarily targeted for use in well-established medical facilities. The time it takes to transport an injured victim at the scene to a medical facility also plays an important role in the recovery process; by introducing optical head mounted display systems, remote off site field support can be provided which can enhance effective medical advice offered to both inexperienced through to properly trained medical staff prior, during transport and upon reception at a medical facility. This device is expected to greatly improve the recovery phase of trauma victims and reduce errors in patient treatment and diagnosis both in and out of hospital care.}
}
@article{GELENBE20123869,
title = {Large scale simulation for human evacuation and rescue},
journal = {Computers & Mathematics with Applications},
volume = {64},
number = {12},
pages = {3869-3880},
year = {2012},
note = {Theory and Practice of Stochastic Modeling},
issn = {0898-1221},
doi = {https://doi.org/10.1016/j.camwa.2012.03.056},
url = {https://www.sciencedirect.com/science/article/pii/S0898122112002611},
author = {Erol Gelenbe and Fang-Jing Wu},
keywords = {Cyber-physical systems, Emergency management, Search and rescue systems, Distributed decision making, Modeling and simulation},
abstract = {This paper surveys recent research on the use of sensor networks, communications and computer systems to enhance the human outcome of emergency situations. Areas covered include sensing, communication with evacuees and emergency personnel, path finding algorithms for safe evacuation, simulation and prediction, and decision tools. The systems being considered are a special instance of real-time cyber-physical-human systems that have become a crucial component of all large scale physical infrastructures such as buildings, campuses, sports and entertainment venues, and transportation hubs.}
}
@article{BABER2009464,
title = {Mobile technology for crime scene examination},
journal = {International Journal of Human-Computer Studies},
volume = {67},
number = {5},
pages = {464-474},
year = {2009},
issn = {1071-5819},
doi = {https://doi.org/10.1016/j.ijhcs.2008.12.004},
url = {https://www.sciencedirect.com/science/article/pii/S1071581908001778},
author = {Chris Baber and Paul Smith and Mark Butler and James Cross and John Hunter},
keywords = {Wearable computers, Tablet computers, Evidence management, Crime scene examination, Distributed cognition, Annotated images},
abstract = {In this paper, the concept of distributed cognition is used to inform the design, development and trialling of technologies to support Crime Scene Examination is reported. A user trial, with trainee Crime Scene Examiners, was conducted to compare the ways in which evidence search and recovery could be combined with the production of a crime scene report (that must be written at the scene). Participants completed the crime scene report using either the conventional paper form, an electronic form on a tablet computer (to represent the current trend in digitisation of crime scene reports), or a wearable computer (with speech input). While both computer conditions (tablet and wearable) led to faster performance, when compared with the paper condition, there was no difference in content or quality of the reports produced in any of the three conditions; thus, the computer conditions produced acceptable reports in much faster time when compared to conventional practice. Furthermore, activity sampling analysis showed that participants found it much easier to integrate the wearable computer (than either paper forms or tablet computer) into their search and recovery activity.}
}
@article{BRUNZINI2023100505,
title = {Human-centred data-driven redesign of simulation-based training: a qualitative study applied on two use cases of the healthcare and industrial domains},
journal = {Journal of Industrial Information Integration},
volume = {35},
pages = {100505},
year = {2023},
issn = {2452-414X},
doi = {https://doi.org/10.1016/j.jii.2023.100505},
url = {https://www.sciencedirect.com/science/article/pii/S2452414X2300078X},
author = {Agnese BRUNZINI and Margherita PERUZZINI and Pamela BARBADORO},
keywords = { Healthcare 4.0, Industry 4.0, Simulation-based training, Design optimization, Human Factors, Ergonomics},
abstract = {Among the main features of Industry 4.0, digitization and the evolution of the human-machine interaction occupy a central role. These concepts are transferring even in the health domain, moving toward Healthcare 4.0. The new concept of Industry 5.0 further promotes the human-centric perspective focusing on the consideration of human factors. In this context, training for workers, both in the industry and in the healthcare sectors, needs to be strongly human-centred to be efficient and effective. This paper refers to simulation-based training and aims to provide a transdisciplinary framework for the simulation assessment from the learners’ perspective. The final scope is to outline a set of data-driven guidelines for the simulation optimization and redesign, throughout a human-centred approach, aiming to improve the workers’ performance and the overall learning process, considering the physical, cognitive, and emotional conditions. The proposed method is suitable for each kind of training (both traditional and with the use of virtual reality/augmented reality systems) and relevant for every sector. Two different use cases are presented, respectively referring to the healthcare and industry fields, proposing a unique assessment protocol. The healthcare use case considered the low-fidelity simulation of lumbar puncture, while the industrial use case referred to the replacement of the engine oil filter on tractors. Although the great differences between the content of the use cases, the results obtained about performance as well as cognitive and emotional states are close enough to define a common set of guidelines to redesign and optimize the simulation-based training.}
}
@article{MORELOT2021104145,
title = {Virtual reality for fire safety training: Influence of immersion and sense of presence on conceptual and procedural acquisition},
journal = {Computers & Education},
volume = {166},
pages = {104145},
year = {2021},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2021.104145},
url = {https://www.sciencedirect.com/science/article/pii/S0360131521000221},
author = {Sarah Morélot and Alain Garrigou and Julie Dedieu and Bernard N'Kaoua},
keywords = {Augmented and virtual reality, Human-computer interface, Media in education, Pedagogical issues},
abstract = {A fire can have serious economic and human consequences. However, in many cases, rapid intervention and appropriate behavior can significantly reduce this threat. For this it is important that people are properly trained. Faced with the economic, ecological and organizational requirements and constraints linked to fire safety training, virtual training environments appear to be a judicious alternative to traditional training. However, before committing companies to invest in expensive devices, it is necessary to ensure the effectiveness of such devices. The literature is rich and divided on this subject, and it appears that certain characteristics of the system and of the learners are decisive. In this context, the objective of our work was to study the effects of immersion, the feeling of presence as well as the interaction between these 2 factors on the performance of conceptual and procedural learning. Certain variables were also controlled such as gender, tendency to immersion, previous experience in computers and video games. Our work shows that immersion promotes procedural but not conceptual learning, and that neither the sense of presence, nor the interaction between immersion and the sense of presence affect these two types of learning in our training task. Apart from the knowledge of fire which potentiates the effect of immersion on procedural learning, the variables considered in our study (computer experience, video game experience and genre) had no impact on performance. Understanding the impact of the technical device or the characteristics of users on conceptual and procedural learning is a major challenge in helping trainers to develop pedagogical devices in order to better exploit the opportunities offered by new technological approaches.}
}
@article{HASAN2022187,
title = {Pedestrian safety using the Internet of Things and sensors: Issues, challenges, and open problems},
journal = {Future Generation Computer Systems},
volume = {134},
pages = {187-203},
year = {2022},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2022.03.036},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X22001170},
author = {Raiful Hasan and Ragib Hasan},
keywords = {Pedestrian safety, Smartphone zombies, Internet of Things, Obstacle detection, Bystanders privacy},
abstract = {Pedestrian safety has emerged recently as a public health challenge worldwide. People are being physically harmed due to losing focus on their surroundings and putting safety at risk. Though pedestrian safety is a shared responsibility, researchers suggest that distractions by smart devices and reduced cognitive skills are major causes of accidents. There is a scope to assist pedestrians through amplifying cognitive skills using heterogeneous Internet of Things (IoT) and sensors. These technologies could discover and warn users about unanticipated events such as just-in-time warnings about the hazards, distractions, extreme weather calamities, and potential impending dangers. An automated personalized agent helps monitor, diagnose problems, and protect people in an urban environment. Researchers have proposed various systems and implemented them in multiple domains. In this survey, we assessed, analyzed, and compared the most recent research on pedestrian safety. We identified the challenges, research gaps, and future directions toward using technology to improve pedestrian safety.}
}
@article{SYAMIMI2020409,
title = {VR industrial applications―A singapore perspective},
journal = {Virtual Reality & Intelligent Hardware},
volume = {2},
number = {5},
pages = {409-420},
year = {2020},
issn = {2096-5796},
doi = {https://doi.org/10.1016/j.vrih.2020.06.001},
url = {https://www.sciencedirect.com/science/article/pii/S209657962030070X},
author = {Athirah Syamimi and Yiwei Gong and Ryan Liew},
keywords = {Virtual reality, VR applications, Building information modeling},
abstract = {Virtual Reality (VR) has been around for a long time but has come into the spotlight only recently. From an industrial perspective, this article serves as a proverbial scalpel to dissect the different use cases and commercial applications of VR in Singapore. Before researching the Singapore market, we examine how VR has evolved. At the moment, the global annual budget for VR (and augmented reality) is at an upward trend with a leading growth in market value for the training sector. VR in Singapore has also seen a rapid development in recent years. We discuss some of the Singapore government's initiatives to promote the commercial adoption of VR for the digital economy of the nation. To address the mass adoption of VR, we present VRcollab's business solutions for the construction and building industry. 2020 is one of the most important years for VR in history.}
}
@article{CHNG2009458,
title = {Experiential archaeology: Is virtual time travel possible?},
journal = {Journal of Cultural Heritage},
volume = {10},
number = {4},
pages = {458-470},
year = {2009},
issn = {1296-2074},
doi = {https://doi.org/10.1016/j.culher.2009.02.001},
url = {https://www.sciencedirect.com/science/article/pii/S1296207409000831},
author = {Eugene Ch’ng},
keywords = {Virtual Time Travel, Experiential Archaeology, Virtual Reality, Mixed Reality, Artificial Life, Artificial Intelligence, Presence},
abstract = {Advances in computing hardware coupled with its software counterparts have, for the past decades, influenced to a greater extent both the workflow of archaeologists and their interpretation of archaeological data. On the leisurely periphery, the synergy that arises between entertainment demands and commercial driven developments of interactive 3D (i3D) computer games has pushed these technologies beyond the expectations of the Virtual Reality (VR) community. This phenomenal growth in useable technology and its proportionate decrease in price have benefited the applicability of VR which in turn, have made it more accessible for researchers wishing to harness its benefits. The last 10 years have seen a steady increase in the use of VR technology to restore, preserve, reconstruct, recreate, and visualise ancient sites, monuments and artefacts. But, is technology ready for virtual time travel (VTT)? This article examines the possibility of experiential archaeology in voltage and silicon with the aim of formulating a strategy for VTT.}
}
@incollection{2018181,
title = {Index},
editor = {Ida Arlene Joiner},
booktitle = {Emerging Library Technologies},
publisher = {Chandos Publishing},
pages = {181-188},
year = {2018},
series = {Chandos Information Professional Series},
isbn = {978-0-08-102253-5},
doi = {https://doi.org/10.1016/B978-0-08-102253-5.00022-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780081022535000228}
}
@article{CHEN2021103631,
title = {Development of BIM, IoT and AR/VR technologies for fire safety and upskilling},
journal = {Automation in Construction},
volume = {125},
pages = {103631},
year = {2021},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2021.103631},
url = {https://www.sciencedirect.com/science/article/pii/S0926580521000820},
author = {Haosen Chen and Lei Hou and Guomin (Kevin) Zhang and Sungkon Moon},
keywords = {Building fires, Situational awareness, Fire safety, IoT, BIM, VR, AR},
abstract = {High-rise building fires can pose a significant threat to occupants and firefighters. The state-of-the-art technologies such as sensor-based Internet of Things (IoT), Building Information Modelling (BIM), Virtual Reality (VR) and Augmented Reality (AR) may offer great potential to improve building fire safety and rescue efficiency, primarily through ameliorating the level of situational awareness. This study proposes an innovative technology integrated framework for prototyping a proof-of-concept BIM, IoT and AR/VR system based upon the rationale of situational awareness. A pilot test based on a simulated fire scenario is conducted to evaluate the functionality of the framework. The outcomes reveal that the data generated by the system can be leveraged by the firefighting department to quickly locate the whereabouts of the indoor fires, and the VR gamification scenarios can expedite the development of situational awareness for the trainees. The limitations and future works are also discussed at the end of this paper.}
}
@incollection{2023311,
title = {Index},
editor = {Surbhi {Bhatia Khan} and Suyel Namasudra and Swati Chandna and Arwa Mashat and Fatos Xhafa},
booktitle = {Innovations in Artificial Intelligence and Human-Computer Interaction in the Digital Era},
publisher = {Academic Press},
pages = {311-321},
year = {2023},
series = {Intelligent Data-Centric Systems},
isbn = {978-0-323-99891-8},
doi = {https://doi.org/10.1016/B978-0-323-99891-8.20001-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780323998918200016}
}
@article{BOURHIM2020102484,
title = {Efficacy of Virtual Reality for Studying People's Pre-evacuation Behavior under Fire},
journal = {International Journal of Human-Computer Studies},
volume = {142},
pages = {102484},
year = {2020},
issn = {1071-5819},
doi = {https://doi.org/10.1016/j.ijhcs.2020.102484},
url = {https://www.sciencedirect.com/science/article/pii/S1071581920300860},
author = {EL Mostafa Bourhim and Abdelghani Cherkaoui},
keywords = {Virtual reality, Pre-evacuation human behavior, Modeling and simulation, Fuzzy comprehensive evaluation model, Analytic hierarchy process (AHP), Usability},
abstract = {The recent proliferation of consumer-level virtual reality (VR) headsets such as the HTC Vive, is creating a growing user-base in demand of highly-controlled immersive virtual environments (VEs). The authors take advantage of the commercial availability of these VR devices to build a high-rise residential buildings fire escape, which provides a highly immersive VR simulation game approach, designed to simulate pre-evacuation human reactions in fire emergencies. We replicated this fire scene in our VE using the unity3D game engine and the HTC Vive head-mounted VR display. The results gathered from this virtual simulation were compared to the data from real fire condition to test the efficacy of the information provided from this VE. Furthermore, we propose a comprehensive evaluation system for VE usability using the analytic hierarchy process (AHP) and the fuzzy evaluation approach. Subjective responses show that our simulation-based VR was effective, realistic, and engaging. Overall, the study results confirm the efficacy of VR technology for research on people's pre-evacuation behavior under fire.}
}
@article{GOLOMINGI2023451,
title = {Augmented reality in forensics and forensic medicine – Current status and future prospects},
journal = {Science & Justice},
volume = {63},
number = {4},
pages = {451-455},
year = {2023},
issn = {1355-0306},
doi = {https://doi.org/10.1016/j.scijus.2023.04.009},
url = {https://www.sciencedirect.com/science/article/pii/S1355030623000321},
author = {Raffael Golomingi and Akos Dobay and Sabine Franckenberg and Lars Ebert and Till Sieberth},
keywords = {Augmented Reality, Forensics, Crime Scene Investigation, Forensic Medicine, Education},
abstract = {Forensic investigations require a vast variety of knowledge and expertise of each specialist involved. With the increase in digitization and advanced technical possibilities, the traditional use of a computer with a screen for visualization and a mouse and keyboard for interactions has limitations, especially when visualizing the content in relation to the real world. Augmented reality (AR) can be used in such instances to support investigators in various tasks at the scene as well as later in the investigation process. In this article, we present current applications of AR in forensics and forensic medicine, the technological basics of AR, and the advantages that AR brings for forensic investigations. Furthermore, we will have a brief look at other fields of application and at future developments of AR in forensics.}
}
@article{BERNDT2019199,
title = {An Integrated Information and Decision-Support System for the Management of Mass Casualty Incidents},
journal = {IFAC-PapersOnLine},
volume = {52},
number = {19},
pages = {199-204},
year = {2019},
note = {14th IFAC Symposium on Analysis, Design, and Evaluation of Human Machine Systems HMS 2019},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2019.12.096},
url = {https://www.sciencedirect.com/science/article/pii/S2405896319319317},
author = {Henrik Berndt and Michael Herczeg},
keywords = {Decision Support Systems, Human-Computer Interaction, Autonomous Systems, Mass Casualty Incident Management, Situation Awareness, Safety-critical Systems},
abstract = {Mass casualty incidents are a challenging safety-critical domain with high complexity, where management and decision-making can make the difference between life and death. As current paper-based tools and software solutions have severe limitations, we examine the use of integrated computer-based support systems in this domain. Instead of being primarily focused on the replacement of paper-based tools, we are looking for additional value of computer systems to support the incident commanders by providing appropriate presentations and offering assistance functions with different automation approaches. For this purpose, we are developing modular software components that can be combined to an integrated system for the management of casualties. We use a user-centered design approach. Therefore, the needs and abilities of prospective users were analyzed thoroughly and considered in system design. This includes interviews and field observations as well as formative evaluations of prototypes. This article summarizes our research for such an integrated management system for MCIs.}
}
@article{ALSBERG201224,
title = {Is sensing spatially distributed chemical information using sensory substitution with hyperspectral imaging possible?},
journal = {Chemometrics and Intelligent Laboratory Systems},
volume = {114},
pages = {24-29},
year = {2012},
issn = {0169-7439},
doi = {https://doi.org/10.1016/j.chemolab.2012.01.012},
url = {https://www.sciencedirect.com/science/article/pii/S0169743912000238},
author = {Bjørn K. Alsberg},
keywords = {Augmented reality, Sensory substitution, Hyperspectral imaging, Hyperspectral camera, Chemometrics},
abstract = {Chemical images which are often computed from hyperspectral images contain the spatial distribution of chemical information of a scene. For many applications visualizing such images on computer screens is sufficient, however there are cases where there is a need to combine the chemical images more naturally with human vision. This is especially true for interactive work where chemical images are being rapidly updated to the user. Effective integration of spatial information in general from external sources with vision is a challenge. One approach is to overlay the view of the real physical world with computer-generated graphics as in augmented reality. However such cluttering of the visual field with computer-generated graphics may confuse the user and reduce functionality. Another is projecting the chemical images back onto the scene under study in order to render the chemical information in situ to the user. This approach, however has challenges in connection with very small and very large scenes under investigation. An alternative approach is here investigated based on the possibility of enhancing the human vision system using a sensory substitution device. Such devices enables a person to sense spatial information conveyed through sensory channels other than the eye, such as hearing and sense of touch. Results presented support the claim that spatial chemical information from a hyperspectral camera can be conveyed to the brain through a sensory channel different from the eyes. As this is tested on a sighted subject it effectively provides an extension of the human vision system to incorporate chemical information which otherwise is invisible to the naked eye.}
}
@article{PARK201854,
title = {An interactive and intuitive control interface for a tele-operated robot (AVATAR) system},
journal = {Mechatronics},
volume = {55},
pages = {54-62},
year = {2018},
issn = {0957-4158},
doi = {https://doi.org/10.1016/j.mechatronics.2018.08.011},
url = {https://www.sciencedirect.com/science/article/pii/S095741581830134X},
author = {Sungman Park and Yeongtae Jung and Joonbum Bae},
keywords = {Human-machine interactions, Robot kinematics, Telerobotics},
abstract = {Robotic systems, which are controlled by artificial intelligent or tele-operation control interfaces, have been developed to be deployed instead of the human in extreme environments. However, insufficient artificial intelligence performance in unknown and unpredictable environments, and non-intuitive control interfaces with low immersive feedback have prevented wide spread of such robotic systems. In this paper, an intuitive and interactive control interface with inertial measurement units (IMUs), haptic gloves and a head mounted display (HMD) was developed to control a tele-operated robot in remote environments, which was abbreviated as AVATAR system. The tele-operated robot can be operated by a user’s motions which are measured by the wearable interface. Through a kinematic analysis of the user and the tele-operated robot, desired robot joint angles are calculated to follow the user’s motions in real time. Also, dual cameras on the robot head provide 3D visual information around the robot to the user. A grasping force of the robot hands, measured by motor current, is transmitted to the user as vibration feedback to fingertips of the haptic gloves. A long term evolution (LTE) was used as wireless communication between the user and the robot. The performance of the proposed AVATAR system has been verified by experiments.}
}
@article{HAFERKAMP201181,
title = {Training disaster communication by means of serious games in virtual environments},
journal = {Entertainment Computing},
volume = {2},
number = {2},
pages = {81-88},
year = {2011},
note = {Serious Games Development and Applications},
issn = {1875-9521},
doi = {https://doi.org/10.1016/j.entcom.2010.12.009},
url = {https://www.sciencedirect.com/science/article/pii/S1875952110000273},
author = {Nina Haferkamp and Nicole C. Kraemer and Conor Linehan and Massimiliano Schembri},
keywords = {Crisis communication, Serious games, Soft skills},
abstract = {The training of social skills in organizational settings has become more and more important for an effective communicative exchange between members of staff. Especially in companies where the line of communication has to be fast and unmistakable, e.g. in crisis management units, the regular training of communication skills is therefore indispensable. The DREAD-ED project proposes an innovative, technology-based teaching methodology to meet these needs. The methodology provides a serious game which enables its users to train soft skills in a virtual environment under safe conditions. The current paper presents the results of two trials conducted with crisis managers and university students in Germany.}
}
@article{BAKHTIARI2023104958,
title = {A critical review for the application of cutting-edge digital visualisation technologies for effective urban flood risk management},
journal = {Sustainable Cities and Society},
volume = {99},
pages = {104958},
year = {2023},
issn = {2210-6707},
doi = {https://doi.org/10.1016/j.scs.2023.104958},
url = {https://www.sciencedirect.com/science/article/pii/S2210670723005693},
author = {Vahid Bakhtiari and Farzad Piadeh and Kourosh Behzadian and Zoran Kapelan},
keywords = {Augmented reality, Digital twin, Digital visualisation, Flood risk management, Systematic review, Virtual reality},
abstract = {Cutting-edge digital visualisation tools (CDVT) are playing an increasingly important role in improving urban flood risk management. However, there is a paucity of comprehensive research examining their role across all stages of urban flood risk management. To address, this study conducts an integrated critical review to identify the application of CDVT and assess their contribution to the prevention, mitigation, preparation, response, and recovery stages of flood risk management. The results show that virtual reality, augmented reality, and digital twin technologies are the primary CDVT used in urban flood visualisation, with virtual reality being the most frequently used. The focus of urban flood visualisation studies has been primarily on preparation and mitigation stages. However, there is a need to investigate the application of these technologies in the entire urban water cycle. Furthermore, there is potential for greater adoption of digital twin, especially in simulating urban flood inundation and flood evacuation routes. Integrating real-time data, data-driven modeling, and CDVT can significantly improve real-time flood forecasting. This benefits stakeholders and the public by enhancing early warning systems, preparedness, and flood resilience, leading to more effective flood risk management and reduced impacts on communities.}
}
@article{REEDY2023100313,
title = {Interpol review of digital evidence for 2019–2022},
journal = {Forensic Science International: Synergy},
volume = {6},
pages = {100313},
year = {2023},
issn = {2589-871X},
doi = {https://doi.org/10.1016/j.fsisyn.2022.100313},
url = {https://www.sciencedirect.com/science/article/pii/S2589871X22000985},
author = {Paul Reedy}
}
@article{JEON2023139101,
title = {Advanced cartridge design for a gas respiratory protection system using experiments, CFD simulation and virtual reality},
journal = {Journal of Cleaner Production},
volume = {426},
pages = {139101},
year = {2023},
issn = {0959-6526},
doi = {https://doi.org/10.1016/j.jclepro.2023.139101},
url = {https://www.sciencedirect.com/science/article/pii/S0959652623032596},
author = {Rakyoung Jeon and Shin Hyuk Kim and Kwangjun Ko and Kihyun Kwon and Myungkyu Park and Ireh Seo and Min Oh and Chang-Ha Lee},
keywords = {Gas respirator cartridge, Adsorption, Optimal design, CFD, Virtual reality},
abstract = {Gas masks are critical for protection against chemical, biological, radiological, and nuclear materials. Efforts are underway to develop advanced cartridges for next-generation gas respirators in civil-military combined use to improve wearability and protection for users (firefighters, military personnel, and environmental and safety-related workers). Herein, the performance of three newly designed cartridges for a next-generation gas respirator was evaluated using flow analysis, along with adsorption characteristics. The adsorption kinetics of cyclohexane gas on ASC (a copper-silver-hexavalent chromium impregnated activated carbon in the study) was measured by breakthrough experiments in a packed bed, and the obtained parameters were used in the computational fluid dynamics (CFD) model for the designed plate-type cartridges. To apply the physical properties of the adsorbent to the CFD simulation, porous materials were expressed using the granular technique and packed bed technique. The CFD model was verified through a gas adsorption experiment using a prototype cartridge. The respiration resistance and breakthrough time for the filled-adsorbent efficiency and lifespan were compared among the three designed cartridges according to the gas inflow conditions. Additionally, virtual engineering was performed by grafting the CFD results to a virtual reality (VR) system with which 3-dimensional performance visuals of the cartridges could be observed. The developed VR system provides detailed information for cartridge design and optimization. Overall, the developed procedure of virtual engineering can be used to improve CFD simulation results.}
}
@article{FOGT2023101870,
title = {Novel silicone elastomer contact lenses designed for simultaneous viewing of distance and near eye displays},
journal = {Contact Lens and Anterior Eye},
volume = {46},
number = {4},
pages = {101870},
year = {2023},
issn = {1367-0484},
doi = {https://doi.org/10.1016/j.clae.2023.101870},
url = {https://www.sciencedirect.com/science/article/pii/S136704842300084X},
author = {Jennifer Swingle Fogt},
keywords = {Silicone elastomer, Contact lenses, Embeddable optical elements, Spectacle-mounted displays},
abstract = {Significance
As technology advances, there is a need for a safe and well-fitting contact lens that can be utilized to carry embedded components without concerns of decreasing oxygen permeability to the eye.
Purpose
The purpose of this study was to assess fitting characteristics, vision and performance of a novel ultra-high Dk silicone elastomer contact lens having a fully encapsulated two-state polarizing filter and a high-powered central lenslet that allows viewing at distance and viewing of a near eye display, while managing the concomitant high water vapor permeability of the material.
Methods
15 participants were fit with the silicone elastomer study lenses. Biomicroscopy was conducted before and after lens wear. Visual acuity with manifest refraction and visual acuity with an over-refraction while wearing the plano-powered study lenses were measured. Participants wore spectacles with micro-displays at the focal length of the lenslet on each eye. Lens fit was assessed including ease of lens removal. Subjective assessments of viewing the micro-displays were completed on a 1(unable) to 10(immediate/profound/stable) scale.
Results
Biomicroscopy revealed no eyes had moderate or severe corneal staining after study lens wear. Mean (±standard deviation) LogMAR acuity for all eyes was −0.13(0.08) with best corrected refraction and −0.03(0.06) with the study lenses and over-refraction. Mean spherical equivalent of the manifest refraction for both eyes was −3.12 D and was −2.75 D over the plano study lenses. Subjective assessments revealed a mean score of 7.67(1.91) for ease of obtaining fusion; 8.47(1.30) for ease of observing three-dimensional vision, and 8.27(1.49) for stability of the fused binocular display vision.
Conclusion
The silicone elastomer study lenses with a two-state polarizing filter and central lenslet allow for vision at distance and on spectacle mounted micro-displays.}
}
@article{BLAKELY2023104052,
title = {Dual-task effects between tone counting and mathematical calculations},
journal = {Applied Ergonomics},
volume = {111},
pages = {104052},
year = {2023},
issn = {0003-6870},
doi = {https://doi.org/10.1016/j.apergo.2023.104052},
url = {https://www.sciencedirect.com/science/article/pii/S000368702300090X},
author = {Megan J. Blakely and Samantha L. Smith and Paul N. Russell and William S. Helton},
keywords = {Calculations, Climbing, Dual-task, Tone counting},
abstract = {We examined the impact of performing a tone counting task of varying cognitive loads and mathematical calculations simultaneously, compared to performance on the same tasks done individually. Participants performed continuous mathematical calculations, performed a high and a low cognitive load tone counting task, and also performed the math and counting tasks simultaneously. Performing the two tasks together resulted in significant dual-task interference. We also compared these results to previous studies employing the tone counting tasks with physically demanding tasks (climbing, kayaking and running). The interference between tone counting and mathematical calculations was worse than the interference between tone counting and running and kayaking. For climbing, the difference in interference was more nuanced with evidence indicating climbing uniquely asserts task prioritization. These findings have implications for operations requiring dual or multi-tasking.}
}
@article{BEHZADAN2008737,
title = {Ubiquitous location tracking for context-specific information delivery on construction sites},
journal = {Automation in Construction},
volume = {17},
number = {6},
pages = {737-748},
year = {2008},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2008.02.002},
url = {https://www.sciencedirect.com/science/article/pii/S0926580508000186},
author = {Amir H. Behzadan and Zeeshan Aziz and Chimay J. Anumba and Vineet R. Kamat},
keywords = {Augmented reality, Construction, Context awareness, Information delivery, Location tracking},
abstract = {Construction projects are information-intensive in nature and require site personnel to have continuous on-demand access to information such as project plans, drawings, schedules, and budgets. Awareness of a user's context (such as user profile, role, preferences, task, and existing project conditions) can enhance the construction project delivery process by providing a mechanism to determine information relevant to a particular context. Context awareness can also be used to improve security, logistics and health and safety practices on construction sites. Location is an important aspect of context awareness. A location aware application can utilize the knowledge of the user/object location to provide relevant information and services. This paper argues that a successful and reliable location tracking system must be able to track a user's spatial context and deliver contextual data continuously in both outdoor and indoor environments to effectively support construction projects. Research describing the use of Wireless Local Area Network (WLAN) for indoor tracking and Global Positioning System (GPS) for outdoor spatial context tracking is presented, and an integrated tracking technique using WLAN and GPS for ubiquitous location sensing is introduced. The key benefits and technical challenges of such an integrated approach are also highlighted. The presented tracking techniques have been validated in both indoor and outdoor environments to ensure their practical implementation on real construction jobsites.}
}
@incollection{1994497,
title = {Index},
editor = {Christopher D. Watkins and Stephen R. Marenka},
booktitle = {Virtual Reality Excursions with Programs in C},
publisher = {Academic Press},
pages = {497-503},
year = {1994},
isbn = {978-0-12-737865-7},
doi = {https://doi.org/10.1016/B978-0-12-737865-7.50020-1},
url = {https://www.sciencedirect.com/science/article/pii/B9780127378657500201}
}
@article{YE2022101668,
title = {Cognitive characteristics in firefighter wayfinding Tasks: An Eye-Tracking analysis},
journal = {Advanced Engineering Informatics},
volume = {53},
pages = {101668},
year = {2022},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2022.101668},
url = {https://www.sciencedirect.com/science/article/pii/S1474034622001318},
author = {Yang Ye and Yangming Shi and Pengxiang Xia and John Kang and Oshin Tyagi and Ranjana K. Mehta and Jing Du},
keywords = {Firefighter, Wayfinding, Virtual Reality, Gaze analysis, Cognitive analysis},
abstract = {During search and rescue, firefighters need to find paths in an unfamiliar space with minimum time and information available. The effective memorization and retrieval of critical spatial information can help reduce risks and increase mission efficiency. Although evidence has shown that different formats of wayfinding information, including landmarks, routes, and surveys, can impact search and rescue performance in different manners, a deeper understanding of the characteristics of firefighters’ cognitive processes related to the varying wayfinding information formats is less explored. To evaluate firefighters’ performance and cognitive characteristics in search and rescue, a firefighter experiment in Virtual Reality (VR) was conducted. Firefighters (n = 40) were recruited to participate in the simulated rescue task. After reviewing the spatial information in different formats, firefighters were requested to find three victims inside a VR maze as quickly as possible. Task performance was evaluated by the number of victims found and the time spent. Firefighters’ gaze patterns were analyzed to evaluate their cognitive status. The result showed that although the cognitive load under the survey and route conditions was significantly higher than under the landmark condition (p < 0.001), the decision-making involved a more effective cognitive process related to choosing the right path at critical waypoints such as where a turning decision must be made. Thus, the perceived workload and fatigue levels of the two conditions were lower, and the wayfinding performance was better. In contrast, with landmark information, the cognitive load levels were consistently high, along with increased mental fatigue. The findings reveal a series of cognitive features related to a more effective spatial decision-making in search and rescue. In the future, it is expected that these cognitive features can be used to develop real-time monitoring and prediction models for wayfinding performance.}
}
@article{KISHIMOTO2023104,
title = {Simulation training for medical emergencies of dental patients: A review of the dental literature},
journal = {Japanese Dental Science Review},
volume = {59},
pages = {104-113},
year = {2023},
issn = {1882-7616},
doi = {https://doi.org/10.1016/j.jdsr.2023.02.004},
url = {https://www.sciencedirect.com/science/article/pii/S1882761623000066},
author = {Naotaka Kishimoto and Takuro Sanuki and Younan Liu and Simon D. Tran and Kenji Seo},
keywords = {Simulation training, Medical emergency, High-fidelity manikin,  simulation, Debriefing, Telesimulation},
abstract = {In recent years, due to the aging of the population, the number of dental patients with comorbidities such as hypertension and diabetes has increased. Although it has been reported that these patients are increasingly developing medical emergencies during their dental treatments, many dental providers still do not possess the skills to manage medical emergencies appropriately. Simulation training is essential to improve this situation however, there is no report describing how to conduct an effective simulation in detail for dental office medical emergencies. The purpose of this review is to provide information on simulations that is effective and practical. The authors will highlight the key characteristics for providing effective simulation trainings, such as the selection of simulators, simulation locations, instructors, debriefings, methods for evaluating educational effectiveness, and the use of telesimulation as a method for simulation training due to the global COVID-19 pandemic. In addition, this review provides recommendations on tailoring an ideal simulation training course for those who wish to create one. The authors hope that this review will promote the spread of effective simulation training and in turn, contribute to improving the medical safety of dental patients.}
}
@article{WATTANASOONTORN2013231,
title = {Serious games for health},
journal = {Entertainment Computing},
volume = {4},
number = {4},
pages = {231-247},
year = {2013},
issn = {1875-9521},
doi = {https://doi.org/10.1016/j.entcom.2013.09.002},
url = {https://www.sciencedirect.com/science/article/pii/S1875952113000153},
author = {Voravika Wattanasoontorn and Imma Boada and Rubén García and Mateu Sbert},
keywords = {Serious games, Healthcare, Medical information system, Interactive learning},
abstract = {Maintaining and restoring health is a basic aspect of well being. On the other hand, serious games is an emerging technology growing in importance for specialized training, taking advantage of 3D games and game engines in order to improve the realistic experience of users. Thus, according to the advancement of technology and the desire to achieve good health using an interesting and enjoyable way, different serious games for health have been proposed during the last few years. In this paper, we present the core process of serious games and explain their functionalities. Then, we survey more than one hundred serious games for health and propose new classifications in four different aspects. Finally, we use fifteen relevant characteristics to classify all the surveyed games and present them with plenty of graphs and charts with corresponding discussion.}
}
@article{PARK2022102898,
title = {Performance evaluation of a tactile and kinesthetic finger feedback system for teleoperation},
journal = {Mechatronics},
volume = {87},
pages = {102898},
year = {2022},
issn = {0957-4158},
doi = {https://doi.org/10.1016/j.mechatronics.2022.102898},
url = {https://www.sciencedirect.com/science/article/pii/S0957415822001167},
author = {Sungman Park and Yeongyu Park and Joonbum Bae},
keywords = {Human–machine interactions, Haptics, Teleoperation},
abstract = {Teleoperation during a catastrophic event requires an interface that can perform under frequently changing circumstances caused by unpredictable and dangerous conditions. Thus, teleoperation interfaces are under active development to provide both visual and haptic feedback to the fingers. However, studies of teleoperation systems with finger haptic feedback based on force profiles are difficult to conduct because of interface limitations. Therefore, in this paper, we introduce an intuitive teleoperation interface, an anthropomorphic teleoperated robot, and a hand-wearable force-feedback system that provides various feedbacks to the fingers. We combined these systems to compare and evaluated the performance of tactile and kinesthetic finger feedback using two experiments: maintaining appropriate grip force for variably fragile objects and following a force trajectory that changed in real time. Ten subjects participated in the experiments. The results were analyzed using repeated measures analysis of variance. Feedback factors differed significantly. Provision of force feedback to the user’s finger was most effective in both teleoperation experiments.}
}
@article{SHI2020101061,
title = {Review visual attention and spatial memory in building inspection: Toward a cognition-driven information system},
journal = {Advanced Engineering Informatics},
volume = {44},
pages = {101061},
year = {2020},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2020.101061},
url = {https://www.sciencedirect.com/science/article/pii/S1474034620300306},
author = {Yangming Shi and Jing Du and Eric Ragan},
keywords = {Attention, Spatial memory, Spatial knowledge, Eye-tracking, Virtual reality},
abstract = {With the increasing complexity of modern buildings, it is becoming more challenging for the professionals in the Architecture, Engineering, and Construction (AEC) industry to effectively digest complex engineering and design information and develop an accurate spatial memory that is critical to their daily tasks. As emerging visualization technologies, such as Virtual Reality, are considered as a promising solution, there is a pressing need to understand the mechanism by which different information visualization methods affect AEC task performance. Cognition literature has discovered a strong relationship between attention and memory development, but little has been done to understand how the visual attention patterns during the design documents review affect the effectiveness of spatial memory in AEC tasks. To fill the knowledge gap, this paper presents a human-subject experiment (n = 63) to test how spatial knowledge is acquired in a building inspection task and how the different visual attention patterns affect the development of spatial memory. Participants were asked to review the design information of a real building on campus. To trigger different attention patterns, they were randomly assigned to one of the three groups based on the forms of information given in the review session, including 2D, 3D, and VR groups. After a brief review session, participants were asked to go to the real building to identify discrepancies (based on memory) that were intentionally inserted by the authors. The inspection performance was used to evaluate the spatial memory development. The results indicate that in general there is a positive relationship between test subjects’ visual attention (fixation time) and spatial memory, but the increasing rate varies across the three groups, suggesting that visual context plays a critical role in the development efficiency of spatial memory. The findings also indicate that the visual attention – spatial memory relationship may be mediated by the use of different spatial knowledge acquisition strategies. This study is expected to contribute to the construction information technology literature by setting the cornerstone of a cognition-driven information system that tailors into the spatial cognitive process of AEC professionals.}
}
@article{QAMAR2023103127,
title = {A systematic threat analysis and defense strategies for the metaverse and extended reality systems},
journal = {Computers & Security},
volume = {128},
pages = {103127},
year = {2023},
issn = {0167-4048},
doi = {https://doi.org/10.1016/j.cose.2023.103127},
url = {https://www.sciencedirect.com/science/article/pii/S0167404823000378},
author = {Sara Qamar and Zahid Anwar and Mehreen Afzal},
keywords = {Extended reality (XR), Metaverse, Cyber defense, Privacy, Cyber threats, Cyberstalking, Physical safety, XR commerce, Virtual reality, Augmented reality, Mixed reality, Blockchain, Cybersickness, Currency scams},
abstract = {With the rapid development and evolution of immersive technologies there are growing concerns of security and privacy threats to the metaverse and extended reality (XR) systems. Immersive reality solutions are a combination of multiple vulnerable technologies allowing attackers to easily undermine security. Furthermore the deployment of appropriate security controls and defensive mechanisms for resource constrained proprietary XR products has been limited. In this paper, we provide a comprehensive overview of extended reality systems and the metaverse with emphasis on technology weaknesses, cyber security challenges and users’ safety concerns. Five major taxonomies have been presented in this research with an aim of identifying privacy inference vectors and potential cyber threats; determining the impact on human health and the extent to which cyberstalking, and digital currency scam activities proliferate when using XR. This research also proposes strategies for primary lines of defense and provides recommendations on the adoption of safety measures.}
}
@article{PECK2007166,
title = {Computer-guided cognitive–behavioural therapy for anxiety states},
journal = {Psychiatry},
volume = {6},
number = {4},
pages = {166-169},
year = {2007},
note = {Anxiety disorders Part 1 of 3},
issn = {1476-1793},
doi = {https://doi.org/10.1016/j.mppsy.2007.01.008},
url = {https://www.sciencedirect.com/science/article/pii/S1476179307000201},
author = {David Peck},
keywords = {anxiety, cognitive–behavioural therapy, CD, computer, Internet, palmtop, virtual reality},
abstract = {There is a wide and ubiquitous gap between the demand for and the supply of cognitive–behavioural therapy (CBT) for anxiety states. Radical means of closing this gap are required, and computerizing the routine aspects of the delivery of CBT is one option. A few randomized controlled trials and effectiveness studies have been conducted, indicating that this approach has much promise, with therapy delivered via the Internet, CDs, palmtops and virtual reality. Outcomes appear to be comparable to those with face-to-face therapy, and patients report high levels of satisfaction. For many patients computer-guided CBT may be the only specialist treatment available to them. Many aspects require further research attention, such as cost-effectiveness, the suitability of this approach for particular groups, and the implications for the therapeutic relationship.}
}
@article{JEROUDI2015374,
title = {Accuracy of Remote Electrocardiogram Interpretation With the Use of Google Glass Technology},
journal = {The American Journal of Cardiology},
volume = {115},
number = {3},
pages = {374-377},
year = {2015},
issn = {0002-9149},
doi = {https://doi.org/10.1016/j.amjcard.2014.11.008},
url = {https://www.sciencedirect.com/science/article/pii/S0002914914020815},
author = {Omar M. Jeroudi and George Christakopoulos and George Christopoulos and Anna Kotsia and Megan A. Kypreos and Bavana V. Rangan and Subhash Banerjee and Emmanouil S. Brilakis},
abstract = {We sought to investigate the accuracy of remote electrocardiogram (ECG) interpretation using Google Glass (Google, Mountain View, California). Google Glass is an optical head mounted display device with growing applications in medicine. We compared interpretation of 10 ECGs with 21 clinically important findings by faculty and fellow cardiologists by (1) viewing the electrocardiographic image at the Google Glass screen; (2) viewing a photograph of the ECG taken using Google Glass and interpreted on a mobile device; (3) viewing the original paper ECG; and (4) viewing a photograph of the ECG taken with a high-resolution camera and interpreted on a mobile device. One point was given for identification of each correct finding. Subjective rating of the user experience was also recorded. Twelve physicians (4 faculty and 8 fellow cardiologists) participated. The average electrocardiographic interpretation score (maximum 21 points) as viewed through the Google Glass, Google Glass photograph on a mobile device, on paper, and high-resolution photograph on a mobile device was 13.5 ± 1.8, 16.1 ± 2.6, 18.3 ± 1.7, and 18.6 ± 1.5, respectively (p = 0.0005 between Google Glass and mobile device, p = 0.0005 between Google Glass and paper, and p = 0.002 between mobile device and paper). Of the 12 physicians, 9 (75%) were dissatisfied with ECGs viewing on the prism display of Google Glass. In conclusion, further improvements are needed before Google Glass can be reliably used for remote electrocardiographic analysis.}
}
@article{LETTERIE2002S37,
title = {How virtual reality may enhance training in obstetrics and gynecology},
journal = {American Journal of Obstetrics and Gynecology},
volume = {187},
number = {3, Supplement },
pages = {S37-S40},
year = {2002},
issn = {0002-9378},
doi = {https://doi.org/10.1067/mob.2002.127361},
url = {https://www.sciencedirect.com/science/article/pii/S000293780200220X},
author = {Gerard S. Letterie},
keywords = {Virtual reality, endoscopic surgery, patient-physician communication, medical education, computer-assisted instruction, graduate education},
abstract = {Objective: Contemporary training in obstetrics and gynecology is aimed at the acquisition of a complex set of skills oriented to both the technical and personal aspects of patient care. The ability to create clinical simulations through virtual reality (VR) may facilitate the accomplishment of these goals. The purpose of this paper is 2-fold: (1) to review the circumstances and equipment in industry, science, and education in which VR has been successfully applied, and (2) to explore the possible role of VR for training in obstetrics and gynecology and to suggest innovative and unique approaches to enhancing this training. Material And Methods: Qualitative assessment of the literature describing successful applications of VR in industry, law enforcement, military, and medicine from 1995 to 2000. Articles were identified through a computer-based search using Medline, Current Contents, and cross referencing bibliographies of articles identified through the search. Results: One hundred and fifty-four articles were reviewed. This review of contemporary literature suggests that VR has been successfully used to simulate person-to-person interactions for training in psychiatry and the social sciences in a variety of circumstances by using real-time simulations of personal interactions, and to launch 3-dimensional trainers for surgical simulation. These successful applications and simulations suggest that this technology may be helpful and should be evaluated as an educational modality in obstetrics and gynecology in two areas: (1) counseling in circumstances ranging from routine preoperative informed consent to intervention in more acute circumstances such as domestic violence or rape, and (2) training in basic and advanced surgical skills for both medical students and residents. Conclusion: Virtual reality is an untested, but potentially useful, modality for training in obstetrics and gynecology. On the basis of successful applications in other nonmedical and medical areas, VR may have a role in teaching essential elements of counseling and surgical skill acquisition. (Am J Obstet Gynecol 2002;187:S37-40.)}
}
@article{CARLI201419,
title = {A joint routing and localization algorithm for emergency scenario},
journal = {Ad Hoc Networks},
volume = {13},
pages = {19-33},
year = {2014},
note = {(1)Special Issue : Wireless Technologies for Humanitarian Relief & (2)Special Issue: Models And Algorithms For Wireless Mesh Networks},
issn = {1570-8705},
doi = {https://doi.org/10.1016/j.adhoc.2012.09.001},
url = {https://www.sciencedirect.com/science/article/pii/S1570870512001588},
author = {M. Carli and S. Panzieri and F. Pascucci},
keywords = {Wireless sensor networks, Clustering, Routing, Location tracking, Location-based services},
abstract = {Wireless Sensor Networks (WSNs) have been adopted in a wide range of industrial and consumer applications such as environmental or industrial monitoring, health control, or military systems, for a decade. Main issues in WSN are represented by the large number of sensor nodes, multi-hop communication approach, and needs for an efficient use of available limited sensor energy. In this work an emergency scenario is considered and a WSN is used as a communication infrastructure. To limit the power consumption, the WSN is activated only when the emergency occurs. Few mobile nodes (the rescuers) are moving in the area. In these critical network scenarios, adaptive routing is essential to ensure reliable communication with first responders. At the same time, localizing both WSN nodes and moving nodes is an essential issue for routing the rescuers towards victims. In this paper, the authors jointly tackle routing and localization problems for reducing the network signaling communication as much as possible, which is the most power-consuming operation in WSNs. In particular, it is proposed a distributed localization algorithm, based on a ranging technique, designed by mapping the localization into a stochastic estimation problem for systems with uncertainties.}
}
@article{KODITHUWAKKUARACHCHIGE2024104145,
title = {Effects of virtual heights, dual-tasking, and training on static postural stability},
journal = {Applied Ergonomics},
volume = {114},
pages = {104145},
year = {2024},
issn = {0003-6870},
doi = {https://doi.org/10.1016/j.apergo.2023.104145},
url = {https://www.sciencedirect.com/science/article/pii/S0003687023001837},
author = {Sachini N.K. {Kodithuwakku Arachchige} and Harish Chander and Alireza Shojaei and Adam C. Knight and Caitlyn Brown and Hannah R. Freeman and Reuben F. {Burch V} and Chih-Chia Chen},
keywords = {Falls, VR, Dual-tasking},
abstract = {Working at altitudes, dual-tasking (DT), and lack of experience cause falls. This study aimed to investigate the impact of virtual heights, DT, and training on static postural stability. Twenty-eight volunteers' balance at seven virtual environments [VE; ground (G), altitude 1 (A1), edge 1 (E1), altitude 2 (A2), edge 2 (E2), altitude 3 (A3), and edge 3 (E3)] were recorded during single-tasking (ST) and DT over three days. Independent variables were analyzed using a 7 (VE) x 3 (DAY) x 2 (TASK) factorial repeated measures ANOVA. Greater postural sway was observed in A3 and E1, on DAY 1, and during DT. The study demonstrated static postural stability deteriorates at higher virtual altitudes and during DT and improves with training. The findings of the study suggest that virtual reality is a great altitude simulator, which could be used as a potential balance training tool in ergonomic settings.}
}
@article{CRIDER2020102579,
title = {Digital Daimons: Algorithmic Rhetorics of Augmented Reality},
journal = {Computers and Composition},
volume = {57},
pages = {102579},
year = {2020},
note = {Composing Algorithms: Writing (with) Rhetorical Machines},
issn = {8755-4615},
doi = {https://doi.org/10.1016/j.compcom.2020.102579},
url = {https://www.sciencedirect.com/science/article/pii/S8755461520300402},
author = {Jason Crider and Jacob Greene and Sean Morey},
keywords = {Algorithms, augmented reality, Daimon, GPS, writing studies, digital rhetoric, Mixed-Reality, Location-Based Writing, Electracy},
abstract = {This article develops a theoretical framework for studying the algorithmic underpinnings of contemporary augmented reality technologies. We delineate this framework through the rhetorical figure of the “daimon,” a greek mythological entity as well as a technical concept within computer science, to articulate an approach to AR algorithms as emergent, material processes that can create unpredicted, unintended effects. Ultimately, we argue that the conceptual framework of the “daimon” provides an interface through which writing and rhetoric scholars can better discern the algorithmic effects of emerging AR composing platforms.}
}
@article{BELLALOUNA2020262,
title = {New Approach for Industrial Training Using Virtual Reality Technology},
journal = {Procedia CIRP},
volume = {93},
pages = {262-267},
year = {2020},
note = {53rd CIRP Conference on Manufacturing Systems 2020},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2020.03.008},
url = {https://www.sciencedirect.com/science/article/pii/S2212827120305539},
author = {Fahmi Bellalouna},
keywords = {Virtual Reality, VR Data, CAD Data, Cognitive Approach, Intuitive Approach},
abstract = {This paper presents two case studies achieved within industrial cooperation projects between the University of Applied Sciences Karlsruhe and German manufacturers for special appliances. The aim of the case studies is development and implementation of training applications for the use and the handling of special vehicle using the virtual reality technology. Based on the experiences gathered during these cooperation projects the challenges that face the VR introduction in the industrial area is outlined in this paper. Furthermore, a best practice approach on how to transfer CAD to VR data to implement industrial VR application is presented in this contribution.}
}
@article{AALTONEN201779,
title = {Field evaluation of a wearable multimodal soldier navigation system},
journal = {Applied Ergonomics},
volume = {63},
pages = {79-90},
year = {2017},
issn = {0003-6870},
doi = {https://doi.org/10.1016/j.apergo.2017.04.005},
url = {https://www.sciencedirect.com/science/article/pii/S0003687017300911},
author = {Iina Aaltonen and Jari Laarni},
keywords = {Navigation, Multimodal, Wearable},
abstract = {Challenging environments pose difficulties for terrain navigation, and therefore wearable and multimodal navigation systems have been proposed to overcome these difficulties. Few such navigation systems, however, have been evaluated in field conditions. We evaluated how a multimodal system can aid in navigating in a forest in the context of a military exercise. The system included a head-mounted display, headphones, and a tactile vibrating vest. Visual, auditory, and tactile modalities were tested and evaluated using unimodal, bimodal, and trimodal conditions. Questionnaires, interviews and observations were used to evaluate the advantages and disadvantages of each modality and their multimodal use. The guidance was considered easy to interpret and helpful in navigation. Simplicity of the displayed information was required, which was partially conflicting with the request for having both distance and directional information available.}
}
@article{DEJESUSOLIVEIRA201818,
title = {Assessment of an articulatory interface for tactile intercommunication in immersive virtual environments},
journal = {Computers & Graphics},
volume = {76},
pages = {18-28},
year = {2018},
issn = {0097-8493},
doi = {https://doi.org/10.1016/j.cag.2018.07.007},
url = {https://www.sciencedirect.com/science/article/pii/S0097849318301067},
author = {Victor Adriel {de Jesus Oliveira} and Luciana Nedel and Anderson Maciel},
keywords = {Tactile intercommunication, Vibrotactile HMD, Articulatory interface},
abstract = {In real life, the sense of touch provides information about the environment that surrounds us. It is an essential sense and a social one, as it typically implies an interaction with another person. However, even though tactile feedback is used to enhance the user experience in Virtual and Augmented Reality applications (VR/AR), tactile cues are usually rendered reactively by the system. In this paper, we design and assess a touch user interface that is built on a Head-Mounted Display (HMD) to allow peers to exchange tactile signals in VR applications. First, we explored the interface capabilities by assessing different gestures to be adopted in the reproduction of tactile signals. Then, we assessed its use in conjunction with a vibrotactile HMD in a collaborative virtual setup where users could communicate only through vibrotactile cues. Results have shown that accuracy in target localization increases as target density decreases, that swipe gestures are performed with more accuracy when supported by anchor-points, and that accuracy of rhythm reproduction decreases with pace. When applied to a collaborative task, the interface presented high usability and allowed subjects to fully use tactile feedback as a means for intercommunication with their partners.}
}
@article{ZHANG2023105133,
title = {Risk analysis of people evacuation and its path optimization during tunnel fires using virtual reality experiments},
journal = {Tunnelling and Underground Space Technology},
volume = {137},
pages = {105133},
year = {2023},
issn = {0886-7798},
doi = {https://doi.org/10.1016/j.tust.2023.105133},
url = {https://www.sciencedirect.com/science/article/pii/S0886779823001530},
author = {Xiaochun Zhang and Linjie Chen and Junhao Jiang and Yixin Ji and Shuyang Han and Ting Zhu and Wenbin Xu and Fei Tang},
keywords = {Tunnel fire, Virtual reality (VR）, Evacuation behavior, Risk analysis, Tunnel lifecycle safety management},
abstract = {The number of urban tunnels has been increasing rapidly, accompanied by frequent tunnel fire accidents owing to the complex tunnel structure and large traffic flow. In this study, a full-size tunnel virtual reality (VR) scenario and computational fluid dynamics (CFD) construction model were established to investigate the evacuation behavior and corresponding risk of people in the early stage of vehicle fires considering four scenarios: normal circumstance, without VR agents, without emergency evacuation signs, and without fire extinguishers. Firstly, the cumulative values of CO, CO2, and temperature along the evacuation path were monitored using CFD. Secondly, the smoke toxicity was calculated using the N-GAS model, and the total risk value was computed based on the analytic hierarchy process which was defined as “smoke hazard: temperature hazard = 7:3.” Thirdly, a multiple regression model was created based on accident data. Finally, to minimize accidents, the design of the evacuation path was optimized using the established mathematical model and A* algorithm to verify the effectiveness of the risk assessment model. The results show that the effects of VR agents, emergency evacuation signs, and fire extinguishers on the evacuation behavior of people are mutual influence. This study combined time and route in the VR evacuation experiments to overcome the limitations of the existing control and VR experiments in quantifying the evacuation results. This research can be utilized to improve emergency evacuation plans and emergency response decision making. Furthermore, it can broaden the application of VR in the field of tunnel lifecycle safety management.}
}
@article{MONICA2023102417,
title = {Improving virtual reality navigation tasks using a haptic vest and upper body tracking},
journal = {Displays},
volume = {78},
pages = {102417},
year = {2023},
issn = {0141-9382},
doi = {https://doi.org/10.1016/j.displa.2023.102417},
url = {https://www.sciencedirect.com/science/article/pii/S0141938223000501},
author = {Riccardo Monica and Jacopo Aleotti},
keywords = {Room-scale virtual reality, Haptic vest, Tracking technologies},
abstract = {Haptic feedback is an important component of immersive virtual reality (VR) applications that is often suggested to complement visual information through the sense of touch. This paper investigates the use of a haptic vest in navigation tasks. The haptic vest produces a repulsive vibrotactile feedback from nearby static virtual obstacles that augments the user spatial awareness. The tasks require the user to perform complex movements in a 3D cluttered virtual environment, like avoiding obstacles while walking backwards and pulling a virtual object. The experimental setup consists of a room-scale environment. Our approach is the first study where a haptic vest is tracked in real time using a motion capture device so that proximity-based haptic feedback can be conveyed according to the actual movement of the upper body of the user. User study experiments have been conducted with and without haptic feedback in virtual environments involving both normal and limited visibility conditions. A quantitative evaluation was carried out by measuring task completion time and error (collision) rate. Multiple haptic rendering techniques have also been tested. Results show that under limited visibility conditions proximity-based haptic feedback generated by a wearable haptic vest can significantly reduce the number of collisions with obstacles in the virtual environment.}
}
@incollection{2013155,
editor = {Gregory Kipper},
booktitle = {Augmented Reality},
publisher = {Syngress},
address = {Boston},
pages = {155-158},
year = {2013},
isbn = {978-1-59749-733-6},
doi = {https://doi.org/10.1016/B978-1-59-749733-6.00017-6},
url = {https://www.sciencedirect.com/science/article/pii/B9781597497336000176}
}
@article{ZHOU2021103944,
title = {Virtual reality sports auxiliary training system based on embedded system and computer technology},
journal = {Microprocessors and Microsystems},
volume = {82},
pages = {103944},
year = {2021},
issn = {0141-9331},
doi = {https://doi.org/10.1016/j.micpro.2021.103944},
url = {https://www.sciencedirect.com/science/article/pii/S014193312100123X},
author = {Jian Zhou},
keywords = {Sports auxiliary training, Embedded system, Virtual reality technology, Training System},
abstract = {Virtual Reality technology, the complex environment can be a simulated, traditional sports courses at the stadium, equipment, it is due to limitations such as safety, to provide scientific and accurate teaching and learning's, a complex by visualizing the theoretical knowledge in the abstract sport, you can get more technical knowledge. Compared to the traditional physical education activities, simulate sports scene only by generating VR panoramas that cannot be virtual reality technology. Based on this, you can improve the enthusiasm and athletic ability of students effectively. Because of immaturity and high-priced equipment of VR technology, at present, people that education is using unpopular making, carefully virtual reality technology. In this context, we can apply virtual reality technology to sports training, which can obtain more effective training effect. In the first part of this paper, we talk about the research of virtual reality panorama, the second part about the research of virtual reality video, the third part about the application of virtual reality in physical education teaching, and the fourth part is the conclusion and investigation process. In the study, VR, as a new technology, found that you have the prospect of a wide range of applications. As long as it has been used in scientific and rational, you can VR is to promote the level of improvement and sports greatly sports scene. Users can increase users' interest; it can be immersed in a variety of preset virtual locations. Therefore, in the VR device, which allows the user to improve the experience of the VR device, you can interact well in a virtual scene.}
}
@article{BECHAR201530,
title = {A review and framework of laser-based collaboration support},
journal = {Annual Reviews in Control},
volume = {39},
pages = {30-45},
year = {2015},
issn = {1367-5788},
doi = {https://doi.org/10.1016/j.arcontrol.2015.03.003},
url = {https://www.sciencedirect.com/science/article/pii/S1367578815000048},
author = {A. Bechar and S.Y. Nof and J.P. Wachs},
abstract = {New technologies are emerging to enable and support physical, implicit and explicit collaborations. They are essential for dealing with increasingly complex systems in unstructured, dynamic environments. The purpose of this article is to review the role of laser technology in enabling better, more precise interactions and their control, and to identify opportunities and challenges in this area. While the most common applications of laser technology are found in medical and health care, manufacturing, and communication, other domains such as safety, quality assurance, agriculture, construction, entertainment, defense, transportation, and law enforcement also benefit from it. In spite of the rapid dissemination of this technology, its role in support of collaboration and discovery is still in its infancy. Research activities concerning new ways of using lasers as a collaboration supporting technology that may strengthen new areas have been relatively limited. Nevertheless, the translation to this domain of collaboration support has been recognized as vital for activities that demand increasingly more coordinated effort among interacting agents (e.g., humans, machines, particles) and digital, possibly also photonic agents. Recent advances in laser technology in a number of application domains are reviewed in this article, focusing primarily on lasers’ role for supporting different forms of precision interactions and collaboration. In addition, a framework with five collaboration support functions and five collaboration dimensions is defined for this review. The taxonomy framework is useful for enabling better understanding of the existing and emerging opportunities that laser-based technology offers for collaboration support, its advantages and several research gaps.}
}
@article{STRAHLER201580,
title = {Psychobiological stress response to a simulated school shooting in police officers},
journal = {Psychoneuroendocrinology},
volume = {51},
pages = {80-91},
year = {2015},
note = {This issue includes a Special Section on Biomarkers in the Military - New Findings from Prospective Studies},
issn = {0306-4530},
doi = {https://doi.org/10.1016/j.psyneuen.2014.09.016},
url = {https://www.sciencedirect.com/science/article/pii/S0306453014003564},
author = {Jana Strahler and Thomas Ziegert},
keywords = {Stress, Police, Amok, Cortisol, Alpha-amylase, Heart rate},
abstract = {Summary
Introduction
Police work is one of the most demanding professions with various sources of high occupational stress. Among the most demanding tasks are amok situations, such as school shootings. Hardly anything is known about endocrine and cardiovascular markers in safety professionals during emergency situations in real life and how this relates to stress perception and management. This study will therefore explore police officers’ stress responses to a reality-based school shooting simulation assessing neuroendocrine, cardiovascular, and psychological stress markers.
Methods
A convenience sample of 50 police officers (39.5±8.7 yrs, 9 women) participating in a basic or refresher amok training session for the German uniformed and criminal police were recruited. Saliva samples were collected shortly before the simulation task (school shooting), immediately after, 20 and 45min after finishing the task for the assessment of cortisol and alpha-amylase (sAA), as markers of the hypothalamic–pituitary–adrenal axis and the autonomic nervous system, respectively. Heart rate (variability) was assessed continuously. Officers rated their actual mood right before and 10min after the simulation. Subjective experience of task stressfulness was assessed minutes after finishing the simulation.
Results
Overall, the simulated school shooting did not result in changes of mood, tiredness, or calmness but higher restlessness was experienced during the basic training, which was also experienced as more controllable. Female officers reported to experience more strain and anxiety. Cortisol showed highest levels at the beginning of the training and steadily decreasing values thereafter. In contrast, sAA increased substantially right after the simulation with officers on the front position showing most pronounced changes. Cardiovascular reactivity was highest in officers acting on the side positions while advancing to find the suspect. Furthermore higher self-efficacy as well as, by trend, controllability and relevance of results correlated with cardiovascular measures.
Discussion
Autonomic but not endocrine stress markers increased to a simulated school shooting, which were further related to the subjective experience of the simulation. Our results provide a more in-depth picture of stress responses in such situations, which will in the long run raise the possibility to refine training programs, design more effective stress-management strategies for these critical incidents, and improve performance but also coping with work-related stress.}
}
@article{SHI2021105231,
title = {Spatial knowledge and firefighters’ wayfinding performance: A virtual reality search and rescue experiment},
journal = {Safety Science},
volume = {139},
pages = {105231},
year = {2021},
issn = {0925-7535},
doi = {https://doi.org/10.1016/j.ssci.2021.105231},
url = {https://www.sciencedirect.com/science/article/pii/S092575352100076X},
author = {Yangming Shi and John Kang and Pengxiang Xia and Oshin Tyagi and Ranjana K. Mehta and Jing Du},
keywords = {Firefighter, Spatial knowledge, Wayfinding, Virtual reality},
abstract = {Firefighters often need to digest complex spatial information within a short period of time for search and rescue. Previous wayfinding literature has documented evidence about how the general population in normal situations leverage different forms of spatial information, including landmarks, routes and survey (maps), to develop spatial knowledge and guide wayfinding. However, little is known about how the arbitrarily given spatial information affects firefighter wayfinding behavior and performance when the time is limited and there is no privilege for them to develop complete spatial knowledge in an evolving manner. To narrow the knowledge gap, we conducted a wayfinding experiment with firefighters (n = 40) using Virtual Reality (VR). In the experiment, firefighters were required to find three victims in a simulated office maze. Each firefighter randomly experienced four experimental conditions in this study including control condition, landmark condition, route condition, and survey (map) condition. For each experimental condition, firefighters had 3 min to memorize the different layouts of the virtual office mazes using one of three spatial information including landmarks, routes, and survey (map), and then went to the virtual office maze to find the victims. The number of victims found, time, and navigation patterns were used to evaluate firefighters’ wayfinding performance. The results indicated that the route and survey spatial information was more efficient in facilitating firefighter to memorize the layout, leading to a better wayfinding performance.We also found that although the survey information provided more complete information about the layout, it also burdened firefighters in a way that they had to plan the path with limited time. Since survey information may induce different path planning strategies, survey information did not result in a better performance than the route information as suggestedby previous studies. This research helps explain the relationship between different forms of spatial information and the wayfinding performance of firefighters. The findings will help professionals design better training protocols and technologies for firefighters.}
}
@article{CHA201212,
title = {A virtual reality based fire training simulator integrated with fire dynamics data},
journal = {Fire Safety Journal},
volume = {50},
pages = {12-24},
year = {2012},
issn = {0379-7112},
doi = {https://doi.org/10.1016/j.firesaf.2012.01.004},
url = {https://www.sciencedirect.com/science/article/pii/S0379711212000136},
author = {Moohyun Cha and Soonhung Han and Jaikyung Lee and Byungil Choi},
keywords = {Virtual reality, Training simulator, CFD (Computational Fluid Dynamics), Fire simulation},
abstract = {VR (virtual reality)-based fire training simulators provide the general public or inexperienced firefighters or commanders with wide-ranging second-hand experience so that they can make prompt decisions and safe and organized responses in actual fire situations. In order to effectively achieve this training goal, it is crucial to reliably express fire dynamics as realistic graphics. In the field of engineering, computational fluid dynamics (CFD) is widely used to precisely predict the behaviors of fluid phenomena. The resultant data, however, have structures and capacities that are not readily applied to real-time virtual reality systems. This study proposes a series of data conversion techniques and a real-time processing framework to develop a fire training simulator on the basis of a precise CFD simulation that is capable of calculating various invisible physical quantities such as toxic gases and heat as well as visible factors such as smoke and flame. By exploiting safety level-based visualization mapping, this study also proposes a new method to intuitively experience dangerous fire environments and perform training and evaluation. Lastly, this study implements a simulator that can undertake simple firefighting activities such as evacuation and rescue in fire situations at road tunnels; the functions and real-time performance of the simulator have been experimentally measured to verify the applicability of the proposed framework.}
}
@article{LOUIE20181229,
title = {Recent Advances in Technology and Its Applications to Pediatric Emergency Care},
journal = {Pediatric Clinics of North America},
volume = {65},
number = {6},
pages = {1229-1246},
year = {2018},
note = {Pediatric Emergency Medicine},
issn = {0031-3955},
doi = {https://doi.org/10.1016/j.pcl.2018.07.013},
url = {https://www.sciencedirect.com/science/article/pii/S003139551830110X},
author = {Marisa C. Louie and Todd P. Chang and Robert W. Grundmeier},
keywords = {Pediatric emergency medicine, Ultrasonography, Electronic health records, Clinical decision support, Simulation-based training, Clinical competence, Free open access medical education}
}