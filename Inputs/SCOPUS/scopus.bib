@CONFERENCE{Doswell2020226,
	author = {Doswell, Jayfus T. and Johnson, Justin and Brockington, Brandon and Mosby, Aaron and Chinery, Arthur},
	title = {Juxtopia®CAMMRAD PREPARE: Wearable AI-AR Platform for Clinical Training Emergency First Response Teams},
	year = {2020},
	journal = {Proceedings - 2020 IEEE International Conference on Artificial Intelligence and Virtual Reality, AIVR 2020},
	pages = {226 – 230},
	doi = {10.1109/AIVR50618.2020.00047},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100056234&doi=10.1109%2fAIVR50618.2020.00047&partnerID=40&md5=e470304e9fa0c174665ca6d4d88de457},
	affiliations = {Juxtopia, Open-Wear Department, Baltimore, United States},
	abstract = {The Juxtopia® Open-Wear research team collaborated with the Maryland Fire Rescue Institute (MFRI) to test how the Juxtopia® artificial intelligent (AI) wearable augmented reality (AR) intervention may better deliver a hands-free clinical training intervention to firefighter Emergency Medical Technicians (EMT) and prepare them for effective response to hazardous material (HAZMAT) incidences. During a controlled study, human subjects participated in a minimal risk research (i.e., both as victims or caregivers) in which firefighter EMTs participated in a simulated training exercise that mimicked their real-world operations. During the study, there were two testing days. Day one included (10) victims and (20) caregivers who participated in a full day of training and familiarized themselves with wearable AR Head Mounted Display (HMD) and a Juxtopia® Virtual Tutor (JVT) software application. The results demonstrated that an AI instructor enabled AR system can train EMTs in core clinical skills for effective HAZMAT response.  © 2020 IEEE.},
	author_keywords = {AR; artificial intelligence; augmented reality; clinical; EMT; firefighter; Paramedic; pedagogical agent},
	keywords = {Application programs; Augmented reality; Clinical research; Distance education; Emergency services; Fire extinguishers; Helmet mounted displays; Virtual reality; Wearable computers; Artificial intelligent; Clinical skills; Clinical training; Emergency medical technicians; Head mounted displays; Real world operations; Simulated trainings; Software applications; Artificial intelligence},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-172817463-1},
	language = {English},
	abbrev_source_title = {Proc. - IEEE Int. Conf. Artif. Intell. Virtual Real., AIVR},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 3rd IEEE International Conference on Artificial Intelligence and Virtual Reality, AIVR 2020; Conference date: 14 December 2020 through 18 December 2020; Conference code: 166562}
}

@ARTICLE{Kman2023,
	author = {Kman, Nicholas E. and Price, Alan and Berezina-Blackburn, Vita and Patterson, Jeremy and Maicher, Kellen and Way, David P. and McGrath, Jillian and Panchal, Ashish R. and Luu, Katherine and Oliszewski, Alex and Swearingen, Scott and Danforth, Douglas},
	title = {First Responder Virtual Reality Simulator to train and assess emergency personnel for mass casualty response},
	year = {2023},
	journal = {JACEP Open},
	volume = {4},
	number = {1},
	doi = {10.1002/emp2.12903},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148572809&doi=10.1002%2femp2.12903&partnerID=40&md5=76871b9c39a630be44ef8fe07e0a7a04},
	affiliations = {Department of Emergency Medicine, The Ohio State University College of Medicine, Columbus, OH, United States; Center for Immersive Media, University of the Arts, Philadelphia, PA, United States; Advanced Computing Center for the Arts and Design, The Ohio State University, Columbus, OH, United States; Wexner Medical Center, James Cancer Hospital, Operations Improvement, The Ohio State University, Columbus, OH, United States; Department of Obstetrics & Gynecology, The Ohio State University College of Medicine, Columbus, OH, United States},
	abstract = {As mass casualty incidents continue to escalate in the United States, we must improve frontline responder performance to increase the odds of victim survival. In this article, we describe the First Responder Virtual Reality Simulator, a high-fidelity, fully immersive, automated, programmable virtual reality (VR) simulation designed to train frontline responders to treat and triage victims of mass casualty incidents. First responder trainees don a wireless VR head-mounted display linked to a compatible desktop computer. Trainees see and hear autonomous, interactive victims who are programmed to simulate individuals with injuries consistent with an explosion in an underground space. Armed with a virtual medical kit, responders are tasked with triaging and treating the victims on the scene. The VR environment can be made more challenging by increasing the environmental chaos, adding patients, or increasing the acuity of patient injuries. The VR platform tracks and records their performance as they navigate the disaster scene. Output from the system provides feedback to participants on their performance. Eventually, we hope that the First Responder system will serve both as an effective replacement for expensive conventional training methods as well as a safe and efficient platform for research on current triage protocols. © 2023 The Authors. JACEP Open published by Wiley Periodicals LLC on behalf of American College of Emergency Physicians.},
	author_keywords = {disaster planning; education; educational measurement; emergency medical services; professional competence; transportation of patients; triage},
	keywords = {Article; controlled study; disaster planning; education; emergency health service; environment; explosion; feedback system; first responder (person); human; injury; mass disaster; patient acuity; patient triage; performance; professional competence; rescue personnel; simulation; victim},
	correspondence_address = {D.P. Way; Department of Emergency Medicine, The Ohio State University College of Medicine, Columbus, 778 Prior Hall, 376 W 10th Ave., 43210, United States; email: David.Way@osumc.edu},
	publisher = {John Wiley and Sons Inc},
	issn = {26881152},
	language = {English},
	abbrev_source_title = {JACEP Open},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{El Raheb2021,
	author = {El Raheb, Katerina and Soulis, Athanasios and Nastos, Dimitris and Lougiakis, Christos and Roussou, Maria and Christopoulos, Dimitris and Sofianopoulos, George and Papagiannis, Spyros and Rüggeberg, Jim and Katsikaris, Lucas and Rüggeberg, Julien},
	title = {Eliciting requirements for a multisensory eXtended reality platform for training and informal learning},
	year = {2021},
	journal = {ACM International Conference Proceeding Series},
	doi = {10.1145/3489410.3489428},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120908534&doi=10.1145%2f3489410.3489428&partnerID=40&md5=b1fe1520bc8cb8590588f4310000d0e1},
	affiliations = {National and Kapodistrian University of Athens Athens, Attica, Greece; Foundation of the Hellenic World, Greece; Athens International Airport, Athens, Greece; Illusion Walk, Berlin, Germany; Bolt Virtual, Athens, Greece},
	abstract = {Aiming at bridging the gap between the recent advancements in eXtended Reality (XR) research and real-world scenarios, in this paper we describe the first steps of an iterative user-centered methodology developed to elicit user requirements and to design the scenarios for a multi-sensory collaborative XR platform, in the framework of the BRIDGES project. The platform aims to be customizable and flexible, and is intended for use in different pedagogical contexts, instantiated by two pilot scenarios: a) XR training for first-responders and fire brigade staff at international airports and b) XR informal learning experiences addressed to visitors of museums and cultural centers. Through a series of workshops and focus groups with users from relevant organizations, we collected a total of nearly 100 pedagogical, technological, experiential, operational and other user needs from within these two different contexts, and discuss here the challenges and limitations but also the opportunities that were encountered. © 2021 ACM.},
	author_keywords = {eXtended Reality; Informal Learning; Training; User Requirements; User-Centered Design},
	keywords = {Bridges; Iterative methods; Personnel training; Customizable; Extended reality; First fire; First responders; Informal learning; Multi-Sensory; Multisensory; Real-world scenario; User requirements; User-centred; User centered design},
	publisher = {Association for Computing Machinery},
	isbn = {978-145038578-7},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 1st International Conference of the ACM Greek SIGCHI Chapter, CHI Greece 2021; Conference date: 25 November 2021 through 27 November 2021; Conference code: 174677; All Open Access, Green Open Access}
}

@CONFERENCE{Jurcevic2021417,
	author = {Jurcevic, Marko and Vitas, Igor},
	title = {5G-Connected Drone for Public Road Safety-Research Challenges and Future Research Roadmap},
	year = {2021},
	journal = {2021 44th International Convention on Information, Communication and Electronic Technology, MIPRO 2021 - Proceedings},
	pages = {417 – 422},
	doi = {10.23919/MIPRO52101.2021.9597065},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123052703&doi=10.23919%2fMIPRO52101.2021.9597065&partnerID=40&md5=93278aaa60c03c7a60646162fd14890c},
	affiliations = {University of Zagreb, Computing Remote Metrology Laboratory, Faculty of Electrical Engineering, Zagreb, Croatia},
	abstract = {5G mobile communication infrastructure attracts increasing attention of stakeholders, going beyond only interconnection of people and increasingly serve to connect and manage 5G-enabled IoT devices. Among others, unmanned aerial vehicles (UAVs) or systems (UAS) already rely on 5G communication infrastructure and in the near future are envisioned to use it even more. 5G systems already support a wide-variety of different applications, such as remote healthcare, self-driving ground vehicles, virtual or augmented reality, drones, surveillance and many more. Among these is the high-resolution video surveillance using drones for different purposes. In road traffic analysis, one of the most important public safety applications, the low compressed or uncompressed video stream can greatly improve the analysis and traffic incident detection performance. On the other hand it is challenging to transmit high-resolution video stream in real time due to its data size. This paper provides an overview of the current research in the area of UAV command and control using 5G systems describing basic concepts and challenges. We review some of the latest research in regard to real-time high-resolution video transfer. A brief discussion of experiments on the 5G private campus network communication between a drone and a ground analytical system is presented.  © 2021 Croatian Society MIPRO.},
	author_keywords = {5G; edge computing; HD video stream; performance evaluation; proof-of-concept; remote control; UAV},
	keywords = {Antennas; Augmented reality; Cybersecurity; Drones; Edge computing; Motor transportation; Remote control; Roads and streets; Security systems; Video streaming; Communication infrastructure; Edge computing; HD video stream; HD videos; High resolution; Performances evaluation; Proof of concept; Public roads; Real- time; Resolution video; 5G mobile communication systems},
	editor = {Koricic M. and Skala K. and Car Z. and Cicin-Sain M. and Babic S. and Sruk V. and Skvorc D. and Ribaric S. and Jerbic B. and Gros S. and Vrdoljak B. and Mauher M. and Tijan E. and Katulic T. and Petrovic J. and Grbac T.G. and Fijan N.F. and Gradisnik V.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-953233101-1},
	language = {English},
	abbrev_source_title = {Int. Conv. Inf., Commun. Electron. Technol., MIPRO - Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 44th International Convention on Information, Communication and Electronic Technology, MIPRO 2021; Conference date: 27 September 2021 through 1 October 2021; Conference code: 174235}
}

@ARTICLE{Rojas-Muñoz2020,
	author = {Rojas-Muñoz, Edgar and Lin, Chengyuan and Sanchez-Tamayo, Natalia and Cabrera, Maria Eugenia and Andersen, Daniel and Popescu, Voicu and Barragan, Juan Antonio and Zarzaur, Ben and Murphy, Patrick and Anderson, Kathryn and Douglas, Thomas and Griffis, Clare and McKee, Jessica and Kirkpatrick, Andrew W. and Wachs, Juan P.},
	title = {Evaluation of an augmented reality platform for austere surgical telementoring: a randomized controlled crossover study in cricothyroidotomies},
	year = {2020},
	journal = {npj Digital Medicine},
	volume = {3},
	number = {1},
	doi = {10.1038/s41746-020-0284-9},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087848610&doi=10.1038%2fs41746-020-0284-9&partnerID=40&md5=68d255c42100215022ef3ba3cf678424},
	affiliations = {School of Industrial Engineering, Purdue University, West Lafayette, IN, United States; Department of Computer Science, Purdue University, West Lafayette, IN, United States; Paul G. Allen School of Computer Science and Engineering, University of Washington, Seattle, WA, United States; Department of Surgery, School of Medicine, Indiana University, Indianapolis, IN, United States; Naval Medical Center Portsmouth, Portsmouth, VA, United States; Department of Surgery, and the Regional Trauma Services, University of Calgary, Calgary, AB, Canada; Department of Critical Care Medicine, University of Calgary, Calgary, AB, Canada; Canadian Forces Medical Services, Ottawa, ON, Canada},
	abstract = {Telementoring platforms can help transfer surgical expertise remotely. However, most telementoring platforms are not designed to assist in austere, pre-hospital settings. This paper evaluates the system for telementoring with augmented reality (STAR), a portable and self-contained telementoring platform based on an augmented reality head-mounted display (ARHMD). The system is designed to assist in austere scenarios: a stabilized first-person view of the operating field is sent to a remote expert, who creates surgical instructions that a local first responder wearing the ARHMD can visualize as three-dimensional models projected onto the patient’s body. Our hypothesis evaluated whether remote guidance with STAR could lead to performing a surgical procedure better, as opposed to remote audio-only guidance. Remote expert surgeons guided first responders through training cricothyroidotomies in a simulated austere scenario, and on-site surgeons evaluated the participants using standardized evaluation tools. The evaluation comprehended completion time and technique performance of specific cricothyroidotomy steps. The analyses were also performed considering the participants’ years of experience as first responders, and their experience performing cricothyroidotomies. A linear mixed model analysis showed that using STAR was associated with higher procedural and non-procedural scores, and overall better performance. Additionally, a binary logistic regression analysis showed that using STAR was associated to safer and more successful executions of cricothyroidotomies. This work demonstrates that remote mentors can use STAR to provide first responders with guidance and surgical knowledge, and represents a first step towards the adoption of ARHMDs to convey clinical expertise remotely in austere scenarios. © 2020, The Author(s).},
	keywords = {Helmet mounted displays; Regression analysis; Stars; Surgery; First person; First responders; Head-mounted-displays; Hospital settings; Operating fields; Performance; Remote experts; Remote guidance; Telementoring; Three dimensional modelling; adult; Article; augmented reality; controlled study; female; human; male; mentoring; priority journal; rating scale; surgeon; telementoring; tracheotomy; work experience; Augmented reality},
	correspondence_address = {J.P. Wachs; School of Industrial Engineering, Purdue University, West Lafayette, United States; email: jpwachs@purdue.edu},
	publisher = {Nature Research},
	issn = {23986352},
	language = {English},
	abbrev_source_title = {npj Digit. Med.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 23; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Glick2021158,
	author = {Glick, Yuval and Avital, B. and Oppenheimer, J. and Nahman, D. and Wagnert-Avraham, L. and Eisenkraft, A. and Dym, L. and Levi, D. and Agur, A. and Gustus, B. and Furer, A.},
	title = {Augmenting prehospital care},
	year = {2021},
	journal = {BMJ Military Health},
	volume = {167},
	number = {3},
	pages = {158 – 162},
	doi = {10.1136/jramc-2019-001320},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106742024&doi=10.1136%2fjramc-2019-001320&partnerID=40&md5=409cffc0fb3b8b48f8e95ff08b6620d0},
	affiliations = {Medical Corps, Israel Defense Forces, Ramat-Gan, Israel; Orthopedic Department, Assuta Ashdod Hospital, Ashdod, Israel; Institute for Research in Military Medicine, The Hebrew University of Jerusalem, Israel Defense Forces Medical Corps, Jerusalem, Israel; Department of Internal Medicine 'A', Hadassah University Hospital, Jerusalem, Israel; Obstetrics and Gynaecology Division, Soroka Medical Centre, Beer Sheva, Israel; Neurosurgery Department, Tel Aviv Sourasky Medical Center, Tel Aviv, Israel; Pediatric Department, Asaf Harofe Hospital, Zerifin, Israel; Faculty of Medicine, Hebrew University of Jerusalem, Jerusalem, Israel},
	abstract = {Introduction: The challenging environment of prehospital casualty care demands providers to make prompt decisions and to engage in lifesaving interventions, occasionally without them being adequately experienced. Telementoring based on augmented reality (AR) devices has the potential to decrease the decision time and minimise the distance gap between an experienced consultant and the first responder. The purpose of this study was to determine whether telementoring with AR glasses would affect chest thoracotomy performance and self-confidence of inexperienced trainees. Methods Two groups of inexperienced medical students performed a chest thoracotomy in an ex vivo pig model. While one group was mentored remotely using HoloLens AR glasses, the second performed the procedure independently. An observer assessed the trainees' performance. In addition, trainees and mentors evaluated their own performance. Results: Quality of performance was found to be superior with remote guidance, without significant prolongation of the procedure (492 s vs 496 s, p=0.943). Moreover, sense of self-confidence among participant was substantially improved in the telementoring group in which 100% of the participants believed the procedure was successful compared with 40% in the control group (p=0.035). Conclusion: AR devices may have a role in future prehospital telementoring systems, to provide accessible consultation for first responders, and could thus positively affect the provider's confidence in decision-making, enhance procedure performance and ultimately improve patient prognosis. That being said, future studies are required to estimate full potential of this technology and additional adjustments are necessary for maximal optimisation and implementation in the field of prehospital care. © 2021 Author(s).},
	author_keywords = {augmented reality; chest thoracotomy; prehospital; telementoring},
	keywords = {Adult; Animals; Augmented Reality; Emergency Medical Services; Female; Humans; Male; Mentoring; Students, Medical; Swine; Telemedicine; Thoracotomy; anatomical location; Article; augmented reality; battle injury; controlled study; distance learning; emergency care; ex vivo study; human; human experiment; medical education; medical student; mentoring; physical examination; porcine model; priority journal; self evaluation; sense of self; telemonitoring; thoracotomy; adult; animal; devices; emergency health service; female; male; pig; procedures; telemedicine; thoracotomy},
	correspondence_address = {A. Furer; Medical Corps, Israel Defense Forces, Ramat-Gan, 01215, Israel; email: furera@gmail.com},
	publisher = {BMJ Publishing Group},
	issn = {26333767},
	pmid = {32086268},
	language = {English},
	abbrev_source_title = {BMJ Mil. Heal.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5}
}

@CONFERENCE{Ledgerwood2023292,
	author = {Ledgerwood, Scott and Lewis, Jack and Karhoff, Jeffrey and Zhu, Qi and Whitlock, Matthew and Chelen, Julia},
	title = {The Technical Development of an Extended Reality Research Testbed for Public Safety},
	year = {2023},
	journal = {ACM International Conference Proceeding Series},
	pages = {292 – 296},
	doi = {10.1145/3576914.3588016},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159776162&doi=10.1145%2f3576914.3588016&partnerID=40&md5=dfca8267f630a7d01527005f252f349f},
	affiliations = {The National Institute of Standards and Technology, Boulder, CO, United States},
	abstract = {The study of public safety technology, interventions, and training involves variable and hazardous conditions, which complicate observation and measurement. Informative evaluation approaches require reasonable representation of these conditions. Nonetheless, representing these conditions is resource intensive and difficult to replicate. For these reasons, public safety research may be limited by low-fidelity approaches that differ from the intended real-world application and by the inaccessibility of more realistic training. Extended Reality (XR) environments offer highly immersive and repeatable training for first responders, as well as controlled methods for technical research. In this paper, we discuss the development of the National Institute of Standards and Technology (NIST) Public Safety Immersive Test Center (PSITC): a testbed for multi-sensory extended reality-based research for public safety scenarios. We describe how the PSITC supports realistic training for public safety with an overview of the center's design, development, and technical implementation. We discuss methods to address the challenges of building such a testbed for XR-based research, including integration of nascent technologies from various vendors, extensive use of sensor and imaging technologies, and intergovernmental cooperation between the First Responder Network Authority and the NIST Public Safety Communications Research Division. This paper introduces a model for the development of immersive centers built to evaluate prototypes for public safety operations, improve training for emergency response, and support public safety technology research.  © 2023 Owner/Author.},
	author_keywords = {Emergency Response; Haptics; Human-Centered Computing; Mixed / Extended / Augmented Reality; Optics; Public Safety; Training; User Experience; Virtual Reality},
	keywords = {Augmented reality; E-learning; Emergency services; Testbeds; Condition; Emergency response; First responders; Haptics; Human-centered computing; Immersive; Mixed / extended / augmented reality; Public safety; Safety technology; Users' experiences; Virtual reality},
	publisher = {Association for Computing Machinery},
	isbn = {979-840070049-1},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2023 Cyber-Physical Systems and Internet-of-Things Week, CPS-IoT Week 2023; Conference date: 9 May 2023 through 12 May 2023; Conference code: 188505}
}

@CONFERENCE{Christaki2022755,
	author = {Christaki, Kyriaki and Tsiakmakis, Dimitrios and Babic, Ivanka and Inglese, Guillaume and Konstantoudakis, Konstantinos and Giunta, Gabriele and Dimou, Anastasios and Balet, Olivier and Daras, Petros},
	title = {Augmented reality points of interest for improved first responder situational awareness},
	year = {2022},
	journal = {Proceedings of the International ISCRAM Conference},
	volume = {2022-May},
	pages = {755 – 770},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171787049&partnerID=40&md5=4472139985780c09c166f09197b49c72},
	affiliations = {Visual Computing Lab (VCL), Information Technologies Institute (ITI), Centre for Research and Technology - Hellas (CERTH), Thessaloniki, Greece; Research Development (R&D) Lab., Engineering Ingegneria Informatica S.p.A., Belgrade, Serbia; Defense and Security Business Line, CS Group, France},
	abstract = {Situational awareness is a vital component of any disaster response mission, both in terms of first responder (FR) safety and efficiency. Points of interest (POI) can pertain to hazards known beforehand, risks discovered during the course of a mission, victims, entry and exit routes, important equipment, and more. Although communications and technical means can expand an individual FR’s situational awareness, they depend on clarity and can increase cognitive load, as this expanded volume of information must be held in each FR’s memory. Augmented reality (AR) can visualize POIs in context with the environment in a clear and intuitive way and reduce cognitive load as the don’t rely on a user’s memory. This paper presents an AR solution for FR team situational awareness, comprising four interconnected and collaborating situational awareness tools sharing a common pool of virtual POIs, alongside a range of different functionalities particular to each. © 2022 Information Systems for Crisis Response and Management, ISCRAM. All rights reserved.},
	author_keywords = {augmented reality; First responders; point of interest; UAV},
	keywords = {Augmented reality; Information management; Information systems; Information use; Awareness tool; Cognitive loads; Disaster-response; First responders; In contexts; Point of interest; Safety and efficiencies; Situational awareness; Unmanned aerial vehicles (UAV)},
	correspondence_address = {K. Christaki; Visual Computing Lab (VCL), Information Technologies Institute (ITI), Centre for Research and Technology - Hellas (CERTH), Thessaloniki, Greece; email: kchristaki@iti.gr},
	publisher = {Information Systems for Crisis Response and Management, ISCRAM},
	issn = {24113387},
	isbn = {978-828427099-9},
	language = {English},
	abbrev_source_title = {Proc. Int. ISCRAM Conf.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 19th International Conference on Information Systems for Crisis Response and Management, ISCRAM 2022; Conference date: 22 May 2022 through 25 May 2022; Conference code: 192192}
}

@ARTICLE{Noorian2021415,
	author = {Noorian, Ali Reza},
	title = {Prehospital EMS Triage for Acute Stroke Care},
	year = {2021},
	journal = {Seminars in Neurology},
	volume = {41},
	number = {1},
	pages = {415 – 418},
	doi = {10.1055/s-0040-1722725},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100332967&doi=10.1055%2fs-0040-1722725&partnerID=40&md5=c59db678054effc6aa2ef52a3d61ff51},
	affiliations = {Department of Neurology, Kaiser Permanente Orange County, 6650 Alton Pkwy #2128A, Irvine, 92618, CA, United States},
	abstract = {Acute stroke has had major advances over the last two decades due to the introduction of pharmacologic and endovascular revascularization, which can improve functional outcome. Stroke systems of care have been developed to provide faster, more efficient care for stroke patients. A major part of these care pathways is prehospital care, when patients are triaged to appropriate levels of care. It is essential that prehospital scales are used accurately and effectively by emergency medical services to assist them with the triage process. New technologies including mobile stroke units, telemedicine, and wearable technology have been introduced as options for optimization of this emergent process. © 2021 Thieme Medical Publishers, Inc.. All rights reserved.},
	author_keywords = {acute stroke; large vessel occlusion; prehospital; stroke center; stroke severity scale},
	keywords = {Critical Care; Emergency Medical Services; Humans; Stroke; Triage; Article; cerebrovascular accident; emergency health service; human; medical technology; patient care; priority journal; stroke unit; cerebrovascular accident; intensive care},
	correspondence_address = {A.R. Noorian; Department of Neurology, Kaiser Permanente Orange County, Irvine, 6650 Alton Pkwy #2128A, 92618, United States; email: alireza.noorian@kp.org},
	publisher = {Thieme Medical Publishers, Inc.},
	issn = {02718235},
	coden = {SEMNE},
	pmid = {33506476},
	language = {English},
	abbrev_source_title = {Semin. Neurol.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Paletta2022,
	author = {Paletta, Lucas and Schneeberger, Michael and Reim, Lilian and Kallus, Wolfgang and Peer, Andreas and Schonauer, Christian and Pszeida, Martin and Dini, Amir and Ladstatter, Stefan and Weber, Anna and Feischl, Richard and Aumayr, Georg},
	title = {Work-in-Progress - Digital Human Factors Measurements in First Responder Virtual Reality-Based Skill Training},
	year = {2022},
	journal = {Proceedings of 2022 8th International Conference of the Immersive Learning Research Network, iLRN 2022},
	doi = {10.23919/iLRN55037.2022.9815976},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134751232&doi=10.23919%2fiLRN55037.2022.9815976&partnerID=40&md5=0f1ce2564adf2749233d832e29828e23},
	affiliations = {Institute DIGITAL, Joanneum Research, Graz, Austria; Joanneum Research, Graz, Austria; Institut für Begleitforschung, Psychologisches Qualitätsmanag, Graz, Austria; M2D MasterMind Development GmbH, Vienna, Austria; Ing. Richard Feischl GmbH, Gumpoldskirchen, Austria; Ausbildung und Forschung GmbH, Johanniter Österreich, Vienna, Austria},
	abstract = {First responders engage in highly stressful situations at the emergency site that may induce stress, fear, panic and a collapse of clear thinking. Staying cognitively under control under these circumstances is a necessary condition to avoid useless risk-taking and particularly to provide accurate situation reports to organize appropriate support in time. This work-in-progress applied a flexible virtual reality (VR) training environment to investigate the performance of reporting under rather realistically simulated mission conditions. In a pilot study, representative emergency forces of the Austrian volunteer fire brigade and paramedics of the Johanniter organization participated in an exploratory pilot study that tested a formalized reporting schema (LEDVV), applying equivalent stress in both, (i) real (physical strain) and non-immersive (cognitive strain), and (ii) fully immersive training environments. Wearable psychophysiological measuring technology was applied to estimate the cognitive-emotional stress level under both training conditions. The results indicate that situation reports achieve a high level of cognitive-emotional stress and should be thoroughly trained. Furthermore, the results motivate the use of VR environments for the training of stress-resilient decision-making behavior of emergency forces. © 2022 Immersive Learning Research Network.},
	author_keywords = {cognitive-emotional stress; first responders; human factors; Virtual reality; wearable biosensors},
	keywords = {Decision making; E-learning; Human engineering; Risk management; Wearable technology; Cognitive-emotional stress; Condition; Digital humans; Emotional stress; First responders; Immersive; Pilot studies; Risk taking; Skill training; Wearable biosensor; Virtual reality},
	editor = {Dengel A. and Bourguet M.-L. and Pedrosa D. and Hutson J. and Erenli K. and Economou D. and Pena-Rios A. and Richter J.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-173489952-8},
	language = {English},
	abbrev_source_title = {Proc. Int. Conf. Immersive Learn. Res. Netw., iLRN},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 8th International Conference of the Immersive Learning Research Network, iLRN 2022; Conference date: 30 May 2022 through 4 June 2022; Conference code: 180846}
}

@ARTICLE{Lawson2023e2330338,
	author = {Lawson, Jason and Martin, Guy and Guha, Payal and Gold, Matthew and Nimer, Amr and Syed, Sadie and Kinross, James},
	title = {Effect of Mixed Reality on Delivery of Emergency Medical Care in a Simulated Environment: A Pilot Randomized Crossover Trial},
	year = {2023},
	journal = {JAMA network open},
	volume = {6},
	number = {8},
	pages = {e2330338},
	doi = {10.1001/jamanetworkopen.2023.30338},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168835532&doi=10.1001%2fjamanetworkopen.2023.30338&partnerID=40&md5=6cb436916396dab5782c482b4cab68c6},
	affiliations = {Department of Surgery and Cancer, Imperial College London, London, United Kingdom; Imperial College Healthcare NHS Trust, London, United Kingdom},
	abstract = {Importance: Mixed-reality (MR) technology has the potential to enhance care delivery, but there remains a paucity of evidence for its efficacy and feasibility. Objective: To assess the efficacy and feasibility of MR technology to enhance emergency care delivery in a simulated environment. Design, Setting, and Participants: This pilot randomized crossover trial was conducted from September to November 2021 at a single center in a high-fidelity simulated environment with participants block randomized to standard care (SC) or MR-supported care (MR-SC) groups. Participants were 22 resident-grade physicians working in acute medical and surgical specialties prospectively recruited from a single UK Academic Health Sciences Centre. Data were analyzed from September to December 2022. Intervention: Participants resuscitated a simulated patient who was acutely unwell, including undertaking invasive procedures. Participants completed 2 scenarios and were randomly assigned to SC or MR-SC for the first scenario prior to crossover. The HoloLens 2 MR device provided interactive holographic content and bidirectional audiovisual communication with senior physicians in the MR-SC group. Main Outcomes and Measures: The primary outcome was error rate assessed via the Imperial College Error Capture (ICECAP) multidimensional error-capture tool. Secondary outcomes included teamwork (Observational Teamwork Assessment for Surgery [OTAS]; range, 0-6 and Teamwork Skills Assessment for Ward Care [T-SAW-C]; range, 1-5), scenario completion, stress and cognitive load (NASA Task Load Index [NASA-TLX; range 0-100]), and MR device user acceptability. Results: A total of 22 physicians (15 males [68.2%]; median [range] age, 28 [25-34] years) were recruited. MR technology significantly reduced the mean (SD) number of errors per scenario compared with SC (5.16 [3.34] vs 8.30 [3.09] errors; P = .003), with substantial reductions in procedural (0.79 [0.75] vs 1.52 [1.20] errors; P = .02), technical (1.95 [1.40] vs 3.65 [2.03] errors; P = .01), and safety (0.37 [0.96] vs 0.96 [0.85] errors; P = .04) domains. MR resulted in significantly greater scenario completion rates vs SC (22 scenarios [100%] vs 14 scenarios [63.6%]; P = .003). It also led to significant improvements in the overall quality of teamwork and interactions vs SC as measured by mean (SD) OTAS (25.41 [6.30] vs 16.33 [5.49]; P < .001) and T-SAW-C (27.35 [6.89] vs 18.37 [6.09]; P < .001) scores. As reported via mean (range) NASA-TLX score, there were significant reductions for MR-SC vs SC in participant temporal demands (38 [20-50] vs 46 [30-70]; P = .03) and significant improvements in self-reported task performance (50 [30-60] vs 39 [10-70]; P = .01). Overall, 19 participants (86.4%) reported that they were more confident in making clinical decisions and undertaking clinical procedures with MR support. Conclusions and Relevance: This study found that the use of MR technology reduced error, improved teamwork, and enhanced practitioner confidence when used to support the delivery of simulated emergency medical care. Trial Registration: ClinicalTrials.gov Identifier: NCT05870137.},
	keywords = {Adult; Augmented Reality; Cross-Over Studies; Emergency Medical Services; Emergency Treatment; Humans; Male; Pilot Projects; adult; augmented reality; controlled study; crossover procedure; emergency health service; emergency treatment; human; male; pilot study; randomized controlled trial},
	publisher = {NLM (Medline)},
	issn = {25743805},
	pmid = {37639272},
	language = {English},
	abbrev_source_title = {JAMA Netw Open},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Shupsky20211106,
	author = {Shupsky, Taylor and Lyman, Adriana and He, Jibo and Zahabi, Maryam},
	title = {Effects of Mobile Computer Terminal Configuration and Level of Driving Control on Police Officers’ Performance and Workload},
	year = {2021},
	journal = {Human Factors},
	volume = {63},
	number = {6},
	pages = {1106 – 1120},
	doi = {10.1177/0018720820908362},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081952216&doi=10.1177%2f0018720820908362&partnerID=40&md5=1d3d1621bbf423a2236033ac5fbf2b9a},
	affiliations = {Wichita State University, KS, United States; Tsinghua University, Beijing, China; Texas A&M University, College Station, United States},
	abstract = {Objective: The objective of this study was to assess police officers’ performance and workload in using two mobile computer terminal (MCT) configurations under operational and tactical driving conditions. Background: Crash reports have identified in-vehicle distraction to be a major cause of law enforcement vehicle crashes. The MCT has been found to be the most frequently used in-vehicle technology and the main source of police in-vehicle distraction. Method: Twenty police officers participated in a driving simulator-based assessment of driving behavior, task completion time, and perceived workload with two MCT configurations under operational and tactical levels of driving. Results: The findings revealed that using the MCT configuration with speech-based data entry and head-up display location while driving improved driving performance, decreased task completion time, and reduced police officers’ workload as compared to the current MCT configuration used by police departments. Officers had better driving but worse secondary task performance under the operational driving as compared to the tactical driving condition. Conclusion: This study provided an empirical support for use of an enhanced MCT configuration in police vehicles to improve police officers’ safety and performance. In addition, the findings emphasize the need for more training to improve officers’ tactical driving skills and multitasking behavior. Application: The findings provide guidelines for vehicle manufacturers, MCT developers, and police agencies to improve the design and implementation of MCTs in police vehicles considering input modality and display eccentricity, which are expected to increase officer and civilian safety. © Copyright 2020, Human Factors and Ergonomics Society.},
	author_keywords = {accidents; distraction; in-vehicle technology; law enforcement; safety},
	keywords = {Computer Terminals; Humans; Law Enforcement; Police; Task Performance and Analysis; Workload; Accident prevention; Accidents; Automobile drivers; Automobile manufacture; Computer terminals; Emergency vehicles; Head-up displays; Vehicle to vehicle communications; Design and implementations; distraction; Driving performance; In-vehicle distractions; In-vehicle technology; Mobile computer terminals; Task completion time; Vehicle manufacturers; computer terminal; human; law enforcement; police; task performance; workload; Law enforcement},
	correspondence_address = {M. Zahabi; Texas A&M University, College Station, United States; email: mzahabi@tamu.edu},
	publisher = {SAGE Publications Inc.},
	issn = {00187208},
	coden = {HUFAA},
	pmid = {32149529},
	language = {English},
	abbrev_source_title = {Hum. Factors},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8}
}

@CONFERENCE{Park20201353,
	author = {Park, Hyunho and Kwon, Eunjung and Byon, Sungwon and Shin, Won-Jae and Jung, Eui-Suk and Lee, Yong-Tae},
	title = {Punch Analysis with FFT and LSTM of Accelerometer and Gyroscope Data},
	year = {2020},
	journal = {International Conference on ICT Convergence},
	volume = {2020-October},
	pages = {1353 – 1355},
	doi = {10.1109/ICTC49870.2020.9289180},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098947065&doi=10.1109%2fICTC49870.2020.9289180&partnerID=40&md5=9a59689789f4338ee2b6dfcfbe824d5d},
	affiliations = {Electronics and Telecommunications Research Institute, Public Safety Intelligence Research Section, Daejeon, South Korea},
	abstract = {Governments around the world are interested in public safety services for protecting the public from violent crimes. For the public safety services, a technology for detecting violent activities attracts attentions. This paper proposes an analysis method for analyzing punches by using fast Fourier transform (FFT) and long short-term memory (LSTM) of accelerometer and gyroscope data of wearable devices. The proposed method analyzed characteristics of accelerometer data in frequency domain by using FFT. The proposed method achieves 97.27% accuracy and 97.27% F1-score for classifying types of punches (e.g., left hook, left jab, right cross, and right hook) by using LSTM. The proposed method will contribute to detect violent activities and thus will help fast response to the violent crimes.  © 2020 IEEE.},
	author_keywords = {accelerometer data; FFT; gyroscope data; LSTM; punch analysis},
	keywords = {Accelerometers; Crime; Fast Fourier transforms; Frequency domain analysis; Gyroscopes; Wearable technology; Accelerometer data; Analysis method; F1 scores; Fast response; Frequency domains; Public safety; Wearable devices; Long short-term memory},
	publisher = {IEEE Computer Society},
	issn = {21621233},
	isbn = {978-172816758-9},
	language = {English},
	abbrev_source_title = {Int. Conf. ICT Convergence},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 11th International Conference on Information and Communication Technology Convergence, ICTC 2020; Conference date: 21 October 2020 through 23 October 2020; Conference code: 166030}
}

@ARTICLE{Hsu2023507,
	author = {Hsu, Ruei-Hau and Wang, Lu-Chin and Fan, Hsiang-Shian},
	title = {Universally Secure Device-to-Device Communications With Privacy Protection and Fine-Grained Access Control Based on 5G-Enabled Multi-Access Edge Computing},
	year = {2023},
	journal = {Journal of Information Science and Engineering},
	volume = {39},
	number = {3},
	pages = {507 – 524},
	doi = {10.6688/JISE.202305_39(3).0004},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160546755&doi=10.6688%2fJISE.202305_39%283%29.0004&partnerID=40&md5=a2229a3ac52af712de0d7c436d790563},
	affiliations = {Department of Computer Science and Engineering, National Sun Yat-Sen University, Kaohsiung, 804, Taiwan},
	abstract = {Device-to-device (D2D) communications enable new user experiences and low latency in communications among devices for new IoT applications, such as augmented reality (AR), virtual reality (VR), public safety, based on the fifth-generation and beyond (B5G) mobile networks. However, typical D2D communications still rely on the assistance of a centralized component, i.e., proximity service (ProSe) application server, for access control during device discovery procedures in mobile networks. Moreover, D2D communications are mainly launched by certain apps running on user equipment (UE) and need to discover the other UE in the same proximity of a base station (i.e., gNB in 5G) according to the identity or the profile of each UE in an app. This procedure will inevitably disclose the user/application's sensitive information and behaviors to the infrastructures above to assist in establishing the corresponding D2D communications. Moreover, most of related works for secure D2D communication cannot support fine-grained access control and hidden policy during device discovery procedure simultaneously. Thus, this work proposes a new multi-access edge computing (MEC) based secure anonymous D2D communications system, so-called SAD2D, based on our newly proposed cooperative anonymous attribute-based encryption (CoAABE). The security proofs of the proposed fundamental CoAABE scheme and the SAD2D protocol are both provably secure. Additionally, this work conducts the performance evaluation for the SAD2D in the aspect of queueing model, which can reflect the effects of device discovery requests in certain arrival rates regarding the performance. Overall, this work paves the way to achieve fine-grain access controllable security and privacy protection simultaneously for secure D2D communications to B5G MEC-enabled IoT applications. © 2023 Institute of Information Science. All rights reserved.},
	author_keywords = {5G; attribute based encryption; device-to-device communications; fine-grained access control; hidden policy; multi-access edge computing; privacy; proximity service},
	keywords = {5G mobile communication systems; Access control; Augmented reality; Cooperative communication; Cryptography; Internet of things; Queueing theory; 5g; Attribute-based encryptions; Device-to-Device communications; Edge computing; Fine grained; Fine-grained access control; Hidden policies; Multi-access edge computing; Multiaccess; Privacy; Proximity service; Edge computing},
	publisher = {Institute of Information Science},
	issn = {10162364},
	coden = {JINEE},
	language = {English},
	abbrev_source_title = {J. Inf. Sci. Eng.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Shang2022433,
	author = {Shang, Jiacheng and Chen, Si and Wu, Jie and Yin, Shu},
	title = {ARSpy: Breaking Location-Based Multi-Player Augmented Reality Application for User Location Tracking},
	year = {2022},
	journal = {IEEE Transactions on Mobile Computing},
	volume = {21},
	number = {2},
	pages = {433 – 447},
	doi = {10.1109/TMC.2020.3007740},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122830751&doi=10.1109%2fTMC.2020.3007740&partnerID=40&md5=ff6256da9500765fdc9baae47672a57a},
	affiliations = {Department of Computer and Information Sciences, Temple University, Philadelphia, PA, United States; Department of Computer Science, West Chester University of Pennsylvania, West Chester, PA, United States; School of Information Science and Technology, Shanghai Tech University, Shanghai, China},
	abstract = {Augmented reality (AR) applications that overlay the perception of the real world with digitally generated information are on the cusp of commercial viability. AR has appeared in several commercial platforms like Microsoft HoloLens and smartphones. They extend the user experience beyond two dimensions and supplement the normal 3D world of a user. A typical location-based multi-player AR application works through a three-step process, wherein the system collects sensory data from the real world, identifies objects based on their context, and finally, renders information on top of senses of a user. However, because these AR applications frequently exchange data with users, they have exposed new individual and public safety issues. In this paper, we develop ARSpy, a user location tracking system solely based on network traffic information of the user, and we test it on location-based multi-player AR applications. We demonstrate the effectiveness and efficiency of the proposed scheme via real-world experiments on 12 volunteers and show that we could obtain the geolocation of any target with high accuracy. We also propose three mitigation methods to mitigate these side channel attacks. Our results reveal a potential security threat in current location-based multi-player AR applications and serve as a critical security reminder to a vast number of AR users. © 2002-2012 IEEE.},
	author_keywords = {attack; Augmented reality; localization},
	keywords = {Location; Side channel attack; Tracking (position); Attack; Augmented reality applications; Breakings; Commercial viability; Localisation; Location based; MicroSoft; Real-world; Smart phones; User location; Augmented reality},
	correspondence_address = {J. Shang; Department of Computer and Information Sciences, Temple University, Philadelphia, United States; email: jiacheng.shang@temple.edu},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {15361233},
	language = {English},
	abbrev_source_title = {IEEE Trans. Mob. Comput.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 15}
}

@ARTICLE{2021,
	title = {2nd International Conference on Design, Operation and Evaluation of Mobile Communications, MOBILE 2021, Held as Part of the 23rd HCI International Conference, HCII 2021},
	year = {2021},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {12796 LNCS},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112211094&partnerID=40&md5=444324d9c6d2261edb322e6e86d9f113},
	abstract = {The proceedings contain 28 papers. The special focus in this conference is on Design, Operation and Evaluation of Mobile Communications. The topics include: Accessibility Challenges of Video Conferencing Technology; technology Craving and Withdrawal: Exploring Compulsive Mobile App Use; The Use of mPOS in Mexico; augmented Reality-Based Dance Training System: A Study of Its Acceptance; The Evaluation Framework for Wearable Devices Service Quality Based on SERVQUAL Model; Stakeholder Perceptions in the Context of Community Risk Reduction (CRR): Self-reported Hazards as Two-Way Communication Between First Responders and the Communities They Serve; global Challenges of Mobile Communication; The Impact of Mobile IT on the Service Innovation Performance of Manufacturing; user Co-creation Value of Short-Video Platform from the Perspective of Interactivity: The Mediating Role of Psychological Attachment; bibliometric Structured Review of Mobile Information Systems; analysis of Malaria Information on a Social Media Platform; the Influence and Prospect of Mobile Communication Technology on Advanced Manufacturing Industry; learners’ Perception on Integration of Human Personality Types on Mobile Learning Platform; customer Satisfaction Evaluation Method Based on Big Data; investigation of Information Requirements for Smartwatch-Based Evacuation Support System; Application of Improved DTW Algorithm in Smart Home Industry; research on Risk Management of Digital Currency Based on Blockchain Technology in Mobile Commerce; developing a Mobile Learning Application for Preschooler; transformation the Business of eCommerce Through Blockchain; task Characteristics and Participants’ Creative Performance in Crowdsourcing Contexts; correction to: Learners’ Perception on Integration of Human Personality Types on Mobile Learning Platform (Design, Operation and Evaluation of Mobile Communications, 10.1007/978-3-030-77025-9_27); foreword.},
	editor = {Salvendy G. and Wei J.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303077024-2},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2nd International Conference on Design, Operation and Evaluation of Mobile Communications, MOBILE 2021, Held as Part of the 23rd HCI International Conference, HCII 2021; Conference date: 24 July 2021 through 29 July 2021; Conference code: 262159}
}

@ARTICLE{Broneder2023155,
	author = {Broneder, Elisabeth and Weiß, Christoph and Schrom-Feiertag, Helmut and Puthenkalam, Jaison and Miu, Valentin and Aumayr, Georg and Kirilova, Sofia and Weismeier-Sammer, Daniela},
	title = {MRespond – An Innovative and Flexible MR Training System for First Responders},
	year = {2023},
	journal = {Communications in Computer and Information Science},
	volume = {1836 CCIS},
	pages = {155 – 162},
	doi = {10.1007/978-3-031-36004-6_21},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169416764&doi=10.1007%2f978-3-031-36004-6_21&partnerID=40&md5=6598194c7d47c14483b7ac2cd037c24c},
	affiliations = {AIT Austrian Institute of Technology GmbH, Vienna, Austria; JOAFG Johanniter Österreich Ausbildung und Forschung gemeinnützige GmbH, Research and Innovation Center, Vienna, Austria},
	abstract = {First responders are often lacking opportunities to train for dangerous situations such as big fires or chemical accidents, because these scenarios are often either too dangerous to simulate in real life or associated with high costs or personnel expenditure. The MRespond project addresses this challenge by providing a Mixed Reality (MR) solution that allows first responders such as fire fighters or paramedics to train hazardous situations in a multi-story building. Virtual hazards such as fire or chemical substances can be blended into the real world. The MR system offers free movement of trainees within a multi-story building and an outdoor area. First responders can train with their usual equipment. Objects and equipment such as doors, fire nozzles or emergency manikins are tracked and integrated into the system, so that the trainees can interact with the training scenario as they are used to. Real objects can interact vith virtual objects so that e.g., the fire propagation changes by opening doors and windows. Virtual injuries can be projected onto real emergency manikins so that trainees can train triage scenarios and still have the tactile feedback if they e.g., apply a bandage. Further, an exercise instructor interface provides the possibility to adapt the scenario in real-time by e.g., placing fires or changing the vital parameters of a patient. Thus, MRespond offers a highly adaptable training system. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {First Responders; Mixed Reality; Training; User Interaction},
	keywords = {Fires; Chemical accident; Cost expenditure; Dangerous situations; Fire accident; First responders; High costs; Mixed reality; Multistory building; Training Systems; User interaction; Mixed reality},
	correspondence_address = {E. Broneder; AIT Austrian Institute of Technology GmbH, Vienna, Austria; email: elisabeth.broneder@ait.ac.at},
	editor = {Stephanidis C. and Antona M. and Ntoa S. and Salvendy G.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {18650929},
	isbn = {978-303136003-9},
	language = {English},
	abbrev_source_title = {Commun. Comput. Info. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 25th International Conference on Human-Computer Interaction, HCII 2023; Conference date: 23 July 2023 through 28 July 2023; Conference code: 297769}
}

@ARTICLE{Islam Molla2022,
	author = {Islam Molla, Md Tahmidul and Dunne, Lucy E.},
	title = {A case study on manufacturing electronic-embedded garments with stitched surface-mount fabrication},
	year = {2022},
	journal = {Flexible and Printed Electronics},
	volume = {7},
	number = {1},
	doi = {10.1088/2058-8585/ac4bfb},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125505707&doi=10.1088%2f2058-8585%2fac4bfb&partnerID=40&md5=c28191fdf2d453079712643975549295},
	affiliations = {Department of Computer Science, Marquette University, Milwaukee, WI, United States; University of Minnesota-Twin Cities, Wearable Technology Lab, St. Paul, MN, United States},
	abstract = {Electronic-embedded textiles or e-textiles preserve the form factor of typical apparel but have the ability to provide required electrical performance, enabling expanded functionality and comfort to the wearer. However, durable, reliable, and scalable manufacturing of e-textiles has remained one of the major challenges to large-scale development of garment-integrated applications of wearable technology. Moreover, there is a gap in our understanding of the impact of integration of electronics into textiles and challenges involved in manufacturing e-textile garments in mass. In this paper, we present the first manufacturing case study for electronic-embedded garments, to the best of our knowledge. We first developed a sensor-integrated fire-fighter turnout gear coat as an example e-textile product. Next, we performed a pre-production study to investigate the new variables that emerge from the prototyping phase to the production phase. To evaluate the challenges of manufacturing e-textiles in mass as compared to non-electronic garments, we produced 40 pieces each of regular and temperature sensing fire-fighter turnout gear coat liner garments using stitched surface-mount fabrication methods. The study results show that the average manufacturing time and cost to produce a sensor-integrated thermal liner are 3.27 and 3.44 times higher, respectively, than producing a regular thermal liner garment, given that all the materials, labor, and standard sewing methods and machines remain constant. Additionally, we show the impact on requisite worker skills and training and quality assurance methods to produce e-textile garments compared to regular garments. We illustrate high-potential areas where strategic product and production design that leverages existing machines and tools can reduce the impact that embedded technologies have on labor, equipment, and cost. We conclude that the stitched surface-mount manufacturing method could potentially be used as an alternative for manufacturing e-textiles in mass.  © 2022 IOP Publishing Ltd.},
	author_keywords = {e-textiles; garment-integrated technologies; manufacturing; mass production; surface-mount fabrication},
	keywords = {Product design; Quality assurance; Smart textiles; Surface mount technology; Temperature sensors; Wearable technology; Case-studies; Electrical performance; Fire fighters; Form factors; Garment-integrated technology; Integrated technologies; Large-scale development; Mass production; Surface-mount fabrication; Thermal; Fabrication},
	correspondence_address = {M.T. Islam Molla; Department of Computer Science, Marquette University, Milwaukee, United States; email: tahmidul.islam@marquette.edu},
	publisher = {IOP Publishing Ltd},
	issn = {20588585},
	language = {English},
	abbrev_source_title = {Flex. Print. Electron.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Friedman2023,
	author = {Friedman, Nicholas and Zuniga-Hernandez, Michelle and Titzler, Janet and Suen, Man Yee and Wang, Ellen and Rosales, Oswaldo and Graham, Jenna and D’Souza, Peter and Menendez, Maria and Caruso, Thomas J.},
	title = {Prehospital Pediatric Emergency Training Using Augmented Reality Simulation: A Prospective, Mixed Methods Study},
	year = {2023},
	journal = {Prehospital Emergency Care},
	doi = {10.1080/10903127.2023.2224876},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163659379&doi=10.1080%2f10903127.2023.2224876&partnerID=40&md5=9886a9fa2360ad929d971d9128fd9c7e},
	affiliations = {Stanford Chariot Program, Lucile Packard Children’s Hospital, Palo Alto, CA, United States; Department of Anesthesiology, Perioperative, and Pain Medicine, Stanford University School of Medicine, Stanford, CA, United States; Mountain View Fire Department, City of Mountain View, Mountain View, CA, United States; Department of Emergency Medicine, Stanford University School of Medicine, Stanford, CA, United States},
	abstract = {Objective: Pediatric emergencies are high-stakes yet low-volume clinical encounters for emergency medical services (EMS) clinicians, necessitating innovative approaches to training. We sought to explore the acceptability, usability, and ergonomics of a novel augmented reality (AR) software for EMS crisis management training. Methods: This was a prospective, mixed-methods study employing qualitative and quantitative analyses. We enrolled emergency medical technicians (EMTs) and paramedics at a municipal fire service in Northern California. We ran the Chariot Augmented Reality Medical simulation software (Stanford Chariot Program, Stanford University, Stanford, CA) on the ML1 headset (Magic Leap, Inc., Plantation, FL), which enabled participants to view an AR image of a patient overlaid with real-world training objects. Participants completed a simulation of a pediatric hypoglycemia-induced seizure and cardiac arrest. Participants subsequently engaged in structured focus group interviews assessing acceptability, which we coded and thematically analyzed. We evaluated the usability of the AR system and ergonomics of the ML1 headset using previously validated scales, and we analyzed findings with descriptive statistics. Results: Twenty-two EMS clinicians participated. We categorized focus group interview statements into seven domains after an iterative thematic analysis: general appraisal, realism, learning efficacy, mixed reality feasibility, technology acceptance, software optimization, and alternate use cases. Participants valued the realism and the mixed reality functionality of the training simulation. They reported that AR could be effective for practicing pediatric clinical algorithms and task prioritization, building verbal communication skills, and promoting stress indoctrination. However, participants also noted challenges with integrating AR images with real-world objects, the learning curve required to adapt to the technology, and areas for software improvement. Participants favorably evaluated the ease of use of the technology and comfortability of wearing the hardware; however, most participants reported that they would need technical support. Conclusion: Participants positively evaluated the acceptability, usability, and ergonomics of an AR simulator for pediatric emergency management training, and participants identified current technological limitations and areas for improvement. AR simulation may serve as an effective training adjunct for prehospital clinicians. © 2023 National Association of EMS Physicians.},
	correspondence_address = {T.J. Caruso; Department of Anesthesiology, Perioperative, and Pain Medicine, Stanford University School of Medicine, Stanford, United States; email: tjcaruso@stanford.edu},
	publisher = {Taylor and Francis Ltd.},
	issn = {10903127},
	coden = {PEMCF},
	language = {English},
	abbrev_source_title = {Prehosp. Emerg. Care},
	type = {Article},
	publication_stage = {Article in press},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Wessels202193,
	author = {Wessels, Lyndsey E. and Roper, Michelle T. and Ignacio, Romeo C. and Davis, Konrad L. and Ambrosio, Art A.},
	title = {Telementorship in Underway Naval Operations: Leveraging Operational Virtual Health for Tactical Combat Casualty Care},
	year = {2021},
	journal = {Journal of special operations medicine : a peer reviewed journal for SOF medical professionals},
	volume = {21},
	number = {3},
	pages = {93 – 95},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116341836&partnerID=40&md5=482f92e09e39f3bdd9786435d4779164},
	abstract = {BACKGROUND: Virtual health (VH) may enhance mentorship to remote first responders. We evaluated the feasibility of synchronous bidirectional VH to mentor life-saving procedures performed by deployed novice providers. METHODS: Video teleconferencing (VTC) was established between the USNS Mercy (T-AH 19) underway in the Pacific Ocean to Naval Medical Center San Diego using surgeon teleconsultation. The adult simulated clinical vignette included injuries following a shipboard explosion with subsequent fire. The pediatric simulated vignette included injuries that resulted from an improvised explosive device (IED) blast. Using VTC, augmented reality (AR) goggles, and airway simulation equipment, corpsmen (HMs) received visual cues to perform advanced life-saving procedures. RESULTS: In adult scenarios, 100% of novice hospital HMs performed tasks on first attempt (n = 12). Mean time for tourniquet placement was 46 seconds (standard deviation [SD], 19 seconds); needle thoracostomy, 70 seconds (SD, 67 seconds); tube thoracostomy, 313 seconds (SD, 152 seconds); and cricothyroidotomy, 274 seconds (SD, 82 seconds). In pediatric scenarios, 100% of novice HMs performed tasks on first attempt (n = 5). Mean time for tube thoracostomy completion was 532 seconds (SD, 109 seconds). CONCLUSION: VH can enhance the training and delivery of trauma care during prolonged field care in resource-limited settings. 2021.},
	keywords = {Adult; Child; Emergency Responders; Humans; Thoracostomy; Tourniquets; adult; child; human; rescue personnel; thoracostomy; tourniquet},
	publisher = {NLM (Medline)},
	issn = {15539768},
	pmid = {34529812},
	language = {English},
	abbrev_source_title = {J Spec Oper Med},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@CONFERENCE{Smit2021209,
	author = {Smit, Bart-Peter and Voûte, Robert and Verbree, Edward},
	title = {CREATING 3D INDOOR FIRST RESPONDER SITUATION AWARENESS in REAL-TIME through A HEAD-MOUNTED AR DEVICE},
	year = {2021},
	journal = {ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences},
	volume = {5},
	number = {4},
	pages = {209 – 216},
	doi = {10.5194/isprs-annals-V-4-2021-209-2021},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119681693&doi=10.5194%2fisprs-annals-V-4-2021-209-2021&partnerID=40&md5=f550741d78f34a7dd72a8e33c2137157},
	affiliations = {CGI Nederland B.V., George Hintzenweg 89, Rotterdam, 3068 AX, Netherlands; Delft University of Technology, Faculty of Architecture and the Built Environment, Architectural Engineering and Technology, Digital Technologies, Delft, 2628 BL, Netherlands},
	abstract = {Emergency operations are a key example for the need of digital twins in the way it is complex, urgent and uncertain. First, the process is complex, as many organizations are involved. Second, it is urgent, as most damage is done in the first moments of an emergency. Third, it is uncertain, as situational conditions tend to change quickly. For outdoor operations, spatial information systems help in creating an overview of the situation, for example by displaying positions of first responder units involved with the incident. However, spatial data of indoor environments is scarce. Static information of the building, such as floor plans, are often outdated or non-existent. Dynamic operational data such as positions of first responders within the building are only available in a very limited way as well, and often without visual representation. To create situation awareness of indoor first responder operation environments, this paper successfully proposes a proof of concept with two objectives. First, the proof of concept will collect spatial environment data in the form of mapping and tracking data by using a Microsoft HoloLens. This means the geometry of the building will be collected, together with traversed routes within the building. Second, the data will be streamed and displayed to a remote first responder coordinator in real-time to create a common operational picture. This enables the coordinator to quickly build situation awareness of the operation environment, enabling the coordinator to improve the quality of decisions, thereby improving first responder performance. The proof of concept showed that situation awareness on all three levels increases with the real-time (live) availability (visualisations) of 3D indoor environments. This concept needs to be tested further on usability and performance. © Copyright: Author(s) 2021.},
	author_keywords = {Digital Twins; First Responder; HoloLens; Indoor; Mapping; Real-Time; Situation Awareness; Tracking},
	keywords = {Emergency operations; First responders; Hololens; Indoor; Indoor environment; Performance; Proof of concept; Real- time; Situation awareness; Tracking; Mapping},
	editor = {Paparoditis N. and Mallet C. and Lafarge F. and Yang M.Y. and Zlatanova S. and Dragicevic S. and Sithole G. and Agugiaro G. and Arsanjani J.J. and Boguslawski P. and Breunig M. and Brovelli M.A. and Christophe S. and Coltekin A. and Delavar M.R. and Al Doori M. and Guilbert E. and Fonte C.C. and Haworth J. and Isikdag U. and Ivanova I. and Kang Z. and Khoshelham K. and Koeva M. and Kokla M. and Liu Y. and Madden M. and Mostafavi M.A. and Navratil G. and Paudyal D.R. and Pettit C. and Spano A. and Stefanakis E. and Tu W. and Vacca G. and Diaz-Vilarino S. and Wise S. and Wu H. and Zhou X.G.},
	publisher = {Copernicus GmbH},
	issn = {21949042},
	language = {English},
	abbrev_source_title = {ISPRS Ann. Photogramm. Remote Sens. Spat. Inf. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2021 24th ISPRS Congress on Imaging Today, Foreseeing Tomorrow, Commission IV; Conference date: 5 July 2021 through 9 July 2021; Conference code: 174093; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Tang20212973,
	author = {Tang, Shuangxia and Shi, Kunquan},
	title = {Data privacy protection technology of wearable-devices},
	year = {2021},
	journal = {Journal of Intelligent and Fuzzy Systems},
	volume = {40},
	number = {2},
	pages = {2973 – 2980},
	doi = {10.3233/JIFS-189336},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100585818&doi=10.3233%2fJIFS-189336&partnerID=40&md5=a87df2ca73ecf2cdd032fe253cf6ce1a},
	affiliations = {College of Information Engineering, Guangzhou Panyu Polytechnic College, Guangzhou, China},
	abstract = {Wearable-devices have developed rapidly. Meanwhile, the security and privacy protection of user data has also occurred frequently. Aiming at the process of privacy protection of wearable-device data release, based on the conventional V-MDAV algorithm, this paper proposes a WSV-MDAV micro accumulation method based on weight W and susceptible attribute value sensitivity parameter S and introduces differential-privacy after micro accumulation operating. By simulating the Starlog dataset and the Adult dataset, the results show that, compared with the conventional multi-variable variable-length algorithm, the privacy protection method proposed in this paper has improved the privacy protection level of related devices, and the information distortion has been properly resolved. The construction of the release model can prevent susceptible data with identity tags from being tampered with, stolen, and leaked by criminals. It can avoid causing great spiritual and property losses to individuals, and avoid harming public safety caused by information leakage. © 2021-IOS Press. All rights reserved.},
	author_keywords = {data privacy-protection; differential privacy; micro accumulation; Wearable-device},
	keywords = {Privacy by design; Attribute values; Data privacy protections; Differential privacies; Information distortion; Information leakage; Privacy protection; Security and privacy protection; Sensitivity parameters; Wearable technology},
	correspondence_address = {K. Shi; College of Information Engineering, Guangzhou Panyu Polytechnic College, Guangzhou, China; email: shikq1985@126.com},
	publisher = {IOS Press BV},
	issn = {10641246},
	language = {English},
	abbrev_source_title = {J. Intelligent Fuzzy Syst.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Paletta2022,
	author = {Paletta, Lucas and Pszeida, Martin and Schneeberger, Michael and Dini, Amir and Reim, Lilian and Kallus, K. Wolfgang},
	title = {Cognitive-emotional Stress and Risk Stratification of Situational Awareness in Immersive First Responder Training},
	year = {2022},
	journal = {BHI-BSN 2022 - IEEE-EMBS International Conference on Biomedical and Health Informatics and IEEE-EMBS International Conference on Wearable and Implantable Body Sensor Networks, Symposium Proceedings},
	doi = {10.1109/BHI56158.2022.9926805},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143081263&doi=10.1109%2fBHI56158.2022.9926805&partnerID=40&md5=f973829a91f51019e3a7fb4768eabe42},
	affiliations = {Institute DIGITAL Joanneum Research, Graz, Austria; Institut für Begleitforschung und Psychologisches Qualitätsmanagement, Graz, Austria},
	abstract = {First responders engage in highly stressful situations at the emergency site. Maintaining cognitive control under these circumstances is a necessary condition to perform efficient decision making for the purpose of own health and to pursue mission objectives. We are aiming at developing biosensor-based decision support for risk stratification on cognitive readiness of first responders at the mission site. In a first development stage, an exploratory pilot study was performed to test a formalized reporting schema applying equivalent stress in real, non-immersive and fully immersive training environments. Wearable psychophysiological measurement technology was applied to estimate the cognitive-emotional stress level under both training conditions. In this work we particularly focus on the potential of predicting the risk level for failures in situation awareness from digital analysis of cognitive-emotional stress. The results provide statistically significant indications for risk stratification of cognitive readiness based on situation awareness theory.  © 2022 IEEE.},
	author_keywords = {cognitive-emotional stress; first responders; situation awareness; virtual reality; wearable biosensors},
	keywords = {Decision making; Decision support systems; Risk assessment; Virtual reality; Wearable technology; Cognitive control; Cognitive readiness; Cognitive-emotional stress; Emotional stress; First responders; Immersive; Risk stratification; Situation awareness; Situational awareness; Wearable biosensor; Biosensors},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-166548791-7},
	language = {English},
	abbrev_source_title = {BHI-BSN - IEEE-EMBS Int. Conf. Biomed. Health Informatics IEEE-EMBS Int. Conf. Wearable Implant. Body Sens. Networks, Symp. Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2022 IEEE-EMBS International Conference on Biomedical and Health Informatics, BHI 2022; Conference date: 27 September 2022 through 30 September 2022; Conference code: 184033}
}

@ARTICLE{Kasnesis2022,
	author = {Kasnesis, Panagiotis and Doulgerakis, Vasileios and Uzunidis, Dimitris and Kogias, Dimitris G. and Funcia, Susana and González, Marta B. and Giannousis, Christos and Patrikakis, Charalampos Z.},
	title = {Deep Learning Empowered Wearable-Based Behavior Recognition for Search and Rescue Dogs},
	year = {2022},
	journal = {Sensors},
	volume = {22},
	number = {3},
	doi = {10.3390/s22030993},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123419122&doi=10.3390%2fs22030993&partnerID=40&md5=38f3c9d3c743f90cadb8375d104817ea},
	affiliations = {Department of Electrical and Electronic Engineering, University of West Attica, Athens, 12244, Greece; Spanish School of Rescue and Detection with Dogs (ESDP), Madrid, 28524, Spain},
	abstract = {Search and Rescue (SaR) dogs are important assets in the hands of first responders, as they have the ability to locate the victim even in cases where the vision and or the sound is limited, due to their inherent talents in olfactory and auditory senses. In this work, we propose a deep-learning-assisted implementation incorporating a wearable device, a base station, a mobile application, and a cloud-based infrastructure that can first monitor in real-time the activity, the audio signals, and the location of a SaR dog, and second, recognize and alert the rescuing team whenever the SaR dog spots a victim. For this purpose, we employed deep Convolutional Neural Networks (CNN) both for the activity recognition and the sound classification, which are trained using data from inertial sensors, such as 3-axial accelerometer and gyroscope and from the wearable’s microphone, respectively. The developed deep learning models were deployed on the wearable device, while the overall proposed implementation was validated in two discrete search and rescue scenarios, managing to successfully spot the victim (i.e., obtained F1-score more than 99%) and inform the rescue team in real-time for both scenarios. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.},
	author_keywords = {Bark detection; Canine activity recognition; Deep learning; Search and rescue system; Wearable computing},
	keywords = {Animals; Deep Learning; Dogs; Neural Networks, Computer; Wearable Electronic Devices; Working Dogs; Convolutional neural networks; Deep neural networks; Pattern recognition; Wearable technology; Activity recognition; Bark detection; Canine activity recognition; Deep learning; Real- time; Rescue systems; Search and rescue; Search system; Wearable computing; Wearable devices; animal; dog; electronic device; Behavioral research},
	correspondence_address = {P. Kasnesis; Department of Electrical and Electronic Engineering, University of West Attica, Athens, 12244, Greece; email: pkasnesis@uniwa.gr},
	publisher = {MDPI},
	issn = {14248220},
	pmid = {35161741},
	language = {English},
	abbrev_source_title = {Sensors},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 12; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Arregui2022,
	author = {Arregui, Harbil and Irigoyen, Eider and Cejudo, Inaki and Simonsen, Sebastian and Ribar, Drazen and Kourtis, Michail-Alexandros and Spyridis, Yannis and Stathakarou, Natalia and Batistatos, Michael C.},
	title = {An Augmented Reality Framework for First Responders: the RESPOND-A project approach},
	year = {2022},
	journal = {2022 Panhellenic Conference on Electronics and Telecommunications, PACET 2022},
	doi = {10.1109/PACET56979.2022.9976376},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145667239&doi=10.1109%2fPACET56979.2022.9976376&partnerID=40&md5=74fc0fd3c25e961bc81d6330c6f81bc4},
	affiliations = {Vicomtech Foundation (BRTA), Donostia, Spain; Prometech B.V., Utrecht, Netherlands; Airbus Ds Scl, Elancourt, France; National Centre for Scientific Research Demokritos (NCSRD), Institute of Informatics and Telecommunications, Agia Paraskevi, Greece; 0Infinity Ltd, London, United Kingdom; Massive Dynamic Sweden, Stockholm, Sweden; University of Peloponnese, Department of Informatics and Telecommunications, Tripolis, Greece},
	abstract = {Augmented and Mixed Reality are promising technologies that can help First Responders in emergency situations by presenting the information in novel ways, extending situational awareness and supporting decision-making. However, the use of these technologies for heterogeneous types of users and roles in emergency management requires particular approaches. This paper presents an interdisciplinary approach. The proposed framework enhances emergency response operations mainly through: 1) The presentation of geospatial information in heterogeneous and interactive ways; 2) The management of aspects related to the health of First Responders and treatments of casualties of all kinds involved in the emergency; 3) The use of video as a key enabler in decision-making; and 4) Multimodal interaction capabilities to help handle the information with less intrusive ways. We present the set of components that compose this framework running on different types of hardware devices and describe their applicability in multiple challenging situations in collaboration with a larger set of tools.  © 2022 IEEE.},
	author_keywords = {augmented reality; computer applications; emergency support; mixed reality},
	keywords = {Civil defense; Decision making; Emergency services; Mixed reality; Risk management; Decisions makings; Emergency management; Emergency response; Emergency situation; Emergency support; First responders; Geospatial information; Mixed reality; Project approach; Situational awareness; Augmented reality},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835039958-5},
	language = {English},
	abbrev_source_title = {Panhellenic Conf. Electron. Telecommun., PACET},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2022 Panhellenic Conference on Electronics and Telecommunications, PACET 2022; Conference date: 2 December 2022 through 3 December 2022; Conference code: 185146}
}

@CONFERENCE{Gkika2023231,
	author = {Gkika, Ioanna and Pattas, Dimitrios and Konstantoudakis, Konstantinos and Zarpalas, Dimitrios},
	title = {Object detection and augmented reality annotations for increased situational awareness in light smoke conditions},
	year = {2023},
	journal = {Proceedings of the International ISCRAM Conference},
	volume = {2023-text},
	pages = {231 – 241},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171789605&partnerID=40&md5=a6323330e431f0c43afab3ff89cb2484},
	affiliations = {Visual Computing Lab (VCL), Information Technologies Institute (ITI), Centre for Research and Technology - Hellas (CERTH), Thessaloniki, Greece},
	abstract = {Innovative technologies powered by Computer Vision algorithms can aid first responders, increasing their situational awareness. However, adverse conditions, such as smoke, can reduce the efficacy of such algorithms by degrading the input images. This paper presents a pipeline of image de-smoking, object detection, and augmented reality display that aims to enhance situational awareness in smoky conditions. A novel smoke-reducing deep learning algorithm is applied as a preprocessing step, before state-of-the-art object detection. The detected objects and persons are highlighted in the user’s augmented reality display. The proposed method is shown to increase detection accuracy and confidence. Testing in realistic environments provides an initial evaluation of the method, both in terms of image processing and of usefulness to first responders. © 2023 Information Systems for Crisis Response and Management, ISCRAM. All rights reserved.},
	author_keywords = {Augmented Reality; Deep Learning; Image Processing; Situational Awareness; Smoke},
	keywords = {Augmented reality; Deep learning; Image enhancement; Information management; Information systems; Information use; Learning algorithms; Object detection; Object recognition; Computer vision algorithms; Condition; Deep learning; First responders; Images processing; Innovative technology; Input image; Objects detection; Situational awareness; Smoke conditions; Smoke},
	correspondence_address = {I. Gkika; Visual Computing Lab (VCL), Information Technologies Institute (ITI), Centre for Research and Technology - Hellas (CERTH), Thessaloniki, Greece; email: ioanna.gkika@iti.gr},
	publisher = {Information Systems for Crisis Response and Management, ISCRAM},
	issn = {24113387},
	isbn = {979-821821749-5},
	language = {English},
	abbrev_source_title = {Proc. Int. ISCRAM Conf.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 20th Global Information Systems for Crisis Response and Management Conference, ISCRAM 2023; Conference date: 28 May 2023 through 31 May 2023; Conference code: 192193}
}

@CONFERENCE{Jewell2022,
	author = {Jewell, Susan and Jewell, Emmy},
	title = {HOLOTRIAGE: A NOVEL MEDICAL FIRST RESPONSE TRAINING FOR ASTRONAUTS INTEGRATING ARTIFICIAL INTELLIGENCE, DIGITAL TWINS, AVATARS, HAPTICS, AND MIXED REALITY SPATIAL COMPUTING TECHNOLOGIES},
	year = {2022},
	journal = {Proceedings of the International Astronautical Congress, IAC},
	volume = {2022-September},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167610882&partnerID=40&md5=85230fdd51835dab34fd20a0cab2b6e8},
	affiliations = {AvatarMEDIC Inc, Lancaster, CA, United States; MMAARS Inc (Mars-Moon Astronautics Academy and Research Sciences), California City, CA, United States},
	abstract = {Simulation based medical training is an effective method for preparing and training medical first responders and astronauts for medical interventions and life-threatening challenges especially in remote, isolated environments and in Space or on a planetary surface. Virtual Reality (VR) has seen usage to run simulation training at lower cost, yet VR does not offer the direct connection to the material reality that first responders will actually be operating in. Thus, AvatarMEDIC Inc has created HoloTRIAGE automated training platform utilizing Mixed Reality (MR) otherwise known as Spatial Computing. MR overlays digital assets onto the physical world in an anchored way, meaning that digital assets behave as if they are literally present in the physical world and are represented as DIGITAL TWINS or teleAVATARS and telepresence (an advancement of telemedicine paradigm). MR is epitomized by devices such as Microsoft HoloLens 2 and MR abilities are available on mobile devices which can be used on ISS for astronauts or medical providers in austere or disaster areas on Earth. Artificial Intelligence (AI) enables the HoloTRIAGE platform to automatically scan and segment the environment for use in automatically constructing scenarios and placing virtual assets, with options to allow instructors to specify broad parameters and have specifics automatically implemented. Further, AI delivers realistic interactive virtual victims, and is utilized to assess trainee performance. Entirely new metrics are available, such as eye-tracking and body pose data, enabling new fidelity of assessments and responsive simulations. Avatars allow remote experts or specialist instructors to record themselves and/or be present in realtime to teach and participate. Haptics enables trainees to feel physical impressions of digital assets, including resistance, pressure, texture and temperature. HoloTRIAGE represents a new era for first response training using virtual assets in real context, and AvatarMEDIC's network of leading experts ensures that training content is focused, accurate and supportive of real first response needs. Designed to augment existing physical simulation exercises and materials, as well as enable complete replacement of physical materials with virtual assets. Developed specifically for conducting training in remote and austere environments where weight and personnel are most limited. Enables cost savings and increase in total number of possible exercises. This presentation will demonstrate the HoloTRIAGE application and discuss development and deployment of the technology and its potential application for space exploration and medical care delivery for astronauts. © 2022 International Astronautical Federation, IAF. All rights reserved.},
	author_keywords = {AR/XR/VR/AI/ML; avatars; rover; space medicine; telemedicine; telepresence; UAV},
	keywords = {Artificial intelligence; Disasters; Eye tracking; Mixed reality; Personnel training; Telemedicine; Textures; Video conferencing; Visual communication; AR/XR/virtual reality/artificial intelligence/ML; Avatar; Digital assets; First responders; Haptics; Mixed reality; Physical world; Space medicines; Spatial computing; Telepresence; Unmanned aerial vehicles (UAV)},
	correspondence_address = {S. Jewell; AvatarMEDIC Inc, Lancaster, United States; email: contact@avatarmedic.com; E. Jewell; AvatarMEDIC Inc, Lancaster, United States; email: mmaarsacademy@gmail.com},
	publisher = {International Astronautical Federation, IAF},
	issn = {00741795},
	language = {English},
	abbrev_source_title = {Proc. Int. Astronaut. Congr., IAC},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 73rd International Astronautical Congress, IAC 2022; Conference date: 18 September 2022 through 22 September 2022; Conference code: 190266}
}

@ARTICLE{Guarda2023123,
	author = {Guarda, Teresa and Lopes, Isabel and Bustos, Samuel and Ribeiro, Isabel and Fernandes, António},
	title = {Augmented Computing and Smart Cities Sustainability},
	year = {2023},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14108 LNCS},
	pages = {123 – 132},
	doi = {10.1007/978-3-031-37117-2_10},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165083222&doi=10.1007%2f978-3-031-37117-2_10&partnerID=40&md5=682d93ad8e452c0d9f6d9873ff3ba868},
	affiliations = {Universidad Estatal Peninsula de Santa Elena, La Libertad, Ecuador; Algoritmi Centre, Minho University, Guimarães, Portugal; Applied Management Research Unit (UNIAG) - Instituto Politécnico de Bragança (IPB), Bragança, 5300-253, Portugal; Centro de Investigação de Montanha (CIMO) - Instituto Politécnico de Bragança, Bragança, Portugal; Laboratório Associado para a Sustentabilidade e Tecnologia em Regiões de Montanha (SusTEC) - Instituto Politécnico de Bragança, Bragança, Portugal},
	abstract = {Smart Cities promote a great improvement in urban environments in terms of sustainability, leveraged by the use of technologies that allow the optimization and monitoring of different systems, from waste management systems to public safety. There are several technologies that can play a key role in this process, highlighting augmented computing, augmented reality, virtual reality, artificial intelligence, and machine learning. In this context, smart cities collects and analyses, optimizing the various systems processes. There are many challenges that arise in order to have sustainable smart cities, challenges in terms of privacy and data security, but also in promoting inclusion and equity. It is important to adopt an inclusive and holistic approach that involves all stakeholders and takes into account the specific needs and objectives of a city. With this in mind, the adoption of augmented computing technologies facilitates the creation of more livable and also more sustainable urban environments. The main objective of this work is to explore the area of augmented computing in the context of smart cities sustainability. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {Artificial Intelligence; Augmented Computing; Machine Learning; Smart City; Virtual and Augmented Reality},
	keywords = {Augmented reality; E-learning; Smart city; Sustainable development; Virtual reality; Waste management; Artificial intelligence learning; Augmented computing; Holistic approach; Machine-learning; Optimisations; Public safety; System process; Urban environments; Virtual and augmented reality; Waste management systems; Machine learning},
	correspondence_address = {T. Guarda; Universidad Estatal Peninsula de Santa Elena, La Libertad, Ecuador; email: tguarda@gmail.com},
	editor = {Gervasi O. and Murgante B. and Scorza F. and Rocha A.M.A.C. and Garau C. and Karaca Y. and Torre C.M.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303137116-5},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 23rd International Conference on Computational Science and Its Applications, ICCSA 2023; Conference date: 3 July 2023 through 6 July 2023; Conference code: 297179}
}

@ARTICLE{Deng2022,
	author = {Deng, Honglei and Peng, Ruidong and Zhong, Meishan and Yang, Rui and Liang, Yongchun and Guo, Deming and Liu, Gang},
	title = {A case study of rupture in overhead ground wire twined by armor rod},
	year = {2022},
	journal = {Engineering Failure Analysis},
	volume = {131},
	doi = {10.1016/j.engfailanal.2021.105844},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118898881&doi=10.1016%2fj.engfailanal.2021.105844&partnerID=40&md5=49bb01fe84460f7b04a8f532d0c1d682},
	affiliations = {School of Electric Power Engineering, South China University of Technology, Guangzhou, 510640, Guangdong, China; Dongguan Power Supply Bureau of Guangdong, Power Grid Co., Ltd., Dongguan, 523008, Guangdong, China; Electric Power Research Institute of Guangdong Power Grid Co., Ltd., Guangzhou, 510080, Guangdong, China},
	abstract = {The armor rod (AR) is used to repair the damaged overhead ground wire (OGW) and prevent the wear of the OGW in the suspension clamp in engineering. Once the OGW at the AR terminal breaks, it may lead to temporary blackout, which also causes the severe economic losses, or even threatening public safety. However, there are few literature or report about this type of accident at present. Therefore, based on a rupture accident of OGW at the AR terminal, the reason for this accident was investigated in this paper. Firstly, the description of the accident background and the material analysis for the accident sample were presented to preliminarily determine the damage characteristics of OGW and the cause of the accident. Secondly, simulation experiments for the transient temperature rise of the AR terminal were conducted. The macroscopic morphology characteristics of the experimental samples were also analyzed. Finally, based on the electromagnetic thermal coupling, a finite element model of the AR terminal of OGW was established. The overheating mechanism at the AR terminal was also discussed according to the model. The discharge occurrs at the AR terminal under the short-circuit current (SCC), and it is also the prime factor that causes the high temperature of OGW. The research methods and conclusions in this paper can provide theoretical guidance for the analysis of similar accidents and the optimization design of structures. © 2021 Elsevier Ltd},
	author_keywords = {Armor rod; Discharge; Overhead ground wire; Rupture; Skin effect},
	keywords = {Accidents; Armor; Losses; Wire; Armor rod; Case-studies; Discharge; Economic loss; Materials analysis; Over head ground wires; Overhead ground wires; Public safety; Rupture; Transient temperature rise; Structural optimization},
	correspondence_address = {D. Guo; School of Electric Power Engineering, South China University of Technology, Guangzhou, 510640, China; email: 201720113678@mail.scut.edu.cn},
	publisher = {Elsevier Ltd},
	issn = {13506307},
	coden = {EFANE},
	language = {English},
	abbrev_source_title = {Eng. Fail. Anal.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@ARTICLE{Henrique de Jesus Prado202218,
	author = {Henrique de Jesus Prado, Kleber and Colaço Júnior, Methanias},
	title = {Data Science Applied to Crime Analysis Based on Brazilian Open Government Data},
	year = {2022},
	journal = {Journal of Applied Security Research},
	volume = {17},
	number = {1},
	pages = {18 – 61},
	doi = {10.1080/19361610.2020.1848057},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099804259&doi=10.1080%2f19361610.2020.1848057&partnerID=40&md5=9c9bcb411f0460840006bdb830738736},
	affiliations = {Computing Department, Federal University of Sergipe, Sergipe, São Cristóvão, Brazil; State of Sergipe’s General Accounting Office, Sergipe, Aracaju, Brazil},
	abstract = {Context: The criminality phenomenon affects the quality of life, the economic growth and the reputation of a nation. Each year, governments spend millions of dollars fighting violence, and consequently, crime prevention and control are highly concerning issues to the public safety agencies. Objective: Applying Data Science fundamentals to analyze open government data on the crimes that occurred in the Brazilian States. Method: We have conducted a controlled experiment to discover the association rules (AR) between the crimes and the States. Additionally, we have developed a ranking of the most dangerous States. Results: From a general viewpoint, with weights for all available crimes, Paraná was the most dangerous local during all the assessed years, followed by Rio de Janeiro. From the single perspective of murders, in 2019, the States of Roraima, Rio Grande do Norte, Sergipe, Acre and Pernambuco were ranked as the ten most violent ones, being Pernambuco and Acre among the most dangerous States from the two perspectives (weighted average and murders). Conclusion: The Data Science enables the execution of more precise diagnoses. The year of 2019 presented a general drop in the crime rates, with special emphasis on Paraíba, Goiás, Rio Grande do Norte and Ceará. © 2021 Taylor & Francis Group, LLC.},
	author_keywords = {Association rules; crime analysis; data science; open government data; R and Python together},
	correspondence_address = {K. Henrique de Jesus Prado; Computing Department, Federal University of Sergipe, Sergipe, Marechal Rondon Avenue, s/n, Rose Elze Garden, São Cristóvão, Brazil; email: kleprado@hotmail.com},
	publisher = {Routledge},
	issn = {19361610},
	language = {English},
	abbrev_source_title = {J. Appl. Secur. Res.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Tunca2023198,
	author = {Tunca, Sezai and Wilk, Violetta and Sezen, Bulent},
	title = {Defining Virtual Consumerism Through Content and Sentiment Analyses},
	year = {2023},
	journal = {Cyberpsychology, Behavior, and Social Networking},
	volume = {26},
	number = {3},
	pages = {198 – 213},
	doi = {10.1089/cyber.2022.0079},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150000332&doi=10.1089%2fcyber.2022.0079&partnerID=40&md5=b2473ffcbf3021f25d72ea9091333f49},
	affiliations = {Faculty of Management, Gebze Technical University, Gebze, Turkey; School of Business and Law, Joondalup, Edith Cowan University, Perth, WA, Australia},
	abstract = {This study set out to better understand virtual consumerism (VC) by applying natural language processing (NLP) methods for sentiment and content analyses. A total of 318 articles related to VC were identified on theguardian.com Web site and analyzed by text mining methodology. A thematic, content analysis using the Leximancer program was performed to explore VC as a concept, and its related concepts and concept associations. For the purposes of "deep-dive insights,"further content and sentiment analyses were performed with MonkeyLearn and valence aware dictionary for sentiment reasoning. This triangulation in methodology enabled a comprehensive unstructured qualitative data analysis. The study identified key themes that characterize and define VC. It uncovered that, although there is predominantly positive sentiment toward VC reported in The Guardian online articles, negative sentiment also exists, presenting challenges for the industry to maneuver. The findings reveal that in the context of VC, a virtual experience is also a social experience in a virtual space, which is becoming and evolving. There are certain industries and sectors that are embracing VC, such as marketing, advertising and public relations, software development/IT, art/design, and entertainment, as well as science/technology. Some sectors and industries are experiencing challenges, such as security/law enforcement and medical, and hence display negative sentiment toward VC. Overall, this study presents a working definition of VC, a synopsis of the state of VC, and highlights areas for potential research to further our understanding of this phenomenon. It contributes to an improved understanding of VC for the industry and academia, and provides impetus for future studies focused on the emergent VC-relevant conceptual relationships.  Copyright © 2023, Mary Ann Liebert, Inc.},
	author_keywords = {augmented reality; content analysis; natural language processing; virtual consumerism; virtual reality},
	keywords = {Data Mining; Humans; Sentiment Analysis; Software; advertising; article; augmented reality; content analysis; data analysis; human; law enforcement; marketing; mining; natural language processing; public relations; reasoning; security; software; systematic review; virtual reality; data mining; procedures},
	correspondence_address = {S. Tunca; Faculty of Management, Gebze Technical University, Gebze, 41400, Turkey; email: stunca@gtu.edu.tr},
	publisher = {Mary Ann Liebert Inc.},
	issn = {21522715},
	pmid = {36720080},
	language = {English},
	abbrev_source_title = {Cyberpsychol. Behav. Soc. Networking},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Doswell2020164,
	author = {Doswell, Jayfus T. and Jolmson, Justin and Brockingon, Brandon and Mosby, Aaron and Salaam, Saboor and Chinery, Arthur},
	title = {Juxtopia®CAMMRAD Prepare: A Wearable AI-AR Platform for Clinical Training Emergency First Response Teams},
	year = {2020},
	journal = {Proceedings - 2020 22nd Symposium on Virtual and Augmented Reality, SVR 2020},
	pages = {164 – 168},
	doi = {10.1109/SVR51698.2020.00036},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099598730&doi=10.1109%2fSVR51698.2020.00036&partnerID=40&md5=b75960f49ff3f1c5ffad90c8429e2c14},
	affiliations = {The Juxtopia Group, Inc., Open-Wear Department, Baltimore, United States},
	abstract = {This paper discusses a Juxtopia® Open-Wear research collaboration with the Maryland Fire Rescue Institute (MFRI) to evaluate how an artificial intelligent (AI) wearable augmented reality (AR) intervention quantifiably improves hands-free clinical training proficiency of firefighter United States (U.S.) Emergency Medical Technicians (EMT) and prepares them for administering effective clinical skills (e.g., Tourniquet) in response to hazardous materials (hazmat) incidences. The AI-AR system, Juxtopia® Context-Aware Mobile Mixed Reality Assistive Device (CAMMRAD) Prepare E-Training system was evaluated in a two day controlled study including firefighter EMTs subjects who participated in simulated training exercise that mimicked their real-world operations. Results of the study indicates a need for AI-AR training to continually improve EMT clinical skill proficiency.  © 2020 IEEE.},
	author_keywords = {artificial intelligence; augmented reality; clinical; EMT; firefighter; parangedic},
	keywords = {Augmented reality; Clinical research; Emergency services; Fire extinguishers; Mixed reality; Wearable computers; Artificial intelligent; Assistive devices; Clinical training; Emergency medical technicians; Mobile mixed realities; Real world operations; Research collaborations; Simulated trainings; Artificial intelligence},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-172819231-4},
	language = {English},
	abbrev_source_title = {Proc. - Symp. Virtual Augment. Real., SVR},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 22nd Symposium on Virtual and Augmented Reality, SVR 2020; Conference date: 7 November 2020 through 10 November 2020; Conference code: 165344}
}

@CONFERENCE{Alarcao2021,
	author = {Alarcao, Rodrigo and Pestana, Gabriel},
	title = {Augmented Reality to Improve Public Awareness and Safety at the Beach},
	year = {2021},
	journal = {Iberian Conference on Information Systems and Technologies, CISTI},
	doi = {10.23919/CISTI52073.2021.9476613},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115760264&doi=10.23919%2fCISTI52073.2021.9476613&partnerID=40&md5=989ac2703b77d99102a91773fc47c1dc},
	affiliations = {Universidade Europeia, Iade, Lisbon, Portugal},
	abstract = {Rip currents pose a threat to the safety of bathers at most beaches around the world. The proposed research includes the specification of a platform to empower the user to become active beach-safety agents. To achieve this strategic goal, a service design approach was implemented to conceptualize a solution for collecting data about potential hazards, including information about the status of active rip currents. The innovation is settled over the combination of immersive technologies (e.g., Augmented Reality) with visual data analytics and Artificial Intelligence (AI). Mobile Augmented Reality mixed with a gamification strategy is also considered in the architectural design to specify a mobile tool that provides an interactive and gamified environment for promoting a safe beach experience. The presented approach also addresses a strategy to create a social movement challenging citizen to integrate and benefit from the services and informational artifacts provided by the Beach Safety Community (BSC). © 2021 AISTI.},
	author_keywords = {and Interaction Design; Augmented Reality; Beach safety; Gamification; Rip Currents},
	keywords = {Beaches; Data Analytics; Information systems; Information use; And interaction design; Beach safety; Design approaches; Gamification; Interaction design; Public awareness; Public safety; Rip currents; Services designs; Strategic goals; Augmented reality},
	editor = {Rocha A. and Goncalves R. and Penalvo F.G. and Martins J.},
	publisher = {IEEE Computer Society},
	issn = {21660727},
	isbn = {978-989546591-0},
	language = {English},
	abbrev_source_title = {Iberian Conf. Inf. Syst. Technol., CISTI},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 16th Iberian Conference on Information Systems and Technologies, CISTI 2021; Conference date: 23 June 2021 through 26 June 2021; Conference code: 170402}
}

@ARTICLE{Ghosh2023,
	author = {Ghosh, Karthik and Nanda, Sanjeev and Hurt, Ryan T. and Schroeder, Darrell R. and West, Colin P. and Fischer, Karen M. and Bauer, Brent A. and Fokken, Shawn C. and Ganesh, Ravindra and Hanson, Jennifer L. and Lindeen, Stephanie A. and Pruthi, Sandhya and Croghan, Ivana T.},
	title = {Mindfulness Using a Wearable Brain Sensing Device for Health Care Professionals During a Pandemic: A Pilot Program},
	year = {2023},
	journal = {Journal of Primary Care and Community Health},
	volume = {14},
	doi = {10.1177/21501319231162308},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150925856&doi=10.1177%2f21501319231162308&partnerID=40&md5=0e78d8746fa71010a2a04a88febddf36},
	affiliations = {Mayo Clinic, Rochester, MN, United States},
	abstract = {Objective: The purpose of this feasibility pilot study was to evaluate safety and adherence of a wearable brain sensing wellness device designed to reduce stress among healthcare professionals (HCP). Methods: A total of 40 HCP were invited to participate in an open-label pilot study. Participants were asked to use a brain sensing wearable device (MUSE-S™) on a daily basis to reduce their stress, for a total of 90 days. Total study participation duration was 180 days. Study enrollment began in August 2021 and ended December 2021. The exploratory outcomes included stress, depression, sleep, burn-out, resilience, quality of life, and cognition. Results: Among the 40 HCP in study, the majority were female (85%), white (87.5%) and with an average age of 41.3 ± 11.0 years (SD). Participants used the wearable device an average of 23.8 times over a 30-day period with a mean duration of 5.8 min with each use. Study results demonstrate the positive impact of guided mindfulness using the wearable device MUSE-S™ and its accompanying application (APP). A statistically significant improvement was found for a reduction in stress (P <.001) and improvement in resilience (P =.02), quality of life (P =.003), and cognition (P <.001). The majority (91.9%) of the participants indicated they felt more relaxed after using the device, and 73% indicated they would continue to use this device at end-of-study. No adverse effects were reported. Conclusion: Study results show that 3 to 10 min of guided meditation during work hours through the use of a brain sensing wearable device is safe and acceptable, with associated health benefits for HCP. © The Author(s) 2023.},
	author_keywords = {brain sensing device; first responders; pandemic; wearable technology; wellness},
	keywords = {Adult; Alprostadil; Brain; Female; Health Personnel; Humans; Male; Middle Aged; Mindfulness; Pandemics; Pilot Projects; Quality of Life; prostaglandin E1; adult; brain; female; health care personnel; human; male; middle aged; mindfulness; pandemic; pilot study; procedures; quality of life},
	correspondence_address = {K. Ghosh; Mayo Clinic, Rochester, United States; email: ghosh.karthik@mayo.edu},
	publisher = {SAGE Publications Inc.},
	issn = {21501319},
	pmid = {36960553},
	language = {English},
	abbrev_source_title = {J. Prim. Care Community Health},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Schlosser2022,
	author = {Schlosser, Paul and Matthews, Ben},
	title = {Designing for Inaccessible Emergency Medical Service Contexts: Development and Evaluation of the Contextual Secondary Video Toolkit},
	year = {2022},
	journal = {Conference on Human Factors in Computing Systems - Proceedings},
	doi = {10.1145/3491102.3517538},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130524612&doi=10.1145%2f3491102.3517538&partnerID=40&md5=ba9a54475f5cb3a0aa13ed9140752338},
	affiliations = {School of Information Technology and Electrical Engineering, The University of Queensland, Brisbane, Australia},
	abstract = {Designing technology for emergency medical services (EMS) can be difficult, for example, due to limited access to domain experts. To support designers who aim to engage in a participatory design process in EMS environments, we created and evaluated the Contextual Secondary Video Toolkit (CSVT). This method uses secondary video material and design cards that allow domain experts to identify and prioritise challenges in their work environment and generate design ideas that address them. We illustrate the effects of the CSVT on design processes by analysing four workshops during which aeromedical EMS staff explored the potential of augmented reality to support their work. Our results indicate that the CSVT can support reflection about work practices, aid the generation of design ideas, and facilitate genuine participation. Furthermore, our data indicates that the use of secondary video in design projects is appropriate and even has certain advantages compared to primary field video. © 2022 ACM.},
	author_keywords = {Augmented reality; Design method; Emergency medical services; Head-worn display; Participatory design; Secondary video},
	keywords = {Augmented reality; Design; Virtual reality; Design ideas; Design method; Design-process; Domain experts; Emergency medical services; Head-worn displays; Participatory design; Secondary video; Service environment; Video material; Emergency services},
	publisher = {Association for Computing Machinery},
	isbn = {978-145039157-3},
	language = {English},
	abbrev_source_title = {Conf Hum Fact Comput Syst Proc},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 2022 CHI Conference on Human Factors in Computing Systems, CHI 2022; Conference date: 30 April 2022 through 5 May 2022; Conference code: 179031}
}

@ARTICLE{2022,
	title = {9th International Conference on Learning and Collaboration Technologies, LCT 2022 Held as Part of the 24th HCI International Conference, HCII 2022},
	year = {2022},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {13329 LNCS},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133186190&partnerID=40&md5=aac0aba77461419752ed81facca872e8},
	abstract = {The proceedings contain 60 papers presendted at a virtual meeting. The special focus in this conference is on Learning and Collaboration Technologies. The topics include: Towards Deep Learning-Powered Chatbot for Translation Learning; an Educational, Semi-autonomous Telepresence Robot Called Sally; The Impact of Avatar Teachers on Student Learning and Engagement in a Virtual Learning Environment for Online STEM Courses; my English Teachers Are Not Human but I Like Them: Research on Virtual Teacher Self-study Learning System in K12; eduino: A Telegram Learning-Based Platform and Chatbot in Higher Education; exploring the Role of Chatbots and Messaging Applications in Higher Education: A Teacher’s Perspective; an Interactive Robot Lecture System Embedding Lecture Behavior Model; learning by Teaching Partner Robot in Collaborative Reading; Applying Natural Language Processing to Teamwork – A New Dashboard for CTMTC Methodology; Assessement of Assisted Navigation in NUI Virtual Architectural Environments; fostering Decision-Making Processes in Health Ecosystems Through Visual Analytics and Machine Learning; Agile CTMTC: Adapting Stages for a Shorter Application of the Teamwork Method; t-Game: A Team Formation Game for Enhancing Cross-Disciplinary Cooperation; virtual Team Collaboration: How the Empathy Tendency Influences User Experience?; how to Apply Bloom’s Taxonomy to Operator Education in the Way of Human-Machine Cooperation?; evaluation of Mixed Reality Technologies in Remote Teaching; design of a Virtual Reality based Pedagogical Framework; HCI Issues, Design and Development for a First Responders VR Training System on Dangerous Goods Transportation Incidents; an Approach of Holographic Technology for the Practical Distance Education; the Use of Augmented Reality to Motivate Scientific Learning for Preschool Children by Fostering Curiosity; foreword.},
	editor = {Zaphiris P. and Ioannou A.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303105674-1},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 9th International Conference on Learning and Collaboration Technologies, LCT 2022 Held as Part of the 24th HCI International Conference, HCII 2022; Conference date: 26 June 2022 through 1 July 2022; Conference code: 279419}
}

@ARTICLE{Garrity2021,
	author = {Garrity, David James and Yusuf, Syed Adnan},
	title = {A predictive decision-aid device to warn firefighters of catastrophic temperature increases using an AI-based time-series algorithm},
	year = {2021},
	journal = {Safety Science},
	volume = {138},
	doi = {10.1016/j.ssci.2021.105237},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102069833&doi=10.1016%2fj.ssci.2021.105237&partnerID=40&md5=7f7306f0298f3ec5f6cf66e94b4e991e},
	affiliations = {STS Defence Ltd, Mumby Road, Gosport, PO12 1AF, United Kingdom},
	abstract = {An experimental firefighter-wearable device exploiting an Artificial Intelligence (AI) based algorithm is described, with the purpose of pre-warning wearers of dangerous rates of temperature rise in the environment, for example ahead of flashover. This exploits a compact embedded Artificial Neural Network (ANN) with a second stage classifier, reading temperature data from the in-built thermocouple, to produce a 30 s output window of predicted temperatures, used to inform pre/full alarm states and a series of audible/visual warnings. The algorithm and device have been tested in two controlled fire behaviour training environments in both the UK and US during multiple flashovers, demonstrating the integrity of the predictions and subsequent alarm triggering in this environment, specifically, triggering an alarm 27 s ahead of flashover for a unit positioned at firefighter crouching height (0.8 m). These experiments included testing on a reference mannequin to explore the potential impact of the boundary effect on temperature measurements close to a tunic, as well as the impact of simulated firefighter movement on the output predictions and therefore alarm states. The results from subsequent testing of the devices in realistic firefighting conditions by firefighter instructors demonstrate the dynamic response of the algorithm to changing conditions equivalent to a serious domestic building fire, including the potential benefit of the precautionary ‘pre-alarm’. Finally, a snapshot of results from extended trials in an uncontrolled training environment with multiple firefighters is discussed, including early developments towards a potential concept of use including cloud-based aggregation of individual firefighter temperature exposure data. © 2021 Elsevier Ltd},
	author_keywords = {AI temperature prediction; Firefighter wearable technology},
	keywords = {Alarm systems; Decision support systems; Fire extinguishers; Fires; Neural networks; Temperature measurement; Thermocouples; Wearable technology; Well testing; Artificial intelligence temperature prediction; Condition; Decision aids; Firefighter wearable technology; Neural-networks; Temperature data; Temperature increase; Temperature rise; Time series algorithms; Wearable devices; Article; artificial intelligence; artificial neural network; Bayes theorem; controlled study; fire fighter; human; probability; simulation; temperature measurement; time series analysis; Forecasting},
	correspondence_address = {D.J. Garrity; STS Defence Ltd, Gosport, Mumby Road, PO12 1AF, United Kingdom; email: DJ_Garrity@physics.org},
	publisher = {Elsevier B.V.},
	issn = {09257535},
	coden = {SSCIE},
	language = {English},
	abbrev_source_title = {Saf. Sci.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 10}
}

@CONFERENCE{Dang2022629,
	author = {Dang, Yongchao and Benzaid, Chafika and Taleb, Tarik and Yang, Bin and Shen, Yulong},
	title = {Transfer Learning based GPS Spoofing Detection for Cellular-Connected UAVs},
	year = {2022},
	journal = {2022 International Wireless Communications and Mobile Computing, IWCMC 2022},
	pages = {629 – 634},
	doi = {10.1109/IWCMC55113.2022.9824124},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135337256&doi=10.1109%2fIWCMC55113.2022.9824124&partnerID=40&md5=2d2f9789ddde73dcbeea23f4fa147e3a},
	affiliations = {Aalto University, Espoo, Finland; University of Oulu, Oulu, Finland; Chuzhou University, Chuzhou, China; Xidian University, Xi'an, China},
	abstract = {Unmanned Aerial Vehicles (UAVs) are set to become an integral part of 5G and beyond systems with the promise of assisting cellular communications and enabling advanced applications and services, such as public safety, caching, and virtual/mixed reality-based remote inspection. However, safe and secure navigation of UAVs is a key requisite for their integration in the airspace. The GPS spoofing is one of the major security threats to remotely and autonomously controlled UAVs. In this paper, we propose a machine learning-based, mobile network-assisted UAV monitoring and control system that allows live monitoring of UAVs' locations and intelligent detection of spoofed positions. We introduce the Convolutional Neural Network (CNN) in the edge UAV Flight Controller (UFC) to locate a UAV and detect any GPS spoofing by comparing differences between the theoretical path loss computed by UFC and the corresponding path loss reported by the connected base station (BS). To reduce the detection latency as well as to increase the detection accuracy, transfer learning is leveraged to transfer the CNN knowledge between edge servers when the UAV handovers from one BS to another. The performance evaluation shows that the proposed solution can successfully detect spoofed GPS positions with an accuracy rate above 88% using only one BS. © 2022 IEEE.},
	author_keywords = {Beyond 5G; Convolutional Neural Network (CNN); GPS spoofing; Transfer Learning; Unmanned Aerial Vehicles (UAVs)},
	keywords = {5G mobile communication systems; Aircraft control; Aircraft detection; Antennas; Convolution; Convolutional neural networks; Flight control systems; Global positioning system; Knowledge management; Learning systems; Aerial vehicle; Beyond 5g; Cellulars; Convolutional neural network; Flight controllers; GPS spoofing; Path loss; Transfer learning; Unmanned aerial vehicle; Unmanned aerial vehicles (UAV)},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-166546749-0},
	language = {English},
	abbrev_source_title = {Int. Wirel. Commun. Mob. Comput., IWCMC},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; Conference name: 18th IEEE International Wireless Communications and Mobile Computing, IWCMC 2022; Conference date: 30 May 2022 through 3 June 2022; Conference code: 181067; All Open Access, Green Open Access}
}

@CONFERENCE{Sassi2022,
	author = {Sassi, Mohamed Saifeddine Hadj and Battisti, Federica and Carli, Marco},
	title = {Simulation-based Virtual Reality Training for Firefighters},
	year = {2022},
	journal = {IS and T International Symposium on Electronic Imaging Science and Technology},
	volume = {34},
	number = {10},
	doi = {10.2352/EI.2022.34.10.IPAS-194},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132360687&doi=10.2352%2fEI.2022.34.10.IPAS-194&partnerID=40&md5=04fb1b297b9c37a72f70559573a4dcb7},
	affiliations = {Department of Industrial, Electronic and Mechanical Engineering, Roma Tre University, Rome, Italy; Department of Information Engineering, University of Padova, Padova, Italy},
	abstract = {Simulation-based training is used to improve learners’ skills and enhance their knowledge. Recently, virtual reality technology has been exploited in simulation mainly for training purposes, to enable learning while performing simulated activities that are dangerous or even impossible to be simulated in the real world. In this context, we present a simulation-based firefighter training for an earthquake scenario developed in collaboration with national Italian firefighters rescue units (Italian “Istituto Superiore Antincendi”). The proposed training model is based on a virtual reality solution and foresees a novel interaction and game model developed specifically for training first-responders. The simulator environment is a head-mounted display where the learner interacts with objects and performs specific tasks. The performed test show that the use of virtual reality can improve the effectiveness of training. Indeed, trainees show a better perception of the scene which is reflected in a faster response in the real situation. The proposed training system can help the firefighter by providing adequate information on how to deal with risks. © 2022, Society for Imaging Science and Technology.},
	keywords = {E-learning; Fire extinguishers; Helmet mounted displays; Earthquake scenario; First responders; Game models; Interaction modeling; Real-world; Simulation-based training; Training model; Training purpose; Virtual reality technology; Virtual reality training; Virtual reality},
	publisher = {Society for Imaging Science and Technology},
	issn = {24701173},
	language = {English},
	abbrev_source_title = {IS T Intl. Symposium Electronic Imaging Science Technol.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: IS and T International Symposium on Electronic Imaging: 20th Image Processing: Algorithms and Systems, IPAS 2022; Conference date: 17 January 2022 through 26 January 2022; Conference code: 179954; All Open Access, Bronze Open Access, Green Open Access}
}

@ARTICLE{Koutitas202183,
	author = {Koutitas, George and Smith, Scott and Lawrence, Grayson},
	title = {Performance evaluation of AR/VR training technologies for EMS first responders},
	year = {2021},
	journal = {Virtual Reality},
	volume = {25},
	number = {1},
	pages = {83 – 94},
	doi = {10.1007/s10055-020-00436-8},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083243644&doi=10.1007%2fs10055-020-00436-8&partnerID=40&md5=019f84aeebab9be3120a1eee7cb0b451},
	affiliations = {Electrical and Computer Engineering, Texas State University, San Marcos, TX, United States; Augmented Training Systems Inc., Austin, TX, United States; Communication Design, Texas State University, San Marcos, TX, United States},
	abstract = {The first responder training sector presents crucial difficulties on adopting “future of work” online training principles because physical (muscle) memory is considered as important as cognitive memory. It is obvious that physical memory cannot be obtained by existing screen- and paper-based trainings. This paper presents a novel training framework for first responders that leverages augmented reality and virtual reality technologies. The framework incorporates novel design thinking processes that are implemented for the design of the training experiences. In addition, a qualitative and quantitative analysis of various metrics such as performance, time on task, accuracy and learning rate are developed to analyze the effectiveness of the proposed framework. A special use case of the emergency medical services called the ambulance bus is investigated and it is shown that the proposed training methodology improved the accuracy of the first responders by a factor of 46% and the speed on executing tasks by 29%. © 2020, This is a U.S. government work and its text is not subject to copyright protection in the United States; however, its text may be subject to foreign copyright protection.},
	author_keywords = {Augmented reality; Evaluation; First responders; Learning technologies; Training; Virtual reality},
	keywords = {Augmented reality; Cognitive memory; Emergency medical services; First responders; Online training; Qualitative and quantitative analysis; Training experiences; Training framework; Virtual reality technology; Emergency services},
	correspondence_address = {G. Koutitas; Electrical and Computer Engineering, Texas State University, San Marcos, United States; email: george.koutitas@txstate.edu},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {13594338},
	language = {English},
	abbrev_source_title = {Virtual Reality},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 37}
}

@ARTICLE{Shenoy202166188,
	author = {Shenoy, Meetha V. and Sridhar, Smriti and Salaka, Girish and Gupta, Anu and Gupta, Rajiv},
	title = {A Holistic Framework for Crime Prevention, Response, and Analysis with Emphasis on Women Safety Using Technology and Societal Participation},
	year = {2021},
	journal = {IEEE Access},
	volume = {9},
	pages = {66188 – 66207},
	doi = {10.1109/ACCESS.2021.3076016},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105063086&doi=10.1109%2fACCESS.2021.3076016&partnerID=40&md5=2aa6f6936ea708fc79db5b110c51daf0},
	affiliations = {Department of Electrical and Electronics Engineering, Birla Institute of Technology and Science (BITS) at Pilani, Pilani, 333031, India; Department of Civil Engineering, Birla Institute of Technology and Science (BITS) at Pilani, Pilani, 333031, India},
	abstract = {Ensuring women's safety in smart cities is a need of the hour. Even though several legal and technological steps are adopted worldwide, women's safety continues to be an international concern. Criminal records are maintained by law enforcement agencies and are most often not available to the public in an easily comprehensible form. While some wearable devices and mobile applications are available which are touted to aid in ensuring women's safety, they utilize limited societal intervention and are not very efficient in ensuring the safety of the women as and when required. Most often the crime response, crime analysis, and crime prevention schemes are not integrated, leading to gaps in ensuring women's safety. Our major contribution is in developing a holistic system encompassing the three crucial aspects, i.e crime analysis and mapping, crime prevention, and emergency response by leveraging societal participation for women safety management. This work applies the Geographic Information System (GIS) for the identification of hotspots and patterns of crime. The proposed system uses data generated from the mobile application and/or wearable gadget prototyped as a part of this work along with the criminal history records for crime response, analysis, and prevention. The system for the hotspot identification is demonstrated for the Pilani town in the Jhunjhunu district in the state of Rajasthan, India, and can be easily scaled up geographically and utilized as a safety strategy for smart cities. While the common man is provided a cost-effective solution via the developed mobile application or wearable gadget, the various components are integrated into a website for supervisory management and can be utilized by law enforcement agencies.  © 2013 IEEE.},
	author_keywords = {crime analysis; crime response; geographic information system (GIS); mobile application; Smart cities; wearable device; women safety},
	keywords = {Cost effectiveness; Mobile computing; Smart city; Wearable technology; Cost-effective solutions; Crime Prevention; Emergency response; Holistic frameworks; Law-enforcement agencies; Mobile applications; Rajasthan , India; Safety management; Crime},
	correspondence_address = {M.V. Shenoy; Department of Electrical and Electronics Engineering, Birla Institute of Technology and Science (BITS) at Pilani, Pilani, 333031, India; email: meetha.shenoy@pilani.bits-pilani.ac.in},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {21693536},
	language = {English},
	abbrev_source_title = {IEEE Access},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; All Open Access, Gold Open Access}
}

@ARTICLE{Kravari2022169,
	author = {Kravari, Kalliopi and Emmanouloudis, Dimitrios and Korka, Elena and Vlachopoulou, Aglaia},
	title = {THE CONTRIBUTION OF INFORMATION TECHNOLOGIES TO THE PROTECTION OF WORLD CULTURAL AND NATURAL HERITAGE MONUMENTS "THE CASE OF ANCIENT PHILIPPI, GREECE"},
	year = {2022},
	journal = {Scientific Culture},
	volume = {8},
	number = {3},
	pages = {169 – 178},
	doi = {10.5281/zenodo.6640266},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165924977&doi=10.5281%2fzenodo.6640266&partnerID=40&md5=d7176e88fa3d980d44540d68e606c28e},
	affiliations = {UNESCO Chair on Conservation and Ecotourism of Riparian and Deltaic Ecosystems, International Hellenic University, Greece; Hellenic Committee of the Blue Shield, 29 Archimidous Str., Athens, 116 36, Greece; International Hellenic University, Greece},
	abstract = {Natural and man-made disasters are happening more and more often, leading to hundreds of casualties and significant catastrophic consequences. Unfortunately, they are affecting not only urban centers, outdoor set-tlements, and infrastructure, but also world cultural and natural heritage sites. Many of these monuments, which are included in the UNESCO World Heritage List, are at risk due to even moderate natural or man-made hazards, given the structural vulnerability created over the course of their hundreds or even millennia of existence. In this context, for several years, the issue of the risks of World Heritage sites has been of concern to UNESCO and in particular the World Heritage Center. Following this effort, the present work aims to enrich methods and techniques with the help of advanced information technologies and in particular a combination of Artificial Intelligence (AI), Virtual and Augmented Reality, and the Internet of Things (IoT). The article presents the first steps towards a holistic and easily adaptable methodology, forming the so-called INBO (IN-DEX + BOOKLET = INBO), a novel combination of INDEX (catalogue) and IT Booklet, which will allow both monument monitoring and real-time emergency response. This methodology will improve the way in which first responders and monument managers, even visitors, react and handle the information provided. INBO will allow the right prognosis to be achieved by leading to timely and smart decisions that will help prevent potential damage to the cultural heritage. The Ancient City of Philippi will serve as a pilot study for the ap-proach. The archaeological site of Philippi, located in Northern Greece, is one of the heritage sites, listed on the UNESCO World Heritage List. © 2022 Henan University. All rights reserved.},
	author_keywords = {Artificial Intelligence; Heritage Protection; INBO; INDEX; Monuments; Risk Assessment; UNESCO},
	correspondence_address = {K. Kravari; UNESCO Chair on Conservation and Ecotourism of Riparian and Deltaic Ecosystems, International Hellenic University, Greece; email: kkravari@ihu.gr},
	publisher = {Henan University},
	issn = {24080071},
	language = {English},
	abbrev_source_title = {Sci. C.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Schmidt2022,
	author = {Schmidt, Arti},
	title = {A Comparison of Gate Detection Algorithms for Autonomous Racing Drones},
	year = {2022},
	journal = {IEEE Aerospace Conference Proceedings},
	volume = {2022-March},
	doi = {10.1109/AERO53065.2022.9843561},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137598448&doi=10.1109%2fAERO53065.2022.9843561&partnerID=40&md5=0316cfbb792e0b56cf40c7883e2ae4ef},
	affiliations = {Princeton University, PO Box 244, Emmaus, 18049, PA, United States},
	abstract = {In this paper, several algorithms for gate detection in ADR (autonomous drone racing) are compared based on accuracy and speed. These are YOLOv5 (You Only Look Once), PP-YOLO, Faster R-CNN (Region Based Convolutional Neural Network), U-Net, and Lines (an original algorithm introduced in the paper). Two variants of the first three are trained, one that detects entire gates and another that detects gate corners. Each of these produce around 99% sufficiently accurate gate center predictions in average times ranging from 20 to 60 ms per image, with YOLOv5 being the fastest overall. U-Net and Lines were generally less accurate and slower, with U-Net scoring 88.70% accuracy at 109.90 ms per image, and Lines scoring 34.64% accuracy at 67.60 ms per image. The paper is a novel contribution as it is the first to compare object detection, image segmentation, and classical computer vision methods for this task in a controlled manner. The comparison is performed across the same set of training and test data, on the same hardware, and uses a consistent scoring mechanism, yielding more correct and complete results than one based on a review of studies on the individual algorithms. Variations on the studied algorithms have been commonly used in published work on ADR, but not directly compared [1]-[3]. The original Lines algorithm serves as a representative for algorithms employing classical computer vision methods, leveraging simplicity and domain knowledge in hopes of faster speed. It combines edge and line detection with a simple heuristic to find the boundaries of a gate. The algorithms are compared in their 'out of the box' states, without modification or optimization, so that the results are generalizable and valuable for both inexperienced users and experienced users who are prototyping. The algorithms predicted the centers and corners of gates that drones navigate through in a race, where each image contained one gate. They were trained and tested using 9,300 images of real gates from the 2019 AlphaPilot Challenge ADR competition. Accuracy was measured as the distance between the labelled and predicted gate center and corner locations relative to the apparent size of the gate in the image. A threshold was chosen to consider a prediction sufficiently accurate. Speed was measured as the elapsed wall clock time for prediction on powerful desktop hardware, under the assumption that their relative prediction speed would scale to hardware onboard a drone. The results of this study could facilitate future work in ADR by providing information on the performance of various common gate detection methods. ADR itself is exciting to watch, with rewards for top teams continuing to grow, but ADR also serves as a testbed for cutting edge drone hardware and software. Its advancement will ultimately improve drone technology in the many industries that drones are finding applications, including agriculture, conservation, deliveries, film, and public safety. Additionally, the development of robust gate detection algorithms could influence other applications for object detection where performance is critical, such as in autonomous vehicles, image search, and augmented reality experiences. © 2022 IEEE.},
	keywords = {Aircraft detection; Computer vision; Forecasting; Image segmentation; Knowledge management; Object detection; Signal detection; Convolutional neural network; Detection algorithm; Domain knowledge; Images segmentations; Objects detection; Original algorithms; Performance; Region-based; Test data; Training data; Drones},
	correspondence_address = {A. Schmidt; Princeton University, Emmaus, PO Box 244, 18049, United States; email: arthurts@princeton.edu},
	publisher = {IEEE Computer Society},
	issn = {1095323X},
	isbn = {978-166543760-8},
	language = {English},
	abbrev_source_title = {IEEE Aerosp. Conf. Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2022 IEEE Aerospace Conference, AERO 2022; Conference date: 5 March 2022 through 12 March 2022; Conference code: 181782}
}

@ARTICLE{Hu2022,
	author = {Hu, Da and Chen, Long and Du, Jing and Cai, Jiannan and Li, Shuai},
	title = {Seeing through Disaster Rubble in 3D with Ground-Penetrating Radar and Interactive Augmented Reality for Urban Search and Rescue},
	year = {2022},
	journal = {Journal of Computing in Civil Engineering},
	volume = {36},
	number = {5},
	doi = {10.1061/(ASCE)CP.1943-5487.0001038},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131217525&doi=10.1061%2f%28ASCE%29CP.1943-5487.0001038&partnerID=40&md5=ab41436f8b8219565205841c3a124cf6},
	affiliations = {Dept. of Civil and Environmental Engineering, The Univ. of Tennessee, Knoxville, 37996, TN, United States; School of Architecture Building and Civil Engineering, Loughborough Univ., Loughborough, LE11 3TU, United Kingdom; Engineering School of Sustainable Infrastructure & Environment, Univ. of Florida, Gainesville, 32611, FL, United States; School of Civil and Environmental Engineering, and Construction Management, The Univ. of Texas at San Antonio, San Antonio, 78207, TX, United States; Dept. of Civil and Environmental Engineering, Affiliated Faculty with the Institute for A Secure & Sustainable Environment, The Univ. of Tennessee, Knoxville, 37996, TN, United States},
	abstract = {First responders often lack information and visual clues regarding interior spaces in disaster rubble, preventing efficient, effective, and safe search and rescue for victims trapped in collapsed structures. Rapidly detecting and acquiring information about the voids in collapsed structures that could contain surviving victims is critical for urban search and rescue. However, reconstructing the buried voids in three dimensions (3D) and communicating the relevant information such as buried depth and void size to first responders remain significant challenges. In response, this study proposes a see-through technique by integrating ground-penetrating radar (GPR) with interactive augmented reality (AR). The contribution of this study is twofold. First, a new method is developed to process collected GPR data to reconstruct potential voids in disaster rubble in 3D and extract the buried depth and void size from the GPR data. The coordinates of void boundaries are extracted from multiple GPR scans to generate sparse point clouds. An improved alpha-shape method is exploited to reconstruct the 3D space beneath disaster rubble from the point clouds. Second, an interactive augmented reality interface is developed to enable first responders to visualize the voids in collapsed structures in 3D together with relevant information to assist urban search and rescue. The results from simulations and pilot experiments demonstrate the feasibility and potential of the proposed methods.  © 2022 American Society of Civil Engineers.},
	author_keywords = {Augmented reality (AR); Disaster; Ground penetrating radar (GPR); Subsurface reconstruction; Urban search and rescue},
	keywords = {Augmented reality; Disaster prevention; Geological surveys; Geophysical prospecting; Ground penetrating radar systems; Image reconstruction; Radar imaging; Augmented reality; Buried depth; Collapsed structures; First responders; Ground penetrating radar; Radar data; Subsurface reconstruction; Urban search and rescue; Void size; Disasters},
	correspondence_address = {S. Li; Dept. of Civil and Environmental Engineering, Affiliated Faculty with the Institute for A Secure & Sustainable Environment, The Univ. of Tennessee, Knoxville, 37996, United States; email: sli48@utk.edu},
	publisher = {American Society of Civil Engineers (ASCE)},
	issn = {08873801},
	coden = {JCCEE},
	language = {English},
	abbrev_source_title = {J. Comput. Civ. Eng.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6}
}

@CONFERENCE{Monaco2021,
	author = {Monaco, Federico and Eremchenko, Eugene and Del Mastro, Antonio and Nelson, Anna and Salmeri, Antonino},
	title = {Simulating Gagarin’s gaze: the charm of a digital Earth for a sustainable planet},
	year = {2021},
	journal = {Proceedings of the International Astronautical Congress, IAC},
	volume = {B1},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127810581&partnerID=40&md5=389281c57fdb45f3aa2fd4c8cbf75243},
	affiliations = {Department of Medicine and Surgery, University of Parma, 43126, Italy; Neogeography R&D Group, Lomonosov Moscow State University, Russian Federation; Marsplanet, BG, Curno, Italy; Marsplanet, Limerick, Ireland; Université du Luxembourg, Luxembourg},
	abstract = {The first space flight made 60 years ago was certainly a pivotal moment in humankind's history. It was not just a matter of new knowledge; the direct and holistic experience of space is no less important than its scientific and technological visions and incorporates them. Since Gagarin’s visual experience as the first man in space, and for all the following astronauts in orbit and beyond, what distinguishes them from the rest of humankind is a shared experience that has been described as a shift in perspective, to seeing earth and all its inhabitants as a whole. Astronauts report the experience of seeing the beauty of nature, of all of Mother Earth at once in orbit as profound. At the beginning of the Space Era, the holistic vision of Earth deeply rooted in the history of humankind, was the prerogative of cosmonauts and astronauts alone, but not anymore. This experience was shared widely due to the environmental initiatives of Al Gore, who proposed and justified the concept of the Digital Earth as a radically new perspective, providing full geocentric situational awareness through the seamless integration of geocentric context beyond the hierarchies imposed by the maps and their distorted scale-bound division of geodata. The Digital Earth project aims to work at the cutting edge of developments in geography, natural sciences and information technology to provide a simulated, enhanced and updated digital twin of Earth. Full of beauty, but also information. The goal of recreating Gagarin's gaze, in the year celebrating the 60th anniversary of the first man in space, is achieved by sharing the visual experiences of astronauts for a simulation of Earth with different scenarios to be experienced in VR or by PCs and smartphones. This use of VR/AR would increase the popularity and impact of space exploration and DE applications: Earth-orbiting satellites, ground-based observations, and other technologies for collecting, analyzing and visualizing data about global phenomena, such as climate sciences and modeling, health emergencies and scenarios about alternative futures, environmental and cultural heritage, and sustainability. In particular, applications for Digital Health Earth (DHE) involving global and local visualization of health and environmental data would fulfill and interoperate with existing monitoring systems concerned with environmental and public safety. Public health policies, but also political discourse would benefit from such a gaze on real time situations at regional, national and worldwide level. Copyright © 2021 by the International Astronautical Federation (IAF). All rights reserved.},
	author_keywords = {Digital Earth; Digital twin; Ecology; Simulation; Sustainability},
	keywords = {Data visualization; Environmental technology; Health; Manned space flight; Orbits; Space research; Sustainable development; Charm+; Digital Earth; Environmental initiatives; Holistic visions; In-orbit; Seamless integration; Shared experiences; Simulation; Situational awareness; Visual experiences; Earth (planet)},
	correspondence_address = {F. Monaco; Department of Medicine and Surgery, University of Parma, 43126, Italy; email: federico.monaco@unipr.it},
	publisher = {International Astronautical Federation, IAF},
	issn = {00741795},
	isbn = {978-171384301-6},
	language = {English},
	abbrev_source_title = {Proc. Int. Astronaut. Congr., IAC},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: IAF Earth Observation Symposium 2021 at the 72nd International Astronautical Congress, IAC 2021; Conference date: 25 October 2021 through 29 October 2021; Conference code: 177580}
}

@ARTICLE{Ek2023,
	author = {Ek, Alfieri and Drawve, Grant and Robinson, Samantha and Datta, Jyotishka},
	title = {Quantifying the Effect of Socio-Economic Predictors and the Built Environment on Mental Health Events in Little Rock, AR},
	year = {2023},
	journal = {ISPRS International Journal of Geo-Information},
	volume = {12},
	number = {5},
	doi = {10.3390/ijgi12050205},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160287884&doi=10.3390%2fijgi12050205&partnerID=40&md5=07826201c15d47bc47ce1422fbede67f},
	affiliations = {Department of Mathematical Sciences, University of Arkansas, Fayetteville, 72701, AR, United States; Department of Sociology and Criminology, University of Arkansas, Fayetteville, 72701, AR, United States; Department of Statistics, Virginia Polytechnic Institute and State University, Blacksburg, 24061, VA, United States},
	abstract = {Law enforcement agencies continue to grow in the use of spatial analysis to assist in identifying patterns of outcomes. Despite the critical nature of proper resource allocation for mental health incidents, there has been little progress in statistical modeling of the geo-spatial nature of mental health events in Little Rock, Arkansas. In this article, we provide insights into the spatial nature of mental health data from Little Rock, Arkansas between 2015 and 2018, under a supervised spatial modeling framework. We provide evidence of spatial clustering and identify the important features influencing such heterogeneity via a spatially informed hierarchy of generalized linear, tree-based, and spatial regression models, viz. the Poisson regression model, the random forest model, the spatial Durbin error model, and the Manski model. The insights obtained from these different models are presented here along with their relative predictive performances. The inferential tools developed here can be used in a broad variety of spatial modeling contexts and have the potential to aid both law enforcement agencies and the city in properly allocating resources. We were able to identify several built-environment and socio-demographic measures related to mental health calls while noting that the results indicated that there are unmeasured factors that contribute to the number of events. © 2023 by the authors.},
	author_keywords = {calls for service; crime analysis; spatial modeling},
	correspondence_address = {G. Drawve; Department of Sociology and Criminology, University of Arkansas, Fayetteville, 72701, United States; email: drawve@uark.edu},
	publisher = {MDPI},
	issn = {22209964},
	language = {English},
	abbrev_source_title = {ISPRS Int. J. Geo-Inf.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Nguyen2021,
	author = {Nguyen, Dung T. and Guzik, Keith and Ramirez, Ronald and Tong, Tony W. and Sesay, Abdul},
	title = {The impact of body-worn cameras on routines and performance in police organization},
	year = {2021},
	journal = {International Conference on Information Systems, ICIS 2020 - Making Digital Inclusive: Blending the Local and the Global},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103448285&partnerID=40&md5=581291e59201e5b203b70bb32785bd8d},
	affiliations = {University of Colorado Denver, Denver, 80202, CO, United States; University of Colorado, Boulder Denver, 80309, CO, United States; University of Georgia, Athens, 30602, GA, United States},
	abstract = {Since 2010, US police departments have widely adopted Body-worn cameras (BWC), most research on BWCs has focused on the impacts of BWCs on stakeholders' perceptions and behavioral changes. Less explored, however, is the impact of BWCs upon policing routines which affect performances of police departments. To address this research gap, we identify BWCs' affordances as its technological capabilities and examine how the affordances reconfigure routines in police organizations and how the reconfigured routines affect performances of US police departments. In practice, our study contributes to the IS academy by providing general insight on the affordances of wearable technology on organizations with the cases of BWC implementation in U.S. police departments. In theory, our study quantitatively confirms the validity of qualitative research on affordance theory, which claims that technological affordance is important in reconfiguring organizational routines that affect organizational performance. © ICIS 2020. All rights reserved.},
	author_keywords = {Affordance theory; Body-worn camera; Police department; Routines},
	keywords = {Blending; Cameras; Information systems; Information use; Wearable technology; Affordance theories; Affordances; Behavioral changes; Organizational performance; Qualitative research; Technological capability; Law enforcement},
	publisher = {Association for Information Systems},
	isbn = {978-173363255-3},
	language = {English},
	abbrev_source_title = {Int. Conf. Inf. Syst., ICIS - Mak. Digit. Incl.: Blending Local Glob.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2020 International Conference on Information Systems - Making Digital Inclusive: Blending the Local and the Global, ICIS 2020; Conference date: 13 December 2020 through 16 December 2020; Conference code: 167844}
}

@ARTICLE{Volodina2021172,
	author = {Volodina, Svetlana Igorevna and Gavrilov, Sergey Nikolaevich and Lipen, Nikita Sergeevich},
	title = {DEVELOPMENT OF ELECTRONIC INTERACTION AND DOCUMENT FLOW: TRANSFORMATION OF THE LEGAL PROFESSION UNDER THE INFLUENCE OF THE INFORMATION SYSTEM; [DESENVOLVIMENTO DA COMUNICAÇÃO ELETRÔNICA E GESTÃO DE DOCUMENTOS: A TRANSFORMAÇÃO DA PROFISSÃO JURÍDICA SOB A INFLUÊNCIA DO SISTEMA DE INFORMAÇÃO]},
	year = {2021},
	journal = {Relacoes Internacionais no Mundo Atual},
	volume = {3},
	number = {32},
	pages = {172 – 185},
	doi = {10.21902/Revrima.v3i32.5639},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129645799&doi=10.21902%2fRevrima.v3i32.5639&partnerID=40&md5=78743d7d377577f784a1082344b24d5b},
	affiliations = {Kutafin Moscow State Law University-Russia, Federal Chamber of Lawyers of the Russian Federation, Russian Federation; Center for the Implementation and Operation of the Integrated Information System of the Russian Bar (IOC CIS AR)-Russia, Federal Chamber of Lawyers of the Russian Federation, Russian Federation; Kutafin Moscow State Law University, Russian Federation},
	abstract = {Objective: The article is devoted to certain aspects of the digital transformation of the Russian Bar. The driver of this transformation is the development, implementation, and operation of the complex information system of the Russian Bar. Methods: The article gives a general description of the complex information system of the Russian Bar and identifies its main tasks. Results: The authors note that the complex information system of the Russian Bar, by its purpose and role, should become not only the core of the information (digital) ecosystem of the Russian Bar but also part of the ecosystem of the country's digital economy, which is ensured by integration with the information systems of justice, courts, law enforcement, and other state bodies. Conclusion: The article defines the information (digital) ecosystem of the legal profession, identifies the main tasks of the complex information system of the Russian Bar, and presents a list of functions that should be implemented in individual segments of the complex information system of the Russian Bar through appropriate information services. © 2021, Centro Universitario Curitiba - UNICURITIBA. All rights reserved.},
	author_keywords = {CIS AR; The digital ecosystem of the Bar; Unified digital environment of the Bar},
	publisher = {Centro Universitario Curitiba - UNICURITIBA},
	issn = {23162880},
	language = {English},
	abbrev_source_title = {Rela . Int. Mundo Atual},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Gandotra2021397,
	author = {Gandotra, Pimmy and Bhatia, Vimal and Lall, Brejesh},
	title = {Broadcast in 5G wireless communication networks and beyond: An overview of public safety communications},
	year = {2021},
	journal = {2021 11th International Workshop on Computer Science and Engineering, WCSE 2021},
	pages = {397 – 402},
	doi = {10.18178/wcse.2021.02.001},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114207218&doi=10.18178%2fwcse.2021.02.001&partnerID=40&md5=335cf1016e4e1b1f73f29e2b55eb7c03},
	affiliations = {Indian Institute of Technology, Delhi, India; Indian Institute of Technology, Indore, India},
	abstract = {The objective of this paper is to cover the present and future scope of the public safety communication, which targets timely and accurate delivery of critical information. The evolution of these services over the generations of wireless communication networks (WCNs) has been discussed in this paper. The basic broadcasting mechanism, for the dissemination of essential information during emergency and lockdown has been described, followed by the supporting architectures for information broadcasting. The role of various technologies of the 5G WCNs, and beyond, in improving the efficiency of the functioning of these networks has been stated. The technologies include spectrum sharing, network slicing, software defined networking (SDN), augmented reality (AR) and virtual reality (VR). A seamless integration of these technologies can help in achieving high efficiency, optimal resource and power availability. Challenges in executing these are also discussed. © 2021 11th International Workshop on Computer Science and Engineering, WCSE 2021. All Rights Reserved.},
	author_keywords = {5G and beyond 5G; AR; Broadcast; IoT; Public warning; SDN; Spectrum sharing; VR},
	keywords = {Augmented reality; Efficiency; Safety engineering; Broadcasting mechanism; Information broadcasting; Public safety communications; Seamless integration; Software defined networking (SDN); Spectrum sharing; Various technologies; Wireless communication network; 5G mobile communication systems},
	correspondence_address = {P. Gandotra; Indian Institute of Technology, Delhi, India; email: pimmy.gandotra@gmail.com},
	publisher = {International Workshop on Computer Science and Engineering (WCSE)},
	isbn = {978-981181791-5},
	language = {English},
	abbrev_source_title = {Int. Workshop Comput. Sci. Eng., WCSE},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2021 11th International Workshop on Computer Science and Engineering, WCSE 2021; Conference date: 19 June 2021 through 21 June 2021; Conference code: 171371; All Open Access, Bronze Open Access}
}

@ARTICLE{Papakostas2021,
	author = {Papakostas, Christos and Troussas, Christos and Krouska, Akrivi and Sgouropoulou, Cleo},
	title = {Measuring user experience, usability and interactivity of a personalized mobile augmented reality training system},
	year = {2021},
	journal = {Sensors},
	volume = {21},
	number = {11},
	doi = {10.3390/s21113888},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107223310&doi=10.3390%2fs21113888&partnerID=40&md5=c4ea3d7aa639d2d96433ea0bc9f37902},
	affiliations = {Department of Informatics and Computer Engineering, University of West Attica, Athens, 12243, Greece},
	abstract = {Innovative technology has been an important part of firefighting, as it advances firefighters’ safety and effectiveness. Prior research has examined the implementation of training systems using augmented reality (AR) in other domains, such as welding, aviation, army, and mathematics, offering significant pedagogical affordances. Nevertheless, firefighting training systems using AR are still an under-researched area. The increasing penetration of AR for training is the driving force behind this study, and the scope is to analyze the main aspects affecting the acceptance of AR by firefighters. The current research uses a technology acceptance model, extended by the external constructs of perceived interactivity and personalization, to consider both the system and individual level. The proposed model was evaluated by a sample of 200 users, and the results show that both the external variables of perceived interactivity and perceived personalization are prerequisite factors in extending the TAM model. The findings reveal that the usability is the strongest predictor of firefighters’ behavioral intentions to use the AR system, followed by the ease of use with smaller, yet meaningful, direct and indirect effects on firefighters’ intentions. The identified acceptance factors help AR developers enhance the firefighters’ experience in training operations. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.},
	author_keywords = {Augmented reality; Factor analysis; Firefighting training; Regression analysis; Technology acceptance model (TAM); Usability; User experience},
	keywords = {Augmented Reality; Firefighters; Humans; Intention; Augmented reality; Fire extinguishers; Fires; Behavioral intention; Indirect effects; Individual levels; Innovative technology; Mobile augmented reality; Personalizations; Technology acceptance model; Training operations; behavior; fire fighter; human; User experience},
	correspondence_address = {C. Troussas; Department of Informatics and Computer Engineering, University of West Attica, Athens, 12243, Greece; email: ctrouss@uniwa.gr},
	publisher = {MDPI AG},
	issn = {14248220},
	pmid = {34199918},
	language = {English},
	abbrev_source_title = {Sensors},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 37; All Open Access, Green Open Access}
}

@CONFERENCE{O'Connor20233132,
	author = {O'Connor, Laurel and Zamani, Sepahrad and Porter, Liam and McGeorge, Nicolette and Latiff, Susan and Boardman, Timothy and Loconte, Matthew and Weiner, Michael and McGarry, Eileen and Pina, Felipe and Hermaan, Jorge Acevedo and Milsten, Andrew and Reznek, Martin and Broach, John},
	title = {Augmented Reality Technology to Facilitate Proficiency in Emergency Medical Procedures},
	year = {2023},
	journal = {Proceedings of the Annual Hawaii International Conference on System Sciences},
	volume = {2023-January},
	pages = {3132 – 3140},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152119931&partnerID=40&md5=ca4c52751153cf633c29ffd2baa28317},
	affiliations = {University of Massachusetts, United States; Hialeah Hospital, United States; Charles River Analytics, United States},
	abstract = {Background: Augmented reality (AR) conveys an experience during which the user's real-time environment is enhanced by computer-generated perceptual information; it is being investigated as a solution to enhance medical education and clinical practice. There is little literature on its utility for teaching emergency procedures. Methods: A within-subjects trial was performed comparing traditional training to AR guidance for two emergency procedures. Lay-subjects and emergency medical technicians received video training and AR guidance for performing bag-valve-mask ventilation and needle-decompression. Subjects performed both procedures in a simulation setting after each training modality. Subject performance, acceptability and usability were analyzed. Results: There was no difference in procedural performance between lay or EMT subjects for AR training, and no difference in subject-reported usefulness between the AR and control training. Conclusion: AR mediated guidance for emergency medical procedures is feasible and efficacious. Subject performance after AR training was statistically undistinguishable from a didactic educational modality. © 2023 IEEE Computer Society. All rights reserved.},
	author_keywords = {Augmented Reality; Education; Emergency Medicine; Healthcare},
	keywords = {Medical education; Medicine; Augmented reality technology; Computer generated; Education practices; Emergency medicine; Emergency procedures; Healthcare; Medical procedures; Perceptual information; Performance; Real-time environment; Augmented reality},
	editor = {Bui T.X.},
	publisher = {IEEE Computer Society},
	issn = {15301605},
	isbn = {978-099813316-4},
	language = {English},
	abbrev_source_title = {Proc. Annu. Hawaii Int. Conf. Syst. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 56th Annual Hawaii International Conference on System Sciences, HICSS 2023; Conference date: 3 January 2023 through 6 January 2023; Conference code: 187535}
}

@CONFERENCE{Grandi202123,
	author = {Grandi, Jeronimo G and Cao, Zekun and Ogren, Mark and Kopper, Regis},
	title = {Design and simulation of next-generation augmented reality user interfaces in virtual reality},
	year = {2021},
	journal = {Proceedings - 2021 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops, VRW 2021},
	pages = {23 – 29},
	doi = {10.1109/VRW52623.2021.00011},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105966767&doi=10.1109%2fVRW52623.2021.00011&partnerID=40&md5=20a6174b1433e69010126446a3248507},
	affiliations = {University of North Carolina at Greensboro, Dept. of Computer Science; Duke University, Dept. of Mechanical Engineering and Materials Science; Duke University, Pratt School of Engineering},
	abstract = {We present a methodology for the simulation of next-generation Augmented Reality (AR) User Interfaces (UIs) within immersive Virtual Reality (VR). We use a user-centered model to support design decisions for specialized operations in high stakes fields, and present augmented reality user interface designs for two use cases in public safety: a law enforcement traffic stop and a firefighting search and rescue scenario. By utilizing VR to simulate AR, we can design and evaluate the benefits of idealized UIs that are unencumbered by hardware limitations. We discuss the trade-offs of Virtual Reality as a medium for simulation and training of next-generation Augmented Reality User Interfaces. © 2021 IEEE.},
	author_keywords = {Human computer interaction (HCI); Human-centered computing; Interaction paradigms; Mixed / augmented reality; Virtual reality},
	keywords = {Abstracting; Augmented reality; Economic and social effects; User centered design; Virtual reality; Design and simulation; Immersive virtual reality; Public safety; Search and rescue; Simulation and training; Support design; User interface designs; User-centered modeling; User interfaces},
	correspondence_address = {J.G. Grandi; University of North Carolina at Greensboro, Dept. of Computer Science; email: jggrandi@uncg.edu},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-073811367-8},
	language = {English},
	abbrev_source_title = {Proc. - IEEE Conf. Virtual Real. 3D User Interfaces Abstr. Workshops, VRW},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 10; Conference name: 2021 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops, VRW 2021; Conference date: 27 March 2021 through 3 April 2021; Conference code: 168770}
}

@ARTICLE{Jakob202111,
	author = {Jakob, Dominik A. and Minneti, Michael and Benjamin, Elizabeth R. and Lam, Lydia and Schellenberg, Morgan and Matsushima, Kazuhide and Demetriades, Demetrios and Inaba, Kenji},
	title = {Practical assessment of different saw types for field amputation: A cadaver-based study},
	year = {2021},
	journal = {American Journal of Emergency Medicine},
	volume = {45},
	pages = {11 – 16},
	doi = {10.1016/j.ajem.2021.02.034},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101554421&doi=10.1016%2fj.ajem.2021.02.034&partnerID=40&md5=28e283cd736f58ca51a01789407980b2},
	affiliations = {Division of Trauma and Surgical Critical Care, Department of Surgery, Los Angeles County + University of Southern California Medical Center, University of Southern California, Los Angeles, 90033, CA, United States},
	abstract = {Introduction: Field amputation can be life-saving for entrapped patients requiring surgical extrication. Under these austere conditions, the procedure must be performed as rapidly as possible with limited equipment, often in a confined space, while minimizing provider risk. The aim of this study was to determine the ideal saw, and optimal approach, through bone or joint, for a field amputation. Methods: This was a prospective cadaver-based study. Four saws (Gigli, manual pruning, electric oscillating and electric reciprocating) were tested in human cadavers. Each saw was used to transect four separate long bones (humerus, ulna/radius, femur and tibia/fibula), previously exposed at a standardized location. The time required for each saw to cut through the bone, the number of attempts required to seat the saw when transecting the bone, slippage, quality of proximal bone cut and extent of body fluid splatter as well as the physical space required by each device during the amputation were recorded. Additionally, the most effective saw in the through bone assessment was compared to limb amputation using scalpel and scissors for a through joint amputation at the elbow, wrist, knee and ankle. Univariate analysis was used to compare the outcomes between the different saws. Results: The fastest saw for the through bone amputation was the reciprocating followed by oscillating (2.1 [1.4–3.7] seconds vs 3.0 [1.6–4.9] seconds). The manual pruning (58.8 [25–121] seconds) was the slowest (p = 0.007). Overall, the oscillating saw was superior or equivalent to the other devices in number of attempts (1), slippage (0), quality of bone cut (100% good) and physical space requirements (4500 cm3), and was the second fastest. In comparison, a through joint amputation (125.0 [50–147] seconds for scalpel and scissor; 125.5 [86–217] seconds for the oscillating saw) was significantly slower than through bone with the Gigli (p = 0.029), the oscillating (p = 0.029) and the reciprocal saw (p = 0.029). Conclusions: The speed, precision, safety, space required, as well as the adjustable blade of the oscillating saw make it ideal for a field amputation. A Gigli saw is an excellent backup for when electrical tools cannot be used. Through bone amputation is faster than a through joint amputation. © 2021},
	author_keywords = {Emergency; Field amputation; Pre-hospital care; Saw type},
	keywords = {Amputation; Animals; Cadaver; Emergency Medical Services; Equipment Design; Ergonomics; Humans; Prospective Studies; Surgical Instruments; Swine; accuracy; adult; aged; amputation; arm amputation; Article; body fluid; bone examination; cadaver; controlled study; female; femur; fibula; field amputation; foot amputation; hand amputation; human; human tissue; humerus; knee amputation; limb amputation; male; operation duration; outcome assessment; patient safety; prospective study; radius; surgical approach; tibia; ulna; amputation; animal; comparative study; devices; emergency health service; equipment design; ergonomics; pig; surgical equipment},
	correspondence_address = {K. Inaba; LAC + USC Medical Center, University of Southern California, Los Angeles, 2051 Marengo Street, IPT, CSL 100, 90033, United States; email: Kenji.Inaba@med.usc.edu},
	publisher = {W.B. Saunders},
	issn = {07356757},
	coden = {AJEME},
	pmid = {33647756},
	language = {English},
	abbrev_source_title = {Am. J. Emerg. Med.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Douklias202137,
	author = {Douklias, Athanasios and Krommyda, Maria and Amditis, Angelos},
	title = {Resilient Communications for the First Responders at the Field},
	year = {2021},
	journal = {Proceedings - 2021 Asia-Pacific Conference on Communications Technology and Computer Science, ACCTCS 2021},
	pages = {37 – 42},
	doi = {10.1109/ACCTCS52002.2021.00016},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105403098&doi=10.1109%2fACCTCS52002.2021.00016&partnerID=40&md5=528cb927f68824d60efef3fcb64a0a80},
	affiliations = {ICCS, Athens, Greece},
	abstract = {Rescue operations in both small-scale emergencies and major natural or man-made disasters are very challenging. The first responders are requested to explore unknown and potentially hazardous environments, risking their own well-being in order to save others. New innovative technologies are essential to support the first responders in their tasks, ensuring their safety and the effectiveness of their operations. These technologies, that may include wearable devices, automated vehicles and drones or back-end services require communications in order to operate in full capacity. Available infrastructure often fails in cases of emergency, while some operational environments may not even support them to begin with. Aiming to alleviate this barrier, a resilient, field deployable system, that can support the communication between all the equipment deployed at the field and multiple backhaul networks is presented here. The design of the communications, the hardware solutions that support the design as well as the selected configurations are discussed in detail.  © 2021 IEEE.},
	author_keywords = {backhaul networks; emergency response; field communications; field operations; first responders; operational environment; resilience; system design},
	keywords = {Computer science; Computers; Automated vehicles; Deployable systems; Hardware solutions; Hazardous environment; Innovative technology; Man-made disasters; Operational environments; Resilient communications; Wearable technology},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-166541538-5},
	language = {English},
	abbrev_source_title = {Proc. - Asia-Pacific Conf. Commun. Technol. Comput. Sci., ACCTCS},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: 2021 Asia-Pacific Conference on Communications Technology and Computer Science, ACCTCS 2021; Conference date: 22 January 2021 through 24 January 2021; Conference code: 168652; All Open Access, Green Open Access}
}

@CONFERENCE{Grigoriou2022,
	author = {Grigoriou, Elisavet and Fountoulakis, Manolis and Kafetzakis, Emmanouil and Giannoulakis, Ioannis and Fountoukidis, Eleftherios and Karypidis, Paris Alexandros and Margounakis, Dimitrios and Mikelidou, Cleo Varianou and Sennekis, Iasonas and Boustras, George},
	title = {Towards the RESPOND-A initiative: Next-generation equipment tools and mission-critical strategies for First Responders},
	year = {2022},
	journal = {2022 IEEE International Conference on Omni-Layer Intelligent Systems, COINS 2022},
	doi = {10.1109/COINS54846.2022.9854967},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138009204&doi=10.1109%2fCOINS54846.2022.9854967&partnerID=40&md5=89d3d432386f0d97563ed41a97bfe3d5},
	affiliations = {Sidroco Holdings Ltd, Nicosia, Cyprus; Eight Bells Ltd, Athens, Greece; European University Cyprus, CeRiDeS, Nicosia, Cyprus},
	abstract = {First Responders (FRs) must access reliable and flexible information management systems that provide better Situational Awareness and a better Common Operational Picture as climate change, and industrial accidents become more severe. Using network-enabled tools and novel equipment, the RespondA platform aims to provide FRs with instant access to technical breakthroughs while also continuously assessing security risks. Pre-disaster planning, on-scene planning, and post-disaster planning may all be achieved in this fashion, allowing FRs to plan for many layers of safety at all stages of the crisis lifecycle.  © 2022 IEEE.},
	author_keywords = {5G; augmented reality; communication; first responder; iot; risk; sensors; uav; virtual reality},
	keywords = {5G mobile communication systems; Augmented reality; Climate change; Disaster prevention; Disasters; Industrial hygiene; Information management; Internet of things; Life cycle; Virtual reality; 5g; Common operational picture; First responders; Generation equipment; Industrial accident; Information management systems; Iot; Mission critical; Situational awareness; Uav; Risk assessment},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-166548356-8},
	language = {English},
	abbrev_source_title = {IEEE Int. Conf. Omni-Layer Intell. Syst., COINS},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2022 IEEE International Conference on Omni-Layer Intelligent Systems, COINS 2022; Conference date: 1 August 2022 through 3 August 2022; Conference code: 182194}
}

@ARTICLE{Saikia20231,
	author = {Saikia, Manob Jyoti},
	title = {K-means Clustering Machine Learning Approach Reveals Groups of Homogeneous Individuals with Unique Brain Activation, Task, and Performance Dynamics using fNIRS},
	year = {2023},
	journal = {IEEE Transactions on Neural Systems and Rehabilitation Engineering},
	pages = {1–1},
	doi = {10.1109/TNSRE.2023.3278268},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161053743&doi=10.1109%2fTNSRE.2023.3278268&partnerID=40&md5=b94faa4877deacbc4e73e2ba5bdeeb59},
	affiliations = {Soldier and Small Unit Ambulatory Virtual Environments Laboratory, Center for Applied Brain and Cognitive Sciences, Medford, MA, USA},
	abstract = {Wearable functional near-infrared spectroscopy (fNIRS) for measuring brain function, in terms of hemodynamic responses, is pervading our everyday life and holds the potential to reliably classify cognitive load in a naturalistic environment. However, human&#x2019;s brain hemodynamic response, behavior, and cognitive and task performance vary, even within and across homogeneous individuals (with same training and skill sets), which limits the reliability of any predictive model for human. In the context of high-stakes tasks, such as in military and first-responder operations, the real-time monitoring of cognitive functions and relating it to the ongoing task, performance outcomes, and behavioral dynamics of the personnel and teams is invaluable. In this work, a portable wearable fNIRS system (WearLight) developed by the author was upgraded, and an experimental protocol was designed to image the prefrontal cortex (PFC) area of the brain of 25 healthy homogeneous participants in a naturalistic environment while participants performed n-back working memory (WM) tasks with four difficulty levels. The raw fNIRS signals were processed using a signal processing pipeline to derive the brain&#x2019;s hemodynamic responses. An unsupervised k-means machine learning (ML) clustering approach, utilizing the task-induced hemodynamic responses as input variables, suggested three unique participant groups. Task performance in terms of % correct, % missing, reaction time, inverse efficiency score (IES), and a proposed IES was extensively evaluated for each participant and the three groups. Results showed that, on average, brain hemodynamic response increased, whereas task performance degraded, with increasing WM load. However, the regression and correlation analysis of WM task, performance, and the brain&#x2019;s hemodynamic responses (TPH) revealed&#x00A0;interesting hidden characteristics and the variation in the TPH relationship between groups. The proposed IES also served as a better scoring method that had distinct score ranges for different load levels as opposed to the overlapping scores of the traditional IES method. Results showed that the k-means clustering has the potential to find groups of individuals in an unsupervised manner using the brain&#x2019;s hemodynamic responses and to study the underlying relationship between the TPH in groups. Using the method presented in this paper,&#x00A0;real-time monitoring of cognitive and task performance of soldiers, and preferentially forming small units to accomplish tasks based on the insights and goals may be helpful. The results showed that WearLight can image PFC, and this study also suggests future directions for the multi-modal body sensor network (BSN) combining advanced ML algorithms for real-time state classification, cognitive and physical performance prediction, and the mitigation of performance degradation in the high-stakes environment. Author},
	author_keywords = {Brain imaging; clustering; cognitive load; Detectors; fNIRS; Functional near-infrared spectroscopy; Hemodynamics; k-means; machine learning; military; performance; Protocols; Real-time systems; Software; soldiers; Task analysis; unsupervised; working memory},
	keywords = {Cluster Analysis; Humans; Machine Learning; Prefrontal Cortex; Reproducibility of Results; Spectroscopy, Near-Infrared; Activation analysis; Brain; Brain mapping; Cognitive systems; Hemodynamics; Infrared devices; Interactive computer systems; Inverse problems; Job analysis; Near infrared spectroscopy; Personnel training; Wearable technology; Brain imaging; Clusterings; Cognitive loads; Functional near infrared spectroscopy; Haemodynamics; K-means; Machine-learning; Military; Performance; Real - Time system; Software; Soldier; Task analysis; Unsupervised; Working memory; cluster analysis; human; machine learning; near infrared spectroscopy; physiology; prefrontal cortex; procedures; reproducibility; Real time systems},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {15344320},
	coden = {ITNSB},
	pmid = {37216239},
	language = {English},
	abbrev_source_title = {IEEE Trans. Neural Syst. Rehabil. Eng.},
	type = {Article},
	publication_stage = {Article in press},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Lessi202162,
	author = {Lessi, Christina C. and Chochliouros, Ioannis P. and Trakadas, Panagiotis and Karkazis, Panagiotis},
	title = {Advanced First Responders’ Services by Using FASTER Project Architectural Solution},
	year = {2021},
	journal = {IFIP Advances in Information and Communication Technology},
	volume = {628},
	pages = {62 – 70},
	doi = {10.1007/978-3-030-79157-5_6},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112667714&doi=10.1007%2f978-3-030-79157-5_6&partnerID=40&md5=61cad868b8dc45e7869aa2c8405cb6e7},
	affiliations = {Hellenic Telecommunications Organization (OTE) S.A., 99 Kifissias Avenue, Maroussi, Athens, 15124, Greece; Synelixis Solutions S.A., 157 Perissou and Chalkidos, Athens, 14343, Greece},
	abstract = {As the 5G technologies start to become a reality in telecommunication networks, more services and applications are designed to take advantage of the new features that 5G technology is offering. Additionally, several vertical sectors are using advanced applications in order to improve their performances. One important vertical is the Mission Critical Services (MCS) sector, which could significantly exploit 5G networks. When an emergency event occurs, such as a strong earthquake or a flood, the network traffic is proved to be rapidly increased. At the same time, the first responders need all the available resources in order to offer their services efficiently. In a situation like the one described which is extremely demanding and the available resources should be used as a priority by the first responders, the existing 4G network does not seem to be sufficient. It must be ensured that the first responders could be interconnected in a reliable network, which will provide a low latency and ultra-high throughput transmission being able to support all the advanced equipment and devices (UAVs, robots, AMRs, augmented reality and virtual reality glasses, etc.) that the first responders need. These requirements are satisfied by 5G networks. The 5G network architecture has been designed and implemented based on a new approach. The 5G network architecture that was designed and implemented for the needs of FASTER project and the advantages that this architecture offers to the first responders is presented in this paper. © 2021, IFIP International Federation for Information Processing.},
	author_keywords = {5G; First responders; Network Functions Virtualization (NFV); Network portability; Network softwarisation; Non-standalone 5G architecture; Small cell (SC); Virtual network function (VNF)},
	keywords = {4G mobile communication systems; Artificial intelligence; Augmented reality; Biomedical engineering; Energy efficiency; Network architecture; Queueing networks; Service industry; Telecommunication services; Advanced applications; Advanced equipment; Architectural solutions; Emergency events; First responders; Reliable Networks; Services and applications; Strong earthquakes; 5G mobile communication systems},
	correspondence_address = {C.C. Lessi; Hellenic Telecommunications Organization (OTE) S.A., Maroussi, Athens, 99 Kifissias Avenue, 15124, Greece; email: clessi@oteresearch.gr},
	editor = {Maglogiannis I. and Macintyre J. and Iliadis L.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {18684238},
	isbn = {978-303079156-8},
	language = {English},
	abbrev_source_title = {IFIP Advances in Information and Communication Technology},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 17th IFIP WG 12.5 International Conference on Artificial Intelligence Applications and Innovations, AIAI 2021, 6th Workshop on 5G-Putting Intelligence to the Network Edge, 5G-PINE 2021, Artificial Intelligence in Biomedical Engineering and Informatics Workshop, AI-BIO 2021, Workshop on Defense Applications of AI, DAAI 2021, Distributed AI for Resource-Constrained Platforms Workshop, DARE 2021, Energy Efficiency and Artificial Intelligence Workshop, EEAI 2021, and 10th Mining Humanistic Data Workshop, MHDW 2021; Conference date: 25 June 2021 through 27 June 2021; Conference code: 261789}
}

@ARTICLE{2021,
	title = {AHFE Conferences on Neuroergonomics and Cognitive Engineering, Industrial Cognitive Ergonomics and Engineering Psychology, and Cognitive Computing and Internet of Things, 2021},
	year = {2021},
	journal = {Lecture Notes in Networks and Systems},
	volume = {259},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112051496&partnerID=40&md5=f88b6b6174f07a581ecfd99af1e53b1b},
	abstract = {The proceedings contain 60 papers. The special focus in this conference is on Neuroergonomics and Cognitive Engineering, Industrial Cognitive Ergonomics and Engineering Psychology, and Cognitive Computing and Internet of Things. The topics include: Human-Computer Interaction (HCI) Approach for the Optimal Generation and Selection of Batches Destination Options in Steel Making Factories; advantage Design of Small Commodities Under Cultural Transfer; cognitive Living Spaces by Using IoT Devices and Ambient Biosensor Technologies; human-Centric Emergent Configurations: Supporting the User Through Self-configuring IoT Systems; playful Screening of Executive Functions Using Augmented Reality and Gaze Based Assessment; towards a Measure of Situation Awareness for Space Mission Schedulers; advanced Cyber and Physical Situation Awareness in Urban Smart Spaces; design of an IoT Architecture in Livestock Environments for the Treatment of Information for the Benefit of Cattle; requirements Analysis on Emotional Preferences for Leisure Activities in Virtual Reality for Female Nursing Home Residents – A Mixed Method Approach; virtual Reality-Based Sensory Triggers and Gaze-Based Estimation for Mental Health Care; towards Decision Support with Assessment of Neuropsychological Profiles in Alzheimer's Dementia Using Playful Tablet-Based Multimodal Activation; THERADIA: Digital Therapies Augmented by Artificial Intelligence; electrotactile Stimulation, A New Feedback Channel for First Responders; multisensory Wearable Vital Monitoring System for Military Training, Exercise and Deployment; a Database for Cognitive Workload Classification Using Electrocardiogram and Respiration Signal; Using BERT Model for Intent Classification in Human-Computer Dialogue Systems to Reduce Data Volume Requirement; monitoring Human Performance on Future Deep Space Missions; human-Machine Learning with Mental Map; preface; expectations in Human-Robot Interaction.},
	editor = {Ayaz H. and Asgher U. and Paletta L.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {23673370},
	isbn = {978-303080284-4},
	language = {English},
	abbrev_source_title = {Lect. Notes Networks Syst.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: AHFE Conferences on Neuroergonomics and Cognitive Engineering, Industrial Cognitive Ergonomics and Engineering Psychology, and Cognitive Computing and Internet of Things, 2021; Conference date: 25 July 2021 through 29 July 2021; Conference code: 262279}
}

@CONFERENCE{Rishi20221085,
	author = {Rishi, R. and Abhishek, S. and Anudeep, N. and Vivek, V.},
	title = {A Survey on Advanced Text Recognition and Projection in Augmented Reality},
	year = {2022},
	journal = {Proceedings - 2022 4th International Conference on Advances in Computing, Communication Control and Networking, ICAC3N 2022},
	pages = {1085 – 1089},
	doi = {10.1109/ICAC3N56670.2022.10074420},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152194066&doi=10.1109%2fICAC3N56670.2022.10074420&partnerID=40&md5=17aa0e5cd6de43c9ed5f4ca5a1de6870},
	affiliations = {Jain (Deemed-to-be University), Dept. CSE-AI and Ml, Bengaluru, India},
	abstract = {Augmented Reality (AR) is a technology that overlays a computer-generated image on a user's view of the real world, thus providing a combined view. Artificial Intelligence (AI) has been used in various sectors such as gaming, manufacturing, military, and law enforcement systems. With the rapid growth of augmented reality development tools and the expansion of their functionality over the years, developers have started believing that with the application of augmented reality for AI developers can create an artificial intelligence-based app that can perform all basic tasks such as adapting to different environments. The survey focuses on studying and comparing different methods and approaches of Augmented Reality and text/image identification and mapping techniques to further combine both the approaches to achieve the end goal of obtaining AR Projections from the recognized text. The process will involve the following steps which are Handwritten text Recognition and extraction using multi model CTC. Emotion and Sentiment Analysis for text mapping and recognition using BiLSTM and SENN, Image Generation using XMC-GAN and then finally converting 2D images to 3D using COLF making it ready for the final Augmented Reality projection. © 2022 IEEE.},
	author_keywords = {Bidirectional Long Short-Term Memory (BiL-STM); Chain-of-lines Feature (COLF); Connectionist Temporal Classification (CTC); Cross(X)-Modal Contrastive Generative Adversarial Network (XMC-GAN); Generative Adversarial Networks (GAN); Handwritten Text Recognition (HTR); Semantic-Emotion Neural Network (SENN)},
	keywords = {Augmented reality; Character recognition; Generative adversarial networks; Mapping; Sentiment analysis; Bidirectional long short-term memory; Chain-of-line feature; Connectionist temporal classification; Cross(X)-modal contrastive generative adversarial network; Generative adversarial network; Hand-written text recognition; Handwritten text recognition; Line features; Neural-networks; Semantic-emotion neural network; Temporal classification; Semantics},
	correspondence_address = {R. Rishi; Jain (Deemed-to-be University), Dept. CSE-AI and Ml, Bengaluru, India; email: 20btrcl025@jainuniveristy.ac.in},
	editor = {Sharma V. and Sharma V. and Singh M. and Singh M. and Sinha J.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-166547436-8},
	language = {English},
	abbrev_source_title = {Int. Conf. Adv. Comput., Commun. Control Netw., ICAC3N},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 4th International Conference on Advances in Computing, Communication Control and Networking, ICAC3N 2022; Conference date: 16 December 2022 through 17 December 2022; Conference code: 187556}
}

@CONFERENCE{Thilagavathi2021,
	author = {Thilagavathi, S. and Nivethitha, K.S. and Preeti, P. and Vikram, D.T.},
	title = {IoT based Smart Retail System with Social Distancing for Covid19 Outbreak},
	year = {2021},
	journal = {Journal of Physics: Conference Series},
	volume = {1917},
	number = {1},
	doi = {10.1088/1742-6596/1917/1/012030},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108619585&doi=10.1088%2f1742-6596%2f1917%2f1%2f012030&partnerID=40&md5=d98d3fad35dfabc543ef5b1037624db1},
	affiliations = {Department of ECE, Dr. Mahalingam College of Engineering and Technology, Tamil Nadu, India},
	abstract = {Covid19 pandemic caused by infection with the severe acute respiratory syndrome corona virus2 is continuously spreading all over the world. The impact of covid19 has been fallen on almost all sectors of development including retail which plays a major role in day to day life. In this paper, we proposed an efficient methodology to create a safe environment of people in retail that contributes to public safety. The proposed smart retail system is focused on the real time monitoring of shopping malls which includes grocery, departmental stores, clothing shops, jewellery shops and shops with food essential products. At first a Mobile Application is developed using Android Studio for prebooking of shopping by users/customers. Using Anaconda Navigator a deep learning trained architecture is developed on distinguishing people with and without face mask. A wearable device is developed using ultra wide band radio technology to ensure safe social distancing which would alert customers as soon as the violation of social distancing is detected. The smart retail system also includes IoT based smart shopping cart with RFID sensors for the customers to check for the availability of items in the web server via Nodemcu and for automatic bill payment. The proposed methodology is also suitable for Religious places, Cinema Theatre, Training centres and Browsing centres.  © Published under licence by IOP Publishing Ltd.},
	keywords = {Computer viruses; Deep learning; Retail stores; Sales; Wearable technology; Departmental stores; Mobile applications; Real time monitoring; Severe acute respiratory syndrome; Shopping carts; Training centres; Ultra-wide band radios; Wearable devices; Internet of things},
	editor = {Rathinavelu A. and Sudhakar R. and Bharathi S. and Senthilarasi M.},
	publisher = {IOP Publishing Ltd},
	issn = {17426588},
	language = {English},
	abbrev_source_title = {J. Phys. Conf. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: National Virtual Conference on Advanced Informatics, Electronics and Vision 2021, NCAIEV 2021; Conference date: 23 April 2021; Conference code: 169633; All Open Access, Gold Open Access}
}

@ARTICLE{Saafi2021,
	author = {Saafi, Salwa and Hosek, Jiri and Kolackova, Aneta},
	title = {Enabling next-generation public safety operations with mission-critical networks and wearable applications},
	year = {2021},
	journal = {Sensors},
	volume = {21},
	number = {17},
	doi = {10.3390/s21175790},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113818091&doi=10.3390%2fs21175790&partnerID=40&md5=6d3930792782978c21dc0168843b7caf},
	affiliations = {Department of Telecommunications, Faculty of Electrical Engineering and Communication, Brno University of Technology, Technicka 12, Brno, 616 00, Czech Republic; Unit of Electrical Engineering, Faculty of Information Technology and Communication Sciences, Tampere University, Tampere, 33720, Finland},
	abstract = {Public safety agencies have been working on the modernization of their communication networks and the enhancement of their mission-critical capabilities with novel technologies and applications. As part of these efforts, migrating from traditional land mobile radio (LMR) systems toward cellular-enabled, next-generation, mission-critical networks is at the top of these agencies’ agendas. In this paper, we provide an overview of cellular technologies ratified by the 3rd Generation Partnership Project (3GPP) to enable next-generation public safety networks. On top of using wireless communication technologies, emergency first responders need to be equipped with advanced devices to develop situational awareness. Therefore, we introduce the concept of the Internet of Life-Saving Things (IoLST) and focus on the role of wearable devices—more precisely, cellular-enabled wearables, in creating new solutions for enhanced public safety operations. Finally, we conduct a performance evaluation of wearable-based, mission-critical applications. So far, most of the mission-critical service evaluations target latency performance without taking into account reliability requirements. In our evaluation, we examine the impact of device-and application-related parameters on the latency and the reliability performance. We also identify major future considerations for better support of the studied requirements in next-generation public safety networks. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.},
	author_keywords = {Cellular connectivity; IoLST; Mission-critical services; Public safety; Wearable technology},
	keywords = {Communication; Reproducibility of Results; Wearable Electronic Devices; Wireless Technology; Cellular radio systems; Mobile telecommunication systems; Wearable technology; 3rd generation partnership project (3GPP); Mission critical applications; Mission critical networks; Public Safety Networks; Reliability performance; Reliability requirements; Technologies and applications; Wireless communication technology; electronic device; interpersonal communication; reproducibility; wireless communication; Next generation networks},
	correspondence_address = {J. Hosek; Department of Telecommunications, Faculty of Electrical Engineering and Communication, Brno University of Technology, Brno, Technicka 12, 616 00, Czech Republic; email: hosek@feec.vutbr.cz},
	publisher = {MDPI AG},
	issn = {14248220},
	pmid = {34502681},
	language = {English},
	abbrev_source_title = {Sensors},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Sainidis2021835,
	author = {Sainidis, Dimitrios and Konstantoudakis, Konstantinos and Dimou, Anastasios and Tsiakmakis, Dimitrios and Albanis, Georgios and Daras, Petros},
	title = {Single-handed gesture UAV control and video feed AR visualization for first responders},
	year = {2021},
	journal = {Proceedings of the International ISCRAM Conference},
	volume = {2021-May},
	pages = {835 – 848},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121253265&partnerID=40&md5=723e98e2634569a4b0da41fd3d7dd0b1},
	affiliations = {Visual Computing Lab (VCL), Information Technologies Institute (ITI), Centre for Research and Technology - Hellas (CERTH), Thessaloniki, Greece},
	abstract = {Unmanned Aerial Vehicles (UAVs) are becoming increasingly widespread in recent years, with numerous applications spanning multiple sectors. UAVs can be of particular benefit to first responders, assisting in both hazard detection and search-and-rescue operations, increasing their situational awareness without endangering human personnel; However, conventional UAV control requires both hands on a remote controller and many hours of training to control efficiently. Furthermore, viewing the UAV video-feed on conventional devices (e.g. smartphones) require first responders to glance downwards to look at the screen, increasing the risk of accident. To this end, this work presents a unified system, incorporating single-hand gesture control for UAVs and an augmented reality (AR) visualization of their video feed, while also allowing for backup remote UAV control from any device and multiple-recipient video streaming. A modular architecture allows the upgrade or replacement of individual modules without affecting the whole. The presented system has been tested in the lab, and in field trials by first responders. © 2021 Information Systems for Crisis Response and Management, ISCRAM. All rights reserved.},
	author_keywords = {Augmented reality; First responders; Gesture control; UAV},
	keywords = {Aircraft control; Aircraft detection; Antennas; Augmented reality; Information management; Information systems; Information use; Personnel training; Remote control; Visualization; First responders; Gesture control; Hand-on; Hazard detection; Remote controllers; Risk of accidents; Search and rescue operations; Single handed gestures; Situational awareness; Smart phones; Unmanned aerial vehicles (UAV)},
	correspondence_address = {D. Sainidis; Visual Computing Lab (VCL), Information Technologies Institute (ITI), Centre for Research and Technology - Hellas (CERTH), Thessaloniki, Greece; email: dsainidis@iti.gr},
	editor = {Adrot A. and Grace R. and Moore K. and Zobel C.W.},
	publisher = {Information Systems for Crisis Response and Management, ISCRAM},
	issn = {24113387},
	isbn = {978-194937361-5},
	language = {English},
	abbrev_source_title = {Proc. Int. ISCRAM Conf.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; Conference name: 18th International Conference on Information Systems for Crisis Response and Management, ISCRAM 2021; Conference date: 23 May 2021 through 26 May 2021; Conference code: 174941}
}

@CONFERENCE{Jindal202381,
	author = {Jindal, Pranshi and Park, Andrew J. and Hwang, Eunju},
	title = {Augmented Reality Campus Exploration Application Incorporating Equity, Diversity, and Inclusion},
	year = {2023},
	journal = {2023 15th International Conference on Computer and Automation Engineering, ICCAE 2023},
	pages = {81 – 86},
	doi = {10.1109/ICCAE56788.2023.10111189},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159623495&doi=10.1109%2fICCAE56788.2023.10111189&partnerID=40&md5=fac1b42abf49848fc5eebf7dc3379da5},
	affiliations = {Aligarh Muslim University, Dept of Computer Engineering, Aligarh, India; Trinity Western University, Dept of Mathematical Sciences, Langley, Canada; Mgmt Virginia Tech, Dept of Apparel, Hsng, and Resource, Blacksburg, United States},
	abstract = {Augmented Reality (AR) is one of the most promising technologies with many practical applications, enhancing/augmenting the real world with virtual information/objects. With advances in AR technology and affordable AR hardware, AR has widely been used in training, classroom education, entertainment, tourism, public safety, retail, and many others. This paper presents an AR application that provides real-time information for campus exploration incorporating Equity, Diversity, and Inclusion (EDI). Many mobile AR applications have been developed for campus tours to help new students and visitors identify campus buildings and their services. However, from the User Experience (UX) design perspective, simply providing general information about each building may not be sufficient for students who need specific information based on their backgrounds and particular needs. The mobile AR application, TWUExplorAR, presented in this paper, incorporates the concept of EDI by overlaying the landmark information tailored to each user's background and needs, thus improving UX. The paper outlines the background and related work, describes the development of the AR application, illustrates the incorporation of EDI in the application, summarizes the usability tests, and suggests future improvements.  © 2023 IEEE.},
	author_keywords = {and inclusiveness (EDI); augmented reality (AR); diversity; equity; global positioning system (GPS); point of interest (POI)},
	keywords = {Augmented reality; Students; And inclusiveness (equity, diversity, and inclusion); Augmented reality; Augmented reality applications; Diversity; Equity; Global positioning system; Mobile augmented reality; Point of interest; Real-world; Virtual information; Global positioning system},
	correspondence_address = {P. Jindal; Aligarh Muslim University, Dept of Computer Engineering, Aligarh, India; email: apranshi11@gmail.com},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835039622-5},
	language = {English},
	abbrev_source_title = {Int. Conf. Comput. Autom. Eng., ICCAE},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 15th International Conference on Computer and Automation Engineering, ICCAE 2023; Conference date: 3 March 2023 through 5 March 2023; Conference code: 188400}
}

@CONFERENCE{Sim20221266,
	author = {Sim, Sang-Hun and Paranjpe, Tara and Roberts, Nicole and Zhao, Ming},
	title = {Exploring Edge Machine Learning-based Stress Prediction using Wearable Devices},
	year = {2022},
	journal = {Proceedings - 21st IEEE International Conference on Machine Learning and Applications, ICMLA 2022},
	pages = {1266 – 1273},
	doi = {10.1109/ICMLA55696.2022.00203},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152213750&doi=10.1109%2fICMLA55696.2022.00203&partnerID=40&md5=8058958f830d5405e47bcac383a2d941},
	affiliations = {Arizona State University, United States},
	abstract = {Stress is a central factor in our daily lives, impacting performance, decisions, well-being, and our interactions with others. With the development of IoT technology, smart wearable devices can handle diverse operations, including networking and recording biometric signals. The enhanced data processing capability of wearables has also allowed for increased stress awareness among users. Edge computing on such devices enables real-time feedback which can provide an opportunity to prevent severe consequences that might result if stress is left unaddressed. Edge computing can also strengthen privacy by implementing stress prediction on local devices without transferring personal information to the public cloud.This paper presents a framework for real-time stress prediction, specifically for police training cadets, using wearable devices and machine learning with support from cloud computing. We developed an application for Fitbit and the user's accompanying smartphone to collect heart rate fluctuations and corresponding stress levels entered by users and a cloud backend for storing data and training models. Real-world data for this study was collected from police cadets during a police academy training program. Machine learning classifiers for stress prediction were built using this data through classic machine learning models and neural networks. To analyze efficiency across different environments, the models were optimized using model compression and other relevant techniques and tested on cloud and edge environments. Evaluation using real data and real devices showed that the highest accuracy came from XGBoost and Tensorflow neural network models, and on-edge stress prediction models produced lower latency results than in-cloud prediction.  © 2022 IEEE.},
	author_keywords = {Classification Models; Edge Learning; Machine Learning; Neural Networks; Stress Prediction; Wearable Devices},
	keywords = {Classification (of information); Edge computing; Forecasting; Machine learning; Wearable technology; Classification models; Daily lives; Edge computing; Edge learning; Machine-learning; Neural-networks; Performance; Stress prediction; Wearable devices; Well being; Law enforcement},
	correspondence_address = {S.-H. Sim; Arizona State University, United States; email: ssim6@asu.edu},
	editor = {Wani M.A. and Kantardzic M. and Palade V. and Neagu D. and Yang L. and Chan K.-Y.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-166546283-9},
	language = {English},
	abbrev_source_title = {Proc. - IEEE Int. Conf. Mach. Learn. Appl., ICMLA},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 21st IEEE International Conference on Machine Learning and Applications, ICMLA 2022; Conference date: 12 December 2022 through 14 December 2022; Conference code: 187486}
}

@ARTICLE{Bendixsen2020108,
	author = {Bendixsen, Synnøve},
	title = {The Care/Security Nexus of the Humanitarian Border: Assisted Return in Norway},
	year = {2020},
	journal = {International Migration},
	volume = {58},
	number = {6},
	pages = {108 – 122},
	doi = {10.1111/imig.12630},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070976534&doi=10.1111%2fimig.12630&partnerID=40&md5=28ffe782bebe840efce491a3a3cd993b},
	affiliations = {University of Bergen, Norway},
	abstract = {While Assisted Return and deportation are frequently viewed as two different return policies, the first represented as humanitarian and the latter as enforcement, this article argues that there is a continuum between these policies and that they form part of humanitarian border enforcement. Drawing on policy document analysis and interviews with NGOs and with irregular migrants, the article provides a two-level analysis by examining how AR is presented from the Norwegian governmental perspective and how it is experienced from the Afghan migrant perspectives. The article argues that the government bases its AR policy on the need to maintain the credibility and sustainability of the asylum system, as part of fighting crime, while presenting it as a humanitarian solution. For irregular migrants, however, the experienced lack of proper asylum procedures delegitimizes return policies. Overall, the performative aspects of humanitarianism in return policies contribute to depoliticizing return. © 2019 The Author. International Migration published by John Wiley & Sons Ltd on behalf of International Organization for Migration},
	keywords = {Norway; immigrant; immigration policy; law enforcement; nongovernmental organization; policy analysis; policy approach; return migration},
	publisher = {Blackwell Publishing Ltd},
	issn = {00207985},
	language = {English},
	abbrev_source_title = {Int. Migr.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; All Open Access, Green Open Access}
}

@CONFERENCE{Hu20211409,
	author = {Hu, Da and Li, Shuai and Du, Jing and Cai, Jiannan},
	title = {Human-in-the-Loop Robot-Augmented Intelligent System for Emergency Reconnaissance},
	year = {2021},
	journal = {Computing in Civil Engineering 2021 - Selected Papers from the ASCE International Conference on Computing in Civil Engineering 2021},
	pages = {1409 – 1416},
	doi = {10.1061/9780784483893.172},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132550300&doi=10.1061%2f9780784483893.172&partnerID=40&md5=2ee5efbb74326b5266273dd9580d77de},
	affiliations = {Dept. of Civil and Environmental Engineering, Univ. of Tennessee, Knoxville, TN, United States; Engineering School of Sustainable Infrastructure and Environment, Univ. of Florida, Gainesville, FL, United States; Dept. of Construction Science, Univ. of Texas at San Antonio, San Antonio, TX, United States},
	abstract = {This study proposes a human-in-the-loop robot-augmented intelligent system for emergency reconnaissance. The system improves situational awareness of first responders by providing robot-collected information through an intelligent and interactive interface. Unmanned aerial vehicles (UAVs) and unmanned ground vehicles (UGVs) equipped with RGB-D camera, thermal camera, GPR, and LiDAR are deployed to acquire information on disaster sites. The collected sensor data are further processed to present actionable information to first responders, such as victim location, buried void shape, and accessible hole through an augmented reality interface. A virtual reality platform is used to validate and evaluate the proposed system. Participants are invited to complete a search and rescue mission with robot-augmented intelligent system to find survival victims under rubbles in the virtual environment. The experiments demonstrated that the proposed system reduces the searching time and false alarms, and increases the accuracy of detecting victims, which will change the search and rescue paradigm from an experience-based practice to an information-based one. © 2021 Computing in Civil Engineering 2021 - Selected Papers from the ASCE International Conference on Computing in Civil Engineering 2021. All rights reserved.},
	keywords = {Antennas; Augmented reality; Geological surveys; Ground penetrating radar systems; Ground vehicles; Intelligent robots; Intelligent systems; Intelligent vehicle highway systems; Search engines; Virtual reality; Aerial vehicle; First responders; Human-in-the-loop; Intelligent interface; Interactive interfaces; Search and rescue; Sensors data; Situational awareness; Thermal camera; Void shape; Cameras},
	editor = {Issa R.R.A.},
	publisher = {American Society of Civil Engineers (ASCE)},
	isbn = {978-078448389-3},
	language = {English},
	abbrev_source_title = {Comput. Civ. Eng. - Sel. Pap. ASCE Int. Conf. Comput. Civ. Eng.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2021 International Conference on Computing in Civil Engineering, I3CE 2021; Conference date: 12 September 2021 through 14 September 2021; Conference code: 179585}
}

@CONFERENCE{Egger-Lampl2022,
	author = {Egger-Lampl, Sebastian and Bieg, Till and Karlseder, Markus and Roszipal, Benjamin},
	title = {Work-in-Progress - EXtended Reality Training for Safety and Medical Procedures: Experiences from a User-Centered-Design Approach to Implementation},
	year = {2022},
	journal = {Proceedings of 2022 8th International Conference of the Immersive Learning Research Network, iLRN 2022},
	doi = {10.23919/iLRN55037.2022.9816000},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134768965&doi=10.23919%2fiLRN55037.2022.9816000&partnerID=40&md5=dc42f07561d840d5e58bdb51a853c835},
	affiliations = {Mindconsole GmbH, Graz, Austria; AIT Austrian Institute of Technology GmbH, Center for Technology Experience, Vienna, Austria; SIM Campus GmbH, Eisenerz, Austria},
	abstract = {eXtended Reality (XR) environments appear to be a promising approach to training in various contexts; however, their potential for safety and medical procedures is still not fully understood. The aim of the presented research project is the user-centered implementation of an XR training for various occupational groups and volunteers of first responder organizations (e.g., physicians, paramedics, health care workers, police officers, firefighters). To achieve this aim, the project has followed three implementation steps: First, multi-stakeholder workshops were conducted to define two use cases for the most promising application areas. Second, based on the previous step, identified use cases were implemented as XR training scenarios. Third, scientific evaluations of the training applications are conducted focusing on subjective and objective performance indicators, learning success, training experience, acceptance, and potential barriers from an end-user perspective. As the last step is still ongoing, this paper puts emphasis on the outcomes of the stakeholder workshops, the respective decisions taken towards selecting two use cases, and the design of the evaluation study. © 2022 Immersive Learning Research Network.},
	author_keywords = {extended reality; immersive learning; learning; pedagogics; procedural training; psychology; training; user-centered-design},
	keywords = {Law enforcement; Extended reality; Immersive learning; Learning; Medical procedures; Pedagogic; Procedural training; Psychology; Safety procedure; User-centered design approaches; User-centred; User centered design},
	editor = {Dengel A. and Bourguet M.-L. and Pedrosa D. and Hutson J. and Erenli K. and Economou D. and Pena-Rios A. and Richter J.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-173489952-8},
	language = {English},
	abbrev_source_title = {Proc. Int. Conf. Immersive Learn. Res. Netw., iLRN},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 8th International Conference of the Immersive Learning Research Network, iLRN 2022; Conference date: 30 May 2022 through 4 June 2022; Conference code: 180846}
}

@CONFERENCE{Kapalo2022634,
	author = {Kapalo, Katelynn A. and Pfeil, Kevin and Bonnell, Joseph and Laviola, Joseph},
	title = {Comparing Firefighters' Perceived Workload Using 2D vs. 3D Building Plans to Support Emergency Response Preplanning in a Simulated Fire Scenario},
	year = {2022},
	journal = {Proceedings - 2022 IEEE International Symposium on Mixed and Augmented Reality Adjunct, ISMAR-Adjunct 2022},
	pages = {634 – 639},
	doi = {10.1109/ISMAR-Adjunct57072.2022.00131},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146054875&doi=10.1109%2fISMAR-Adjunct57072.2022.00131&partnerID=40&md5=bd870ec1e1db26a4f9b503eb19fffd94},
	affiliations = {Christian Regenhard Center for Emergency Response Studies; University of North Florida, United States; Phoenix Fire Department; University of Central Florida, United States},
	abstract = {Firefighters rely on visual information to make tactical decisions during structure fire events. Consequently, user interface design for public safety requires a comprehensive understanding of how these visual cues impact performance in terms of expertise and domain knowledge, as well as cognitive load. However, very few studies have captured baseline measures (e.g., subjective workload) associated with the use of pre-incident planning, the phase prior to deciding how to extinguish the fire. Virtual environments and 3D modeling have been suggested as a tool that can better support the exploration of emerging technology to better support pre-incident planning practices. Sixty-four (n = 64) North American firefighters participated in this study. Our work focuses on providing baseline data to define effective ways to present building and hazard information to incident commanders using both current systems (e.g., 2D diagrams) and emerging technologies (e.g., 3D models, virtual reality, augmented reality).  © 2022 IEEE.},
	author_keywords = {HCI design and evaluation methods; Human-centered computing [Human computer interaction (HCI)]; User Studies},
	keywords = {3D modeling; Domain Knowledge; Fire extinguishers; Human computer interaction; Structural design; User interfaces; Virtual reality; 3d buildings; Design and evaluation methods; Emerging technologies; Human computer interaction design and evaluation method; Human-centered computing; Human-centered computing [human computer interaction ]; Human-computer-interaction designs; Interaction design methods; Interaction evaluations; User study; Augmented reality},
	correspondence_address = {K.A. Kapalo; Christian Regenhard Center for Emergency Response Studies; email: kate.kapalo@knights.ucf.edu},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-166545365-3},
	language = {English},
	abbrev_source_title = {Proc. - IEEE Int. Symp. Mixed Augment. Real. Adjun., ISMAR-Adjunct},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 21st IEEE International Symposium on Mixed and Augmented Reality Adjunct, ISMAR-Adjunct 2022; Conference date: 17 October 2022 through 21 October 2022; Conference code: 185190}
}

@ARTICLE{Grothe2023,
	author = {Grothe, Jacob and Tucker, Sarah and Blake, Anthony and Achutan, Chandran and Medcalf, Sharon and Suwondo, Troy and Fruhling, Ann and Yoder, Aaron},
	title = {Exploring First Responders’ Use and Perceptions on Continuous Health and Environmental Monitoring},
	year = {2023},
	journal = {International Journal of Environmental Research and Public Health},
	volume = {20},
	number = {6},
	doi = {10.3390/ijerph20064787},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151114629&doi=10.3390%2fijerph20064787&partnerID=40&md5=bc8fcf58079336473b433ed00a9384bf},
	affiliations = {College of Public Health, University of Nebraska Medical Center, Omaha, 68198, NE, United States; College of Information Science & Technology, University of Nebraska-Omaha, Omaha, 68182, NE, United States},
	abstract = {First responders lose their lives in the line of duty each year, and many of these deaths result from strenuous physical exertion and exposure to harmful environmental agents. Continuous health monitoring may detect diseases and alert the first responder when vital signs are reaching critical levels. However, continuous monitoring must be acceptable to first responders. The purpose of this study was to discover first responders’ current use of wearable technology, their perceptions of what health and environmental indicators should be monitored, and who should be permitted to monitor them. The survey was sent to 645 first responders employed by 24 local fire department stations. A total of 115 (17.8%) first responders answered the survey and 112 were used for analysis. Results found first responders perceived a need for health and environmental monitoring. The health and environmental indicators that respondents perceived as most important for monitoring in the field were heart rate (98.2%) and carbon monoxide (100%), respectively. Overall, using and wearing monitoring devices was not age-dependent and health and environmental concerns were important for first responders at any stage of their career. However, current wearable technology does not seem to be a viable solution for first responders due to device expense and durability issues. © 2023 by the authors.},
	author_keywords = {attitude; behavior; first responders; physiological; safety; sensor monitoring; survey},
	keywords = {Emergency Responders; Environmental Monitoring; Heart Rate; Humans; Monitoring, Physiologic; Vital Signs; Wearable Electronic Devices; carbon monoxide; environmental monitoring; perception; physiological response; safety; sensor; survey method; adult; Article; attitude to health; brain blood flow; environmental indicator; environmental monitoring; exercise; first responder (person); health care; health survey; heart output; heart rate; heart stroke volume; heat stress; human; male; muscle blood flow; electronic device; environmental monitoring; physiologic monitoring; procedures; rescue personnel; vital sign},
	correspondence_address = {A. Yoder; College of Public Health, University of Nebraska Medical Center, Omaha, 68198, United States; email: aaron.yoder@unmc.edu},
	publisher = {MDPI},
	issn = {16617827},
	pmid = {36981694},
	language = {English},
	abbrev_source_title = {Int. J. Environ. Res. Public Health},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Danylec2022,
	author = {Danylec, Andrew and Shahabadkar, Krutika and Dia, Hussein and Kulkarni, Ambarish},
	title = {Cognitive Implementation of Metaverse Embedded Learning and Training Framework for Drivers in Rolling Stock},
	year = {2022},
	journal = {Machines},
	volume = {10},
	number = {10},
	doi = {10.3390/machines10100926},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140903734&doi=10.3390%2fmachines10100926&partnerID=40&md5=9b224176a625c9388e56a4d88c80eaa6},
	affiliations = {School of Engineering, Swinburne University of Technology, Hawthorn, 3122, VIC, Australia},
	abstract = {Public safety is prime concern in rail industry and driver training on hazard perception is crucial. Additionally, a new driver’s skill set determines the productivity and quality of existing driver training methods. Apprentice train drivers are required to complete massive hours under supervision of experienced drivers to attain the required skill sets causing productivity issues. Traditional driver training is paper based, and assessments are individually evaluated without any scientific rigor, resulting in quality challenges. This paper proposes a Metaverse embedded learning and training framework for drivers in rolling stock. The framework includes driver vision analysis by eye tracking and pupil dilation focusing on enhancing the productivity and quality of driver training and hazard detection for drivers in rolling stock. Metaverse embedded training and learning enhances experiential learning with unique benefits. In this paper, a metaverse-based training framework is proposed for train drivers to enhance productivity, quality, and safety aspects through case studies including: (i) driver sightline studies and (ii) vision analysis. The studies developed quantifying driver hazard perceptions and related comprehension rates based on eye tracking and vision studies. In conclusion, the overall savings on cost and time are 95% effective using Metaverse-based training method compared to traditional methods. Stakeholders need to supervise on driver tasks, knowledge retention, damage control due to the occurrence of hazards. The framework substantially reduced hazards to 50% with saving up to 3696 man-hours. The assessment was completely automated to provide real time assessment thus providing 93% more positive results compared to traditional methods. © 2022 by the authors.},
	author_keywords = {augmented reality; eye tracking; hazard perception; Metaverse; rolling stock; virtual reality; vision analysis},
	correspondence_address = {K. Shahabadkar; School of Engineering, Swinburne University of Technology, Hawthorn, 3122, Australia; email: kshahabadkar@swin.edu.au},
	publisher = {MDPI},
	issn = {20751702},
	language = {English},
	abbrev_source_title = {Mach.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; All Open Access, Gold Open Access}
}

@ARTICLE{Quezada-Tavárez202169,
	author = {Quezada-Tavárez, Katherine},
	title = {Augmented reality in law enforcement from an EU data protection law perspective: The darlene project as a case study},
	year = {2021},
	journal = {Revue Internationale de Droit Penal},
	volume = {92},
	number = {1},
	pages = {69 – 86},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120538116&partnerID=40&md5=36e075b6be24529e39f77bfe5e5312df},
	affiliations = {KU Leuven Centre for IT and IP Law (CiTiP), Belgium},
	abstract = {Augmented reality (AR) is gaining popularity given its ability to blend the digital and physical worlds, amplifying human capabilities and improving the performance of tasks. In the law enforcement domain, a promising application is AR combined with artificial intelligence (AI) to improve situational awareness by enabling the optimal and timely delivery of crucial information during tactical decision-making. These technological advances create great opportunities for the fight against crime and terrorism, but they also raise a plethora of legal and ethical concerns. This paper aims to contribute to the growing literature on AI in criminal justice by examining AI-based AR solutions in law enforcement through the lens of EU data protection law. Focus is placed on three major issues, namely data minimisation, processing of special categories of data and automated decision-making. The analysis is concretised by looking at a specific project in this field, the EU-funded Deep AR Law Enforcement Ecosystem (DARLENE) project, to illustrate the possible implications. © 2021 Editions Eres. All rights reserved.},
	correspondence_address = {K. Quezada-Tavárez; KU Leuven Centre for IT and IP Law (CiTiP), Belgium; email: katherine.quezada@kuleuven.be},
	publisher = {Maklu Publishers},
	issn = {02235404},
	language = {English},
	abbrev_source_title = {Rev. Int. Droit Penal},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Schönauer202353,
	author = {Schönauer, Christian and Roussou, Maria and Rüggeberg, Julien and Rüggeberg, Jim and Katsikaris, Lucas and Rogkas, Sakis and Christopoulos, Dimitris},
	title = {Creating Informal Learning and First Responder Training XR Experiences with the ImmersiveDeck},
	year = {2023},
	journal = {Proceedings - 2023 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops, VRW 2023},
	pages = {53 – 60},
	doi = {10.1109/VRW58643.2023.00016},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159704979&doi=10.1109%2fVRW58643.2023.00016&partnerID=40&md5=e3b575151d84e599d0fc23c114e612ab},
	affiliations = {Hannes Kaufmann TU Wien, Austria; National and Kapodistrian, University of Athens, Greece; Illusion Walk KG, Germany; Bolt Virtual, Greece; Foundation of the Hellenic World, Greece},
	abstract = {In recent years eXtended Reality (XR) technologies have matured and have become affordable, yet creating XR experiences for training and learning in many cases is still a time-consuming and costly process, hindering widespread adoption. One factor driving effort is that content and features commonly required by many applications get re-implemented for each experience, instead of sharing and reusing these resources by means of a common platform. In this paper we present two XR experiences in the context of informal learning and first responder training along with the shared platform they have been created with and the creation process. Furthermore, we have technically evaluated relevant parts of the platform for feasibility of use with experience requirements and confirmed ap-plicability. Finally, we present an informal expert evaluation of the content creation process's user experience for the informal learning experience along with guidelines derived from the findings.  © 2023 IEEE.},
	author_keywords = {Human-centered computing; Human-centered computing; Visualization; Visualization; Visualization design and evaluation methods},
	keywords = {User interfaces; Common platform; Creation process; Design and evaluation methods; First responders; Human-centered computing; Informal learning; One-factor; Visualization design and evaluation method; Visualization designs; Visualization},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835034839-2},
	language = {English},
	abbrev_source_title = {Proc. - IEEE Conf. Virtual Real. 3D User Interfaces Abstr. Workshops, VRW},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2023 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops, VRW 2023; Conference date: 25 March 2023 through 29 March 2023; Conference code: 188382; All Open Access, Green Open Access}
}

@ARTICLE{Jain2022E213,
	author = {Jain, Piyush and Kapoor, Amit and Rubeshkumar, Polani and Raju, Mohankumar and Joseph, Bency and Bhat, Prashant and Ganeshkumar, Parasuraman and Kesavachandran, Chandrasekharan Nair and Patel, Devendra Kumar and Manickam, Natesan and Kaur, Prabhdeep},
	title = {Sudden deaths due to accidental leakage of Lindane from a storage tank in a village, Sitapur, Uttar Pradesh, India, 2020: A field epidemiological investigation},
	year = {2022},
	journal = {Environmental Epidemiology},
	volume = {6},
	number = {3},
	pages = {E213},
	doi = {10.1097/EE9.0000000000000213},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148442888&doi=10.1097%2fEE9.0000000000000213&partnerID=40&md5=22160e2ca1116d1d7e729457a8c9a7bd},
	affiliations = {ICMR-National Institute of Epidemiology, R 127, TNHB, Tamil Nadu, Chennai, 600077, India; Department of Health and Family Welfare, Uttar Pradesh, India; CSIR-Indian Institute of Toxicology Research, Uttar Pradesh, Lucknow, India},
	abstract = {Background: Chemical leakages cause devastating health effects on humans. On 6 February 2020, seven deaths were reported following a hazardous chemical leakage in a village in Uttar Pradesh, India. We investigated the event to identify the cause and propose recommendations. Methods: We defined a case as sudden onset of breathlessness, headache, or death in the village, 6-7 February 2020. We conducted a house-to-house case search and calculated attack rate (AR) and case-fatality rate (CFR) by age and gender. We conducted an environmental investigation at the leakage site and sent the chemicals for forensic analysis. We obtained the cause of death through autopsy reports. Results: Out of 2,942 residents, we identified 23 cases (AR = 8/1,000) and seven deaths (CFR = 30%). The median age of the case was 42 years (range, 2-64 years). The AR was higher among males (14/1,000 [19/1,402]). All the 23 case-patients who were sleeping at the chemical leakage site or visited to witness the event developed symptoms, and all seven cases who were sleeping within 150 meters of the leakage site died. The environmental investigation revealed leakage of hazardous substances from the storage tank. Toxicology analysis confirmed the leaked chemical as Lindane (gamma-hexachlorocyclohexane), and autopsy reports confirmed the cause of death as asphyxia. Conclusions: Asphyxia following the leakage of Lindane from the storage tank possibly led to sudden deaths. We recommend using leak-proof tanks to ensure safe storage and disposal, law enforcement, and regulations to prevent people from staying close to chemical storage sites. © 2022 Wolters Kluwer Health. All rights reserved.},
	author_keywords = {Chemical accidents; Hazardous chemicals; India; Lindane},
	keywords = {lindane; adolescent; adult; aged; Article; asphyxia; attack rate; autopsy; case fatality rate; cause of death; chemical accident; child; clinical article; criminalistics; dangerous goods; dyspnea; female; headache; human; male; middle aged; sex difference; sudden death; toxicology; Uttar Pradesh},
	correspondence_address = {P. Rubeshkumar; ICMR-National Institute of Epidemiology, Chennai, R 127, TNHB, Tamil Nadu, 600077, India; email: rubesh.pc@gmail.com},
	publisher = {Wolters Kluwer Health},
	issn = {24747882},
	language = {English},
	abbrev_source_title = {Environ.  Epidemiology},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Schlosser2021,
	author = {Schlosser, Paul},
	title = {Head-Worn Displays for Emergency Medical Services},
	year = {2021},
	journal = {Conference on Human Factors in Computing Systems - Proceedings},
	doi = {10.1145/3411763.3443421},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105796020&doi=10.1145%2f3411763.3443421&partnerID=40&md5=bc81b2737b2efeec97fa73a34fbd0eed},
	affiliations = {School of Itee, The University of Queensland, Australia},
	abstract = {In the prehospital environment, head-worn displays (HWDs) could support paramedics and emergency physicians during complex tasks and procedures. Previously, HWDs have been used in emergency medical service (EMS) contexts to support triage, telemedicine, patient monitoring, and patient localization. However, research on HWDs in EMS has three limitations: (1) HWD applications have not been developed based on field research of prehospital operations and training, (2) there are few guidelines that direct HWD deployment and application design, and (3) HWD applications seldom have been tested in randomized controlled trials. Therefore, it is unclear how HWDs affect EMS work and patient outcomes. During my PhD studies, I am investigating the potential of HWDs in EMS. I am addressing the limitations of previous research by conducting a literature review, a field study, design workshops, and a controlled evaluation study. The ultimate aims of this research are to benefit the work of EMS staff and to improve patient safety. © 2021 Owner/Author.},
	author_keywords = {Augmented reality; Emergency medical services; Head-worn display},
	keywords = {Human engineering; Patient monitoring; Application design; Design workshops; Emergency medical services; Evaluation study; Head-worn displays; Literature reviews; Patient localization; Randomized controlled trial; Emergency services},
	correspondence_address = {P. Schlosser; School of Itee, The University of Queensland, Australia; email: p.schlosser@uq.edu.au},
	publisher = {Association for Computing Machinery},
	isbn = {978-145038095-9},
	language = {English},
	abbrev_source_title = {Conf Hum Fact Comput Syst Proc},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2021 CHI Conference on Human Factors in Computing Systems: Making Waves, Combining Strengths, CHI EA 2021; Conference date: 8 May 2021 through 13 May 2021; Conference code: 168787}
}

@CONFERENCE{Economidou20211,
	author = {Economidou, Eleni and Hengeveld, Bart},
	title = {No Door Handle, No Entry! Expressing Cues through a Shape-Changing Door},
	year = {2021},
	journal = {ISS 2021 - Companion Proceedings of the 2021 Conference on Interactive Surfaces and Spaces},
	pages = {1 – 7},
	doi = {10.1145/3447932.3492326},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119610635&doi=10.1145%2f3447932.3492326&partnerID=40&md5=dcb2ee653353e81ffe7cd6be07ba673f},
	affiliations = {Center for Human-Computer Interaction, University of Salzburg, Austria; Industrial Design, Eindhoven University of Technology, Netherlands},
	abstract = {Computation is increasingly seen as a design material, finding its way into once mundane objects, surfaces and spaces. As such, demonstrations of the convergence of architectural elements and interactive systems are becoming commonplace in both research and industry. While eXtended Reality (XR) and projection mapping technologies seem to be ubiquitous in this field, shape-changing interfaces are under-represented. In this case study we explore the domain of shape-changing thresholds in the form of an interactive door panel. Corresponding to conditions of space occupancy, the design communicates through dynamic affordances and affordance elimination three ascribed social cues: entry invitation, entry permission, and entry prohibition. In a user evaluation study, all participants were able to correctly interpret the entry invitation and the entry prohibition cues. Based on our learnings and findings, we discuss aspects of our design and implications of shape-changing doors.  © 2021 Owner/Author.},
	author_keywords = {affordance elimination; dynamic affordances; interactive architecture; shape changing interfaces},
	keywords = {Industrial research; Memory architecture; Affordance elimination; Affordances; Architectural element; Design materials; Dynamic affordance; Interactive architecture; Interactive system; Object space; Object surface; Shape changing interface; Law enforcement},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {978-145038340-0},
	language = {English},
	abbrev_source_title = {ISS - Companion Proc. Conf. Interact. Surfaces Spaces},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; Conference name: 2021 Conference on Interactive Surfaces and Spaces, ISS 2021; Conference date: 15 November 2021 through 17 November 2021; Conference code: 174014}
}

@ARTICLE{Siddiqi202010745,
	author = {Siddiqi, Muhammad and Ali, Syed Taha and Sivaraman, Vijay},
	title = {Forensic Verification of Health Data from Wearable Devices Using Anonymous Witnesses},
	year = {2020},
	journal = {IEEE Internet of Things Journal},
	volume = {7},
	number = {11},
	pages = {10745 – 10762},
	doi = {10.1109/JIOT.2020.2982958},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096244395&doi=10.1109%2fJIOT.2020.2982958&partnerID=40&md5=0b5d63b43898aaecc42f15878a64fc3f},
	affiliations = {Department of Business Information Systems, Australian Institute of Higher Education, Sydney, 2000, NSW, Australia; School of Electrical Engineering and Computer Science, National University of Science and Technology, Islamabad, 44000, Pakistan; School of Electrical Engineering and Telecommunications, University of New South Wales, Sydney, 2052, NSW, Australia},
	abstract = {The use of wearable devices, such as smartwatches, glasses, clothes, and fitness bracelets is increasing at an ever-growing pace. Major corporations and insurance companies have started mandating their use for their employees and clients. Data from such devices have begun to feature in settlement claims and as evidence in courts as well, requiring it to be irrefutable and tamper-proof. Lack of protection for personal data as well as the contextual information such as location tracking and its use by law enforcement agencies is raising serious privacy concerns among the general public and civil liberty advocates. In this article, we propose a novel scheme to secure the wearable sensor's communication through its crowdsourced logging by neighboring wearable and smart devices called witnesses preserving the contextual information (such as time and location) as well. To ensure witness privacy, gateway and witness devices use the reciprocity property of wireless medium between them to generate pairs of closely matching link signatures, which not only provide the proof of presence for the witnesses in the vicinity but also act as their time-varying pseudonyms. We demonstrate the feasibility and efficacy of our scheme through the prototype implementation using real wireless devices, and via simulation and experimental results. © 2014 IEEE.},
	author_keywords = {Body sensor networks; crowdsourcing; forensics; Internet of Things; network security; wearable sensors},
	keywords = {Data privacy; Digital forensics; Insurance; Civil liberties; Contextual information; Insurance companies; Law-enforcement agencies; Privacy concerns; Prototype implementations; Wearable devices; Wireless devices; Wearable technology},
	correspondence_address = {M. Siddiqi; Department of Business Information Systems, Australian Institute of Higher Education, Sydney, 2000, Australia; email: m.siddiqi@aih.nsw.edu.au},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {23274662},
	language = {English},
	abbrev_source_title = {IEEE Internet Things J.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4}
}

@ARTICLE{Otero-Varela2023,
	author = {Otero-Varela, Lucía and Cintora, Ana María and Espinosa, Salvador and Redondo, María and Uzuriaga, Miriam and González, Myriam and García, Mario and Naldrett, Jessica and Alonso, Juan and Vazquez, Tatiana and Blanco, Alberto and del Carmen Cardós Alonso, María},
	title = {Extended reality as a training method for medical first responders in mass casualty incidents: A protocol for a systematic review},
	year = {2023},
	journal = {PLoS ONE},
	volume = {18},
	number = {3 March},
	doi = {10.1371/journal.pone.0282698},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150683629&doi=10.1371%2fjournal.pone.0282698&partnerID=40&md5=a5ebbf4a5fd7c616b837f95cd8f2cdc5},
	affiliations = {Servicio de Urgencias Médicas de la Comunidad de Madrid (SUMMA112), Madrid, Spain; Fundación para la Innovación e Investigación Biosanitarias en Atención Primaria (FIIBAP), Madrid, Spain; Departamento de Enfermería, Universidad Complutense de Madrid, Madrid, Spain},
	abstract = {Introduction/Background Mass-casualty incidents (MCIs) and disasters require an organised and effective response from medical first responders (MFRs). As such, novel training methods have emerged to prepare and adequately train MFRs for these challenging situations. Particular focus should be placed on extended reality (XR), which encompasses virtual, augmented and mixed reality (VR, AR, and MR, respectively), and allows participants to develop high-quality skills in realistic and immersive environments. Given the rapid evolution of high-fidelity simulation technology and its advantages, XR simulation has become a promising tool for emergency medicine. Accordingly, this systematic review aims to: 1) evaluate the effectiveness of XR training methods and 2) explore the experience of MFRs undergoing such training. Methods A comprehensive search strategy will encompass four distinct themes: MFRs, disasters/ MCIs, education and simulation, and XR. Four databases (MEDLINE, EMBASE, CINAHL and LILACs) will be searched along with an in-depth examination of the grey literature and reference lists of relevant articles. MetaQAT will be used as a study quality assessment tool and integrated into Covidence as part of the data extraction form. Given the predicted high heterogeneity between studies, it may not be possible to standardise data for quantitative comparison and meta-analysis. Thus, data will be synthesised in a narrative, semi-quantitative manner. Discussion This review will examine the existing literature on the effectiveness of XR simulation as a tool to train MFRs for MCIs, which could ultimately improve preparedness and response to disasters. Copyright: © 2023 Otero-Varela et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.},
	keywords = {Augmented Reality; Computer Simulation; Educational Status; Emergency Responders; Humans; Mass Casualty Incidents; Meta-Analysis as Topic; Systematic Reviews as Topic; adult; article; Cinahl; comparative effectiveness; data extraction; disaster; education; Embase; emergency medicine; female; grey literature; high-fidelity simulation; human; human experiment; male; mass disaster; Medline; meta analysis; narrative; quality assessment tool; quantitative analysis; simulation; systematic review; computer simulation; educational status; meta analysis (topic); rescue personnel},
	correspondence_address = {M. del Carmen Cardós Alonso; Servicio de Urgencias Médicas de la Comunidad de Madrid (SUMMA112), Madrid, Spain; email: carmen.cardos@salud.madrid.org},
	publisher = {Public Library of Science},
	issn = {19326203},
	coden = {POLNC},
	pmid = {36952495},
	language = {English},
	abbrev_source_title = {PLoS ONE},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Vivek2023919,
	author = {Vivek, Meghashyam and Prathap, Boppuru Rudra},
	title = {Crime Analysis and Forecasting using Twitter Data in the Indian Context},
	year = {2023},
	journal = {2023 International Conference on Artificial Intelligence and Smart Communication, AISC 2023},
	pages = {919 – 924},
	doi = {10.1109/AISC56616.2023.10085282},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153519036&doi=10.1109%2fAISC56616.2023.10085282&partnerID=40&md5=fc7d19a78977998370c9d23913a09a37},
	affiliations = {CHRIST(Deemed to Be University), Computer Science and Engineering, Bangalore, India},
	abstract = {Since the late 1990s, social media has added more features and users. Due to the rise of social media, blogs and posts by common people are now a part of mainstream journalism. Twitter is a place where people can share their ideas about culture, society, the economy, and politics. India's large population and rising crime rate make it hard for law enforcement to find and stop illegal activities. This article shows the use of Twitter data to analyse, forecast, and visualise criminal activity using statistical and machine learning models and geospatial visualisation techniques. This helps law enforcement agencies make the best use of their limited resources and put them in the right places. The research aims to present a spatial and temporal picture of crime in India and is split into three parts: Classification, Visualisation, and Forecasting. Crime tweets are identified using a hashtag query argument in the tweepy python package's search_tweets function, followed by substring-keyword classification. The visualisation uses gmaps and bokeh python packages for geospatial and matplotlib for analytical applications. The forecasting portion compares AR, ARIMA, and LSTM to determine the best model for time series forecasting of crime tweet count.  © 2023 IEEE.},
	author_keywords = {Crime prediction; Crimeanalysis; Machine Learning; Social media; Twitter},
	keywords = {Crime; High level languages; Long short-term memory; Social networking (online); Visualization; Crime prediction; Crimeanalyse; Criminal activities; Illegal activities; Large population; Machine learning models; Machine-learning; Social media; Statistical learning; Twitter; Forecasting},
	correspondence_address = {M. Vivek; CHRIST(Deemed to Be University), Computer Science and Engineering, Bangalore, India; email: meghashyam.vivek@btech.christuniversity.in},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835032230-9},
	language = {English},
	abbrev_source_title = {Int. Conf. Artif. Intell. Smart Commun., AISC},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2023 International Conference on Artificial Intelligence and Smart Communication, AISC 2023; Conference date: 27 January 2023 through 29 January 2023; Conference code: 187724}
}

@CONFERENCE{Uhl2023,
	author = {Uhl, Jakob Carl and Schrom-Feiertag, Helmut and Regal, Georg and Gallhuber, Katja and Tscheligi, Manfred},
	title = {Tangible Immersive Trauma Simulation: Is Mixed Reality the next level of medical skills training?},
	year = {2023},
	journal = {Conference on Human Factors in Computing Systems - Proceedings},
	doi = {10.1145/3544548.3581292},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160009186&doi=10.1145%2f3544548.3581292&partnerID=40&md5=7624d3172892745a17344122d6dde01f},
	affiliations = {Ait Austrian Institute of Technology, Vienna, Austria; Plus University of Salzburg, Salzburg, Austria},
	abstract = {In medical simulation training two approaches are currently rather disjunct: realistic manikins are used to teach physical skills and procedures and VR systems are used to train situation assessment and decision making. We propose a mixed reality approach, which allows trainees to use real tools and their hands when interacting with a physical manikin overlaid with a responsive virtual avatar. In close exchange with first responder organizations, we developed and evaluated an MR training scenario. In the scenario, users can talk to injured people in a car accident, assess the threat of the environment, and utilize real medical equipment. Participants experienced high levels of physical- and self-presence, increased stress levels, and reported a high technology acceptance. The proposed main requirements of first responders regarding haptic multi-sensory skill training in MR and the lessons learned from the workshop aim to guide the design of training solutions for medical training in MR. © 2023 Owner/Author.},
	author_keywords = {first responder; haptic feedback; mixed reality; presence; training},
	keywords = {Accidents; Behavioral research; Decision making; First responders; Haptic feedbacks; Immersive; Medical simulations; Mixed reality; Presence; Simulation training; Situation assessment; Skill training; VR systems; Mixed reality},
	publisher = {Association for Computing Machinery},
	isbn = {978-145039421-5},
	language = {English},
	abbrev_source_title = {Conf Hum Fact Comput Syst Proc},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; Conference name: 2023 CHI Conference on Human Factors in Computing Systems, CHI 2023; Conference date: 23 April 2023 through 28 April 2023; Conference code: 188036; All Open Access, Bronze Open Access}
}

@CONFERENCE{Laffan2020439,
	author = {Laffan, Cassandra Frances and Coleshill, James Elliott and Stanfield, Brodie and Stanfield, Michael and Ferworn, Alexander},
	title = {Using the ARAIG Haptic Suit to Assist in Navigating Firefighters out of Hazardous Environments},
	year = {2020},
	journal = {11th Annual IEEE Information Technology, Electronics and Mobile Communication Conference, IEMCON 2020},
	pages = {439 – 444},
	doi = {10.1109/IEMCON51383.2020.9284922},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099280534&doi=10.1109%2fIEMCON51383.2020.9284922&partnerID=40&md5=4473bed5925ddbc88763ae064863eb1f},
	affiliations = {Ryerson University, Department of Computer Science, Toronto, Canada; IFTech Inventing Future Technology Inc., Whitby, Canada},
	abstract = {The field of search and rescue (SAR) has not yet fully benefited from strides in haptic technologies. In this research, we seek to rectify this issue by proposing a novel application of IFTech's 'As Real As It Gets' (ARAIG) wearable haptic suit for firefighters. First, we examine recent research in this field in order to lay down the groundwork for our project. Next, we present a wearable haptic system in which the ARAIG suit is outfitted with peripheral sensors in order to track the emergency responder's path; the system will then recreate the path and relay exit directions via haptic feedback to the wearer. Thus, the first responder does not have to dedicate more attention than necessary to remembering their entry path. Finally, the future of this project is outlined, which includes a physical implementation of this proposed system. © 2020 IEEE.},
	author_keywords = {Haptics; Navigation; Path Planning; Search and Rescue},
	keywords = {Fire extinguishers; Wearable technology; Emergency responders; Haptic feedbacks; Haptic technology; Hazardous environment; Novel applications; Peripheral sensors; Recent researches; Search and rescue; Mobile telecommunication systems},
	editor = {Paul R.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-172818416-6},
	language = {English},
	abbrev_source_title = {Annu. IEEE Inf. Technol., Electron. Mob. Commun. Conf., IEMCON},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; Conference name: 11th Annual IEEE Information Technology, Electronics and Mobile Communication Conference, IEMCON 2020; Conference date: 4 November 2020 through 7 November 2020; Conference code: 166022}
}

@ARTICLE{Rebol2023415,
	author = {Rebol, Manuel and Steinmaurer, Alexander and Gamillscheg, Florian and Pietroszek, Krzysztof and Gütl, Christian and Ranniger, Claudia and Hood, Colton and Rutenberg, Adam and Sikka, Neal},
	title = {CPR Emergency Assistance Through Mixed Reality Communication},
	year = {2023},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {13891 LNCS},
	pages = {415 – 429},
	doi = {10.1007/978-3-031-32883-1_38},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163278370&doi=10.1007%2f978-3-031-32883-1_38&partnerID=40&md5=cd4cc99216d95e735845e323c99c15f7},
	affiliations = {Graz University of Technology, Graz, Austria; American University, Washington, DC, United States; George Washington University, Washington, DC, United States},
	abstract = {We design and evaluate a mixed reality real-time communication system for remote assistance during CPR emergencies. Our system allows an expert to guide a first responder, remotely, on how to give first aid. RGBD cameras capture a volumetric view of the local scene including the patient, the first responder, and the environment. The volumetric capture is augmented onto the remote expert’s view to spatially guide the first responder using visual and verbal instructions. We evaluate the mixed reality communication system in a research study in which participants face a simulated emergency. The first responder moves the patient to the recovery position and performs chest compressions as well as mouth-to-mask ventilation. Our study compares mixed reality against videoconferencing-based assistance using CPR performance measures, cognitive workload surveys, and semi-structured interviews. We find that more visual communication including gestures and objects is used by the remote expert when assisting in mixed reality compared to videoconferencing. Moreover, the performance and the workload for the first responder during simulation does not differ significantly between the two technologies. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {CPR; Mixed Reality; Remote collaboration},
	keywords = {Patient rehabilitation; Video conferencing; Visual communication; CPR; First aids; First responders; Mixed reality; Real-time communication system; Remote assistance; Remote collaboration; Remote experts; Verbal instructions; Volumetrics; Mixed reality},
	correspondence_address = {M. Rebol; Graz University of Technology, Graz, Austria; email: rebol@gwu.edu},
	editor = {Frasson C. and Mylonas P. and Troussas C.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303132882-4},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 19th International Conference on Augmented Intelligence and Intelligent Tutoring Systems, ITS 2023; Conference date: 2 June 2023 through 5 June 2023; Conference code: 295299}
}

@CONFERENCE{Dahlke2023242,
	author = {Dahlke, Dennis and Kaiser, Susanna and Bayer, Steven},
	title = {Self-Localization: A proposal to equip first responders with a robust and accurate GNSS device},
	year = {2023},
	journal = {Proceedings of the International ISCRAM Conference},
	volume = {2023-text},
	pages = {242 – 251},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171776408&partnerID=40&md5=287a961ec722b02f7c67f50907df4b4b},
	affiliations = {DLR German Aerospace Center, Germany; I.S.A.R, Germany},
	abstract = {In this paper we explore the GNSS positioning capabilities in the context of search and rescue operations. Our contribution is a tool that robustly receives and precisely evaluates GNSS signals. The final positioning information is then transmitted to an orchestrator where other tools like augmented reality utilities or the command and control have access to. During the time from the project start in September 2021 to December 2022 the components have been chosen, and the design and software of the tool have been developed. Furthermore, some of the tool’s capabilities have been tested and compared during field trials with first responders and measurement campaigns. The developed tool outperforms the commonly used smartphone localization in terms of accuracy, operation time and time to get a GNSS fix. This reliability improvement helps to identify someones position in adverse conditions. © 2023 Information Systems for Crisis Response and Management, ISCRAM. All rights reserved.},
	author_keywords = {first responder localization; GNSS; multi constellation GNSS; multi frequency GNSS; Self-Localization},
	keywords = {Access control; Augmented reality; Global positioning system; Information management; Information systems; First responder localization; First responders; GNSS; GNSS signals; Localisation; Multi constellation GNSS; Multi frequency; Multi frequency GNSS; Search and rescue operations; Self localization; Information use},
	correspondence_address = {D. Dahlke; DLR German Aerospace Center, Germany; email: dennis.dahlke@dlr.de},
	publisher = {Information Systems for Crisis Response and Management, ISCRAM},
	issn = {24113387},
	isbn = {979-821821749-5},
	language = {English},
	abbrev_source_title = {Proc. Int. ISCRAM Conf.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 20th Global Information Systems for Crisis Response and Management Conference, ISCRAM 2023; Conference date: 28 May 2023 through 31 May 2023; Conference code: 192193}
}

@ARTICLE{Croghan2022,
	author = {Croghan, Ivana T. and Hurt, Ryan T. and Aakre, Christopher A. and Fokken, Shawn C. and Fischer, Karen M. and Lindeen, Stephanie A. and Schroeder, Darrell R. and Ganesh, Ravindra and Ghosh, Karthik and Bauer, Brent A.},
	title = {Virtual Reality for Health Care Professionals During a Pandemic: A Pilot Program},
	year = {2022},
	journal = {Journal of Primary Care and Community Health},
	volume = {13},
	doi = {10.1177/21501319221086716},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127267049&doi=10.1177%2f21501319221086716&partnerID=40&md5=3a955be578f3f4b0afee67200a1e3e43},
	affiliations = {Mayo Clinic, Rochester, MN, United States},
	abstract = {Objective: The purpose of this pilot study was to evaluate the safety and use of a nature-based virtual reality (VR) experience among health care providers (HCP) during a pandemic. Methods: Twenty-four frontline HCP participated in this crossover pilot where the viewing order of the experiences were randomized. All participants attended in-person consent, baseline, and end-of-study visits. The intervention consisted of viewing 2 nature-based scenes (“walk in the woods” and “forest of focus”) through 3-D VR and with computer 4K graphic imagery. Randomization took place with regards to the viewing order (VR vs 4K computer video, scene 1 and 2). Outcomes measured were safety, acceptability and changes in intensity of anxiety feelings, resilience, emotional distress, cognitive function, and self-efficacy. Results: Among the 26 HCP expressing interest in the study, 24 enrolled in this study. The majority were male (58.3%), white (66.7%) and of an average age of 46.3 ± 10.5 years (standard deviation (SD)). End of the study survey showed that almost all participants (96%) would participate in the study again and recommend it to others. Twenty-three of the 24 participants also felt relaxed after seeing the imagery. With respect to anxiety (as measured by the STAI Y1), the VR “walk in the woods” had the greatest reduction from pre to post (6.4 points, SD = 5.98) followed by VR “forest of focus” (5.8 points, SD = 9.29), computer screen “forest of focus” (5.0 points, SD = 8.89), and computer screen “walk in the woods” (4.1 points, SD = 6.22). All 4 sessions had a significant decrease in score from pre to post (P-values ≤.005), but there was no significant difference in the change from pre- to post-session between the 4 groups (P-value =.5835). Conclusion: The use of the VR among HCP has promise for reducing stress among health care providers during a high stress period, such as a pandemic but much larger studies are needed. © The Author(s) 2022.},
	author_keywords = {first responders; pandemic; virtual reality; wearable technology},
	keywords = {Adult; Emotions; Female; Health Personnel; Humans; Male; Middle Aged; Pandemics; Pilot Projects; Virtual Reality; adult; emotion; female; health care personnel; human; male; middle aged; pandemic; pilot study; virtual reality},
	correspondence_address = {I.T. Croghan; Mayo Clinic, Rochester, United States; email: croghan.ivana@mayo.edu},
	publisher = {SAGE Publications Inc.},
	issn = {21501319},
	pmid = {35352605},
	language = {English},
	abbrev_source_title = {J. Prim. Care Community Health},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Stefanidi202223367,
	author = {Stefanidi, Zinovia and Margetis, George and Ntoa, Stavroula and Papagiannakis, George},
	title = {Real-Time Adaptation of Con-Aware Intelligent User Interfaces, for Enhanced Situational Awareness},
	year = {2022},
	journal = {IEEE Access},
	volume = {10},
	pages = {23367 – 23393},
	doi = {10.1109/ACCESS.2022.3152743},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125348791&doi=10.1109%2fACCESS.2022.3152743&partnerID=40&md5=09625214432e87c2a401b0b9ebda1511},
	affiliations = {Institute of Computer Science, Foundation for Research and Technology - Hellas (FORTH), Heraklion, 70013, Greece; Department of Computer Science, University of Crete, Heraklion, 700 13, Greece},
	abstract = {In this work, a novel computational approach for the dynamic adaptation of User Interfaces (UIs) is proposed, which aims at enhancing the Situational Awareness (SA) of users by leveraging the current con and providing the most useful information, in an optimal and efficient manner. By combining Ontology modeling and reasoning with Combinatorial Optimization, the system decides what information to present, when to present it, where to visualize it in the display - and how, taking into consideration conual factors as well as placement constraints. The main objective of the proposed approach is to optimize the SA associated with the displayed UI at run-time, while avoiding information overload and induced stress. In the con of this work, we have deployed our computational approach to the use case of an Augmented Reality (AR) system for Law Enforcement Agents (LEAs). To explore the benefits and limitations of the developed system, two evaluations have been conducted. The first one was an expert-based evaluation with LEAs and User Experience (UX) experts, assessing the appropriateness of the system's decisions. The second one was a user-based evaluation involving LEAs from different agencies, estimating the SA, the mental workload and the overall UX associated with the system, through an AR simulation. The results indicate that the system enhances SA, and while not imposing workload, it provides an overall positive UX.  © 2013 IEEE.},
	author_keywords = {Adaptive user interfaces; augmented reality; con-awareness; intelligent user interfaces; ontology modeling; ontology reasoning; situational awareness; user interface optimization},
	keywords = {Augmented reality; Combinatorial optimization; Computational methods; Ontology; Adaptive user interface; Computational approach; Context- awareness; Intelligent User Interfaces; Ontology model; Ontology reasonings; Optimisations; Real-time adaptation; Situational awareness; User interface optimization; User interfaces},
	correspondence_address = {G. Margetis; Institute of Computer Science, Foundation for Research and Technology - Hellas (FORTH), Heraklion, 70013, Greece; email: gmarget@ics.forth.gr},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {21693536},
	language = {English},
	abbrev_source_title = {IEEE Access},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Gold Open Access}
}

@ARTICLE{Voskobitova2022251,
	author = {Voskobitova, Lidiya A. and Przhilenskiy, Vladimir I.},
	title = {Transformation of Legal Reality under the Impact of Digitalization},
	year = {2022},
	journal = {Kutafin Law Review},
	volume = {9},
	number = {2},
	pages = {251 – 276},
	doi = {10.17803/2713-0525.2022.2.20.251-276},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134319777&doi=10.17803%2f2713-0525.2022.2.20.251-276&partnerID=40&md5=a9624ba0536eb50e12c6e2aa7c83e832},
	affiliations = {Department of Criminal Procedure Law, Kutafin Moscow State Law University (MSAL), Moscow, Russia, 9 Sadovaya-Kudrinskaya ulitsa, Moscow, 125993, Russian Federation; Department of Philosophic and Socio-Economic Disciplines, Kutafin Moscow State Law University (MSAL), Moscow, Russia, 9 Sadovaya-Kudrinskaya ulitsa, Moscow, 125993, Russian Federation},
	abstract = {The article examines the processes of digitalization of law, their causes, sources, driving forces, real and foreseeable consequences from a social constructivist perspective. Local experiences in the design and implementation of digitalization of criminal proceedings are described in detail, and expert assessments of the early successes and difficulties of digitalization in the sphere of rulemaking, law enforcement and law implementation in general are given. A counterpoint to the analysis of the processes of change in the legal reality, which takes place under the impact of its digitalization, is the hypothesis expressed in the literature about possible transformation of law into another social regulator or the birth of some hybrid form, which would include only certain elements of legal regulation. The article comments on the debate about the significance of digitalization for the essence of law as a social regulator. It considers the arguments of those who believe that the changes will lead to a radical transformation and the arguments of those who see these changes as merely technical details of law enforcement, not affecting its essence. Separate consideration is given to practical cases such as the project aimed at digitalization of criminal proceedings in the UK as well as experiments in digital, virtual and augmented reality in the US (digital environment "META," "virtual reality," "reality+," etc.). The philosophical and legal theoretical concepts of digitalization of law in the context of projects of total virtualization of reality and digitalization of social practices are critically analyzed. © 2022 The authors.},
	author_keywords = {construction of reality; digital reality; digitalization; legal reality; regulator; virtual reality},
	publisher = {Kutafin Moscow State Law University (MSAL)},
	issn = {27130525},
	language = {English},
	abbrev_source_title = {Kutafin. Law. Rev.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Jiang2021732,
	author = {Jiang, Lin and Zhao, Sensen and Wang, Lijun},
	title = {A training system for the rescue process of acute and severe diseases based on AR},
	year = {2021},
	journal = {Digest of Technical Papers - SID International Symposium},
	volume = {52},
	number = {S2},
	pages = {732},
	doi = {10.1002/sdtp.15269},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115856168&doi=10.1002%2fsdtp.15269&partnerID=40&md5=775da1f2cb0eda861e2f2c98883c210b},
	affiliations = {School of Information Science and Technology, North China University of Technology, Beijing, China},
	abstract = {China is one of the countries with the most serious natural disasters in the world. Hidden dangers and risks of all kinds of accidents are intertwined and superimposed, and the factors affecting public safety are increasing. It is urgent to strengthen the construction of emergency medical rescue capacity. During the nineteenth collective learning of the Central Political Bureau, general secretary Xi Jinping stressed that we should strengthen the capacity building of aviation emergency rescue and improve the airspace guarantee mechanism for emergency rescue. As the most important aerial medical evacuation platform, helicopter has the advantages of fast response, strong mobility, wide rescue range, direct arrival at the first line of treatment, etc. it has become an important means of modern rescue, and also the only way to open life treatment in case of land damage. From the international experience, the helicopter emergency medical system established by most developed countries plays an important role in disaster relief and anti-terrorism. China has a large population, complex terrain and uneven regional development. In case of disasters, the casualties are often more severe and the demand for treatment is more urgent. It is urgent to establish an aviation medical emergency rescue system suitable for the national conditions and with helicopters as the main carrier, and accelerate the research and development of key technical equipment. In recent years, more and more people realize the necessity and benefits of the application of interactive technology for aviation medical simulation training in major events and disasters. Interaction refers to the transmission and exchange of intelligence, data, data and technical knowledge in all aspects of nature and society. From the perspective of information theory, local chronicles are a tangible text information carrier, which collects all kinds of information in a certain region. Interactive technology is to use certain means to achieve the purpose of interaction, and gradually enter the era of multi field application! In the field of aviation medical rescue, it is in urgent need of penetration and integration. This paper mainly develops an AR emergency rescue process training system. Through the creation of data sets, action recognition based on computer vision and deep learning, the selection of recognition model and action capture, the action is recognized based on AR, and then 22 joint points of human hand and upper arm skeleton are taken to label the data space position. Through the above learning results, we can get the real-time hand recognition based on depth information Upper arm skeleton output. Neural network is used to recognize human skeleton action. The skeleton information coordinates are imported into RNN neural network for deep learning. Finally, based on the complementarity of CNN and LSTM, combined with the idea of dual stream structure network, the action recognition is carried out. © 2021, John Wiley and Sons Inc. All rights reserved.},
	author_keywords = {AR; Aviation medical rescue; Key points of hand; Simulation training},
	keywords = {Antennas; Disaster prevention; Knowledge management; Regional planning; Terrorism; Action recognition; AR; Aviation medical rescue; Emergency rescue; Interactive technology; Key point of hand; Keypoints; Rescue process; Simulation training; Training Systems; Deep learning},
	publisher = {John Wiley and Sons Inc},
	issn = {0097966X},
	language = {English},
	abbrev_source_title = {Dig. Tech. Pap. SID Int. Symp.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: International Conference on Display Technology, ICDT 2021; Conference date: 30 May 2021 through 2 June 2021; Conference code: 264989}
}

@CONFERENCE{Saidi2023,
	author = {Saidi, Sofian and Zyout, Imad and Matar, B. and Alsebeyi, A. and Binsultan, M. and Alreesi, F. and Almarzooqi, S.},
	title = {Smart Inspection Glove: A real-time inspection and analysis system based on Raspberry Pi},
	year = {2023},
	journal = {2023 Advances in Science and Engineering Technology International Conferences, ASET 2023},
	doi = {10.1109/ASET56582.2023.10180873},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167463578&doi=10.1109%2fASET56582.2023.10180873&partnerID=40&md5=7bcd0cc617ac33b4bc6216f24e50e4a8},
	affiliations = {Higher Colleges of Technology, Electrical Engineering Technology, United Arab Emirates},
	abstract = {This paper presents a new device for prisoner screening and inspection called a smart inspection glove system (SIG) system. This proposed system for monitoring and recording the inspection procedure, assures high safety and availability of a healthy environment in prisons. The dashboard feature is also provided to allow the end user to capture and track different checkpoints. The primary cause of creating SIG is to enable agents to use it in prisons for the inmates that can detect if they have metal tools, capture serious movements and drugs, and record heart rate. Most policemen will get an advantage from this glove as having all these features in a glove will ease the inspection process as well as it would be safer for them as it will capture every movement of the inmate. Furthermore, to make the gloves secure, when used, the RFID reader is added to verify the inspector's identity at beginning of the duty. On the other hand, all the data of the prisoner will be saved and can be reviewed later by police officers through their dashboards. The Raspberry Pi has been chosen for developing the system prototype because of its versatile features and excellent performance at low costs.  © 2023 IEEE.},
	author_keywords = {IoT; Raspberry Pi; Safety screening; Wearable device},
	keywords = {Internet of things; Law enforcement; Wearable technology; Analysis system; Inspection procedures; Inspection system; IoT; New devices; Raspberry pi; Real time analysis; Realtime inspection; Safety screening; Wearable devices; Inspection},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-166545474-2},
	language = {English},
	abbrev_source_title = {Adv. Sci. Eng. Technol. Int. Conf., ASET},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2023 Advances in Science and Engineering Technology International Conferences, ASET 2023; Conference date: 20 February 2023 through 23 February 2023; Conference code: 190914}
}

@ARTICLE{de Vries2023,
	author = {de Vries, Herman J. and Pennings, Helena J. M. and van der Schans, Cees P. and Sanderman, Robbert and Oldenhuis, Hilbrand K. E. and Kamphuis, Wim},
	title = {Wearable-Measured Sleep and Resting Heart Rate Variability as an Outcome of and Predictor for Subjective Stress Measures: A Multiple N-of-1 Observational Study},
	year = {2023},
	journal = {Sensors},
	volume = {23},
	number = {1},
	doi = {10.3390/s23010332},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145884718&doi=10.3390%2fs23010332&partnerID=40&md5=ce99d29bcdfe217f36e0fa521b10dfa1},
	affiliations = {Research Group Digital Transformation, Hanze University of Applied Sciences, Groningen, 9747 AS, Netherlands; Department of Human Behaviour & Training, Netherlands Organization for Applied Scientific Research (TNO), Soesterberg, 3769 DE, Netherlands; Department of Health Psychology, University Medical Center Groningen, Groningen, 9700 AB, Netherlands; Utrecht Center for Research and Development of Health Professions Education, University Medical Center Utrecht, Utrecht, 3584 CX, Netherlands; Department of Rehabilitation Medicine, University Medical Center Groningen, Groningen, 9700 AB, Netherlands; Research Group Healthy Ageing Allied Health Care and Nursing, Hanze University of Applied Sciences, Groningen, 9747 AS, Netherlands; Department of Psychology, Health and Technology, University of Twente, Enschede, 7522 NB, Netherlands},
	abstract = {The effects of stress may be alleviated when its impact or a decreased stress-resilience are detected early. This study explores whether wearable-measured sleep and resting HRV in police officers can be predicted by stress-related Ecological Momentary Assessment (EMA) measures in preceding days and predict stress-related EMA outcomes in subsequent days. Eight police officers used an Oura ring to collect daily Total Sleep Time (TST) and resting Heart Rate Variability (HRV) and an EMA app for measuring demands, stress, mental exhaustion, and vigor during 15–55 weeks. Vector Autoregression (VAR) models were created and complemented by Granger causation tests and Impulse Response Function visualizations. Demands negatively predicted TST and HRV in one participant. TST negatively predicted demands, stress, and mental exhaustion in two, three, and five participants, respectively, and positively predicted vigor in five participants. HRV negatively predicted demands in two participants, and stress and mental exhaustion in one participant. Changes in HRV lasted longer than those in TST. Bidirectional associations of TST and resting HRV with stress-related outcomes were observed at a weak-to-moderate strength, but not consistently across participants. TST and resting HRV are more consistent predictors of stress-resilience in upcoming days than indicators of stress-related measures in prior days. © 2022 by the authors.},
	author_keywords = {ecological momentary assessment; heart rate variability; police; resilience; sleep; stress; time series analysis; wearables},
	keywords = {Computers; Heart Rate; Humans; Sleep; Sleep Duration; Wearable Electronic Devices; Ecology; Heart; Impulse response; Law enforcement; Regression analysis; Sleep research; Wearable technology; Demand stress; Ecological momentary assessment; Heart rate variability; Police officers; Resilience; Resting heart rate; Sleep; Sleep time; Time-series analysis; Wearables; computer; electronic device; heart rate; human; physiology; sleep; sleep time; Time series analysis},
	correspondence_address = {H.J. de Vries; Research Group Digital Transformation, Hanze University of Applied Sciences, Groningen, 9747 AS, Netherlands; email: herman.devries@tno.nl},
	publisher = {MDPI},
	issn = {14248220},
	pmid = {36616929},
	language = {English},
	abbrev_source_title = {Sensors},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Ghosh2023157,
	author = {Ghosh, Partho and Istiak, Md. Abrar and Rashid, Nayeeb and Akash, Ahsan Habib and Abrar, Ridwan and Dastider, Ankan Ghosh and Sushmit, Asif Shahriyar and Hasan, Taufiq},
	title = {Activity Classification from First-Person Office Videos with Visual Privacy Protection},
	year = {2023},
	journal = {Lecture Notes in Electrical Engineering},
	volume = {980 LNEE},
	pages = {157 – 169},
	doi = {10.1007/978-981-19-8032-9_12},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164953343&doi=10.1007%2f978-981-19-8032-9_12&partnerID=40&md5=83cb7803d2c6475337062ed7400b3bdc},
	affiliations = {Department of Electrical and Electronic Engineering (EEE), Bangladesh University of Engineering and Technology (BUET), Dhaka, 1205, Bangladesh; mHealth Research Group, Department of Biomedical Engineering (BME), Bangladesh University of Engineering and Technology (BUET), Dhaka, 1205, Bangladesh},
	abstract = {With the advent of wearable body cameras, human activity classification from First-Person Videos (FPV) has become a topic of increasing importance for various applications, including life-logging, law enforcement, sports, workplace, and health care. One of the challenging aspects of FPV is its exposure to potentially sensitive objects within the user’s field of view. In this work, we developed a visual privacy-aware activity classification system focusing on office videos. We utilized a Mask R-CNN with an Inception-ResNet hybrid as a feature extractor for detecting and later blurring out sensitive objects (e.g., digital screens, human face, paper) from the videos. We incorporate an ensemble of Recurrent Neural Networks (RNNs) with ResNet, ResNeXt, and DenseNet-based feature extractors for activity classification. The proposed system was trained and evaluated on the FPV office video dataset which is a subset of the BON [1] vision dataset for office activity recognition (2021) and includes 18 classes made available through the IEEE Video and Image Processing (VIP) Cup 2019 competition. On the original unprotected FPVs, the proposed activity classifier ensemble reached an accuracy of 85.078% with precision, recall, and F1 scores of 0.88, 0.85, and 0.86, respectively. The performances were slightly degraded on privacy-protected videos, with accuracy, precision, recall, and F1 scores at 73.68%, 0.79, 0.75, and 0.74, respectively. © 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.},
	author_keywords = {Activity classification; First person video; Visual privacy protection},
	keywords = {Image processing; Sports; Wearable technology; Activity classifications; F1 scores; Feature extractor; Field of views; First person; First person video; Human activities; Lifelogging; Privacy protection; Visual privacy protection; Recurrent neural networks},
	correspondence_address = {T. Hasan; mHealth Research Group, Department of Biomedical Engineering (BME), Bangladesh University of Engineering and Technology (BUET), Dhaka, 1205, Bangladesh; email: taufiq@bme.buet.ac.bd},
	editor = {Hossain M.S. and Majumder S.P. and Siddique N. and Hossain M.S.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {18761100},
	isbn = {978-981198031-2},
	language = {English},
	abbrev_source_title = {Lect. Notes Electr. Eng.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: International Conference on 4th Industrial Revolution and Beyond, IC4IR 2021; Conference date: 10 December 2021 through 11 December 2021; Conference code: 297489}
}

@CONFERENCE{Ismael2023591,
	author = {Ismael, Muhannad and McCall, Roderick and Cornil, Maël and Griffin, Mike and Baixauli, Joan},
	title = {Radiological Incident System using Augmented Reality (RISAR)},
	year = {2023},
	journal = {Proceedings - 2023 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops, VRW 2023},
	pages = {591 – 592},
	doi = {10.1109/VRW58643.2023.00138},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159711059&doi=10.1109%2fVRW58643.2023.00138&partnerID=40&md5=ccb518571781d8b4ffd3878d48615b0f},
	affiliations = {Luxembourg Institute of Science and Technology (LIST), IT for Innovative Services (ITIS) Department, Luxembourg, Luxembourg},
	abstract = {This paper presents an Augmented Reality (AR) solution called RISAR that allows for the real-time visualisation of Radiological hazards based on sensor data captured from detectors as well as Unmanned Aerial and Ground Vehicles. RISAR improves safety for first responders during radiological events by enhancing their situation awareness. This lowers the risk of harm, and with it any health impacts and costs.  © 2023 IEEE.},
	author_keywords = {Human computer interaction (HCI); Human-centered computing; Mixed / Augmented reality},
	keywords = {Antennas; Ground vehicles; Health risks; Human computer interaction; First responders; Health costs; Health impact; Human computer interaction; Human-centered computing; Mixed / augmented reality; Radiological hazard; Real time visualization; Sensors data; Situation awareness; Augmented reality},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835034839-2},
	language = {English},
	abbrev_source_title = {Proc. - IEEE Conf. Virtual Real. 3D User Interfaces Abstr. Workshops, VRW},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2023 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops, VRW 2023; Conference date: 25 March 2023 through 29 March 2023; Conference code: 188382}
}

@ARTICLE{Waldman2022763,
	author = {Waldman, Hunter S. and Bryant, Andrea R. and Shepherd, Brandon D. and Egan, Brendan and McAllister, Matthew J.},
	title = {No Effect of a Ketone Monoester on Markers of Stress and Performance in a Live-Burn Search and Rescue in Firefighters},
	year = {2022},
	journal = {Journal of Strength and Conditioning Research},
	volume = {36},
	number = {3},
	pages = {763 – 771},
	doi = {10.1519/JSC.0000000000004194},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124931590&doi=10.1519%2fJSC.0000000000004194&partnerID=40&md5=23ef5d888c2f72b165290059dfd83f9f},
	affiliations = {Human Performance Research Laboratory, Department of Kinesiology, University of North Alabama, Florence, AL, United States; Applied Physiology Laboratory, Department of Kinesiology, Mississippi State University, Starkville, MS, United States; School of Health and Human Performance, National Institute for Cellular Biotechnology, Dublin City University, Dublin, Ireland; Metabolic and Applied Physiology Laboratory, Department of Health and Human Performance, Texas State University, San Marcos, TX, United States},
	abstract = {Waldman, HS, Bryant, AR, Shepherd, BD, Egan, B, and McAllister, MJ. No effect of a ketone monoester on markers of stress and performance in a live-burn search and rescue in firefighters. J Strength Cond Res 36(3): 763-771, 2022 - Firefighters experience a range of stressors that impair performance and elevate the risk for developing cardiometabolic diseases. β-Hydroxybutyrate (βHB) has been shown to mitigate markers of oxidative stress and inflammation and serve as an alternative fuel with implications to physical performance. On 2 occasions in a double-blind, counterbalanced, and crossover design, 14 professional firefighters performed a live-burn, search and rescue (S&R) 30 minutes after ingestion of a ketone monoester (KME; 0.5 g·kg-1) or a placebo (PLA). Dependent variables collected before and after the S&R included salivary markers of stress and inflammation (cortisol, α-amylase, interleukin-1 beta, uric acid), perceptual markers (profile of mood state [POMS]), gastrointestinal distress (GI), rating of perceived exertion [RPE]), time to completion, and capillary blood measurement of βHB and glucose. KME resulted in capillary βHB concentrations of approximately 2.1-3.2 mM throughout the protocol. Capillary glucose concentrations were lower for the KME compared with PLA (∼7%) (interaction effect, p < 0.001). Salivary markers of stress, GI, and time to complete the S&R (∼10 minutes) did not differ between trials, although KME ingestion resulted in significantly higher RPE after the live-burn S&R (KME,6 ± 1; PLA, 4 ± 1). However, POMS data showed the KME also lowered subjective states of nervousness (KME, 0.0 ± 0.0; PLA, 0.6 ± 0.8) and anxiety (KME, 0.0 ± 0.0; PLA, 0.6 ± 0.7) before the S&R (all p < 0.05; large effect sizes). Compared with PLA, ingestion of a KME by firefighters did not mitigate the rise in various markers of salivary stress or impact physical performance during a live-burn S&R. However, differences in RPE and POMS variables were observed, suggesting a possible cognitive role for βHB. © 2022 NSCA National Strength and Conditioning Association. All rights reserved.},
	author_keywords = {cognition; high-stress occupation; inflammation; ketosis; oxidative stress; β-hydroxybutyrate},
	keywords = {Blood Glucose; Burns; Dietary Supplements; Firefighters; Humans; Ketones; Rescue Work; ketone; burn; controlled study; dietary supplement; fire fighter; glucose blood level; human; randomized controlled trial; rescue work},
	correspondence_address = {H.S. Waldman; Human Performance Research Laboratory, Department of Kinesiology, University of North Alabama, Florence, United States; email: Hswaldman@una.edu},
	publisher = {NSCA National Strength and Conditioning Association},
	issn = {10648011},
	pmid = {35180190},
	language = {English},
	abbrev_source_title = {J. Strength Cond. Res.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4}
}

@ARTICLE{Maneli20221,
	author = {Maneli, Mfundo A. and Isafiade, Omowunmi E.},
	title = {3D Forensic Crime Scene Reconstruction involving Immersive Technology: A Systematic Literature Review},
	year = {2022},
	journal = {IEEE Access},
	pages = {1–1},
	doi = {10.1109/ACCESS.2022.3199437},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136839898&doi=10.1109%2fACCESS.2022.3199437&partnerID=40&md5=6078a4dc80af78d7049190591269ad76},
	affiliations = {Department of Computer Science, Faculty of Natural Sciences, University of the Western Cape, Bellville, Cape Town, South Africa},
	abstract = {Recreation of 3D crime scenes is critical for law enforcement in the investigation of serious crimes for criminal justice responses. This work presents a premier systematic literature review (SLR) that offers a structured, methodical, and rigorous approach to understanding the trend of research in 3D crime scene reconstruction as well as tools, technologies, methods, and techniques employed thereof in the last 17 years. Major credible scholarly database sources, Scopus, and Google Scholar, which index journals and conferences that are promoted by entities such as IEEE, ACM, Elsevier, and SpringerLink were explored as data sources. Of the initial 17, 912 papers that resulted from the first search string, 258 were found to be relevant to our research questions after implementing the inclusion and exclusion criteria. To summarize the existing efforts, we compared and analysed various classical 3D reconstruction approaches. This study presents the first comprehensive review of key milestones in the development of methods for 3D crime scene reconstruction, gaps for improvement and where immersive technology has been used to enhance crime scene findings. This study found that the implementation of light detection and ranging (LiDAR) scanners and immersive technologies, alongside traditional methods, has been beneficial in the recreation of crime scenes. The SLR is limited to existing applications with peer-reviewed papers published between 2005 and 2021. Results based on the analysed published data indicated that 20.2% of the articles implemented immersive technologies in crime scene reconstruction, of which Augmented Reality (AR) accounted for 15.3%, Virtual Reality (VR) accounted for 75%, Mixed reality (MR) accounted for 5.9% and VR and AR mixture accounted for 3.8%. Finally, we summarize the development trend of design and key technology prospects of crime scene recreation using immersive technology and provide insights into potential future research. To the best of the researchers&#x2019; knowledge, this is the first survey that accomplishes such goals. Author},
	author_keywords = {3D reconstruction; augmented reality; Augmented reality; Crime scene; Documentation; forensic investigation; Forensics; image forensic; Immersive experience; immersive technology; Law enforcement; Market research; Reliability; systematic literature review (SLR); Systematics; Three-dimensional displays; Virtual reality; virtual reality},
	keywords = {Crime; Image reconstruction; Market Research; Mixed reality; Optical radar; Three dimensional displays; 3D reconstruction; Crime scenes; Documentation; Forensic; Forensic investigation; Image forensics; Immersive; Immersive experience; Immersive technologies; Market researches; Systematic; Systematic literature review; Three-dimensional display; Augmented reality},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {21693536},
	language = {English},
	abbrev_source_title = {IEEE Access},
	type = {Article},
	publication_stage = {Article in press},
	source = {Scopus},
	note = {Cited by: 8; All Open Access, Gold Open Access}
}

@CONFERENCE{Peretti2022,
	author = {Peretti, Oceane and Spyridis, Yannis and Sesis, Achilleas and Efstathopoulos, Georgios and Lytos, Anastasios and Lagkas, Thomas and Sarigiannidis, Panagiotis},
	title = {Augmented reality training, command and control framework for first responders},
	year = {2022},
	journal = {7th South-East Europe Design Automation, Computer Engineering, Computer Networks and Social Media Conference, SEEDA-CECNSM 2022},
	doi = {10.1109/SEEDA-CECNSM57760.2022.9932966},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142235028&doi=10.1109%2fSEEDA-CECNSM57760.2022.9932966&partnerID=40&md5=b9aff85b3abeab5b5f5e6d67cf003c36},
	affiliations = {0 Infinity Limited, London, United Kingdom; Sidroco Holdings Ltd, Nicosia, Cyprus; International Hellenic University, Department of Computer Science, Kavala, Greece; University of Western Macedonia, Department of Electrical and Computer Engineering, Kozani, Greece},
	abstract = {This paper presents an augmented reality (AR) training, command and control framework targeting the preparation of first responders for emergency situations. Utilising novel AR and virtual reality (VR) technologies, the framework aims to offer efficient training sessions, while minimising the cost and complexity associated with real-world exercises. An assortment of training examples and task execution sequences are available, while particular focus is given in the ability to personalise each training session according to specific emergencies or first responder needs. The control aspect of the framework offers insight about the deployment of each first responder on the field, allowing real-time visualisation based on their current location, while displaying useful information regarding health status and mission data.  © 2022 IEEE.},
	author_keywords = {augmented reality; command; emergency; first responders; training},
	keywords = {Emergency services; Virtual reality; Command; Command and control; Control framework; Emergency; Emergency situation; First responders; Real-world; Training framework; Training sessions; Virtual reality technology; Augmented reality},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835039858-8},
	language = {English},
	abbrev_source_title = {South-East Europe Des. Autom., Comput. Eng., Comput. Networks Soc. Media Conf., SEEDA-CECNSM},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 7th South-East Europe Design Automation, Computer Engineering, Computer Networks and Social Media Conference, SEEDA-CECNSM 2022; Conference date: 23 September 2022 through 25 September 2022; Conference code: 183967}
}

@ARTICLE{Myers202195,
	author = {Myers, Lorna and Trobliger, Robert and Goszulak, Shanneen},
	title = {Firefighter With Co-Morbid Psychogenic Non-Epileptic Seizures and Post-Traumatic Stress Disorder Treated With Prolonged Exposure Therapy: Long-Term Follow-Up},
	year = {2021},
	journal = {Clinical Case Studies},
	volume = {20},
	number = {2},
	pages = {95 – 114},
	doi = {10.1177/1534650120963181},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092151608&doi=10.1177%2f1534650120963181&partnerID=40&md5=c39514ea74c4809bf32b9263d7d61b5d},
	affiliations = {Northeast Regional Epilepsy Group, New York, NY, United States; Private Practice, Fort McMurray, AB, Canada},
	abstract = {Psychogenic non-epileptic seizures (PNES), are events that resemble epileptic seizures but lack electrophysiological or clinical evidence for epilepsy. Instead, they are psychogenic in origin. These episodes tend to occur with alterations in consciousness and bodily functions and are the result of mechanisms of conversion. Psychological trauma and post-traumatic stress disorder (PTSD) are prevalent among patients with PNES. This is a case report of a 32-year-old male who began treatment 1-year after developing PTSD followed some months later by PNES. His seizures were characterized by contorted movements of the head and neck, guttural sounds, and left sided movements or whole-body arching and were accompanied by frequent falls and injuries. They were usually brief but occurred daily. Psychotherapy had been discontinued because violent seizures often interrupted the sessions. He was treated with prolonged exposure (PE) at a PNES program and by the last session, had achieved an improvement in his seizure frequency (one every 4–6 days rather than daily episodes). This allowed him to begin therapy with a local therapist. Two years after completing treatment, the patient returned for a follow up visit. At that point, his seizure frequency, was one per month which shows he sustained and improved on this symptom. Former head drops, and grunting sounds disappeared, and he was no longer using a cane to ambulate. From an emotional standpoint (PTSD, suicidality, anxiety, quality of life), the patient had achieved and maintained a much healthier level of functioning (though no change on alexithymia, anger, depression, and trait anxiety). © The Author(s) 2020.},
	author_keywords = {conversion disorder; prolonged exposure; psychotherapy outcome; PTSD; trauma-focused CBT},
	keywords = {amphetamine; amphetamine plus dexamphetamine; clonazepam; gabapentin; naproxen; risperidone; sertraline; valaciclovir; adult; alexithymia; anger; anxiety; Article; breathing exercise; case report; clinical article; clinical assessment; cognitive function test; depression; DSM-5; electroencephalography; fire fighter; follow up; head movement; hematoma; human; interview; male; memory; middle aged; post traumatic stress diagnostic scale; posttraumatic stress disorder; psychogenic nonepileptic seizure; psychotherapist; psychotherapy; quality of life; seizure; sound; suicidal behavior; visual memory; Wechsler memory scale},
	correspondence_address = {L. Myers; Northeast Regional Epilepsy Group, New York, United States; email: lmyers@epilepsygroup.com},
	publisher = {SAGE Publications Inc.},
	issn = {15346501},
	language = {English},
	abbrev_source_title = {Clin. Case Stud.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@CONFERENCE{Wu20213122,
	author = {Wu, Jinting and Zhang, Yujia and Zhao, Xiaoguang},
	title = {Stress Detection Using Wearable Devices based on Transfer Learning},
	year = {2021},
	journal = {Proceedings - 2021 IEEE International Conference on Bioinformatics and Biomedicine, BIBM 2021},
	pages = {3122 – 3128},
	doi = {10.1109/BIBM52615.2021.9669904},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125182121&doi=10.1109%2fBIBM52615.2021.9669904&partnerID=40&md5=77b97d95be9709bf48004147ba72288e},
	affiliations = {The State Key Laboratory of Management and Control for Complex Systems Institute of Automation, Chinese Academy of Sciences, China; School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China},
	abstract = {Excessive stress will have a negative impact on people's physical and mental health, especially for some special occupations. Because stressful stimuli can trigger a variety of physiological responses, analyzing physiological signals collected by wearable devices has become an important way to evaluate the stress state in recent years. However, the number of available subjects of a target group may be small, and collecting a large amount of data when the target group changes is costly and time-consuming. To solve this problem, we propose a stress detection framework for a small target group which uses adversarial transfer learning method to learn shared knowledge about stress between different groups. In order to verify the performance of the framework, we establish a dataset consisting of 264 ordinary college students and 32 police school students, aiming to evaluate the acute stress state of police school students under video stimuli for psychological training in the future. Comprehensive experiments show that our algorithm has achieved a significant improvement in the target group compared with the baseline methods.  © 2021 IEEE.},
	author_keywords = {Physiological Signal Processing; Stress Detection; Transfer Learning; Wearable Devices},
	keywords = {Law enforcement; Learning systems; Physiological models; Physiology; Signal detection; Stresses; Wearable technology; Mental health; Physical health; Physiological response; Physiological signal processing; School students; Stress detection; Stress state; Target group; Transfer learning; Wearable devices; Students},
	editor = {Huang Y. and Kurgan L. and Luo F. and Hu X.T. and Chen Y. and Dougherty E. and Kloczkowski A. and Li Y.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-166540126-5},
	language = {English},
	abbrev_source_title = {Proc. - IEEE Int. Conf. Bioinform. Biomed., BIBM},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 2021 IEEE International Conference on Bioinformatics and Biomedicine, BIBM 2021; Conference date: 9 December 2021 through 12 December 2021; Conference code: 176400}
}

@CONFERENCE{Nelson2022336,
	author = {Nelson, Cassidy R. and Gabbard, Joseph L. and Moats, Jason B. and Mehta, Ranjana K.},
	title = {User-Centered Design and Evaluation of ARTTS: an Augmented Reality Triage Tool Suite for Mass Casualty Incidents},
	year = {2022},
	journal = {Proceedings - 2022 IEEE International Symposium on Mixed and Augmented Reality, ISMAR 2022},
	pages = {336 – 345},
	doi = {10.1109/ISMAR55827.2022.00049},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146419188&doi=10.1109%2fISMAR55827.2022.00049&partnerID=40&md5=421d89db54eb562898a23be1f3074ba4},
	affiliations = {Virginia Tech, United States; Texas A&m, United States},
	abstract = {In this work we present ARTTS: a head-worn Augmented Reality (AR) Triage Tool Suite containing an initial sorting tool, virtual assessment tool, and virtual triage tag to assist emergency responders in mass casualty incidents. The initial sorting tool can prompt novice responders through first-wave tasks to aid recalibration from shock to triage. The virtual assessment tool provides novice responders, potentially confused by the chaos, with a walkthrough of the SALT triage flowchart. Finally, current emergency medical triage processes leverage static paper tags susceptible to loss or illegible damage. ARTTS' virtual triage tags are dynamic, can be updated through responder interaction, and employ user interface emergent features based on individual patient conditions. This paper describes ARTTS' capabilities, as well as the applied user-centered design process including review of existing triage material, subject-matter expert interview transcripts, wireframing, application of usability and user-centered design principles, as well as iterative usability subject-matter expert assessments and design walkthroughs. The ARTTS user experience aims to enhance, not upend, existing triage processes. Finally, this paper provides a usability evaluation comparing ARTTS' virtual triage tag to a physical paper triage tag. Our tag achieved requisite System Usability Scale (SUS) scores and showed negligible differences to the paper triage tag on usability and mental workload.  © 2022 IEEE.},
	author_keywords = {Augmented reality; emergency response; first responders; mass casualty incident; triage},
	keywords = {Emergency services; Software design; Usability engineering; User centered design; User interfaces; Assessment tool; Design and evaluations; Emergency response; First responders; Mass casualty incidents; Subject matter experts; Toolsuite; Triage; Triage tags; Walkthroughs; Augmented reality},
	correspondence_address = {C.R. Nelson; Virginia Tech, United States; email: cassidynelson@vt.edu},
	editor = {Duh H. and Williams I. and Grubert J. and Jones J.A. and Zheng J.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-166545325-7},
	language = {English},
	abbrev_source_title = {Proc. - IEEE Int. Symp. Mixed Augment. Real., ISMAR},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 21st IEEE International Symposium on Mixed and Augmented Reality, ISMAR 2022; Conference date: 17 October 2022 through 21 October 2022; Conference code: 185651}
}

@ARTICLE{Chukhno2021593,
	author = {Chukhno, Nadezhda and Chukhno, Olga and Pizzi, Sara and Molinaro, Antonella and Iera, Antonio and Araniti, Giuseppe},
	title = {Efficient Management of Multicast Traffic in Directional mmWave Networks},
	year = {2021},
	journal = {IEEE Transactions on Broadcasting},
	volume = {67},
	number = {3},
	pages = {593 – 605},
	doi = {10.1109/TBC.2021.3061979},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102688938&doi=10.1109%2fTBC.2021.3061979&partnerID=40&md5=6ec74e5e9c6a22e4363a5af09e47fe93},
	affiliations = {DIIES Department, University Mediterranea of Reggio Calabria, Reggio Calabria, 89124, Italy; Institute of New Imaging Technologies, Universitat Jaume I, Castelló de la Plana, Castelló de la Plana, 12071, Spain; DIIE, University Mediterranea of Reggio Calabria, Reggio Calabria, 89124, Italy; ITC Faculty, Department of Electrical Engineering, Tampere University, Tampere, 33014, Finland; CNIT, Parma, Italy; DIMES Department, University of Calabria, Rende, 87036, Italy},
	abstract = {Multicasting is becoming more and more important in the Internet of Things (IoT) and wearable applications (e.g., high definition video streaming, virtual reality gaming, public safety, among others) that require high bandwidth efficiency and low energy consumption. In this regard, millimeter wave (mmWave) communications can play a crucial role to efficiently disseminate large volumes of data as well as to enhance the throughput gain in fifth-generation (5G) and beyond networks. There are, however, challenges to face in view of providing multicast services with high data rates under the conditions of short propagation range caused by high path loss at mmWave frequencies. Indeed, the strong directionality required at extremely high frequency bands excludes the possibility of serving all multicast users via a single transmission. Therefore, multicasting in directional systems consists of a sequence of beamformed transmissions to serve all multicast group members, subgroup by subgroup. This paper focuses on multicast data transmission optimization in terms of throughput and, hence, of the energy efficiency of resource-constrained devices such as wearables, running their resource-hungry applications. In particular, we provide a means to perform the beam switching and propose a radio resource management (RRM) policy that can determine the number and width of the beams required to deliver the multicast content to all interested users. Achieved simulation results show that the proposed RRM policy significantly improves network throughput with respect to benchmark approaches. It also achieves a high gain in energy efficiency over unicast and multicast with fixed predefined beams. © 1963-12012 IEEE.},
	author_keywords = {millimeter wave communication; Multicast; radio resource management; wearable devices},
	keywords = {Energy efficiency; Energy utilization; Internet of things; Millimeter waves; Multicasting; Wearable technology; Extremely-high frequency bands; Internet of thing (IOT); Low energy consumption; Millimeter waves (mmwave); Multicast group members; Radio resource management; Resourceconstrained devices; Wearable applications; 5G mobile communication systems},
	correspondence_address = {G. Araniti; DIIES Department, University Mediterranea of Reggio Calabria, Reggio Calabria, 89124, Italy; email: araniti@unirc.it},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {00189316},
	coden = {IETBA},
	language = {English},
	abbrev_source_title = {IEEE Trans Broadcast},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8; All Open Access, Green Open Access}
}

@ARTICLE{2022,
	title = {9th International Conference on Learning and Collaboration Technologies, LCT 2022 Held as Part of the 24th HCI International Conference, HCII 2022},
	year = {2022},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {13328 LNCS},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133226930&partnerID=40&md5=3e322195c12ad1c7296d439e7a1d18e7},
	abstract = {The proceedings contain 60 papers presendted at a virtual meeting. The special focus in this conference is on Learning and Collaboration Technologies. The topics include: Towards Deep Learning-Powered Chatbot for Translation Learning; an Educational, Semi-autonomous Telepresence Robot Called Sally; The Impact of Avatar Teachers on Student Learning and Engagement in a Virtual Learning Environment for Online STEM Courses; my English Teachers Are Not Human but I Like Them: Research on Virtual Teacher Self-study Learning System in K12; eduino: A Telegram Learning-Based Platform and Chatbot in Higher Education; exploring the Role of Chatbots and Messaging Applications in Higher Education: A Teacher’s Perspective; an Interactive Robot Lecture System Embedding Lecture Behavior Model; learning by Teaching Partner Robot in Collaborative Reading; Applying Natural Language Processing to Teamwork – A New Dashboard for CTMTC Methodology; Assessement of Assisted Navigation in NUI Virtual Architectural Environments; fostering Decision-Making Processes in Health Ecosystems Through Visual Analytics and Machine Learning; Agile CTMTC: Adapting Stages for a Shorter Application of the Teamwork Method; t-Game: A Team Formation Game for Enhancing Cross-Disciplinary Cooperation; virtual Team Collaboration: How the Empathy Tendency Influences User Experience?; how to Apply Bloom’s Taxonomy to Operator Education in the Way of Human-Machine Cooperation?; evaluation of Mixed Reality Technologies in Remote Teaching; design of a Virtual Reality based Pedagogical Framework; HCI Issues, Design and Development for a First Responders VR Training System on Dangerous Goods Transportation Incidents; an Approach of Holographic Technology for the Practical Distance Education; the Use of Augmented Reality to Motivate Scientific Learning for Preschool Children by Fostering Curiosity; foreword.},
	editor = {Zaphiris P. and Ioannou A.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303105656-7},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 9th International Conference on Learning and Collaboration Technologies, LCT 2022 Held as Part of the 24th HCI International Conference, HCII 2022; Conference date: 26 June 2022 through 1 July 2022; Conference code: 279419}
}

@ARTICLE{Bustamante2023,
	author = {Bustamante, Pedro and Gomez, Marcela and Lehr, William and Murtazashvili, Ilia and Palida, Ali and Weiss, Martin BH.},
	title = {Examining the US amateur-radio community through a polycentricity lens},
	year = {2023},
	journal = {Telecommunications Policy},
	doi = {10.1016/j.telpol.2023.102667},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173847617&doi=10.1016%2fj.telpol.2023.102667&partnerID=40&md5=07da2e6ea58e84bc324dcd7f702baf65},
	affiliations = {Carnegie Mellon University, Information Networking Institute, United States; University of Pittsburgh, Office of the Senior Vice Chancellor for Research, United States; Massachusetts Institute of Technology, CSAIL, United States; University of Pittsburgh, Center for Governance and Markets, United States; University of Pittsburgh, School of Computing and Information, United States},
	abstract = {Amateur radio (AR) operators provide societal services in public safety, spectrum applications, and training future experts. However, benefits derived from these services are challenging to define formally or contractually, resulting in potential under-provisioning in traditional market economies. We propose that communities like AR that aim to promote such open-ended innovation may not benefit from exclusive-resource rights and trading. Instead of market mechanisms, non-exclusive rights regimes can be analyzed through a lens of polycentricity, but such regimes require consensus on adaptable non-market governance rules and incentive-compatible mechanisms for monitoring, sanctioning, and exclusion of nonmembers. Our AR case study exemplifies stakeholders replacing market governance with nonexclusive property-rights models to harmonize diverse autonomous entities in producing open-ended societal services. © 2023},
	author_keywords = {Amateur radio; Coproduction; Open-ended innovation; Polycentricity; Social-service provision; Unassigned spectrum rights},
	keywords = {Commerce; Amateur radio; Co-production; Open-ended innovation; Polycentricity; Public safety; Service provisions; Social service; Social-service provision; Spectra's; Unassigned spectrum right; Personnel training},
	correspondence_address = {A. Palida; University of Pittsburgh, Center for Governance and Markets, United States; email: AFP31@pitt.edu},
	publisher = {Elsevier Ltd},
	issn = {03085961},
	coden = {TEPOD},
	language = {English},
	abbrev_source_title = {Telecommun Policy},
	type = {Article},
	publication_stage = {Article in press},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Hashem2022468,
	author = {Hashem, Ahmed and Schlechter, Thomas},
	title = {Drone Detection Using Deep Learning: A Benchmark Study},
	year = {2022},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {13789 LNCS},
	pages = {468 – 475},
	doi = {10.1007/978-3-031-25312-6_55},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151118371&doi=10.1007%2f978-3-031-25312-6_55&partnerID=40&md5=a5c952c9d8f17fff1d2011ea73979b0a},
	affiliations = {Linz Center of Mechatronics GmbH, Linz, 4040, Austria; University of Applied Sciences Upper Austria, Wels, 4600, Austria},
	abstract = {Since Unmanned Aerial Vehicles (UAVs) became available to the civilian public, it has witnessed dramatic spread and exponential popularity. This escalation gave rise to privacy and security concerns, both on the recreational and institutional levels. Although it is mainly used for leisure and productivity activities, it is evident that UAVs can also be used for malicious purposes. Today, as legislation and law enforcement federations can hardly control every incident, many institutions resort to surveillance systems to prevent hostile drone intrusion. Although drone detection can be carried out using different technologies, such as radar or ultra-sonic, visual detection is arguably the most efficient method. Other than being cheap and readily available, cameras are typically a part of any surveillance system. Moreover, the rise of deep learning and neural network models rendered visual recognition very reliable [9, 21]. In this work, three state-of-the-art object detectors, namely YOLOv4, SSD-MobileNetv1 and SSD-VGG16, are tested and compared to find the best performing detector on our drone data-set of 23,863 collected and annotated images. The main work covers detailed reportage of the results of each model, as well as a comprehensive comparison between them. In terms of accuracy and real-time capability, the best performance was achieved by the SSD-VGG16 model, which scored average precision (AP50) of 90.4%, average recall (AR) of 72.7% and inference speed of 58 frames per second on the NVIDIA Jetson Xavier kit. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {Artificial intelligence; Drone detection; Neural network; Security},
	keywords = {Aircraft detection; Antennas; Deep learning; Laws and legislation; Network security; Neural networks; Object detection; Security systems; Aerial vehicle; Benchmark study; Drone detection; Exponentials; Neural-networks; Privacy and security; Security; Surveillance systems; Ultra sonic; Visual detection; Drones},
	correspondence_address = {T. Schlechter; University of Applied Sciences Upper Austria, Wels, 4600, Austria; email: thomas.schlechter@ieee.org},
	editor = {Moreno-Díaz R. and Pichler F. and Quesada-Arencibia A.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303125311-9},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 18th International Conference on Computer Aided Systems Theory,  EUROCAST 2022; Conference date: 20 February 2022 through 25 February 2022; Conference code: 291639}
}@CONFERENCE{Starks2019289,
	author = {Starks, Denny L. and Dillahunt, Tawanna and Haimson, Oliver L.},
	title = {Designing technology to support safety for transgender women & non-binary people of color},
	year = {2019},
	journal = {DIS 2019 Companion - Companion Publication of the 2019 ACM Designing Interactive Systems Conference},
	pages = {289 – 294},
	doi = {10.1145/3301019.3323898},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069501247&doi=10.1145%2f3301019.3323898&partnerID=40&md5=9b853b98606bb726fdef509c5751872c},
	affiliations = {University of Michigan, Ann Arbor, 48109, MI, United States},
	abstract = {This work provides a preliminary understanding of how transgender women and non-binary people of color experience violence and manage safety, and what opportunities exist for HCI to support the safety needs of this community. We conducted nine interviews to understand how participants practice safety and what role technology played, if any, in these experiences. Interviewees expressed physical and psychological safety concerns, and managed safety by informing friends of their location using digital technologies, making compromises, and avoiding law enforcement. We designed U-Signal, a wearable technology and accompanying smartphone application prototype to increase physical safety and decrease safety concerns, reduce violence, and help build community. © 2019 Copyright is held by the owner/author(s).},
	author_keywords = {Community; Location-based applications; Non-binary; People of color; Safety; Trans people of color (TPOC); Transgender; Transphobia; Violence; Wearables},
	keywords = {Accident prevention; Color; Community; Location-based applications; Non-binary; Trans people of color (TPOC); Transgender; Transphobia; Violence; Wearables; Wearable technology},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {978-145036270-2},
	language = {English},
	abbrev_source_title = {DIS Companion - Companion Publ. ACM Des. Interact. Syst. Conf.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 26; Conference name: 2019 ACM Conference on Designing Interactive Systems, DIS 2019; Conference date: 23 June 2019 through 28 June 2019; Conference code: 148977; All Open Access, Green Open Access}
}

@CONFERENCE{Detjen202058,
	author = {Detjen, Henrik and Geisler, Stefan and Schneegass, Stefan},
	title = {Help, accident ahead using mixed reality environments in automated vehicles to support occupants after passive accident experiences},
	year = {2020},
	journal = {Adjunct Proceedings - 12th International ACM Conference on Automotive User Interfaces and Interactive Vehicular Applications, AutomotiveUI 2020},
	pages = {58 – 61},
	doi = {10.1145/3409251.3411723},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092232722&doi=10.1145%2f3409251.3411723&partnerID=40&md5=abf17f1ed3cc9e5073614b91dedc32e0},
	affiliations = {University of Applied Science Ruhr West, Germany; University of Duisburg-Essen, Germany},
	abstract = {Currently, car assistant systems mainly try to prevent accidents. Increasing built-in car technology also extends the potential applications in vehicles. Future cars might have virtual windshields that augment the traffic or individual virtual assistants interacting with the user. In this paper, we explore the potential of an assistant system that helps the car's occupants to calm down and reduce stress when they experience an accident in front of them. We present requirements from a discussion (N = 11) and derive a system design from them. Further, we test the system design in a video-based simulator study (N = 43). Our results indicate that an accident support system increases perceived control and trust and helps to calm down the user. © 2020 Owner/Author.},
	author_keywords = {Accidents; Augmented Reality; Automated Vehicles; First Responders.; Mixed Reality; Stress; Virtual Windshields},
	keywords = {Mixed reality; Systems analysis; User interfaces; Automated vehicles; In-car technology; Mixed-reality environment; Support systems; Virtual assistants; Accidents},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {978-145038066-9},
	language = {English},
	abbrev_source_title = {Adjun. Proc. - Int. ACM Conf. Automot. User Interfaces Interact. Veh. Appl., AutomotiveUI},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; Conference name: 12th ACM International Conference on Automotive User Interfaces and Interactive Vehicular Applications, AutomotiveUI 2020; Conference date: 21 September 2020 through 22 September 2020; Conference code: 163112}
}

@CONFERENCE{Eneman2019,
	author = {Eneman, Marie and Stenmark, Dick and Ljunberg, Jan and Borglund, Erik},
	title = {REGULATING POLICE BODY-WORN CAMERA PRACTICE-A FOUR MODALITY PERSPECTIVE},
	year = {2019},
	journal = {10th Scandinavian Conference on Information Systems, SCIS 2019},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138680287&partnerID=40&md5=2b0acdd4b089dceadb23557caee4c064},
	affiliations = {University of Gothenburg, Gothenburg, Sweden; Mid Sweden University, Härnösand, Sweden},
	abstract = {Police authorities in a number of countries have recently introduced body-worn cameras (BWC). With the use of body-worn cameras, the police have gained access to new forms of wearable and powerful law enforcing technologies. The cameras enable collection of large volume of personal information and in some cases even sensitive information that must be managed and stored within the organisation in line with rules of law. As is often the case when technology develops faster than societal norms and values, a range of questions concerning issues related to regulation of these practises are still unin-vestigated. Therefore, this paper will analyse what actually regulates individual police officers’ body-worn camera practice. Empirically, we use the Swedish police as a case and our study is based on qualitative interviews. Theoretically we draw upon Lawrence Lessig’s four modality model-law, norms, market, and architecture-and we conclude that i) law is considered important although law regarding BWC is still in its infancy, ii) while law and official directives have a more macro applicability, norms are developed and maintained more locally, iii) market regulate indirectly via availability and cost, and iv) architecture is not necessarily as self-executed as often stated. © 2019, Association for Information Systems. All rights reserved.},
	author_keywords = {Body-worn cameras; Lessig’s modalities of regulation; Police authorities},
	keywords = {Commerce; Law enforcement; Wearable technology; Body-worn camera; Large volumes; Lessig’s modality of regulation; New forms; Personal information; Police authority; Police officers; Qualitative interviews; Sensitive informations; Swedishs; Cameras},
	publisher = {Association for Information Systems},
	language = {English},
	abbrev_source_title = {Scand. Conf. Inform. Sys.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 10th Scandinavian Conference on Information Systems, SCIS 2019; Conference date: 11 August 2019 through 14 August 2019; Conference code: 281119}
}

@CONFERENCE{Saafi2020201,
	author = {Saafi, Salwa and Hosek, Jiri and Kolackova, Aneta},
	title = {Cellular-enabled Wearables in Public Safety Networks: State of the Art and Performance Evaluation},
	year = {2020},
	journal = {International Congress on Ultra Modern Telecommunications and Control Systems and Workshops},
	volume = {2020-October},
	pages = {201 – 207},
	doi = {10.1109/ICUMT51630.2020.9222459},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094889842&doi=10.1109%2fICUMT51630.2020.9222459&partnerID=40&md5=faf292f413041daa2d83c91f0f95aba4},
	affiliations = {Brno University of Technology, Department of Telecommunications, Brno, Czech Republic},
	abstract = {With the aim of offering services and products that ensure the safety of people and properties, public safety organizations are responsible for providing the first responders, i.e., police officers, firefighters, and emergency medical service workers, with devices and communication systems that help them exchange time-sensitive and critical information. To address the mission-critical requirements and to target new broadband public safety applications, these organizations started migrating from traditional land mobile radio towards cellular communication systems with the consideration of a new set of deployed devices, such as wearables. In this paper, we first provide a state of the art overview of the features that are introduced by the 3rd Generation Partnership Project (3GPP) and that can be used for public safety services. Second, we discuss the role of wearable devices, more precisely cellular-enabled wearables, in creating several new use cases as part of the concept of the Internet of Life Saving Things. Finally, we conduct a performance evaluation of a mission-critical service using cellular-enabled wearables, specifically a mission-critical push-to-talk (MCPTT) application using LTE Cat-M2-enabled smartwatches. In this evaluation, we examine the impact of different parameters related to the wearable device capabilities and the MCPTT call scenarios on the key performance indicator defined by 3GPP for this type of applications, which is the MCPTT access time.  © 2020 IEEE.},
	author_keywords = {Cellular connectivity; Internet of Life Saving Things; Public safety; Wearables},
	keywords = {Benchmarking; Control systems; Emergency services; Law enforcement; Medical information systems; Mobile telecommunication systems; Radio communication; Wearable technology; 3rd generation partnership project (3GPP); Emergency medical services; Key performance indicators; Land mobile radio; Mission critical; Public Safety Applications; Public Safety Networks; State of the art; Cellular radio systems},
	publisher = {IEEE Computer Society},
	issn = {21570221},
	isbn = {978-172819281-9},
	language = {English},
	abbrev_source_title = {Int. Cong. Ultra Mod.Telecommun. Control Syst. Workshops},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; Conference name: 12th International Congress on Ultra Modern Telecommunications and Control Systems and Workshops, ICUMT 2020; Conference date: 5 October 2020 through 7 October 2020; Conference code: 164070; All Open Access, Green Open Access}
}

@ARTICLE{Nunes2019195,
	author = {Nunes, Isabel L. and Lucas, Raquel and Simões-Marques, Mário and Correia, Nuno},
	title = {An augmented reality application to support deployed emergency teams},
	year = {2019},
	journal = {Advances in Intelligent Systems and Computing},
	volume = {822},
	pages = {195 – 204},
	doi = {10.1007/978-3-319-96077-7_21},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052138812&doi=10.1007%2f978-3-319-96077-7_21&partnerID=40&md5=e23b2e79f474bad213e20f2555079f82},
	affiliations = {Faculdade de Ciencias e Tecnologia, Universidade NOVA de Lisboa, Caparica, 2829-516, Portugal; UNIDEMI, Faculdade de Ciencias e Tecnologia, Universidade NOVA de Lisboa, Caparica, 2829-516, Portugal; NOVA-LINCS, Faculdade de Ciencias e Tecnologia, Universidade NOVA de Lisboa, Caparica, 2829-516, Portugal; CINAV - Portuguese Navy, Alfeite, Almada, 2810-001, Portugal},
	abstract = {THEMIS-AR is an augmented reality (AR) app designed for mobile devices that was developed to assist first responders on disaster relief operations, which a very demanding context for users, regarding both the physical and the cognitive and emotional demands. In fact, the specificity of the usage environment imposes special care in addressing the interaction of the users with the system, regarding both the mobile devices technical characteristics and the workload. The paper provides a brief description of the THEMIS-AR architecture and features, focusing on the assessment of a concept demonstrator developed based on the UCD cycle (i.e., context of use characterization, requirements definition, solution implementation, and testing and validation). The usability testing setup and script adopted while performing field tests are described and the results obtained, namely regarding the application of the User Experience Questionnaire to benchmark the app evaluation in comparison with a set of previous evaluations made with this methodology. These results were compared with the user perceptions collected using a final questionnaire namely based on the System Usability Scale. The main findings resulting from this initial set of users are summarized and presented the way ahead for this component of the THEMIS project. © Springer Nature Switzerland AG 2019.},
	author_keywords = {Augmented reality; Emergency teams; SUS; THEMIS; UEQ; User centered design},
	keywords = {Augmented reality; Disaster prevention; Ergonomics; Surveys; User centered design; Virtual reality; Augmented reality applications; Concept demonstrators; Disaster relief operations; Emergency teams; Emotional demands; Requirements definition; THEMIS; Usability testing; Benchmarking},
	correspondence_address = {I.L. Nunes; Faculdade de Ciencias e Tecnologia, Universidade NOVA de Lisboa, Caparica, 2829-516, Portugal; email: imn@fct.unl.pt},
	editor = {Fujita Y. and Bagnara S. and Tartaglia R. and Albolino S. and Alexander T.},
	publisher = {Springer Verlag},
	issn = {21945357},
	isbn = {978-331996076-0},
	language = {English},
	abbrev_source_title = {Adv. Intell. Sys. Comput.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 10; Conference name: 20th Congress of the International Ergonomics Association, IEA 2018; Conference date: 26 August 2018 through 30 August 2018; Conference code: 216789}
}

@ARTICLE{Stone2017280,
	author = {Stone, Robert J. and Guest, R. and Mahoney, P. and Lamb, D. and Gibson, C.},
	title = {A ‘mixed reality’ simulator concept for future medical emergency response team training},
	year = {2017},
	journal = {Journal of the Royal Army Medical Corps},
	volume = {163},
	number = {4},
	pages = {280 – 287},
	doi = {10.1136/jramc-2016-000726},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026903329&doi=10.1136%2fjramc-2016-000726&partnerID=40&md5=f26a7d854a4d44d890a4e8e9292787e6},
	affiliations = {University of Birmingham, EESE, Birmingham, United Kingdom; Academic Department of Military Anaesthesia and Critical Care, Royal Centre for Defence Medicine, Birmingham, United Kingdom; Academic Department of Military Nursing, Royal Centre for Defence Medicine, Birmingham, United Kingdom; Clinical Policy, Royal Army Medical Corps, Royal Centre for Defence Medicine, Birmingham, United Kingdom},
	abstract = {The UK Defence Medical Service’s Pre-Hospital Emergency Care (PHEC) capability includes rapid-deployment Medical Emergency Response Teams (MERTs) comprising tri-service trauma consultants, paramedics and specialised nurses, all of whom are qualified to administer emergency care under extreme conditions to improve the survival prospects of combat casualties. The pre-deployment training of MERT personnel is designed to foster individual knowledge, skills and abilities in PHEC and in small team performance and cohesion in ‘mission-specific’ contexts. Until now, the provision of airborne pre-deployment MERT training had been dependent on either the availability of an operational aircraft (eg, the CH-47 Chinook helicopter) or access to one of only two ground-based facsimiles of the Chinook’s rear cargo/passenger cabin. Although MERT training has high priority, there will always be competition with other military taskings for access to helicopter assets (and for other platforms in other branches of the Armed Forces). This paper describes the development of an inexpensive, reconfigurable and transportable MERT training concept based on ‘mixed reality’ technologies— in effect the ‘blending’ of real-world objects of training relevance with virtual reality reconstructions of operational contexts. © 2017, BMJ Publishing Group. All rights reserved.},
	keywords = {Emergency Medical Services; Humans; Manikins; Military Medicine; Simulation Training; United Kingdom; education; emergency health service; human; manikin; military medicine; simulation training; United Kingdom},
	correspondence_address = {R.J. Stone; Human Interface Technologies Team, University of Birmingham, EESE, Birmingham, Pritchatts Road, B15 2TT, United Kingdom; email: r.j.stone@bham.ac.uk},
	publisher = {BMJ Publishing Group},
	issn = {00358665},
	coden = {JRAMA},
	pmid = {28062529},
	language = {English},
	abbrev_source_title = {J. R. Army Med. Corps},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 13; All Open Access, Green Open Access}
}

@ARTICLE{Peterson2020173,
	author = {Peterson, Eleanor and Porter, Melissa and Calhoun, Aaron},
	title = {Mixed-Reality Simulation for a Pediatric Transport Team: A Pilot Study},
	year = {2020},
	journal = {Air Medical Journal},
	volume = {39},
	number = {3},
	pages = {173 – 177},
	doi = {10.1016/j.amj.2020.03.001},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082700259&doi=10.1016%2fj.amj.2020.03.001&partnerID=40&md5=d53979eb02e18fd1f80ddcaadb85c895},
	affiliations = {Department of Pediatrics, Division of Critical Care Medicine, University of Louisville School of Medicine, Louisville, KY, United States},
	abstract = {Objective: Transport medicine requires a complex set of skills including fast-paced medical decision making, in-depth medical knowledge, procedural competence, interpersonal and communication skills, leadership, and professionalism. There has been a call for more training in these areas. Simulation-based training can be a way to acquire these necessary skills and bridge the gap to higher-quality transport care. The purpose of this study was to develop a novel mixed-reality simulation program to enhance medical and communication skills for a pediatric transport team. Methods: A mixed-reality simulation program using standardized patients portraying family members and high-fidelity manikins to simulate a medical emergency was developed and implemented for a pediatric transport team. Ten nurses, 9 respiratory therapists, and 8 emergency medical technicians participated. Pre-post self-perceptions of skill and program quality were assessed prospectively. Results: Team members rated the overall program quality highly, with a median 5 on a 5-point Likert scale. There was a statistically significant change in pre- versus postprogram self-perceptions of skill in the areas of communication (premedian = 3 vs. postmedian = 4, 5-point Likert scale, P < .001). Conclusion: Mixed-reality simulation programs can enhance standard technical skills training by providing an additional relational element. Such programs are translatable to other institutions. © 2020 Air Medical Journal Associates},
	keywords = {Air Ambulances; Emergency Medical Technicians; Female; Humans; Male; Manikins; Patient Care Team; Pediatrics; Pilot Projects; Professional Competence; Simulation Training; Surveys and Questionnaires; Article; communication skill; education program; family; female; human; Likert scale; male; medical education; multidisciplinary team; nurse; patient transport; pilot study; priority journal; prospective study; rescue personnel; respiratory therapist; self concept; simulation training; skill; teamwork; air medical transport; education; manikin; patient care; pediatrics; professional competence; questionnaire},
	correspondence_address = {E. Peterson; Department of Pediatrics, Division of Critical Care Medicine, University of Louisville School of Medicine, Louisville, 571 South Floyd Street, Suite 332, 40202, United States; email: ebpete01@louisville.edu},
	publisher = {Mosby Inc.},
	issn = {1067991X},
	coden = {AMJIA},
	pmid = {32540107},
	language = {English},
	abbrev_source_title = {Air Med. J.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6}
}

@ARTICLE{Greenberg2020190,
	author = {Greenberg, Ariel M. and Spitaletta, Jason A.},
	title = {Mixed Reality Social Prosthetic System},
	year = {2020},
	journal = {Johns Hopkins APL Technical Digest (Applied Physics Laboratory)},
	volume = {35},
	number = {3},
	pages = {190 – 199},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139476803&partnerID=40&md5=ff5e0c1e0dd3a54e195476f2a24016af},
	affiliations = {Johns Hopkins University, Applied Physics Laboratory, Laurel, MD, United States},
	abstract = {A Johns Hopkins University Applied Physics Laboratory (APL) team conceived of and developed a first-of-its-kind mixed reality "social prosthetic" system aimed at improving emotion recognition training and performance by displaying information about nonverbal signals in a way that is easily interpretable by a user. Called IN:URfACE (for Investigating Non-verbals: Using xReality for the Augmented Consideration of Emotion), the proof-of-concept prototype system uses infrared sensors to measure facial movements, pupil size, blink rate, and gaze direction. These signals are synchronized in real time, registered in real space, and then overlaid on the face of an interaction partner, such as an interviewee, through a mixed reality headset. The result is dramatic accentuation of subtle changes in the face, including changes that people are not usually aware of, like pupil dilation or nostril flare. The ability to discern these changes has applications in fields such as law enforcement, intelligence collection, and health care. This article describes how the system works, the technical challenges and solutions in designing it, and possible areas of application. © 2020 John Hopkins University. All rights reserved.},
	keywords = {Emotion Recognition; Infrared detectors; Prosthetics; Concept prototype; Emotion recognition; Infrared sensor; Johns Hopkins University Applied Physics Laboratory; Mixed reality; Non-verbal signals; Performance; Proof of concept; Prototype system; System use; Mixed reality},
	publisher = {John Hopkins University},
	issn = {02705214},
	coden = {JHADD},
	language = {English},
	abbrev_source_title = {Johns Hopkins APL Tech Dig},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Gao202014903,
	author = {Gao, Guangwei and Wang, Yannan and Huang, Pu and Chang, Heyou and Lu, Huimin and Yue, Dong},
	title = {Locality-constrained feature space learning for cross-resolution sketch-photo face recognition},
	year = {2020},
	journal = {Multimedia Tools and Applications},
	volume = {79},
	number = {21-22},
	pages = {14903 – 14917},
	doi = {10.1007/s11042-019-08488-y},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076517448&doi=10.1007%2fs11042-019-08488-y&partnerID=40&md5=f7fc590f80ae4f89c4af7c71129d3d63},
	affiliations = {Institute of Advanced Technology, Nanjing University of Posts and Telecommunications, Nanjing, China; Provincial Key Laboratory for Computer Information Processing Technology, Soochow University, Suzhou, China; School of Automation, Nanjing University of Posts and Telecommunications, Nanjing, China; Key Laboratory of Trusted Cloud Computing and Big Data Analysis, Nanjing XiaoZhuang University, Nanjing, China; Department of Mechanical and Control Engineering, Kyushu Institute of Technology, Kitakyushu, Japan},
	abstract = {Matching sketch facial images to mug-shot images have crucial significance in law enforcement and digital entertainment. Conventional methods always assume that both the sketch and photo face images have the same resolutions. However, in real criminal detection, the target facial sketches obtained by the artist usually have different resolutions against the source photos in the mug-shot database. In this paper, we propose a locality-constrained feature space learning (LCFSL) method to address the above cross-resolution sketch-photo facial images matching problem. The proposed LCFSL approach not only build bridge to associate cross-domain face images, but also can learn resolution robust representation features for cross-resolution sketch-photo face recognition purpose. After common feature space learning, we simply use nearest neighbor classifier to perform recognition based on the projected features obtained from sketch-photo faces with different resolutions. Experiments conducted on CUHK student database and AR database have shown the effectiveness and superiority of our method to some state-of-the-art face recognition approaches. © 2019, Springer Science+Business Media, LLC, part of Springer Nature.},
	author_keywords = {Cross-resolution; Face recognition; Feature learning; Locality-constrained},
	keywords = {Database systems; Laws and legislation; Conventional methods; Different resolutions; Digital entertainment; Feature learning; Locality-constrained; Matching problems; Nearest Neighbor classifier; State of the art; Face recognition},
	correspondence_address = {G. Gao; Provincial Key Laboratory for Computer Information Processing Technology, Soochow University, Suzhou, China; email: csggao@gmail.com},
	publisher = {Springer},
	issn = {13807501},
	coden = {MTAPF},
	language = {English},
	abbrev_source_title = {Multimedia Tools Appl},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Li2019,
	author = {Li, Sen and Feng, Chunyong and Niu, Yunchen and Shi, Long and Wu, Zeqi and Song, Huaitao},
	title = {A fire reconnaissance robot based on SLAM position, thermal imaging technologies, and AR display},
	year = {2019},
	journal = {Sensors (Switzerland)},
	volume = {19},
	number = {22},
	doi = {10.3390/s19225036},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075098266&doi=10.3390%2fs19225036&partnerID=40&md5=9444ce341039b83048121e32aa7701a5},
	affiliations = {School of Building Environment Engineering, Zhengzhou University of Light Industry, 5 Dongfeng Road, Zhengzhou, 450002, Henan, China; Civil and Infrastructure Engineering Discipline, School of Engineering, RMIT University, Melbourne, 3000, VIC, Australia},
	abstract = {Due to hot toxic smoke and unknown risks under fire conditions, detection and relevant reconnaissance are significant in avoiding casualties. A fire reconnaissance robot was therefore developed to assist in the problem by offering important fire information to fire fighters. The robot consists of three main systems, a display operating system, video surveillance, and mapping and positioning navigation. Augmented reality (AR) goggle technology with a display operating system was also developed to free fire fighters’ hands, which enables them to focus on rescuing processes and not system operation. Considering smoke disturbance, a thermal imaging video surveillance system was included to extract information from the complicated fire conditions. Meanwhile, a simultaneous localization and mapping (SLAM) technology was adopted to build the map, together with the help of a mapping and positioning navigation system. This can provide a real-time map under the rapidly changing fire conditions to guide the fire fighters to the fire sources or the trapped occupants. Based on our experiments, it was found that all the tested system components work quite well under the fire conditions, while the video surveillance system produces clear images under dense smoke and a high-temperature environment; SLAM shows a high accuracy with an average error of less than 3.43%; the positioning accuracy error is 0.31 m; and the maximum error for the navigation system is 3.48%. The developed fire reconnaissance robot can provide a practically important platform to improve fire rescue efficiency to reduce the fire casualties of fire fighters. © 2019 by the authors. Licensee MDPI, Basel, Switzerland.},
	author_keywords = {AR; Fire reconnaissance robot; SLAM; Thermal imaging},
	keywords = {Argon; Augmented reality; Errors; Infrared imaging; Mapping; Monitoring; Navigation systems; Robotics; Robots; Security systems; Smoke; Extract informations; High-temperature environment; Positioning accuracy; Reconnaissance robot; Simultaneous localization and mapping technologies; SLAM; Thermal imaging technology; Video surveillance systems; Fires},
	correspondence_address = {L. Shi; Civil and Infrastructure Engineering Discipline, School of Engineering, RMIT University, Melbourne, 3000, Australia; email: shilong@mail.ustc.edu.cn},
	publisher = {MDPI AG},
	issn = {14248220},
	pmid = {31752251},
	language = {English},
	abbrev_source_title = {Sensors},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 17; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Yun2018,
	author = {Yun, Kyongsik and Lu, Thomas and Chow, Edward},
	title = {Occluded object reconstruction for first responders with augmented reality glasses using conditional generative adversarial networks},
	year = {2018},
	journal = {Proceedings of SPIE - The International Society for Optical Engineering},
	volume = {10649},
	doi = {10.1117/12.2305151},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049165392&doi=10.1117%2f12.2305151&partnerID=40&md5=7c351c03c4787d7c40ebdaf5c694e315},
	affiliations = {Jet Propulsion Laboratory, California Institute of Technology, 4800 Oak Grove Drive, Pasadena, 91109, CA, United States},
	abstract = {Firefighters suffer a variety of life-threatening risks, including line-of-duty deaths, injuries, and exposures to hazardous substances. Support for reducing these risks is important. We built a partially occluded object reconstruction method on augmented reality glasses for first responders. We used a deep learning based on conditional generative adversarial networks to train associations between the various images of flammable and hazardous objects and their partially occluded counterparts. Our system then reconstructed an image of a new flammable object. Finally, the reconstructed image was superimposed on the input image to provide »transparency». The system imitates human learning about the laws of physics through experience by learning the shape of flammable objects and the flame characteristics. © 2018 SPIE.},
	author_keywords = {augmented reality; computer vision; generative adversarial networks; machine learning; Partially occluded object reconstruction},
	keywords = {Augmented reality; Computer vision; Deep learning; Flammability; Glass; Hazards; Learning systems; Pattern recognition; Adversarial networks; First responders; Flame characteristics; Hazardous substances; Line-of-duty deaths; Occluded objects; Partially occluded objects; Reconstructed image; Image reconstruction},
	editor = {Alam M.S.},
	publisher = {SPIE},
	issn = {0277786X},
	isbn = {978-151061809-1},
	coden = {PSISD},
	language = {English},
	abbrev_source_title = {Proc SPIE Int Soc Opt Eng},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; Conference name: Pattern Recognition and Tracking XXIX 2018; Conference date: 18 April 2018 through 19 April 2018; Conference code: 137206; All Open Access, Green Open Access}
}

@ARTICLE{Carlson2019108,
	author = {Carlson, Gordon and Caporusso, Nicholas},
	title = {A physically immersive platform for training emergency responders and law enforcement officers},
	year = {2019},
	journal = {Advances in Intelligent Systems and Computing},
	volume = {785},
	pages = {108 – 116},
	doi = {10.1007/978-3-319-93882-0_11},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049622979&doi=10.1007%2f978-3-319-93882-0_11&partnerID=40&md5=31cb1a049e90b43103527acc6b104342},
	affiliations = {Fort Hays State University, 600 Park Street, Hays, United States},
	abstract = {Training law enforcement officers and emergency responders requires significant investment in terms of time, financial resources, logistics, organization, and personnel reallocation. In this paper, we introduce a physically immersive platform based on Virtual Reality for training enforcement and emergency personnel, and for evaluating physical and psychological stress. The proposed system is co-designed with end users to maximize the performance and outcome of training. Moreover, the platform includes features for accelerating the development of innovative technologies, equipment, and user interfaces, by integrating the knowledge and experience of law enforcement officers and emergency responders into virtual/augmented reality design simulations. © Springer International Publishing AG, part of Springer Nature 2019.},
	author_keywords = {Emergency responders; Law enforcement; Motion tracking; Physical immersion; Training},
	keywords = {Emergency services; Human computer interaction; Human engineering; Investments; Law enforcement; User interfaces; Virtual reality; Emergency responders; Financial resources; Innovative technology; Knowledge and experience; Law enforcement officers; Motion tracking; Physical immersion; Psychological stress; Personnel training},
	correspondence_address = {N. Caporusso; Fort Hays State University, Hays, 600 Park Street, United States; email: n_caporusso@fhsu.edu},
	editor = {Polak-Sopinska A. and Nazir S. and Teperi A.-M.},
	publisher = {Springer Verlag},
	issn = {21945357},
	isbn = {978-331993881-3},
	language = {English},
	abbrev_source_title = {Adv. Intell. Sys. Comput.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8; Conference name: AHFE International Conference on Human Factors in Training, Education, and Learning Sciences, 2018; Conference date: 21 July 2018 through 25 July 2018; Conference code: 215369}
}

@CONFERENCE{Cochrane2018645,
	author = {Cochrane, Thomas and Cook, Stuart and Aiello, Stephen and Aguayo, Claudio and Danobeitia, Cristobal and Boncompte, Gonzalo},
	title = {Designing Immersive Mobile Mixed Reality for Paramedic Education},
	year = {2018},
	journal = {Proceedings of 2018 IEEE International Conference on Teaching, Assessment, and Learning for Engineering, TALE 2018},
	pages = {645 – 650},
	doi = {10.1109/TALE.2018.8615124},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062102634&doi=10.1109%2fTALE.2018.8615124&partnerID=40&md5=68aed1db85d4a3183089687cd7c3cf98},
	affiliations = {Centre for Learning and Teaching, Auckland University of Technology, Auckland, New Zealand; Paramedicine Auckland University of Technology, Auckland, New Zealand; Embodied Group, Las Condes Santiago, Chile; Embodied Group, Las Condes Sant., Chile},
	abstract = {This paper outlines and critiques the first two stages of a mobile mixed reality design-based research study exploring the design and evaluation of mobile virtual reality for paramedic education. We triangulate subjective student immersive environment feedback with objective biometric data to gain clearer insights into the impact of these immersive environments on student learning. In the study high-risk critical care scenarios are simulated using a low-cost mobile virtual reality environment, utilizing student-owned devices. The scenarios are designed to stimulate student identification of environmental risk factors before treating a critical care patient, ensuring the safety of both the patient and the first-responders, leading to increased chances of patient survival and recovery. We discuss the design principles behind the proj ect and evaluate the first prototype scenario to guide the redesign of the data capture methodology for the next stage of the research. © 2018 IEEE.},
	author_keywords = {biometric feedback; design-based research; enhanced critical response scenarios; mobile mixed reality; paramedic education},
	keywords = {Biometrics; Mixed reality; Patient rehabilitation; Risk perception; Biometric feedback; Critical care; Critical response; Design-based research; Enhanced critical response scenario; Immersive; Immersive environment; Mobile mixed realities; Paramedic education; Research studies; Students},
	editor = {Lee M.J.W. and Nikolic S. and Ros M. and Shen J. and Lei L.C.U. and Wong G.K.W. and Venkatarayalu N.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-153866522-0},
	language = {English},
	abbrev_source_title = {Proc. IEEE Int. Conf. Teach., Assess., Learn. Eng., TALE},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: 2018 IEEE International Conference on Teaching, Assessment, and Learning for Engineering, TALE 2018; Conference date: 4 December 2018 through 7 December 2018; Conference code: 144397}
}

@ARTICLE{Cavalieri d'Oro2019,
	author = {Cavalieri d'Oro, Edoardo and Colombo, Simone and Gribaudo, Marco and Iacono, Mauro and Manca, Davide and Piazzolla, Pietro},
	title = {Modeling and evaluating a complex edge computing based systems: An emergency management support system case study},
	year = {2019},
	journal = {Internet of Things (Netherlands)},
	volume = {6},
	doi = {10.1016/j.iot.2019.100054},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076764725&doi=10.1016%2fj.iot.2019.100054&partnerID=40&md5=07ec108044745b0796fadea0e3c96a9d},
	affiliations = {Italian National Fire Corp, Milano, Italy; Politecnico di Milano, PSE-Lab, CMIC, Milano, Italy; Politecnico di Milano, Dipartimento di Elettronica, Informazione e Bioingegneria, Milano, Italy; Dipartimento di Matematica e Fisica, Università degli Studi della Campania “Luigi Vanvitelli”, Caserta, Italy; Politecnico di Torino, Dipartimento di Ingegneria Gestionale e della Produzione, Torino, Italy},
	abstract = {The edge computing paradigm enhances the exploitability of cloud computing by providing, in principle, the means to overcome the limitations in terms of responsiveness, bandwidth needs, privacy and availability in critical applications. By moving some of the components of the system towards the physical location where results are timely needed, it is possible to support mission critical applications and back them up with the flexibility and the resource availability and scalability offered by the cloud, while keeping mission costs lower (and response efficiency higher) than classical approaches. The main challenge in merging cloud and edge components lies in their correct balance to allow for the best results at the lowest costs. This means that performance-oriented evaluation models are crucial in the design, deployment and execution phases of the system lifetime. In this paper we present a modeling approach for complex, critical-edge computing-based systems relying on the use of queuing networks, applied to a novel architecture aiming at supporting operations in case of medium or large-scale accidents that involve interoperability among responders during the emergency phase. The proposed architecture allows the coordination of fire brigade teams, equipped with sensors and augmented reality devices, to minimize mission problems and timely exploit local and external information, as well as supporting interoperations with other first responders. The results show that, even with a standard modeling approach, these systems are extremely interesting and show non-trivial behaviors. Security and dependability issues of the proposed architecture are discussed. © 2019 Elsevier B.V.},
	author_keywords = {CBRN response; Cloud computing; Crisis management systems; Critical systems; Edge computing; Emergency management; IoT; Performance evaluation},
	correspondence_address = {M. Iacono; Dipartimento di Matematica e Fisica, Università degli Studi della Campania “Luigi Vanvitelli”, Caserta, Italy; email: mauro.iacono@unicampania.it},
	publisher = {Elsevier B.V.},
	issn = {25426605},
	language = {English},
	abbrev_source_title = {Internet. Thing.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 14}
}

@CONFERENCE{Islam201876,
	author = {Islam, Muhammad Nazrul and Toma, Mohoshina Akter and Khaledur, Syeda Nusraht and Promi, Nuzhat Tabassum and Pushpo, Maria Afnan and Anannya, Tasmiah Tamzid and Shaila, Jannatul Maowa and Alam, Fatema Binte and Fazle Rabbi, Md.},
	title = {SAFeBanD: A wearable device for the safety of women in Bangladesh},
	year = {2018},
	journal = {ACM International Conference Proceeding Series},
	pages = {76 – 83},
	doi = {10.1145/3282353.3282363},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060929961&doi=10.1145%2f3282353.3282363&partnerID=40&md5=53f37fd999176a13cc3a29361b0d75a0},
	affiliations = {Military Institute of Science and Technology, Dhaka, Bangladesh},
	abstract = {Even in the twenty-first century, while people are debating over various reasons of assault, women from all walks of life are continuously being harassed and violated in the streets, public transportation and public spaces. The safety of women has become a progressively emphasized concern in Bangladesh also. Though a number of initiatives have been introduced by the government to keep the women safe, there is no or little Information and Communication Technology (ICT) based solution exist to ensure the woman's safety in the context of Bangladesh. Therefore, the objective of this paper is to design and develop a safety device called 'SafeBand' for women to fight against physical harassment. The 'SafeBand' system is comprised of a wearable band to be used by the victim, and two mobile applications to be used by the victim and by the police. Women can wear the device as a wristband or locket which will comprise of a button and a light. When the user (victim) presses the button, it identifies the location of the user through Global Positioning System (GPS) and sends a message incorporating the location to the nearest police station and previously saved contacts (number of relatives). An empirical study was carried out to evaluate the 'SafeBand' system, which was replicated with 15 participants. The study results show that the developed system is effective, efficient, useful and acceptable to all users. © 2018 Association for Computing Machinery.},
	author_keywords = {Bangladesh; ICT; Physical harassment; Wearable device; Women safety},
	keywords = {Global positioning system; Law enforcement; Mobile computing; Bangladesh; Empirical studies; Information and Communication Technologies; Mobile applications; Physical harassment; Police station; Public transportation; Wearable devices; Wearable technology},
	editor = {Salvadori I.L. and Khalil I. and Steinbauer M. and Haghighi P.D. and Anderst K.G.},
	publisher = {Association for Computing Machinery},
	isbn = {978-145036452-2},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 18; Conference name: 16th International Conference on Advances in Mobile Computing and Multimedia, MoMM 2018; Conference date: 19 November 2018 through 21 November 2018; Conference code: 144111}
}

@CONFERENCE{Francesco20202148,
	author = {Francesco, Filippone and Ciro, Bolognese and Luciano, Roncalli and Matteo, Monterosso},
	title = {The response of the rescue system to large scale emergencies A case study: The collapse of the Morandi bridge Part 2 of 2: Technologies for rescue service},
	year = {2020},
	journal = {30th European Safety and Reliability Conference, ESREL 2020 and 15th Probabilistic Safety Assessment and Management Conference, PSAM 2020},
	pages = {2148 – 2153},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85110296310&partnerID=40&md5=5dea9956e254149917cdf10d934f2dab},
	affiliations = {Italian National Fire and Rescue Service, Genoa Fire and Rescue Service, Italy; Italian National Fire and Rescue Service, Novara Fire and Rescue Service, Italy; Italian National Fire and Rescue Service, Milan Fire and Rescue Service, Italy; Italian National Fire and Rescue Service, National Headquarters, Italy},
	abstract = {When a complex scenario occurs (e.g. earthquakes, forest fires, floods), the Italian National Fire and Rescue Service 1 mobilizes a large response by local first responders and additional specialized teams. In this age of disaster, also due to climate change and critical anthropic environments, the effectiveness of the response to various scenarios is also played by the availability of proper technologies that may support the skills and the expertise of rescuers. Taking into consideration some collapses of civil engineering structures occurred in Genoa in recent years, with a particular focus on the collapse of the Morandi bridge, the paper illustrates how the interaction between humans and technology is nowadays able to facilitate both the speedy risk-based decision making in the operational activities of the emergency phase and the residual risk assessments in the early recovery phase. The issues of the paper are: the technological tools of Urban Search & Rescue teams for a fast localization of victims; the application of a search and rescue methodology according to international procedures and guidelines (INSARAG2); the structural risk management for an immediate evaluation of the collapsed structures and rubble to care the rescuer's safety and the numerical modelling of artefacts for post-emergency evaluations; a description of a monitoring alarm system - designed by experts of the scientific community and industry and installed by firefighters in a synergic role play - to ensure safety measures for rescuers and population during the activity of the asset recovery in the built environments under the residual structures of the bridge; the use of geolocalization technologies in the forensic assistance; the use of modern technologies and instruments in the aeronautics industry (drones and helicopters) as valid support in search and rescue activity, giving a different "point of view" of the scenario to be analysed; the use of artificial intelligence, augmented reality, IoT for reducing the workload of the flight rescuers and increasing their operational efficacy. New challenges: the use of humanoid robots in search & rescue activities or in industrial applications, characterized by high risk for humans, to reach inaccessible zone and to ensure shorter time response. © ESREL2020-PSAM15 Organizers.},
	author_keywords = {Big data and iot applications; Disaster management; INSARAG international guideline; Public safety; Risk assessment; Risk management; Risk-based decision making},
	keywords = {Accident prevention; Alarm systems; Anthropomorphic robots; Artificial intelligence; Augmented reality; Bridges; Climate change; Deforestation; Human resource management; Industrial robots; Population statistics; Risk assessment; Risk management; Risk perception; Aeronautics industry; Civil engineering structures; Collapsed structures; Fire and rescue services; Large-scale emergency; Operational activity; Risk based decision making; Scientific community; Emergency services},
	editor = {Baraldi P. and Di Maio F. and Zio E.},
	publisher = {Research Publishing Services},
	isbn = {978-981148593-0},
	language = {English},
	abbrev_source_title = {Eur. Saf. Reliab. Conf., ESREL Probab. Saf. Assess. Manag. Conf., PSAM},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 30th European Safety and Reliability Conference, ESREL 2020 and 15th Probabilistic Safety Assessment and Management Conference, PSAM 2020; Conference date: 1 November 2020 through 5 November 2020; Conference code: 169730}
}

@ARTICLE{Li20181494,
	author = {Li, Chen and Liang, Mengti and Song, Wei and Xiao, Ke},
	title = {A multi-scale parallel convolutional neural network based intelligent human identification using face information},
	year = {2018},
	journal = {Journal of Information Processing Systems},
	volume = {14},
	number = {6},
	pages = {1494 – 1507},
	doi = {10.3745/JIPS.02.0103},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059393491&doi=10.3745%2fJIPS.02.0103&partnerID=40&md5=56c1c48fc5346b36de252a04a7eb070e},
	affiliations = {School of Computer Science, North China University of Technology, Beijing, China},
	abstract = {Intelligent human identification using face information has been the research hotspot ranging from Internet of Things (IoT) application, intelligent self-service bank, intelligent surveillance to public safety and intelligent access control. Since 2D face images are usually captured from a long distance in an unconstrained environment, to fully exploit this advantage and make human recognition appropriate for wider intelligent applications with higher security and convenience, the key difficulties here include gray scale change caused by illumination variance, occlusion caused by glasses, hair or scarf, self-occlusion and deformation caused by pose or expression variation. To conquer these, many solutions have been proposed. However, most of them only improve recognition performance under one influence factor, which still cannot meet the real face recognition scenario. In this paper we propose a multi-scale parallel convolutional neural network architecture to extract deep robust facial features with high discriminative ability. Abundant experiments are conducted on CMU-PIE, extended FERET and AR database. And the experiment results show that the proposed algorithm exhibits excellent discriminative ability compared with other existing algorithms. © 2018 KIPS.},
	author_keywords = {Face recognition; Intelligent human identification; MP-CNN; Robust feature},
	keywords = {Access control; Convolution; Information use; Internet of things; Network architecture; Network security; Neural networks; Convolutional neural network; Human identification; Intelligent applications; Intelligent surveillance; Internet of Things (IOT); MP-CNN; Robust feature; Unconstrained environments; Face recognition},
	correspondence_address = {K. Xiao; School of Computer Science, North China University of Technology, Beijing, China; email: zehan_xiao@163.com},
	publisher = {Korea Information Processing Society},
	issn = {1976913X},
	language = {English},
	abbrev_source_title = {J. Inf. Process. Syst.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 10}
}

@CONFERENCE{Engström2020,
	author = {Engström, Philip},
	title = {Visualizations techniques for forensic training applications},
	year = {2020},
	journal = {Proceedings of SPIE - The International Society for Optical Engineering},
	volume = {11426},
	doi = {10.1117/12.2562134},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089562464&doi=10.1117%2f12.2562134&partnerID=40&md5=41ab5bf70dd595024ecb9392b592a5e4},
	affiliations = {Swedish National Forensic Centre, Nfc Sweden, Linköping, 581 94, Sweden},
	abstract = {The Swedish National Forensic Centre, NFC, has been developing methods for 3D modeling of crime scenes since and methods for Virtual Reality (VR) visualizations since 2016. Documentation in 3D opens up new possibilities for visualization, documentation and forensic analysis and VR as well as Augmented Reality (AR) may within the near future become common practice in several forensic training situations. NFC has developed a proof of concept system for VR Crime scene reconstruction which has been tested by over two hundred individuals, both from law enforcement and from other fields, and the most common comment is that it is incredibly realistic reconstruction and that it is easy to understand how this can be of value within a crime scene investigation. The main limitations have been seen to lie within the 3D-modelling itself, creating close to perfect and realistic models takes a lot of time and effort, time that usually is not reasonable to add to an criminal investigation. However, for training purposes the payback of increased efficiency might be high enough to motivate the cost. For example being able to train in situations that are usually hard to recreate due to for example risk of injury or public safety reasons or being able to quickly switch between completely different environments without having to travel or make preparations. There is also a fundamental difference with learning from experience rather than from theory, and this is a main motivator behind trying to create an as immersive and realistic training experience as possible. © 2020 SPIE.},
	author_keywords = {Augmented reality; Forensics; Police; Training; Virtual reality; Visualization},
	keywords = {3D modeling; Augmented reality; Crime; Forensic science; Three dimensional computer graphics; Visualization; Crime scene investigations; Crime scene reconstruction; Criminal investigation; Forensic analysis; Learning from experiences; Proof of concept; Training applications; Training experiences; Mixed reality},
	editor = {Dennison M.S.},
	publisher = {SPIE},
	issn = {0277786X},
	isbn = {978-151063629-3},
	coden = {PSISD},
	language = {English},
	abbrev_source_title = {Proc SPIE Int Soc Opt Eng},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: Virtual, Augmented, and Mixed Reality ,XR Technology for Multi-Domain Operations 2020; Conference date: 27 April 2020 through 8 May 2020; Conference code: 161136}
}

@ARTICLE{Whitlock2020503,
	author = {Whitlock, Matt and Wu, Keke and Szafir, Danielle Albers},
	title = {Designing for Mobile and Immersive Visual Analytics in the Field},
	year = {2020},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	volume = {26},
	number = {1},
	pages = {503 – 513},
	doi = {10.1109/TVCG.2019.2934282},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075632881&doi=10.1109%2fTVCG.2019.2934282&partnerID=40&md5=4f2ccbc606dd8a7cacc375c5ba49473d},
	affiliations = {University of Colorado, United States},
	abstract = {Data collection and analysis in the field is critical for operations in domains such as environmental science and public safety. However, field workers currently face data-and platform-oriented issues in efficient data collection and analysis in the field, such as limited connectivity, screen space, and attentional resources. In this paper, we explore how visual analytics tools might transform field practices by more deeply integrating data into these operations. We use a design probe coupling mobile, cloud, and immersive analytics components to guide interviews with ten experts from five domains to explore how visual analytics could support data collection and analysis needs in the field. The results identify shortcomings of current approaches and target scenarios and design considerations for future field analysis systems. We embody these findings in FieldView, an extensible, open-source prototype designed to support critical use cases for situated field analysis. Our findings suggest the potential for integrating mobile and immersive technologies to enhance data's utility for various field operations and new directions for visual analytics tools to transform fieldwork. © 1995-2012 IEEE.},
	author_keywords = {Augmented Reality; Emergency Response; Immersive Analytics; Mobile Visualization; Outdoor Visualization},
	keywords = {Augmented reality; Data integration; Visualization; Data collection; Design considerations; Emergency response; Environmental science; Immersive; Immersive technologies; Mobile visualization; Visual analytics; article; field work; human; interview; Data acquisition},
	publisher = {IEEE Computer Society},
	issn = {10772626},
	coden = {ITVGE},
	pmid = {31425088},
	language = {English},
	abbrev_source_title = {IEEE Trans Visual Comput Graphics},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 20; All Open Access, Green Open Access}
}

@ARTICLE{Radman2019259,
	author = {Radman, Abduljalil and Suandi, Shahrel Azmin},
	title = {Markov random fields and facial landmarks for handling uncontrolled images of face sketch synthesis},
	year = {2019},
	journal = {Pattern Analysis and Applications},
	volume = {22},
	number = {1},
	pages = {259 – 271},
	doi = {10.1007/s10044-018-0755-7},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056311148&doi=10.1007%2fs10044-018-0755-7&partnerID=40&md5=1fbf8249e29fdc37138fe30d6a4b8a9a},
	affiliations = {Intelligent Biometric Group, School of Electrical and Electronic Engineering, Universiti Sains Malaysia, Nibong Tebal, 14300, Pulau Pinang, Malaysia; Faculty of Engineering and Information Technology, Taiz University, Taiz, Yemen},
	abstract = {Face sketch synthesis has drawn great attention in many computer vision applications such as law enforcement and digital entertainment. The majority of existing face sketch synthesis techniques are exemplar-based techniques, where a set of training photo–sketch pairs are first divided into patches. For an input photo patch from the face to be synthesized, k similar photo patches are found from the training set. The corresponding sketch patch of the best match is then selected to be synthesized. In such techniques, a multiscale Markov random fields (MRF) model is utilized for synthesizing a sketch using candidate sketch patches; having observed that techniques tend to fail with face photos acquired in uncontrolled imaging conditions like pose and lighting variations. For example, some structures along the lower part of the face sketch contour get lost due to ignoring the global face shape information and illumination changes. In this paper, we propose a reliable face sketch synthesis method based on MRF model and facial landmarks, called MRF-FL that can maintain further structures with uncontrolled face photos. Besides matching the input photo with training photo, the input photo and training sketch are also matched based on the facial landmarks so as to enhance face sketch structures around the lower part of face sketch contour. Experimental results showed that the proposed MRF-FL achieves superior performance compared with recent face sketch synthesis methods on CUHK and AR face sketch databases. © 2018, Springer-Verlag London Ltd., part of Springer Nature.},
	author_keywords = {Face recognition; Face sketch synthesis; Facial landmarks; Markov random fields},
	correspondence_address = {A. Radman; Intelligent Biometric Group, School of Electrical and Electronic Engineering, Universiti Sains Malaysia, Nibong Tebal, 14300, Malaysia; email: abdurad@usm.my},
	publisher = {Springer London},
	issn = {14337541},
	language = {English},
	abbrev_source_title = {Pattern Anal. Appl.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6}
}

@ARTICLE{Cozzolino2019,
	author = {Cozzolino, Marilena and Gabrielli, Roberto and Galatà, Pasquale and Gentile, Vincenzo and Greco, Giorgia and Scopinaro, Eleonora},
	title = {“Combined use of 3D metric surveys and non-invasive geophysical surveys at the stylite tower (UMM AR-RASAS, JORDAN)„},
	year = {2019},
	journal = {Annals of Geophysics},
	volume = {62},
	number = {3},
	doi = {10.4401/ag-8060},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075970124&doi=10.4401%2fag-8060&partnerID=40&md5=75b0d2fa6c607392271d54c10c4060ad},
	affiliations = {Institute for Technologies Applied to Cultural Heritage, National Council of Researches, Rome, Italy},
	abstract = {The Stylite Tower is part of the UNESCO archaeological site of Umm ar−Rasas (Jordan). It represents a unicum in its category and has a fundamental value for the Jordanian Cultural Heritage as a symbol and an emblem of Jordan’s history and culture. The monument has evident signs of deterioration that appear in the form of substantial detachments of the plaster, water infiltration, erosion and fractures. Given the need to preserve this important ancient monument and for public safety reasons, a high−detail analysis of the Tower has been achieved through the realization of 3D geometrical surveys (Photogrammetry and Laser Scanner) and non−invasive geophysical surveys (using Ground Penetrating Radar Technique). The use of non−destructive testing techniques has provided encouraging results for the struc− tural planning of diagnostic, consolidation and restoration activities. © 2019 the Istituto Nazionale di Geofisica e Vulcanologia.},
	keywords = {Jordan; archaeology; cultural heritage; geophysical survey; ground penetrating radar; monument; UNESCO},
	correspondence_address = {M. Cozzolino; Institute for Technologies Applied to Cultural Heritage, National Council of Researches, Rome, Italy; email: marilena.cozzolino@itabc.cnr.it},
	publisher = {Editrice Compositori s.r.l.},
	issn = {15935213},
	language = {English},
	abbrev_source_title = {Ann. Geophys.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 12; All Open Access, Gold Open Access}
}

@ARTICLE{Almeshal2018,
	author = {Almeshal, Abdullah M. and Alenezi, Mohammad R.},
	title = {A vision-based neural network controller for the autonomous landing of a quadrotor on moving targets},
	year = {2018},
	journal = {Robotics},
	volume = {7},
	number = {4},
	doi = {10.3390/robotics7040071},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058780655&doi=10.3390%2frobotics7040071&partnerID=40&md5=c941cd74c46a254aa65173ae5a96dbf7},
	affiliations = {PAAET, College of Technological Studies, Shuwaikh, 13092, Kuwait},
	abstract = {Time constraints is the most critical factor that faces the first responders' teams for search and rescue operations during the aftermath of natural disasters and hazardous areas. The utilization of robotic solutions to speed up search missions would help save the lives of humans who are in need of help as quickly as possible. With such a human-robot collaboration, by using autonomous robotic solutions, the first response team will be able to locate the causalities and possible victims in order to be able to drop emergency kits at their locations. This paper presents a design of vision-based neural network controller for the autonomous landing of a quadrotor on fixed and moving targets for Maritime Search and Rescue applications. The proposed controller does not require prior information about the target location and depends entirely on the vision system to estimate the target positions. Simulations of the proposed controller are presented using ROS Gazebo environment and are validated experimentally in the laboratory using a Parrot AR Drone system. The simulation and experimental results show the successful control of the quadrotor in autonomously landing on both fixed and moving landing platforms. © 2018 by the authors.},
	author_keywords = {Intelligent control; Neural network; ROS; Search and rescue; UAV; Unmanned aerial vehicles},
	correspondence_address = {A.M. Almeshal; PAAET, College of Technological Studies, Shuwaikh, 13092, Kuwait; email: am.almeshal@paaet.edu.kw},
	publisher = {MDPI AG},
	issn = {22186581},
	language = {English},
	abbrev_source_title = {Robotics},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 23; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Uddin2019,
	author = {Uddin, Mohammad Salah},
	title = {Development of Wearable Emergency Response System for Women},
	year = {2019},
	journal = {ICETAS 2019 - 2019 6th IEEE International Conference on Engineering, Technologies and Applied Sciences},
	doi = {10.1109/ICETAS48360.2019.9117562},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090207561&doi=10.1109%2fICETAS48360.2019.9117562&partnerID=40&md5=9a0baf5bf91318df6d1c085f4c131e8b},
	affiliations = {East West University, Department of Computer Science and Engineering, Aftabnagar, Dhaka, 1212, Bangladesh},
	abstract = {This paper presents a wearable emergency response system for women based on Internet of things (IoT) by considering the viewpoint of Bangladesh. Different type of sexual violence against women are happened all over the Bangladesh. Rape is the most common type of violence against women in recent days in our country. Rape is increasing rapidly. Victims of rape are not interested to file a legal complain against rapist, due to social barriers. Sometimes they feel shy and uncomfortable. In this regard a connected wearable device is introduced. This wearable device will established a communication among women with their family members, police station and nearby volunteer people. In extreme condition, a victim can able to make a help request directly to police station as well as nearby volunteer people (eager to help) and their family members by simply pressing a button of the proposed device. The conceptual design and implementation of the wearable device is discussed on this paper. © 2019 IEEE.},
	author_keywords = {Embedded Systems; Emergency Device; Internet of things; Rape; Sensors etc.; Wearable Device},
	keywords = {Conceptual design; Emergency services; Internet of things; Law enforcement; Bangladesh; Design and implementations; Emergency response systems; Extreme conditions; Internet of Things (IOT); Police station; Wearable devices; Wearable technology},
	correspondence_address = {M.S. Uddin; East West University, Department of Computer Science and Engineering, Aftabnagar, Dhaka, 1212, Bangladesh; email: uddin@ewubd.edu},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-172814082-7},
	language = {English},
	abbrev_source_title = {ICETAS - IEEE Int. Conf. Eng., Technol. Appl. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 6th IEEE International Conference on Engineering, Technologies and Applied Sciences, ICETAS 2019; Conference date: 20 December 2019 through 21 December 2019; Conference code: 161181}
}

@ARTICLE{Hanif2020722,
	author = {Hanif, Md. Imtiaz and Ahmed, Shakil and Akanda, Wahiduzzaman and Barman, Shohag},
	title = {Anti-Molestation: An IoT based Device for Women’s Self-Security System to Avoid Unlawful Activities},
	year = {2020},
	journal = {International Journal of Advanced Computer Science and Applications},
	volume = {11},
	number = {11},
	pages = {722 – 727},
	doi = {10.14569/IJACSA.2020.0111188},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099486663&doi=10.14569%2fIJACSA.2020.0111188&partnerID=40&md5=5807bc370908a6ad4442769b4990c678},
	affiliations = {Department of Computer Science, American International University-Bangladesh, Dhaka-1229, Bangladesh},
	abstract = {Now-a-days, the public, mostly women and children are facing much harassment from the societies. The unlawful activities against ladies and children have been increasing significantly, and regularly we find out about eve-teasing, sexual assault cases, and attempt to molest or even killing after rape in public places or open areas. Also, many cases had gone unwarranted due to short pieces of evidence. In Bangladesh, the current statistics of sexual assaults and various unlawful activities are proliferating. To acknowledge these problems, in this paper, we have designed an IoT-based (Internet of Things) embedded device that is able to communicate with the law enforcement agency by dialing “999” (An Emergency Telephone Number in Bangladesh) on demand. The device contains Arduino Pro-Mini Microcontroller with a GSM (Global System for Mobile communication) module and can send SMS (short message service) with the victim’s present area to the law enforcement agency and relatives via GPRS (General Packet Radio Services). The proposed device’s form factor is too tiny to carry out easily at anywhere and anytime. The device features the “Plug & Play” functionalities, which means one button to operate the entire device. Also, the device is cost-effective so that people of every level can afford it at a reasonable price. © 2020. All Rights Reserved.},
	author_keywords = {Anti-rape; GSM/GPRS; IoT device; smart-safety device; wearable device; women safety},
	keywords = {Cost effectiveness; Emergency traffic control; Global system for mobile communications; Law enforcement; Text messaging; Wearable technology; Anti-rape; Bangladesh; General Packet Radio Service; Global system for mobile communication/general packet radio service; IoT device; Sexual assault; Smart safeties; Smart-safety device; Wearable devices; Woman safety; Internet of things},
	publisher = {Science and Information Organization},
	issn = {2158107X},
	language = {English},
	abbrev_source_title = {Intl. J. Adv.  Comput. Sci. Appl.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; All Open Access, Gold Open Access}
}

@ARTICLE{Follmann2019,
	author = {Follmann, Andreas and Ohligs, Marian and Hochhausen, Nadine and Beckers, Stefan K. and Rossaint, Rolf and Czaplik, Michael},
	title = {Technical support by smart glasses during a mass casualty incident: A randomized controlled simulation trial on technically assisted triage and telemedical app use in disaster medicine},
	year = {2019},
	journal = {Journal of Medical Internet Research},
	volume = {21},
	number = {1},
	doi = {10.2196/11939},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059503168&doi=10.2196%2f11939&partnerID=40&md5=a4be9dcdc8e2908e38c194fa7d01dd1e},
	affiliations = {Docs in Clouds GmbH, Aachen, Germany; Medical Direction, Emergency Medical Service, City of Aachen, Aachen, Germany; Medical Technology Section, Department of Anaesthesiology, University Hospital RWTH Aachen, Pauwelsstraße 30, Aachen, D-52074, Germany},
	abstract = {Background: To treat many patients despite lacking personnel resources, triage is important in disaster medicine. Various triage algorithms help but often are used incorrectly or not at all. One potential problem-solving approach is to support triage with Smart Glasses. Objective: In this study, augmented reality was used to display a triage algorithm and telemedicine assistance was enabled to compare the duration and quality of triage with a conventional one. Methods: A specific Android app was designed for use with Smart Glasses, which added information in terms of augmented reality with two different methods—through the display of a triage algorithm in data glasses and a telemedical connection to a senior emergency physician realized by the integrated camera. A scenario was created (ie, randomized simulation study) in which 31 paramedics carried out a triage of 12 patients in 3 groups as follows: without technical support (control group), with a triage algorithm display, and with telemedical contact. Results: A total of 362 assessments were performed. The accuracy in the control group was only 58%, but the assessments were quicker (on average 16.6 seconds). In contrast, an accuracy of 92% (P=.04) was achieved when using technical support by displaying the triage algorithm. This triaging took an average of 37.0 seconds. The triage group wearing data glasses and being telemedically connected achieved 90% accuracy (P=.01) in 35.0 seconds. Conclusions: Triage with data glasses required markedly more time. While only a tally was recorded in the control group, Smart Glasses led to digital capture of the triage results, which have many tactical advantages. We expect a high potential in the application of Smart Glasses in disaster scenarios when using telemedicine and augmented reality features to improve the quality of triage. © Andreas Follmann, Marian Ohligs, Nadine Hochhausen, Stefan K Beckers, Rolf Rossaint, Michael Czaplik.},
	author_keywords = {Augmented reality; Disaster medicine; Emergency medical service physician; Mass casualty incident; Smart Glasses; Telemedicine; Triage},
	keywords = {Disaster Medicine; Emergency Medical Services; Eyeglasses; Humans; Mass Casualty Incidents; Telemedicine; Triage; controlled study; disaster medicine; emergency health service; human; mass disaster; mortality; procedures; psychology; randomized controlled trial; spectacles; telemedicine},
	correspondence_address = {A. Follmann; Medical Technology Section, Department of Anaesthesiology, University Hospital RWTH Aachen, Aachen, Pauwelsstraße 30, D-52074, Germany; email: afollmann@ukaachen.de},
	publisher = {JMIR Publications Inc.},
	issn = {14388871},
	pmid = {30609988},
	language = {English},
	abbrev_source_title = {J. Med. Internet Res.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 42; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Roossien2020,
	author = {Roossien, C.C. and Heus, R. and Reneman, M.F. and Verkerke, G.J.},
	title = {Monitoring core temperature of firefighters to validate a wearable non-invasive core thermometer in different types of protective clothing: Concurrent in-vivo validation},
	year = {2020},
	journal = {Applied Ergonomics},
	volume = {83},
	doi = {10.1016/j.apergo.2019.103001},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074977283&doi=10.1016%2fj.apergo.2019.103001&partnerID=40&md5=e1b1cc680893da43fe819c080b2babea},
	affiliations = {University of Groningen, University Medical Center Groningen, Department of Rehabilitation Medicine, Hanzeplein 1, Groningen, 9713, GZ, Netherlands; Institute for Safety (IFV), Zilverstraat 91, Zoetermeer, 2718, RP, Netherlands; University of Twente, Department of Biomechanical Engineering, Drienerlolaan 5, Enschede, 7522, NB, Netherlands},
	abstract = {This study aims (1) to test the validity of a new non-invasive core thermometer, Cosinuss°, in rest and (2) during firefighting simulation tasks, against invasive temperature pill and inner-ear temperature and (3) to compare the change in core temperature of firefighters when working in two types of protective clothing (traditional turnout gear versus new concept). 11 active firefighters performed twice a selection of tasks during their periodic preventive medical examination and a fire-extinguishing task. Without correction no correlation between the Cosinuss° and thermometer pill (ICC≤0.09, p ≥ 0.154, LoA≥1.37) and a moderate correlation between Cosinuss° and inner-ear infrared (ICC = 0.40, p = 0.044, LoA±1.20) was observed. With individual correction both correlations were excellent (ICC≥0.84, p = 0.000, LoA≤0.30). However, during and after working all correlations were poor and non-significant (ICC≤0.38, p ≥ 0.091, LoA≥1.71). During firefighting tasks, the Cosinuss° is invalid for measuring the core temperature. No differences in heat development in the two types of protective clothing was proven. © 2019 Elsevier Ltd},
	author_keywords = {Ambient conditions; Core temperature; Heat stress; Physical activity},
	keywords = {Adult; Body Temperature; Body Temperature Regulation; Firefighters; Humans; Male; Occupational Exposure; Physical Exertion; Protective Clothing; Skin Temperature; Stress, Physiological; Diagnosis; Fires; Protective clothing; Thermometers; Wearable technology; Ambient conditions; Core temperature; Fire-extinguishing; Heat development; Heat stress; In-vivo; Inner ear; Physical activity; adult; aged; Article; body temperature monitoring; core temperature; environmental temperature; female; fire fighter; fire protection; heat stress; human; human experiment; humidity; in vivo study; male; medical examination; physical activity; reliability; sensitivity analysis; simulation training; temperature measurement; thermography; validation process; work environment; body temperature; exercise; occupational exposure; physiological stress; physiology; protective clothing; skin temperature; thermoregulation; Fire extinguishers},
	correspondence_address = {C.C. Roossien; Groningen, A. Deusinglaan 1, FB33 (3215.1105), 9713, Netherlands; email: c.c.roossien@umcg.nl},
	publisher = {Elsevier Ltd},
	issn = {00036870},
	coden = {AERGB},
	pmid = {31739139},
	language = {English},
	abbrev_source_title = {Appl. Ergon.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 14; All Open Access, Green Open Access}
}

@ARTICLE{2019,
	title = {AHFE International Conference on Human Factors in Training, Education, and Learning Sciences, 2018},
	year = {2019},
	journal = {Advances in Intelligent Systems and Computing},
	volume = {785},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049644159&partnerID=40&md5=19b71092116027f9051740755ab12d01},
	abstract = {The proceedings contain 45 papers. The special focus in this conference is on Human Factors in Training, Education, and Learning Sciences. The topics include: A physically immersive platform for training emergency responders and law enforcement officers; conceptual description of the key determinants of effective monitoring and evaluation system; effectiveness of enhancing classroom by using augmented reality technology; inspirational messages to motivate students: A human centered smartphone application for stress relieve; capacity building through strengthening professional skills in engineering graduates; sense and sensibility in fashion design education; certain approaches to automated designing of competence-oriented models for knowledge engineers using the tutoring integrated expert systems; advancing performance assessment for aviation training; assessing the role of behavioral markers in adaptive learning for emergency medical services; participant training for a flight test evaluation of interval management; name tags and pipes: Assessing the role of metaphors in students’ early exposure to computer programming using emoticoding; extending the sentence verification technique to tables and node-link diagrams; increasing flexibility of employees in production processes using the differential learning approach – adaptation and validation of motor learning theories; evaluating training efficacy and return on investment for augmented reality: A theoretical framework; challenges in creating a mobile digital tutor for clinical communications training; “Step into the future” program as a system of non-formal research education in Russia; crucial moments in professional careers of preschool and primary teachers; redesign of chinese traditional culture: Take longmen grottoes as an example; spatial ability for university biology education; enhanced pilot learning interface.},
	editor = {Polak-Sopinska A. and Nazir S. and Teperi A.-M.},
	publisher = {Springer Verlag},
	issn = {21945357},
	isbn = {978-331993881-3},
	language = {English},
	abbrev_source_title = {Adv. Intell. Sys. Comput.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: AHFE International Conference on Human Factors in Training, Education, and Learning Sciences, 2018; Conference date: 21 July 2018 through 25 July 2018; Conference code: 215369}
}

@CONFERENCE{Pleva202051,
	author = {Pleva, Matus and Ondas, Stanislav and Juhar, Jozef and Hudson, Christopher R. and Carruth, Daniel W. and Bethel, Cindy L.},
	title = {Non-native vs native english speakers user experience in HMD vs desktop immersive training},
	year = {2020},
	journal = {11th IEEE International Conference on Cognitive Infocommunications, CogInfoCom 2020 - Proceedings},
	pages = {51 – 54},
	doi = {10.1109/CogInfoCom50765.2020.9237815},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096354865&doi=10.1109%2fCogInfoCom50765.2020.9237815&partnerID=40&md5=b3e53fe21f6dbe5613d1e6aa1562f31f},
	affiliations = {Technical University of Kosice, Faculty of Electrical Engineering and Informatics, Department of Electronics and Multimedia Communications, Letna 9, Kosice, 04200, Slovakia; Center for Advanced Vehicular Systems, Mississippi State University, Starkville, 39759, MS, United States; Mississippi State University, Department of Computer Science and Engineering, Mississippi State, 39762, MS, United States},
	abstract = {During previous years, researchers from TUKE (Technical University of Kosice) and MSU (Mississippi State University) collaborated on building a virtual immersive training environment for law enforcement officers. The training tool was designed for operation in Virtual Reality (VR) using HMD (Head Mounted Display) and 3D Desktop modes. The goal was to control a Jaguar V4 robot in a virtual environment using both joystick and voice commands, because not all functions could be accessed by hand controllers alone. The speech recognition was designed for English speakers. Firstly it was tested at MSU with five US participants and later the same tests were repeated with 16 students at TUKE, who were non-native English speakers. This article provides an overview of the experiment and a comparison of cognitive aspects and user acceptance levels resulted from these trials on different continents and different English speakers (native and non-native ones). © 2020 IEEE.},
	author_keywords = {Human-robot interaction; Speech recognition; Usability; Virtual reality},
	keywords = {Environmental regulations; Helmet mounted displays; Speech recognition; User experience; Cognitive aspects; Head mounted displays; Law enforcement officers; Mississippi State University; Previous year; Technical universities; Training tools; User acceptance; Virtual reality},
	correspondence_address = {M. Pleva; Technical University of Kosice, Faculty of Electrical Engineering and Informatics, Department of Electronics and Multimedia Communications, Kosice, Letna 9, 04200, Slovakia; email: matus.pleva@tuke.sk; S. Ondas; Technical University of Kosice, Faculty of Electrical Engineering and Informatics, Department of Electronics and Multimedia Communications, Kosice, Letna 9, 04200, Slovakia; email: stanislav.ondas@tuke.sk; J. Juhar; Technical University of Kosice, Faculty of Electrical Engineering and Informatics, Department of Electronics and Multimedia Communications, Kosice, Letna 9, 04200, Slovakia; email: jozef.juhar@tuke.sk},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-172818213-1},
	language = {English},
	abbrev_source_title = {IEEE Int. Conf. Cogn. Infocommunications, CogInfoCom - Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 11th IEEE International Conference on Cognitive Infocommunications, CogInfoCom 2020; Conference date: 23 September 2020 through 25 September 2020; Conference code: 164650}
}

@CONFERENCE{2020,
	title = {Virtual, Augmented, and Mixed Reality (XR) Technology for Multi-Domain Operations},
	year = {2020},
	journal = {Proceedings of SPIE - The International Society for Optical Engineering},
	volume = {11426},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089601352&partnerID=40&md5=3a0c9654a23b34f868bea44701b56fbd},
	abstract = {The proceedings contain 16 papers. The topics discussed include: on the use of operations research for decision making with uncertainty for IoT devices in battlefield situations: simulations and outcomes; tools for enabling teaming during mission planning and rehearsal; visualizations techniques for forensic training applications; physical object interaction in first responder mixed reality training; a systematic literature review on dynamic cognitive augmentation through immersive reality: challenges and perspectives; the impact of immersion level and virtual reality experience on outcomes from navigating in a virtual environment; divisive display augmented reality (ddAR) for real-world warfighter performance; and designing augmented reality visualizations for synchronized and time-dominant human-robot teaming.},
	editor = {Dennison M.S.},
	publisher = {SPIE},
	issn = {0277786X},
	isbn = {978-151063629-3},
	coden = {PSISD},
	language = {English},
	abbrev_source_title = {Proc SPIE Int Soc Opt Eng},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: Virtual, Augmented, and Mixed Reality ,XR Technology for Multi-Domain Operations 2020; Conference date: 27 April 2020 through 8 May 2020; Conference code: 161136}
}

@CONFERENCE{Yang2018453,
	author = {Yang, Li and Liang, Yu and Wu, Dalei and Gault, Jim},
	title = {Train and equip firefighters with cognitive virtual and augmented reality},
	year = {2018},
	journal = {Proceedings - 4th IEEE International Conference on Collaboration and Internet Computing, CIC 2018},
	pages = {453 – 459},
	doi = {10.1109/CIC.2018.00068},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059779744&doi=10.1109%2fCIC.2018.00068&partnerID=40&md5=94fa26da4ad10278924f55280727406c},
	affiliations = {Department of Computer Science and Engineering, University of Tennessee at Chattanooga, Chattanooga, TN, United States; Red Bank Fire Department, Chattanooga, TN, United States},
	abstract = {It is important to reduce loss caused by fires through improved operations performed by virtual and augmented reality (VR/AR) trained and equipped fire-fighters. This paper collaborates with firefighting professionals to training firefighting skills with VR/AR systems. The system is also integrated with computational models and decision tools to provide situational awareness and address challenges faced by firefighters on the fire ground. © 2018 IEEE.},
	author_keywords = {Fire dynamic simulation; Firefighting; Virtual and augmented reality},
	keywords = {Augmented reality; Fire extinguishers; Computational model; Decision tool; Fire dynamics; Fire fighters; Firefighting; Situational awareness; Virtual and augmented reality; Fires},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-153869502-9},
	language = {English},
	abbrev_source_title = {Proc. - IEEE Int. Conf. Collab. Internet Comput., CIC},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 9; Conference name: 4th IEEE International Conference on Collaboration and Internet Computing, CIC 2018; Conference date: 18 October 2018 through 20 October 2018; Conference code: 142784}
}

@CONFERENCE{Qaosar2018269,
	author = {Qaosar, Mahboob and Ahmed, Saleh and Li, Chen and Morimoto, Yasuhiko},
	title = {Hybrid sensing and wearable smart device for health monitoring and medication: opportunities and challenges},
	year = {2018},
	journal = {AAAI Spring Symposium - Technical Report},
	volume = {2018-March},
	pages = {269 – 274},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088252269&partnerID=40&md5=9f3ed968df5547173870f2a8b86b6a4f},
	affiliations = {Graduate School of Engineering, Hiroshima University Kagamiyama, 1-7-1, Higashi-Hiroshima, 739-8521, Japan},
	abstract = {Global health-care systems are struggling with rapid increasing of aging population, the prevalence of chronic diseases, and raising of medical treatment costs. In this paper, we proposed a hybrid sensing and wearable device for health informatics and emergency medication. The proposed device will include some of the existing individual modules for monitoring health attributes and emergency medication. Moreover, it will also include information communication modules, which will assist the prescribed physician and health center to monitor the patient remotely. In addition, the communication modules will enable the device to communicate automatically with emergency medical services when needed. Furthermore, the proposed device will also act as a virtual medical assistant to advice regular medicine to the patient according to his/her prescription. © 2018 AI Access Foundation. All rights reserved.},
	keywords = {Diseases; Emergency services; Wearable technology; Aging population; Chronic disease; Communication modules; Emergency medical services; Health monitoring; Information communication; Medical treatment; Wearable devices; Medical informatics},
	publisher = {AI Access Foundation},
	language = {English},
	abbrev_source_title = {AAAI Spring Symp. Tech. Rep.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 2018 AAAI Spring Symposium; Conference date: 26 March 2018 through 28 March 2018; Conference code: 167564}
}

@CONFERENCE{Melzer2018,
	author = {Melzer, James E. and Morde, Ashutosh},
	title = {Location and head orientation tracking in GPS-denied environments},
	year = {2018},
	journal = {Proceedings of SPIE - The International Society for Optical Engineering},
	volume = {10642},
	doi = {10.1117/12.2304013},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050604033&doi=10.1117%2f12.2304013&partnerID=40&md5=ca65c09c9b63086d970b4aaf1669ae75},
	affiliations = {Thales Visionix, Inc., 1444 N. Farnsworth Ave, Aurora, 60505, IL, United States; Thales Visionix, Inc., 700 Technology Park Dr, Billerica, 01821, MA, United States},
	abstract = {Wayfinding has been investigated by multiple researchers in the context of a Landmark-to-Route-to-Survey learning construct that relies on multiple and - across the population - varying cognitive mechanisms. The development of GPS-based cellphone navigation AIDS has made wayfinding easier for most situations, though for First Responders and Ground Warfighters, the need to navigate in GPS-denied environments without such assistance may compromise their ability to get their job done as well as their safety. We will discuss wayfinding research and look at bio-inspired navigation methods because they may point us to navigation solutions that do not rely on GPS. Finally, we will discuss a hybrid inertial and visual navigation and tracking system that we have integrated into an augmented reality ensemble for high stress, GPS-denied applications with some recommendations for future growth. © 2018 SPIE.},
	author_keywords = {Gaze tracking; GPS-denied; Location tracking; Navigation; Tracking; Wayfinding},
	keywords = {Augmented reality; Eye tracking; Navigation; Surface discharges; Tracking (position); Cognitive mechanisms; First responders; Navigation aids; Navigation methods; Navigation solution; Orientation tracking; Visual Navigation; Way-finding; Global positioning system},
	correspondence_address = {J.E. Melzer; Thales Visionix, Inc., Aurora, 1444 N. Farnsworth Ave, 60505, United States; email: Jim.Melzer@ThalesVisionix.com},
	editor = {Sanders-Reed J.N. and Arthur J.J.},
	publisher = {SPIE},
	issn = {0277786X},
	isbn = {978-151061795-7},
	coden = {PSISD},
	language = {English},
	abbrev_source_title = {Proc SPIE Int Soc Opt Eng},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: Degraded Environments: Sensing, Processing, and Display 2018; Conference date: 17 April 2018 through 18 April 2018; Conference code: 138054}
}

@CONFERENCE{Schönauer2020,
	author = {Schönauer, Christian and Bösch, Chris and Wechdorn, Thomas and Göllner, Johannes and Peer, Andreas and Mossel, Annette and Kaufmann, Hannes},
	title = {Physical object interaction in first responder mixed reality training},
	year = {2020},
	journal = {Proceedings of SPIE - The International Society for Optical Engineering},
	volume = {11426},
	doi = {10.1117/12.2557396},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089582263&doi=10.1117%2f12.2557396&partnerID=40&md5=781b0518066da677363bfcab37b7d0b0},
	affiliations = {Tu Wien, Favoritenstrae 9, Wien/Vienna, A-1040, Austria; National Defense Academy, Stiftsgasse 2a, Wien/Vienna, A-1070, Austria},
	abstract = {Virtual Reality (VR) systems can improve the training of first responders and soldiers in multi-domain operations in a number of ways. Realistic simulation of physical objects, however, is challenging. The huge variety of equipment pieces and other objects specialists in first responder units-and in particular CBRN-troops-interact with further increases the effort. In this paper, we present a novel and flexible Mixed Reality (MR) training system for first responders that enables the integration of physical objects by using Augmented Virtuality (AV) and inary tracking". A Head Mounted Display (HMD) immerses the user in VR, while augmenting the visualization with 3D imagery of real objects, captured by an RGB-D sensor. In addition, a RFID-reader at the user's hand detects the presence or absence (binary response) of certain equipment items. Our proposed MR system fuses this information with data of an inertial motion capture suit to an approximate global object pose and distributes it. Our solution provides a wide range of options for physical object interaction and collaboration in a multi-user MR environment. In addition, we demonstrate the training capabilities of our proposed system with a multi-user training scenario, simulating a CBRN crisis. Results from our technical and quantitative user evaluation with 13 experts in CBRN response from the Austrian Armed Forces (National Defense Academy and Competence Center NBC Defense) indicate strong applicability and user acceptance. Over 80% of the participants found it easy or very easy to interact with physical objects and liked the multi-user training much or very much. © 2020 SPIE.},
	author_keywords = {Augmented Virtuality; First Responder Training; Mixed Reality; Physical Object Interaction},
	keywords = {Helmet mounted displays; Network security; Object tracking; Three dimensional computer graphics; Augmented virtualities; First responders; Head mounted displays; Inertial motion captures; National defense; Physical objects; Realistic simulation; User evaluations; Mixed reality},
	correspondence_address = {C. Schönauer; Tu Wien, Wien/Vienna, Favoritenstrae 9, A-1040, Austria; email: christian.schoenauer@tuwien.ac.at},
	editor = {Dennison M.S.},
	publisher = {SPIE},
	issn = {0277786X},
	isbn = {978-151063629-3},
	coden = {PSISD},
	language = {English},
	abbrev_source_title = {Proc SPIE Int Soc Opt Eng},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: Virtual, Augmented, and Mixed Reality ,XR Technology for Multi-Domain Operations 2020; Conference date: 27 April 2020 through 8 May 2020; Conference code: 161136}
}

@CONFERENCE{Ling20191044,
	author = {Ling, Frank Fong and Elvezio, Carmine and Bullock, Jacob and Henderson, Steve and Feiner, Steven},
	title = {A hybrid RTK GNSS and SLAM outdoor augmented reality system},
	year = {2019},
	journal = {26th IEEE Conference on Virtual Reality and 3D User Interfaces, VR 2019 - Proceedings},
	pages = {1044 – 1045},
	doi = {10.1109/VR.2019.8798315},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071851728&doi=10.1109%2fVR.2019.8798315&partnerID=40&md5=a861c94f9d82dcd993f9a117dc00be3c},
	affiliations = {Columbia University, United States},
	abstract = {In the real world, we are surrounded by potentially important data. For example, military personnel and first responders may need to understand the layout of an environment, including the locations of designated assets, specified in latitude and longitude. However, many augmented reality (AR) systems cannot associate absolute geographic coordinates with the coordinate system in which they track. We describe a simple approach for developing a wide-area outdoor wearable AR system that uses RTK GNSS position tracking to align together and georegister multiple smaller maps from an existing SLAM tracking system. © 2019 IEEE.},
	author_keywords = {Centered computing; Computer GraphicsGraphics systems and interfacesMixed / augmented reality; Computer interaction (HCI); Computing methodologies; Human; Human; Interaction paradigms; Mixed / augmented reality},
	keywords = {Augmented reality; Global positioning system; Human computer interaction; Tracking (position); Virtual reality; Centered computing; Computer interaction; Computing methodologies; Human; Interaction paradigm; Mixed/augmented reality; User interfaces},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-172811377-7},
	language = {English},
	abbrev_source_title = {IEEE Conf. Virtual Real. 3D User Interfaces, VR - Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8; Conference name: 26th IEEE Conference on Virtual Reality and 3D User Interfaces, VR 2019; Conference date: 23 March 2019 through 27 March 2019; Conference code: 150842}
}

@CONFERENCE{Sharma202070,
	author = {Sharma, Sharad and Stigal, James and Bodempudi, Sri Teja},
	title = {Situational Awareness-based Augmented Reality Instructional (ARI) Module for Building Evacuation},
	year = {2020},
	journal = {Proceedings - 2020 IEEE Conference on Virtual Reality and 3D User Interfaces, VRW 2020},
	pages = {70 – 78},
	doi = {10.1109/VRW50115.2020.00020},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085387972&doi=10.1109%2fVRW50115.2020.00020&partnerID=40&md5=0fa8e910bd88a1efe9d8172da307a562},
	affiliations = {Bowie State University, Department of Computer Science, Bowie, MD, United States},
	abstract = {Emergency response in indoor building evacuation is essential for effective rescue and safety management. First responders often lack the situational awareness capability to quickly assess the layout of a building upon initial entry. For occupants of the building, situational awareness becomes more important in cases of active shooter events or circumstances of fire and smoke. One of the challenges is to provide user-specific personalized evacuation routes in real-time. In multilevel building environments, the complexity of the architecture creates problems for both visual and mental representation of the 3D spaces. This paper presents three cutting edge Augmented Reality Instructional (ARI) modules that overcome the visual limitations associated with the traditional, static 2D methods of communicating evacuation plans for multilevel buildings. Using existing building features, the authors demonstrate how the three modules provide contextualized 3D visualizations that promote and support spatial knowledge acquisition and cognitive mapping thereby enhancing situational awareness. These ARI visualizations are developed for first responders and building occupants to help increase emergency preparedness and mitigate the evacuation related risks in multilevel building rescues and safety management. Specifically, the paper describes the design and implementation of the ARI modules and reports the results of the pilot studies conducted to evaluate their perceived usefulness, ease-of-use, and usability. The results suggest the desirability of further heuristic examination of three-dimensional situational awareness-based ARI application effectiveness in multilevel building evacuations. © 2020 IEEE.},
	author_keywords = {Augmented reality; emergency management; indoor evacuation; two-dimensional/three-dimensional visualizations},
	keywords = {Augmented reality; Building components; Emergency services; Smoke; Three dimensional computer graphics; User interfaces; Visualization; Building evacuation; Design and implementations; Emergency preparedness; Mental representations; Multi-level buildings; Perceived usefulness; Situational awareness; Spatial knowledge acquisitions; Virtual reality},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-172816532-5},
	language = {English},
	abbrev_source_title = {Proc. - IEEE Conf. Virtual Real. 3D User Interfaces, VRW},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 12; Conference name: 2020 IEEE Conference on Virtual Reality and 3D User Interfaces, VRW 2020; Conference date: 22 March 2020 through 26 March 2020; Conference code: 115117}
}

@CONFERENCE{Polese201744,
	author = {Polese, Michele and Mezzavilla, Marco and Rangan, Sundeep and Kessler, Coitt and Zorzi, Michele},
	title = {Mmwave for future public safety communications},
	year = {2017},
	journal = {I-TENDER 2017 - Proceedings of the 2017 1st CoNEXT Workshop on ICT Tools for Emergency Networks and DisastEr Relief},
	pages = {44 – 49},
	doi = {10.1145/3152896.3152905},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041228870&doi=10.1145%2f3152896.3152905&partnerID=40&md5=3d935077857a090f09128c06681a635a},
	affiliations = {University of Padova, Italy; NYU Wireless, Brooklyn, United States; Austin Fire Department, Austin, United States},
	abstract = {The technologies developed for the next generation of cellular networks (i.e., 5G) are potential enablers for future Public Safety Communication (PSC) systems. These will indeed need advanced communication techniques, capable of providing real-time, lowlatency and reliable interactions in different scenarios (vehicular, aerial, unmanned) and different network architectures. There is great interest in the millimeter wave (mmWave) band and in general in the spectrum above 6 GHz, since the bandwidth that can be allocated at these frequencies is much higher compared to the traditional (and congested) sub-6 GHz bands. This would enable orders of magnitude greater throughput and low latency, which could be used for example to stream high definition video or virtual/augmented reality data to first responders or for the remote control of autonomous robots. In this paper we illustrate both the potential of mmWave communications for PSC (also with a typical use case) and the issues that must be solved before this technology can be reliably adopted and mmWave PSC networks become a reality. © 2017 Association for Computing Machinery.},
	author_keywords = {Emergency networks; MmWave; Public safety communications},
	keywords = {Disaster prevention; Disasters; Emergency services; Millimeter waves; Network architecture; Remote control; Communication techniques; Emergency networks; High definition video; Millimeter waves (mmwave); mm-Wave; Mm-wave Communications; Orders of magnitude; Public safety communications; 5G mobile communication systems},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {978-145035424-0},
	language = {English},
	abbrev_source_title = {I-TENDER - Proc. CoNEXT Workshop ICT Tools Emerg. Networks DisastEr Relief},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 1st CoNEXT Workshop on ICT Tools for Emergency Networks and DisastEr Relief, I-TENDER 2017; Conference date: 12 December 2017; Conference code: 132754}
}

@CONFERENCE{Collington2018377,
	author = {Collington, Deshawn and Doswell, Jayfus and Johnson, Justin and Messam, Marcus and Salaam, Saboor and Boykin, Ashley},
	title = {The pervasive rapid E-preparedness augmented reality environment (PREPARE) E-learning intervention for HAZWOPER training of fire fighter/EMTs},
	year = {2018},
	journal = {Proceedings - IEEE 18th International Conference on Advanced Learning Technologies, ICALT 2018},
	pages = {377 – 379},
	doi = {10.1109/ICALT.2018.00096},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052492699&doi=10.1109%2fICALT.2018.00096&partnerID=40&md5=9ed45843d7a43b301f383157bf19be46},
	affiliations = {National Institutes of Health ASCEND-BUILD, Morgan State University, Baltimore, MD, United States; Juxtopia, LLC, Baltimore, MD, United States},
	abstract = {A Juxtopia research team collaborated with the Maryland Fire & Rescue Institute (MFRI) to test how the Juxtopia® wearable augmented reality (AR) intervention may better deliver a hands-on clinical training intervention to firefighter Emergency Medical Technicians (EMT) and prepare them for effective response to HAZMAT (hazardous materials) incidences. During a controlled study, human subjects participated in a minimal risk research study (i.e., both as victims or caregivers) in which firefighter EMTs participated in a simulated training exercise that mimicked their real-world operations. This study consisted of two testing days. Day one included 10 participants that completed a full day of training and familiarity with wearable augmented reality (AR) goggles and a Juxtopia® Virtual Tutor (JVT) software application, which is derived from the Juxtopia® Intelligent Virtual Instructor (JiVi) platform. Day two included the completion of four psychomotor clinical skills performed by EMTs. It also included the application of moulage injuries for victims, using the Juxtopia® CAMMRAD PREPARE system to administer clinical skills on patient actors. This paper discusses the research methods and results. © 2018 IEEE.},
	author_keywords = {Augmented reality; Clinical skills; EMT; HAZWOPER},
	keywords = {Application programs; Augmented reality; Distance education; Fire extinguishers; Wearable computers; Clinical skills; Emergency medical technicians; HAZWOPER; Real world operations; Simulated trainings; Software applications; Virtual instructors; Wearable augmented realities; Clinical research},
	editor = {Chen N.-S. and Chang M. and Huang R. and Kinshuk K. and Moudgalya K. and Murthy S. and Sampson D.G.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-153866049-2},
	language = {English},
	abbrev_source_title = {Proc. - IEEE Int. Conf. Adv. Learn. Technol., ICALT},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 18th IEEE International Conference on Advanced Learning Technologies, ICALT 2018; Conference date: 9 July 2018 through 13 July 2018; Conference code: 138586}
}

@ARTICLE{Smink2019,
	author = {Smink, Anne R. and Frowijn, Sanne and van Reijmersdal, Eva A. and van Noort, Guda and Neijens, Peter C.},
	title = {Try online before you buy: How does shopping with augmented reality affect brand responses and personal data disclosure},
	year = {2019},
	journal = {Electronic Commerce Research and Applications},
	volume = {35},
	doi = {10.1016/j.elerap.2019.100854},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065174727&doi=10.1016%2fj.elerap.2019.100854&partnerID=40&md5=5dceeb8c08daaa52e0031adec93599b2},
	affiliations = {Amsterdam School of Communication Research (ASCoR), University of Amsterdam, Amsterdam, Netherlands},
	abstract = {Augmented Reality (AR)enables consumers to virtually try products on their own face or surroundings in real time (e.g., make-up, furniture), which could help providing consumers a ‘try before you buy’ experience when shopping online. In an online experiment, we examined the potential positive and negative effects of online product presentation with AR, compared to two non-AR product presentations on a picture of the self or a model. Results suggest that AR enhances perceived informativeness and enjoyment of the shopping experience, as opposed to both non-AR product presentations. Consequently, perceived informativeness leads to a cognitive process which enhances purchase intention and willingness to share personal data with the brand, while perceived enjoyment leads to an affective process which enhances attitude towards the brand. At the same time, AR is perceived as more intrusive, but against expectations, this does not lead to any negative effects. © 2019 Elsevier B.V.},
	author_keywords = {Augmented reality; Enjoyment; Informativeness; Intrusiveness; Online shopping; Personal data disclosure; Persuasion},
	keywords = {Augmented reality; Law enforcement; Enjoyment; Informative ness; Intrusiveness; Online shopping; Persuasion; Data reduction},
	correspondence_address = {A.R. Smink; University of Amsterdam, NG Amsterdam, P.O. Box 15791, 1001, Netherlands; email: A.R.Smink@uva.nl},
	publisher = {Elsevier B.V.},
	issn = {15674223},
	language = {English},
	abbrev_source_title = {Elect. Commer. Res. Appl.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 97; All Open Access, Green Open Access}
}

@CONFERENCE{Gallagher2019,
	author = {Gallagher, Dennis G.},
	title = {LED air warning system (LAWS) for first responders and public safety divers: A new product development-based senior capstone design project},
	year = {2019},
	journal = {OCEANS 2019 MTS/IEEE Seattle, OCEANS 2019},
	doi = {10.23919/OCEANS40490.2019.8962589},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079042932&doi=10.23919%2fOCEANS40490.2019.8962589&partnerID=40&md5=f1b1c2a5412e4fdb0e8407792bd6eb44},
	affiliations = {Naval Surface Warfare Center, Panama City Division, Code E15, Panama City, 32407, FL, United States},
	abstract = {First Responder/Public Safety Divers (FR/PSDs) conduct rescue and evidence recovery operations in dark, turbid waters, where visibility is often non-existent, making it impossible to read their pressure gauges to determine if they are low on air. The Florida State University-Panama City (FSUPC) Senior Electrical Engineering Class (EEL 4915C Senior Design II), working in collaboration with the Naval Surface Warfare Center-Panama City Division (NSWC PCD) under an Education Partnership Agreement (EPA), engaged in a senior design project that developed a concept prototype to reduce risk and help save lives for the FR/PSD community. The LED Air Warning System (LAWS) incorporates a pressure transducer connected to the diver's air tank and a multi-LED array attached to the diver's mask. The system provides detailed visual information about remaining air pressure during a dive clearly visible even in extremely poor visibility conditions. To continue development of the LAWS into a commercial product for the FR/PSD community NSWC PCD collaborated with industry partner Interspiro, Inc. (diving equipment manufacturer) through a Cooperative Research and Development Agreement (CRADA) to complete product development, user evaluation, and technology transition of the LAWS into production. © 2019 Marine Technology Society.},
	author_keywords = {Diving; Head-up displays; Safety},
	keywords = {Accident prevention; Head-up displays; Light emitting diodes; Manufacture; Naval warfare; Oceanography; Product development; Safety engineering; Visibility; Diving; Education partnerships; Equipment manufacturers; Florida State University; Naval Surface Warfare Center; New product development; Research and development; Technology transition; Product design},
	correspondence_address = {D.G. Gallagher; Naval Surface Warfare Center, Panama City Division, Code E15, Panama City, 32407, United States; email: dennis.g.gallagher@navy.mil},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-057857618-3},
	language = {English},
	abbrev_source_title = {OCEANS MTS/IEEE Seattle, OCEANS},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2019 OCEANS MTS/IEEE Seattle, OCEANS 2019; Conference date: 27 October 2019 through 31 October 2019; Conference code: 156992}
}

@CONFERENCE{Pluntke20192207,
	author = {Pluntke, U. and Gerke, S. and Sridhar, A. and Weiss, J. and Michel, B.},
	title = {Evaluation and Classification of Physical and Psychological Stress in Firefighters using Heart Rate Variability},
	year = {2019},
	journal = {Proceedings of the Annual International Conference of the IEEE Engineering in Medicine and Biology Society, EMBS},
	pages = {2207 – 2212},
	doi = {10.1109/EMBC.2019.8856596},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073908771&doi=10.1109%2fEMBC.2019.8856596&partnerID=40&md5=e86db91da00a1d8dec155dfb22a1fe84},
	affiliations = {IBM Watson IoT Center, Munich, 80807, Germany; IBM Research, Zurich, Switzerland},
	abstract = {Stress detection has a huge potential for disease prevention and management, and to improve the quality of life of people. Also, work safety can be improved if stress is timely and reliably detected. The availability of low-cost consumer wearable devices that monitor vital-signs, gives access to stress detection schemes. Heart rate variability (HRV), a stress-related vital-sign, was derived from wearable device data to reliably determine stress-levels. In order to build and train a deployable stress-detector, we collected labeled HRV data in controlled environments, where subjects were exposed to physical, psychological and combined stress. We then applied machine learning to separate and identify the different stress types and understand the relationship with HRV data. The resulting C5 decision tree model is capable of identifying the stress type with 88% accuracy, in a 1-minute time window. For the first time physical and psychological stress can be distinguished with a 1-minute time resolution from smoke-divers, firefighters, who enter high-risk environments to rescue people, and experience intense physical and psychological stress. To improve our model, we created an integrated system to acquire expert labels in real-time from firefighters during their training in a Rescue Maze. A next goal is to transfer the algorithms into generic systems for monitoring and coaching high-risk professionals to improve their stress resilience during training and reduce their risk in the field. © 2019 IEEE.},
	keywords = {Firefighters; Heart Rate; Humans; Quality of Life; Stress, Psychological; Wearable Electronic Devices; Decision trees; Heart; Smoke; Stresses; Wearable technology; Applied machine learning; Controlled environment; Decision tree modeling; Evaluation and classifications; Heart rate variability; High risk environment; Integrated systems; Psychological stress; electronic device; fire fighter; heart rate; human; mental stress; psychology; quality of life; Fire extinguishers},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {1557170X},
	isbn = {978-153861311-5},
	pmid = {31946339},
	language = {English},
	abbrev_source_title = {Proc. Annu. Int. Conf. IEEE Eng. Med. Biol. Soc. EMBS},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 26; Conference name: 41st Annual International Conference of the IEEE Engineering in Medicine and Biology Society, EMBC 2019; Conference date: 23 July 2019 through 27 July 2019; Conference code: 152547}
}

@CONFERENCE{2019,
	title = {Proceedings of the Mensch und Computer 2019, MuC 2019 - Workshop on Konstruktion und praktischer Einsatz von User Experience Fragebogen},
	year = {2019},
	journal = {Lecture Notes in Informatics (LNI), Proceedings - Series of the Gesellschaft fur Informatik (GI)},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138745333&partnerID=40&md5=1f3fc22a55ceaddd0db6b67c6ae3a76d},
	abstract = {The proceedings contain 136 papers. The topics discssed include: an active tangible device for multitouch-display interaction; active tangibles for tabletop interaction based on the Kniwwelino prototyping platform; adaptive dark mode: investigating text and transparency of windshield display content for automated driving; adjusting AR-workflows of care tasks: experiences from an initial study; adoption, use and diffusion of crisis apps in Germany: a representative survey; aicracy: everyday objects from a future society governed by artificial intelligence; AMAP: a visual programming language based system to support document image analysis; analyzing the communication between the public safety authorities and the population in crisis situations; application scenarios for 3D-printed organ models for collaboration in VRAR; and applying voting methods in user research.},
	publisher = {Gesellschaft fur Informatik (GI)},
	issn = {16175468},
	language = {English},
	abbrev_source_title = {Lect. Notes Informatics (LNI), Proc. - Series Ges. Inform. (GI)},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: Proceedings of the Mensch und Computer 2019, MuC 2019 - Workshop on Konstruktion und praktischer Einsatz von User Experience Fragebogen - Proceedings of the Human and Computer 2019, MuC 2019 - Workshop on Construction and Practical Use of User Experience Questionnaires; Conference date: 8 September 2019 through 11 September 2019; Conference code: 182647}
}

@CONFERENCE{Morales-Mere2020,
	author = {Morales-Mere, Jose and Chessa, Juan J. and Palomares, Ricardo and Cornejo, Jose},
	title = {Mixed Reality System for Education and Innovation in Prehospital Interventions at Peruvian Fire Department},
	year = {2020},
	journal = {Proceedings of the 2020 IEEE 27th International Conference on Electronics, Electrical Engineering and Computing, INTERCON 2020},
	doi = {10.1109/INTERCON50315.2020.9220259},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095409964&doi=10.1109%2fINTERCON50315.2020.9220259&partnerID=40&md5=468d920f94577eaa8468cf8ebe1a7a00},
	affiliations = {Ricardo Palma University, Society of Fire Protection Engineers, School of Mechatronics Engineering, Lima, Peru; International Trauma Life Support, Peruvian Fire Department-La Molina, Lima, Peru},
	abstract = {This research is focused on improving personnel training at the Peruvian Fire Department (PFD) using Multimedia Systems in Biomedical Applications. Currently, the PFD performs their prehospital interventions (PI) training using live actors and low-fidelity manikins, these training methods do not simulate a realistic environment that puts the fireman under stress. Besides, it is not possible to measure the evolution of the firemen's performance during their training. In the design stage, a tool was created for emergency training during stressful situations to improve decision-making at PI scenarios. The equipment included a control system, a trauma simulator-manikin, a mixed reality software, and an appropriate algorithm. The system was implemented in the Mechatronics Laboratory at Ricardo Palma University-Peru from 2018 to 2020. The main components were the communication network between the visual interface of the Mixed Reality System (MRS) software and a fuzzy logic program developed in Matlab's Simulink tool. The tests were based on training cases established by the National Association of Emergency Medical Technicians (NAEMT) and the International Trauma Life Support for Emergency Care Providers. The results of the simulation showed a successful design of the diffuse controller and hardware. In addition, there is an improvement in the trainees' decision-making under pressure, which is evidenced in the reduction of time it takes to develop the diagnosis, stabilization, and the total duration of the PI. In conclusion, MRS for simulation of a PI can improve the quality of the personnel training of the PFD at reduced costs.  © 2020 IEEE.},
	author_keywords = {Biomedical Applications; Decision-Making; Emergency Training; Mixed Reality System; Multimedia Systems; Peruvian Fire Department; Prehospital Intervention; Trauma Simulator},
	keywords = {Decision making; Diagnosis; Fuzzy logic; Logic programming; MATLAB; Medical applications; Multimedia systems; Personnel training; Biomedical applications; Emergency medical technicians; Emergency training; Mechatronics laboratory; Mixed reality systems; Realistic environments; Training methods; Visual Interface; Mixed reality},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-172819377-9},
	language = {English},
	abbrev_source_title = {Proc. IEEE Int. Conf. Electron., Electr. Eng. Comput., INTERCON},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 16; Conference name: 27th IEEE International Conference on Electronics, Electrical Engineering and Computing, INTERCON 2020; Conference date: 3 September 2020 through 5 September 2020; Conference code: 164020}
}

@ARTICLE{Shang201899,
	author = {Shang, Kun and Huang, Zheng-Hai and Liu, Wanquan and Li, Zhi-Ming},
	title = {A single gallery-based face recognition using extended joint sparse representation},
	year = {2018},
	journal = {Applied Mathematics and Computation},
	volume = {320},
	pages = {99 – 115},
	doi = {10.1016/j.amc.2017.07.058},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030708410&doi=10.1016%2fj.amc.2017.07.058&partnerID=40&md5=7cbb515d1baa067a9253f1ef62e67d8e},
	affiliations = {Center for Applied Mathematics, Tianjin University, Tianjin, China; School of Mathematics, Tianjin University, Tianjin, China; Department of Computing, Curtin University, Perth, WA, Australia; Faculty of Applied Math, Shanxi University of Finance and Economics, Taiyuan, China},
	abstract = {For many practical face recognition problems, such as law enforcement, e-passport, ID card identification, and video surveillance, there is usually only a single sample per person enrolled for training, meanwhile the probe samples can usually be captured on the spot, it is possible to collect multiple face images per person. This is a new face recognition problem with many challenges, and we name it as the single-image-to-image-set face recognition problem (ISFR). In this paper, a customized dictionary-based face recognition approach is proposed to solve this problem using the extended joint sparse representation. We first learn a customized variation dictionary from the on-location probing face images, and then propose the extended joint sparse representation, which utilizes the information of both the customized dictionary and the gallery samples, to classify the probe samples. Finally we compare the proposed method with the related methods on several popular face databases, including Yale, AR, CMU-PIE, Georgia, Multi-PIE and LFW databases. The experimental results show that the proposed method outperforms most of these popular face recognition methods for the ISFR problem. © 2017 Elsevier Inc.},
	author_keywords = {Customized dictionary; Dictionary learning; Extended joint sparse representation; Face recognition; Single image to image set},
	keywords = {Classification (of information); Probes; Problem solving; Security systems; Dictionary learning; Face database; Face recognition methods; Image sets; Single images; Single sample; Sparse representation; Video surveillance; Face recognition},
	correspondence_address = {Z.-M. Li; Faculty of Applied Math, Shanxi University of Finance and Economics, Taiyuan, China; email: li_zm@sxufe.edu.cn},
	publisher = {Elsevier Inc.},
	issn = {00963003},
	coden = {AMHCB},
	language = {English},
	abbrev_source_title = {Appl. Math. Comput.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 14}
}

@CONFERENCE{Kwon20191292,
	author = {Kwon, Eunjung and Shin, WonJae and Park, Hyunho and Byon, Sungwon and Jung, Eui-Suk and Lee, Yong-Tae and Lee, Kyu-Chul},
	title = {A Novel Location Prediction Scheme Based on Trajectory Data},
	year = {2019},
	journal = {ICTC 2019 - 10th International Conference on ICT Convergence: ICT Convergence Leading the Autonomous Future},
	pages = {1292 – 1294},
	doi = {10.1109/ICTC46691.2019.8939738},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078259665&doi=10.1109%2fICTC46691.2019.8939738&partnerID=40&md5=2a2379ac9728d635c53428a405103138},
	affiliations = {Electronic and Telecommunications Research Institute (ETRI), Chungnam National University, 218 Gajeongro, Yuseong-gu, Daejeon, South Korea},
	abstract = {many of location based services using mobile devices have pervaded theses day. They provide the new opportunity of analyzing the location prediction in an innovative method by using a lots of data generated from the mobile devices. In this paper, we propose a location prediction method using sensor data generated from smartphones or wearable devices. The location prediction scheme needs to include a predictive model to guarantee with high level analysis accuracy score. There are two-step approaches with regard to this: (I) extracting feature patterns on the history of an interesting object; (II) validating results of predicting the next location of users based on users' movement patterns. To do this, we propose a novel location prediction scheme using a frequent patterns matching and similarity measurement technique while considering the location-based statistical information for providing a public safety service in the future. © 2019 IEEE.},
	author_keywords = {Location Prediction; Mobile Data; Trejactory},
	keywords = {Forecasting; Location; Telecommunication services; Wearable technology; Extracting features; High-level analysis; Location prediction; Mobile data; Predictive modeling; Similarity measurements; Statistical information; Trejactory; Location based services},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-172810892-6},
	language = {English},
	abbrev_source_title = {ICTC - Int. Conf. ICT Converg.: ICT Converg. Lead. Auton. Future},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 10th International Conference on Information and Communication Technology Convergence, ICTC 2019; Conference date: 16 October 2019 through 18 October 2019; Conference code: 156267}
}

@ARTICLE{Weichelt2019,
	author = {Weichelt, Bryan and Heimonen, Tomi and Pilz, Matthew and Yoder, Aaron and Bendixsen, Casper},
	title = {An argument against cross-platform development: Lessons from an augmented reality app prototype for rural emergency responders},
	year = {2019},
	journal = {JMIR mHealth and uHealth},
	volume = {7},
	number = {3},
	doi = {10.2196/12207},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074191124&doi=10.2196%2f12207&partnerID=40&md5=a6c9566440ffc10cf1c6287f2f6d7162},
	affiliations = {University of Wisconsin-Stevens Point, Stevens Point, WI, United States; linkedPIXEL LLC, Marshfield, WI, United States; Department of Environmental, Agricultural and Occupational Health, University of Nebraska Medical Center, University of Nebraska-Lincoln, Omaha, NE, United States; Marshfield Clinic Research Institute, National Farm Medicine Center, 1000 N Oak Ave, Marshfield, 54449, WI, United States},
	abstract = {Background: Mobile augmented reality (MAR) apps offer potential support for emergency responders in rural areas. Objective: In this report, we described lessons learned from the development process of augmented reality (AR) Farm Mapping to Assist, Protect and Prepare Emergency Responders (MAPPER), a MAR app that provides emergency responders onsite information about the agricultural operation they enter. Methods: Cross-platform frameworks were used to create AR MAPPER to accommodate budget constraints and overcome issues with markerless MAR technologies. Although the single codebase and Web technologies streamlined development, cross-device hardware limitations impacted location accuracy, lengthened the development cycle, and required regular updates to third-party libraries. Results: A hybrid development approach of using Web-based technologies with native tie-ins for specialized components and enhanced performance cut time and costs. This also led to consistency across multiple platforms and ensured that there is only a single set of source files to modify for Android and iPhone operating systems. Meanwhile, active development was delayed by some major hurdles. Apple and Google both released new versions of their operating systems, and the Wikitude framework issued four major updates, each of which brought with it some important enhancements and also led to some new issues. Conclusions: Developers should consider single platform native development to benefit from platform-specific MAR implementations and to avoid development, testing, and maintenance costs associated with cross-platform implementation. Emergency response organizations may be more likely to utilize a single platform across the devices used by their command staff. This also reduces the benefits of cross-platform development. Furthermore, providing map-based, non-AR cross-platform apps for landowners, farmers, and ranchers would help improve and maintain data quality, which is crucial for the utility and user experience of MAR apps. © Bryan Weichelt, Tomi Heimonen, Matthew Pilz, Aaron Yoder, Casper Bendixsen.},
	author_keywords = {Emergency medical services; Mhealth; Rural health; Telemedicine},
	correspondence_address = {B. Weichelt; Marshfield Clinic Research Institute, National Farm Medicine Center, Marshfield, 1000 N Oak Ave, 54449, United States; email: weichelt.bryan@marshfieldresearch.org},
	publisher = {JMIR Publications Inc.},
	issn = {22915222},
	language = {English},
	abbrev_source_title = {JMIR mHealth uHealth},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Dabby201738,
	author = {Dabby, Nadine and Aleksov, Aleksandar and Lewallen, Eric and Oster, Sasha and Fygenson, Racquel and Lathrop, Braxton and Bynum, Michael and Samady, Mezhgan and Klein, Steven and Girouard, Steven},
	title = {A scalable process for manufacturing integrated, washable smart garments applied to heart rate monitoring},
	year = {2017},
	journal = {Proceedings - International Symposium on Wearable Computers, ISWC},
	volume = {Part F130534},
	pages = {38 – 41},
	doi = {10.1145/3123021.3123045},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030479478&doi=10.1145%2f3123021.3123045&partnerID=40&md5=5f4cc30d876a9fe7bd95f7e0876c3526},
	affiliations = {Intel Corporation, 2200 Mission College Blvd, Santa Clara, 95054, CA, United States},
	abstract = {We present a new method for building wearable electronic and sensor systems in which all components are permanently integrated directly into garments in high volume except for the battery. We discuss the design and construction of the first such fully-integrated sensor system, wearable heart rate monitoring garments (a sports bra, a compression short, and a compression shirt) that are machine washable. We demonstrate that heart rate measurements can be detected by our system's fabric-based electrodes. We also show experimental results from wash testing of the garment. The process described herein can be applied to the construction of computational and sensor systems for healthcare, sports, virtual reality, and first responder and military personnel monitoring, among others. © 2017 Copyright is held by the owner/author(s).},
	author_keywords = {Biometric monitoring; Design; E-textile; Form factor; Smart clothing; Smart textile; User experience; Wearable systems},
	keywords = {Design; Heart; Patient monitoring; Smart textiles; Sports; Textiles; Virtual reality; Wearable computers; Wearable technology; Biometric monitoring; Form factors; Smart clothing; User experience; Wearable systems; Wearable sensors},
	publisher = {Association for Computing Machinery},
	issn = {15504816},
	isbn = {978-145035188-1},
	language = {English},
	abbrev_source_title = {Proc. Int. Symp. Wearable Comput. ISWC},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 11; Conference name: 29th ACM International Symposium on Wearable Computers, ISWC 2017; Conference date: 11 September 2017 through 15 September 2017; Conference code: 130534}
}

@CONFERENCE{Grandi2020827,
	author = {Grandi, Jeronimo G and Cao, Zekun and Ogren, Mark and Kopper, Regis},
	title = {Simulating Next-Generation User Interfaces for Law Enforcement Traffic Stops},
	year = {2020},
	journal = {Proceedings - 2020 IEEE Conference on Virtual Reality and 3D User Interfaces, VRW 2020},
	pages = {827 – 828},
	doi = {10.1109/VRW50115.2020.00264},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085390755&doi=10.1109%2fVRW50115.2020.00264&partnerID=40&md5=067339df3d67414bf19ec7d889be604c},
	affiliations = {University of North Carolina at Greensboro, Dept. of Computer Science, United States; Duke University, Dept. of Mechanical Engineering and Materials Science, United States; Duke University, Pratt School of Engineering, United States},
	abstract = {We present the design of a next-generation user interface for law enforcement officers, developed to assist with current traffic procedures. Our design leverages the futuristic capabilities of augmented reality displays, integrating real and virtual elements. Our team has created a traffic stop scenario in immersive virtual reality, where the participant assumes the role of a police officer and interacts with a simulated augmented user interface and a virtual driver. © 2020 IEEE.},
	author_keywords = {Human computer interaction (HCI); Human-centered computing; Interaction paradigms; Virtual reality},
	keywords = {Augmented reality; Law enforcement; Virtual reality; Immersive virtual reality; Law enforcement officers; Next generation user interfaces; Police officers; Virtual elements; User interfaces},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-172816532-5},
	language = {English},
	abbrev_source_title = {Proc. - IEEE Conf. Virtual Real. 3D User Interfaces, VRW},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 2020 IEEE Conference on Virtual Reality and 3D User Interfaces, VRW 2020; Conference date: 22 March 2020 through 26 March 2020; Conference code: 115117}
}

@ARTICLE{Marins2018426,
	author = {Marins, Eduardo Frio and Ferreira, Rodrigo Wiltgen and Del Vecchio, Fabrício Boscolo},
	title = {Cardiorespiratory and neuromuscular fitness of federal highway police officers; [Aptidão cardiorrespiratória e neuromuscular de policiais rodoviários federais aptitud cardiorrespiratoria y neuromuscular de policías de seguridad vial federales]; [Aptitud cardiorrespiratoria y neuromuscular de policías de seguridad vial federales]},
	year = {2018},
	journal = {Revista Brasileira de Medicina do Esporte},
	volume = {24},
	number = {6},
	pages = {426 – 431},
	doi = {10.1590/1517-869220182406185222},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061301691&doi=10.1590%2f1517-869220182406185222&partnerID=40&md5=01a5a148b930eb3c326b490658f154ff},
	affiliations = {Universidade Federal de Pelotas, Upper School of Physical Education, Pelotas, RS, Brazil; Federal Highway Police Department, DF, Brasília, Brazil},
	abstract = {Introduction: Higher levels of physical fitness are associated with better quality of life and indicators of health and performance in police forces. Objective: This study aims to describe and evaluate the level of cardiorespiratory and neuromuscular fitness of a national sample of federal highway patrol officers. Methods: Cross-sectional study with data from 6212 agents of the Federal Highway Police. Endpoints were as follows: abdominal resistance (AR); upper limb muscular resistance (ULMR); upper limb muscle strength (ULMS) and cardiorespiratory fitness (CF). The following independent variables were included: sex; age; geographic region of posting and participation in the Institutional Physical Education Program (IPEP). The linear regression model was used to test the association between endpoints and independent variables. Results: The highest proportion of police officers obtained an excellent score for neuromuscular endpoints (AR: 63.9% men, 69.6% women, ULMR: 68.8% men, 61.8% women, ULMS: 22.2% men, 40% women). In CF, the highest percentage of scores was average and good (respectively, 30.6% and 43.0% for men, 39.1% and 39.2% for women). Male officers were fitter than female officers, except for the ULMS endpoint. There was a decrease in fitness levels for all endpoints according to age. Police officers from the northern region were fitter than in the other regions. Police officers who were not registered in the IPEP were fitter than those registered. Conclusion: Federal Highway Patrol officers have good levels of fitness, which declines with age. Level of Evidence III; Study of nonconsecutive patients; without consistently applied ‘‘gold’’ reference standard. © 2018, Redprint Editora Ltda. All rights reserved.},
	author_keywords = {Health; Muscle strength; Physical endurance; Physical fitness; Police},
	correspondence_address = {E.F. Marins; Pelotas, Rua Luis de Camões, 625, Bairro Tablada, 96055-630, Brazil; email: eduardo.marins@prf.gov.br},
	publisher = {Redprint Editora Ltda},
	issn = {15178692},
	coden = {RBMEB},
	language = {English},
	abbrev_source_title = {Rev. Bras. Med. Esporte},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Engelbrecht2018386,
	author = {Engelbrecht, Hendrik and Lukosch, Stephan G.},
	title = {Viability of Augmented Content for Field Policing},
	year = {2018},
	journal = {Adjunct Proceedings - 2018 IEEE International Symposium on Mixed and Augmented Reality, ISMAR-Adjunct 2018},
	pages = {386 – 389},
	doi = {10.1109/ISMAR-Adjunct.2018.00111},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065513887&doi=10.1109%2fISMAR-Adjunct.2018.00111&partnerID=40&md5=2f0b1659501a96233a443be1e943beeb},
	affiliations = {Delft University of Technology, Netherlands},
	abstract = {This paper describes the design and evaluation of a prototype for mobile information provisioning in augmented reality (AR) for field officers of the Dutch police. Five different fictional cases were constructed in cooperation with officers from the Dutch police. These cases were comprised of dynamic as well as static hotspots that would occur naturally during field work. Three different versions of the early prototype were tested using the method of heuristic evaluation. The application was shown to three experts from two police departments. Evaluation of the heuristics, possible future improvements as well as AR viability considerations for field policing are discussed. © 2018 IEEE.},
	author_keywords = {HCI design and evaluation methods; Human-centered computing; Human-centered computing; Interaction paradigms; Mixed/augmented reality; Usability testing},
	keywords = {Augmented reality; Law enforcement; Petroleum reservoir evaluation; User interfaces; HCI design; Human-centered computing; Interaction paradigm; Mixed/augmented reality; Usability testing; Heuristic methods},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-153867592-2},
	language = {English},
	abbrev_source_title = {Adjun. Proc. - IEEE Int. Symp. Mixed Augment. Real., ISMAR-Adjunct},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: 17th IEEE International Symposium on Mixed and Augmented Reality, ISMAR-Adjunct 2018; Conference date: 16 October 2018 through 20 October 2018; Conference code: 147665}
}

@ARTICLE{Dong2019329,
	author = {Dong, Tony},
	title = {Run, Hide, Fight—From the AR-15? A Study of Firearms Depictions in Active/Mass Shooter Instructional Videos},
	year = {2019},
	journal = {Journal of Applied Security Research},
	volume = {14},
	number = {3},
	pages = {329 – 349},
	doi = {10.1080/19361610.2019.1621666},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070068646&doi=10.1080%2f19361610.2019.1621666&partnerID=40&md5=bd5ca09284a0193f7b1aea514c9a7342},
	affiliations = {Securiguard Services Ltd - Manager, Risk & Internal Investigations, Vancouver, BC, Canada},
	abstract = {The depiction of firearms in mass media coverage of active/mass shootings begets an important question: How do the security and law enforcement experts in charge of prevention, mitigation, and response think about firearms? To answer this question, a qualitative content analysis of firearms depictions in post 2010, North American based active/mass shooter instructional training videos was conducted. A sample of 24 videos was selected for analysis based on the previous criteria. The study utilized limited quantitative measures to produce an overall picture regarding numerous firearms characteristics as they related to depiction. Characteristics were coded into thematic categories and an overarching analytical theme. Overall, this study found evidence that depictions generally constituted of firearms characteristics which produced feelings of fear in the intended audience. A limited application of Protection Motivation Theory (PMT) was provided as a preliminary explanation for both the nature of the findings and the rationale behind such depictions. Implications for future research and the role of expert protection professional involved in the production of instructional media are discussed. © 2019, © 2019 Taylor & Francis Group, LLC.},
	author_keywords = {Active shooter; AR-15; mass shooting; PMT; training},
	correspondence_address = {T. Dong; Burnaby, 708-9232 University Crescent, V5A 0A3, Canada; email: tonyd@securiguard.com},
	publisher = {Routledge},
	issn = {19361610},
	language = {English},
	abbrev_source_title = {J. Appl. Secur. Res.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Broach20181416,
	author = {Broach, John and Hart, Alexander and Griswold, Matthew and Lai, Jeffrey and Boyer, Edward W. and Skolnik, Aaron B. and Chai, Peter R.},
	title = {Usability and reliability of smart glasses for secondary triage during mass casualty incidents},
	year = {2018},
	journal = {Proceedings of the Annual Hawaii International Conference on System Sciences},
	volume = {2018-January},
	pages = {1416 – 1422},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049566528&partnerID=40&md5=7943d433253399590ecbf36d4228a5cc},
	affiliations = {Department of Emergency Medicine, UMASS Medical School, United States; Department of Emergency Medicine, Beth Israel Deaconess Medical Center, United States; Department of Emergency Medicine, Hartford Hospital, United States; Department of Emergency Medicine, Brigham and Women’s Hospital, United States; Department of Emergency Medicine, University of Pittsburgh, United States},
	abstract = {Wearable smart glasses like Google Glass provide real-time video and image transmission to remote viewers. The use of Google Glass and other Augmented Reality (AR) platforms in mass casualty incidents (MCIs) can provide incident commanders and physicians at receiving hospitals real-time data regarding injuries sustained by victims at the scene. This real-time data is critical to allocation of hospital resources prior to receiving victims of a MCI. Remote physician participation in real-time MCI care prior to victims’ hospital arrival may improve triage, and direct emergency and critical care services to those most in need. We report the use of Google Glass among first responders to transmit real-time data from a simulated MCI to allow remote physicians to complete augmented secondary triage. © 2018 IEEE Computer Society. All rights reserved.},
	keywords = {Augmented reality; Hospitals; Wearable computers; Critical care; First responders; Incident commander; Mass casualty incidents; Real time; Real time videos; Real-time data; Smart glass; Glass},
	editor = {Bui T.X.},
	publisher = {IEEE Computer Society},
	issn = {15301605},
	isbn = {978-099813311-9},
	language = {English},
	abbrev_source_title = {Proc. Annu. Hawaii Int. Conf. Syst. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 22; Conference name: 51st Annual Hawaii International Conference on System Sciences, HICSS 2018; Conference date: 2 January 2018 through 6 January 2018; Conference code: 169516}
}

@ARTICLE{Norton201867,
	author = {Norton, Tomas and Piette, Deborah and Exadaktylos, Vasileios and Berckmans, Daniel},
	title = {Automated real-time stress monitoring of police horses using wearable technology},
	year = {2018},
	journal = {Applied Animal Behaviour Science},
	volume = {198},
	pages = {67 – 74},
	doi = {10.1016/j.applanim.2017.09.009},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032904459&doi=10.1016%2fj.applanim.2017.09.009&partnerID=40&md5=4ecc157652227937ae41465769140fa6},
	affiliations = {M3-BIORES, Division Animal and Human Health Engineering, Department of Biosystems, KU Leuven University, Oude Markt 13, Leuven, 3000, Belgium; BioRICS NV, Technologielaan 3, Heverlee, 3001, Belgium},
	abstract = {Mounted police horses and riders are repeatedly subjected to demanding and stressful situations. Intensive selection and training of police horses is required to ensure performance, safety and welfare of the horses and their riders. At the mounted police in Brussels, Belgium, the selection of police horses is mainly based on intuition built upon previous experience which makes it a subjective decision. Although this decision mostly leads to good results, sometimes horses are purchased that turn out to be unsuited for the mounted police. Including an objective measure when evaluating the longer term suitability of candidate police horses could help the mounted police to further improve their selection procedure for police horses. This study investigated the potential of real-time stress detection as a measure to evaluate the longer term suitability of police horses. Four experimental protocols were developed in consultation with the mounted police and were performed by 17 horse-rider pairs. The horses were divided into four categories according to their experience and suitability as police horses: good beginner, bad beginner, good experienced and bad experienced. The relative stress of the horses was monitored with wearable technology during every protocol. For one protocol, the time percentage spent over 20% relative stress by the horse was found to be significantly lower for good compared to bad beginner horses (p-value = 0.0277). In conclusion this study demonstrated that real-time stress detection with wearable technology in mounted police horses provides information on the longer term suitability of police horses. © 2017 Elsevier B.V.},
	author_keywords = {Horse; Performance; Police; Stress; Suitability; Wearable technology},
	keywords = {Belgium; Brussels [Belgium]; Equidae; automation; detection method; environmental stress; guideline; horse; monitoring; performance assessment; police force; real time; technology; training},
	correspondence_address = {D. Berckmans; Kasteelpark Arenberg 30, Heverlee, 3001, Belgium; email: daniel.berckmans@kuleuven.be},
	publisher = {Elsevier B.V.},
	issn = {01681591},
	coden = {AABSE},
	language = {English},
	abbrev_source_title = {Appl. Anim. Behav. Sci.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 18; All Open Access, Green Open Access}
}

@CONFERENCE{Scheurer20175,
	author = {Scheurer, Sebastian and Tedesco, Salvatore and Brown, Kenneth N. and O'Flynn, Brendan},
	title = {Human activity recognition for emergency first responders via body-worn inertial sensors},
	year = {2017},
	journal = {2017 IEEE 14th International Conference on Wearable and Implantable Body Sensor Networks, BSN 2017},
	pages = {5 – 8},
	doi = {10.1109/BSN.2017.7935994},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025433662&doi=10.1109%2fBSN.2017.7935994&partnerID=40&md5=f3f3a90f8a9b98366db8401e77ba7a04},
	affiliations = {Insight Centre for Data Analytics, Dep. of Computer Science, University College Cork, Ireland; Tyndall National Institute, University College Cork, Ireland},
	abstract = {Every year over 75 000 firefighters are injured and 159 die in the line of duty. Some of these accidents could be averted if first response team leaders had better information about the situation on the ground. The SAFESENS project is developing a novel monitoring system for first responders designed to provide response team leaders with timely and reliable information about their firefighters' status during operations, based on data from wireless inertial measurement units. In this paper we investigate if Gradient Boosted Trees (GBT) could be used for recognising 17 activities, selected in consultation with first responders, from inertial data. By arranging these into more general groups we generate three additional classification problems which are used for comparing GBT with k-Nearest Neighbours (kNN) and Support Vector Machines (SVM). The results show that GBT outperforms both kNN and SVM for three of these four problems with a mean absolute error of less than 7%, which is distributed more evenly across the target activities than that from either kNN or SVM. © 2017 IEEE.},
	keywords = {Fire extinguishers; Fire fighting equipment; Nearest neighbor search; Support vector machines; Trees (mathematics); Units of measurement; Wearable sensors; Wearable technology; First responders; Human activity recognition; Inertial measurement unit; Inertial sensor; K nearest neighbours (k-NN); Mean absolute error; Monitoring system; Target activity; Body sensor networks},
	correspondence_address = {S. Scheurer; Insight Centre for Data Analytics, Dep. of Computer Science, University College Cork, Ireland; email: sebastian.scheurer@insight-centre.org},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-150906244-7},
	language = {English},
	abbrev_source_title = {IEEE Int. Conf. Wearable Implant. Body Sens. Netw., BSN},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 31; Conference name: 14th IEEE International Conference on Wearable and Implantable Body Sensor Networks, BSN 2017; Conference date: 9 May 2017 through 12 May 2017; Conference code: 128171; All Open Access, Green Open Access}
}

@CONFERENCE{La Salla2018,
	author = {La Salla, Leah Margaret and Odubela, Ayodele and Espada, Giselle and Correa, Maria Camila Belduque and Lewis, La Shana and Wood, Aaron},
	title = {The EDNA Public Safety Drone: Bullet-Stopping Lifesaving},
	year = {2018},
	journal = {GHTC 2018 - IEEE Global Humanitarian Technology Conference, Proceedings},
	doi = {10.1109/GHTC.2018.8601597},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061792914&doi=10.1109%2fGHTC.2018.8601597&partnerID=40&md5=1bf305beef6a9d4b9781a14c7ae936cc},
	affiliations = {Software Architect, Austin, TX, United States; Machine Learning, Denver, CO, United States; St. Luis, Missouri, United States; College Station, TX, United States},
	abstract = {Urban gun violence in cities across the world is a serious issue for public safety agencies and disaster management organizations. This led us to the development of the EDNA drone, an aerial robotics solution designed to equip first responders in high-risk settings with lifesaving-edge tools for situational awareness and non-lethal conflict resolution. The EDNA is an unmanned aerial vehicle (UAV) that delivers the patent-pending 'Predictive Probable Cause' technology. The EDNA drone is designed to provide automated real-Time analysis to assist teams entering high-risk situations where gun violence may occur. By leveraging machine learning, biometric sensors, and advanced materials in the field and routing feedback to an intuitive augmented-reality interface, the EDNA will provide autonomous threat detection and bullet-stopping capabilities wherever those features are needed-to groups such as Police and Sheriff's Departments, Fire Departments, and EMT and emergency rescue teams. Data from the EDNA drone's sensors is fed to machine learning algorithms running on the drone in real-Time. Through a neural network trained on past data, the EDNA is able to detect the presence and location of firearms and explosives, even through walls or other obstacles. Through the use of advanced metal foams and composite materials, the armored drone can even stop bullets-functionality which has obvious benefits for humanitarian deployment. © 2018 IEEE.},
	author_keywords = {Bullet-Stopping; CV; Deescalation; Disasters; Drones; Emergency Management; Gun Violence Prevention; Humanitarian; ML; Public Safety; Situational Awareness; UAV},
	keywords = {Aircraft accidents; Antennas; Disaster prevention; Drones; Glass ceramics; Learning algorithms; Machine learning; Metals; Military applications; Risk assessment; Risk management; Aerial vehicle; Bullet-stopping; CV; Deescalation; Emergency management; Gun violence prevention; Humanitarian; ML; Public safety; Situational awareness; Unmanned aerial vehicle; Disasters},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-153865566-5},
	language = {English},
	abbrev_source_title = {GHTC - IEEE Glob. Humanit. Technol. Conf., Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 8th Annual IEEE Global Humanitarian Technology Conference, GHTC 2018; Conference date: 18 October 2018 through 21 October 2018; Conference code: 144280}
}

@CONFERENCE{Haider20172457,
	author = {Haider, Fezza and Shaker, George},
	title = {Wearable-free wireless fall detection system},
	year = {2017},
	journal = {2017 IEEE Antennas and Propagation Society International Symposium, Proceedings},
	volume = {2017-January},
	pages = {2457 – 2458},
	doi = {10.1109/APUSNCURSINRSM.2017.8073271},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042198240&doi=10.1109%2fAPUSNCURSINRSM.2017.8073271&partnerID=40&md5=507bcb88b839698e573301671e32330e},
	affiliations = {Department of Electrical and Computer Engineering, University of Waterloo, Waterloo, Canada},
	abstract = {Falls among the elderly population are a major concern for public safety since they are the dominant cause of injuries and hospitalization. Nearly a quarter of these falls can result in serious injuries that require immediate medical attention; hence, an external, privacy-preserving and device-free system is required for fall detection. Herein, we investigate the use of radars to monitor human motion and detect falls. This approach has been implemented with the use of a low-cost UWB radio operating between 3GHz-10GHz. The resulting radar data is shown to successfully enable fall detection for a person in a furnished room. This study demonstrates the enormous potential using indoor radars for motion detection, activity recognition, home-security, and fall alert systems. © 2017 IEEE.},
	author_keywords = {Activity monitoring; Fall detection; Home security; Radio frequency (RF) radars; Smart homes; Wearable-free},
	keywords = {Automation; Data privacy; Intelligent buildings; Radar; Wearable technology; Activity monitoring; Fall detection; Home security; Radio frequencies; Smart homes; Wearable-free; Tracking radar},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-153863284-0},
	language = {English},
	abbrev_source_title = {IEEE Antennas Propag. Soc. Int. Symp., Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; Conference name: 2017 IEEE International Symposium on Antennas and Propagation and USNC-URSI Radio Science Meeting, APSURSI 2017; Conference date: 9 July 2017 through 14 July 2017; Conference code: 131256}
}

@ARTICLE{Carruth201934,
	author = {Carruth, Daniel W. and Hudson, Christopher R. and Bethel, Cindy L. and Pleva, Matus and Ondas, Stanislav and Juhar, Jozef},
	title = {Using HMD for Immersive Training of Voice-Based Operation of Small Unmanned Ground Vehicles},
	year = {2019},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {11575 LNCS},
	pages = {34 – 46},
	doi = {10.1007/978-3-030-21565-1_3},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069688716&doi=10.1007%2f978-3-030-21565-1_3&partnerID=40&md5=95acb7046f5bebf3cd9b2913b00aec7e},
	affiliations = {Mississippi State University, Starkville, 39759, MS, United States; Technical University of Kosice, Letna 9, Kosice, 042 00, Slovakia},
	abstract = {Voice recognition systems provide a method of hands-free control of robotic systems that may be helpful in law enforcement or military domains. However, the constraints of the operational environment limit the capabilities of the on-board voice recognition system to a keyword-based command system. To effectively use the system, the users must learn the available commands and practice pronunciation to ensure accurate recognition. Virtual reality simulation provides users the opportunity to train with the voice recognition system and the robot platform in realistic interactive scenarios. Training using virtual reality with a head-mounted display may increase immersion and sense of presence compared to using a keyboard and monitor. A small pilot study compared user experience in the desktop mode and the virtual reality mode of our voice recognition system training tool. Participants controlled a simulated unmanned ground vehicle in two different modes across four different environments. The results revealed no significant differences in simulator sickness, sense of presence, or perceived usability. However, when asked to choose between the desktop mode and the head-mounted display mode, results indicate users’ overall preference for the head-mounted display. However, the users also perceive the head-mounted display to be more complex, less consistent, and more difficult to learn to use. The desktop mode was perceived as easier to use and users reported being more confident when using it. © 2019, Springer Nature Switzerland AG.},
	author_keywords = {Human-robot interaction; Speech recognition; Usability; Virtual reality},
	keywords = {Ground vehicles; Human computer interaction; Human robot interaction; Intelligent vehicle highway systems; Mixed reality; Simulation platform; Speech recognition; Virtual reality; Head mounted displays; Operational environments; Perceived usability; Small unmanned ground vehicles; Unmanned ground vehicles; Usability; Virtual reality simulations; Voice-recognition systems; Helmet mounted displays},
	correspondence_address = {D.W. Carruth; Mississippi State University, Starkville, 39759, United States; email: dwc2@cavs.msstate.edu},
	editor = {Chen J.Y.C. and Fragomeni G.},
	publisher = {Springer Verlag},
	issn = {03029743},
	isbn = {978-303021564-4},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 9; Conference name: 11th International Conference on Virtual, Augmented and Mixed Reality, VAMR 2019, held as part of the 21st International Conference on Human-Computer Interaction, HCI International 2019; Conference date: 26 July 2019 through 31 July 2019; Conference code: 228589}
}

@CONFERENCE{Koutitas2019299,
	author = {Koutitas, George and Smith, Kenneth Scott and Lawrence, Grayson and Metsis, Vangelis and Stamper, Clayton and Trahan, Mark and Lehr, Ted},
	title = {A virtual and augmented reality platform for the training of first responders of the ambulance bus},
	year = {2019},
	journal = {ACM International Conference Proceeding Series},
	pages = {299 – 302},
	doi = {10.1145/3316782.3321542},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069203441&doi=10.1145%2f3316782.3321542&partnerID=40&md5=64f5da0593cc330fb0df173601aadc72},
	affiliations = {Electrical and Computer Engineering, Texas State University, San Marcos, TX, United States; School of Social Work, Texas State University, San Marcos, TX, United States; School of Art and Design, Texas State University, San Marcos, TX, United States; Computer Science Texas State University, San Marcos, TX, United States; Austin Smart City City of Austin, Austin, TX, United States},
	abstract = {AmBus is a bus-sized ambulance that EMS personnel utilize during large-scale emergencies. Although EMS personnel receive annual training, evidence shows current training efforts leave some personnel unfamiliar with the AmBus system and unprepared to respond to an emergency. This work presents a novel interactive training application, utilizing emerging technologies in virtual and augmented reality, that can be delivered remotely to the distributed EMS personnel before they assemble, or as they are assembling. Our initial findings show that such an application can better prepare first responders to be as effective as possible in using the life-saving features of the AmBus. The methodology described in this work can be expanded to include other first responders, and, ultimately, lives may be saved because personnel are better prepared. © 2019 Copyright held by the owner/author(s). Publication rights licensed to ACM.},
	author_keywords = {Augmented reality; First responders; Training; Virtual reality},
	keywords = {Ambulances; Augmented reality; E-learning; Virtual reality; Annual training; Emerging technologies; First responders; Interactive training; Large-scale emergency; Virtual and augmented reality; Personnel training},
	publisher = {Association for Computing Machinery},
	isbn = {978-145036232-0},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 14; Conference name: 12th ACM International Conference on PErvasive Technologies Related to Assistive Environments, PETRA 2019; Conference date: 5 June 2019 through 7 June 2019; Conference code: 149147}
}

@ARTICLE{Rushton2020281,
	author = {Rushton, Melanie Ann and Drumm, Ian Anthony and Campion, Simon Peter and O'Hare, John Joseph},
	title = {The use of immersive and virtual reality technologies to enable nursing students to experience scenario-based, basic life support training-exploring the impact on confidence and skills},
	year = {2020},
	journal = {CIN - Computers Informatics Nursing},
	volume = {38},
	number = {6},
	pages = {281 – 293},
	doi = {10.1097/CIN.0000000000000608},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086282310&doi=10.1097%2fCIN.0000000000000608&partnerID=40&md5=99f7914846fcbf696100d7221d03f15c},
	affiliations = {School of Health and Society, University of Salford, Manchester, United Kingdom; Informatics Research Centre, University of Salford, Manchester, United Kingdom; School of the Built Environment, University of Salford, Manchester, United Kingdom; Octave Multimodal Research Platform, University of Salford, Manchester, United Kingdom},
	abstract = {The link between effective basic life support and survival following cardiac arrest is well known. Nurses are often first responders at in-hospital cardiac arrests and receive annual basic life support training to ensure they have the adequate skills, and student nurses are taught this in preparation for their clinical practice. However, it is clear that some nurses still lack confidence and skills to perform basic life support in an emergency situation. This innovative study included 209 participants, used a mixed-methods approach, and examined three environments to compare confidence and skills in basic life support training. The environments were nonimmersive (basic skills room), immersive (immersive room with video technology), and the Octave (mixed reality facility). The skills were measured using a Laerdal training manikin (QCPR manikin), with data recorded on a wireless Laerdal Simpad, and confidence levels before and after training were measured using a questionnaire. The nonimmersive and the immersive rooms were familiar environments, and the students felt more comfortable, relaxed, and, thus, more confident. The Octave offered the higher level of simulation utilizing virtual reality technology. Students felt less comfortable and less confident in the Octave; we assert that this was because the environment was unfamiliar. The study identified that placing students in an unfamiliar environment influences the confidence and skills associated with basic life support; this could be used as a way of preparing student nurses with the necessary emotional resilience to cope in stressful situations. Copyright © 2020 Wolters Kluwer Health, Inc. All rights reserved.},
	author_keywords = {Clinical skills; Competence; Confidence; Student nurses; Virtual reality},
	keywords = {Cardiopulmonary Resuscitation; Clinical Competence; Education, Nursing, Baccalaureate; Humans; Manikins; Students, Nursing; Surveys and Questionnaires; Technology; Virtual Reality; clinical competence; education; human; manikin; nursing education; nursing student; questionnaire; resuscitation; technology; virtual reality},
	correspondence_address = {M.A. Rushton; School of Health and Society, Mary Seacole Building, Ms 2.52, University of Salford, Manchester, M54WT, United Kingdom; email: m.a.rushton@salford.ac.uk},
	publisher = {Lippincott Williams and Wilkins},
	issn = {15382931},
	pmid = {32149741},
	language = {English},
	abbrev_source_title = {CIN Comput. Informatics Nurs.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 15; All Open Access, Green Open Access}
}

@CONFERENCE{Sharma2017665,
	author = {Sharma, Neha and Kumar, Ashok and Arya, Ashwini Kumar},
	title = {Design of reconfigurable compact dual polarized antenna for multiband operation},
	year = {2017},
	journal = {2017 International Conference on Computer, Communications and Electronics, COMPTELIX 2017},
	pages = {665 – 668},
	doi = {10.1109/COMPTELIX.2017.8004052},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034645408&doi=10.1109%2fCOMPTELIX.2017.8004052&partnerID=40&md5=575fa1c6a4e20f55703a539b7cf6d888},
	affiliations = {Dept. of Electronics and Communication Engineering, Govt. Women Engineering College, Ajmer (Rajasthan), India; Dept. of Electronics and Communication Engineering, College of Technology, GBPUAT Pantnagar, Uttarakhand, India},
	abstract = {A compact coplanar waveguide (CPW)-fed F-shaped stub printed antenna is presented. The first and second resonance modes are excited due to F-shaped stub connected to modified CPW ground plane and third resonance mode due to modified L-shaped CPW feeding. The impedance bandwidths of 190 MHz (2.06-2.25 GHz) for UMTS band, 530 MHz (4.61-5.14 GHz) for 4.9 GHz public safety WLAN, 1490 MHz (5.45-6.94 GHz) for 5.5 GHz WiMAX, 5.8 GHz WLAN, and ITS (intelligent transport systems) bands application is achieved. The proposed antenna provides circular polarization (CP) in the 4.9 GHz public safety WLAN band with 3-dB axial ratio (AR) bandwidth of 170 MHz (4.88-5.05 GHz) and linear polarization in the other two bands. By employing a single switch between F-shaped arms and changing the state of switch, antenna exhibits narrowband and wideband functionality with dual- and triple-band behaviour while keeping antenna size 25 × 25 mm2. © 2017 IEEE.},
	author_keywords = {Circular Polarization; F-shaped stub; L-shaped feeding; Reconfigurable antenna},
	keywords = {Antenna feeders; Antenna grounds; Bandwidth; Circular polarization; Coplanar waveguides; Electric impedance; Intelligent systems; Intelligent vehicle highway systems; Microstrip antennas; Polarization; Wireless local area networks (WLAN); Coplanar waveguide fed; Dual  and triple bands; Dual polarized antennas; Impedance bandwidths; Intelligent transport systems; L-shaped; Multi-band operations; Reconfigurable antenna; Microwave antennas},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-150904708-6},
	language = {English},
	abbrev_source_title = {Int. Conf. Comput., Commun. Electro., COMPTELIX},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: 1st International Conference on Computer, Communications and Electronics, COMPTELIX 2017; Conference date: 1 July 2017 through 2 July 2017; Conference code: 129872}
}

@ARTICLE{Phillips2020591,
	author = {Phillips, Nate and Kruse, Brady and Khan, Farzana Alam and Swan II, J. Edward and Bethel, Cindy L.},
	title = {A robotic augmented reality virtual window for law enforcement operations},
	year = {2020},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {12190 LNCS},
	pages = {591 – 610},
	doi = {10.1007/978-3-030-49695-1_40},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088530234&doi=10.1007%2f978-3-030-49695-1_40&partnerID=40&md5=ddacf8fa528411baa1463d55e282a3ca},
	affiliations = {Mississippi State University, 39762, MS, United States},
	abstract = {In room-clearing tasks, SWAT team members suffer from a lack of initial environmental information: knowledge about what is in a room and what relevance or threat level it represents for mission parameters. Normally this gap in situation awareness is rectified only upon room entry, forcing SWAT team members to rely on quick responses and near-instinctual reactions. This can lead to dangerously escalating situations or important missed information which, in turn, can increase the likelihood of injury and even mortality. Thus, we present an x-ray vision system for the dynamic scanning and display of room content, using a robotic platform to mitigate operator risk. This system maps a room using a robot-equipped stereo depth camera and, using an augmented reality (AR) system, presents the resulting geographic information according to the perspective of each officer. This intervention has the potential to notably lower risk and increase officer situation awareness, all while team members are in the relative safety of cover. With these potential stakes, it is important to test the viability of this system natively and in an operational SWAT team context. © Springer Nature Switzerland AG 2020.},
	author_keywords = {Augmented reality; Robotics; Situation awareness; X-Ray Vision},
	keywords = {Augmented reality; Robotics; Stereo image processing; Dynamic displays; Environmental information; Forcings; Mission parameters; Quick response; Situation awareness; Team members; Threat levels; Vision systems; X-ray vision; SWAT},
	correspondence_address = {C.L. Bethel; Mississippi State University, 39762, United States; email: cbethel@cse.msstate.edu},
	editor = {Chen J.Y.C. and Fragomeni G.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303049694-4},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 12th International Conference on Virtual, Augmented and Mixed Reality, VAMR 2020, held as part of the 22nd International Conference on Human-Computer Interaction, HCII 2020; Conference date: 19 July 2020 through 24 July 2020; Conference code: 242159}
}

@ARTICLE{2019,
	title = {AHFE International Conference on Human Factors and Systems Interaction, 2018},
	year = {2019},
	journal = {Advances in Intelligent Systems and Computing},
	volume = {781},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049628495&partnerID=40&md5=4b0715d59b16030329f2de413069d8ed},
	abstract = {The proceedings contain 39 papers. The special focus in this conference is on Human Factors and Systems Interaction. The topics include: Research on comparison experiment of humanized interface design of Smart TV based on user experience; moving forward with autonomous systems: Ethical dilemmas; signal-processing transformation from smartwatch to Arm movement gestures; How can AI help reduce the burden of disaster management decision-making?; tackling autonomous driving challenges – How the design of autonomous vehicles is mirroring universal design; assessment of pilots mental fatigue status with the eye movement features; effect of far infrared radiation therapy on improving microcirculation of the diabetic foot; microinteractions of forms in web based systems usability and eye tracking metrics analysis; design and realization of shooting training system for police force; analysis of trust in automation survey instruments using semantic network analysis; an examination of close calls reported within the international association of fire chiefs database; analysis and improvement of the usability of a tele-rehabilitation platform for hip surgery patients; educational resources accessible on the tele-rehabilitation platform; design of an architecture for accessible web maps for visually impaired users; analysis and improvement of the web accessibility of a tele-rehabilitation platform for hip arthroplasty patients; interaction with a tele-rehabilitation platform through a natural user interface: A case study of hip arthroplasty patients; comparison of theory of mind tests in augmented reality and 2D environments for children with neurodevelopmental disorders; a real-time algorithm for movement assessment using fuzzy logic of hip arthroplasty patients; opportunities of digitalization for productivity management.},
	editor = {Nunes I.L.},
	publisher = {Springer Verlag},
	issn = {21945357},
	isbn = {978-331994333-6},
	language = {English},
	abbrev_source_title = {Adv. Intell. Sys. Comput.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: AHFE International Conference on Human Factors and Systems Interaction, 2018; Conference date: 21 July 2018 through 25 July 2018; Conference code: 215339}
}

@ARTICLE{Friedman2020441,
	author = {Friedman, Jessica and Hendrix, Vera and Fustok, Judy and Reza, Tara and Madda, Prathima and Smith, Alison and Mayer, Scott and Duchesne, Juan and Greiffenstein, Patrick and Schroll, Rebecca},
	title = {Correlation of ride sharing service availability and decreased alcohol-related motor vehicle collision incidence and fatality},
	year = {2020},
	journal = {Journal of Trauma and Acute Care Surgery},
	volume = {89},
	number = {3},
	pages = {441 – 447},
	doi = {10.1097/TA.0000000000002802},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089811669&doi=10.1097%2fTA.0000000000002802&partnerID=40&md5=c947e0984f0741d2bf9a4e417caaf69a},
	affiliations = {Department of Surgery, Tulane University School of Medicine, United States; Louisiana State University Center Health Sciences Center, New Orleans, LA, United States},
	abstract = {BACKGROUND: Alcohol-related motor vehicle collisions (AR-MVCs) account for ~30% of all US traffic fatalities. Ride-sharing services (RSS) have existed since 2010, but few studies to date have investigated their impact on AR-MVCs. We hypothesized that the availability of RSS would be correlated with a decrease in AR-MVCs at an urban Level I trauma center. METHODS: A retrospective chart review was conducted of all AR-MVC trauma activations at a Level I trauma center from 2012 to 2018. Additional data were gathered from regional governmental traffic and law enforcement databases, including crash incidence, fatalities, and demographics. Data were compared pre- and post-RSS and analyzed using an unpaired t test with p less than 0.05 considered significant. RESULTS: There were 1,474 patients in AR-MVCs during the study period. There was a significant decrease in the annual average proportion of MVCs that were AR-MVCs pre- vs. post-RSS (39% vs. 29%, p = 0.02) as well as a decrease in the average annual incidence of fatal AR-MVCs (11.6 vs. 5, p = 0.02). Subset analysis showed a decrease in AR-MVC incidence in 18- to 29-year-olds (12.7% vs. 7.5%; p = 0.03), which was also demonstrated by data from a local law enforcement database. Availability of RSS was also correlated with a decreased proportion of nighttime AR-MVCs (14.7% vs. 7.6%, p = 0.03) and decreased number of driving while intoxicated (1198.0 ± 78.5 vs. 612.8 ± 137.6, p = <0.01). CONCLUSION: We found that the incidence of both total AR-MVCs and fatal AR-MVCs presenting to our trauma center decreased after the introduction of RSS. Ride-sharing services may play a role in preventing AR-MVCs. Further research is needed to correlate AR-MVC incidence with granular proprietary RSS usage data and to account for any confounding factors. Future studies may identify ways to better utilize RSS availability as a targeted intervention for certain demographic groups to prevent AR-MVCs. (J Trauma Acute Care Surg. 2020;89: 441-447. © 2020 Wolters Kluwer Health, Inc. All rights reserved.) LEVEL OF EVIDENCE: Therapeutic/Care Management, Level IV. Copyright © 2020 Wolters Kluwer Health, Inc. All rights reserved.},
	author_keywords = {Alcohol-related motor vehicle collisions; Alcohol-related traffic incidents; Motor-vehicle collisions; Rideshare; Uber},
	keywords = {accidental injury; adolescent; adult; aged; alcohol blood level; Article; case fatality rate; comparative study; controlled study; demography; drunken driving; emergency health service; fatality; female; human; incidence; infant; law enforcement; major clinical study; male; medical record review; middle aged; motor vehicle; newborn; observational study; priority journal; retrospective study; traffic accident; United States},
	correspondence_address = {R. Schroll; Department of Surgery, Tulane University School of Medicine, New Orleans, 8622, 1430 Tulane Ave, 70112, United States; email: rschroll@tulane.edu},
	publisher = {Lippincott Williams and Wilkins},
	issn = {21630755},
	pmid = {32467472},
	language = {English},
	abbrev_source_title = {J. Trauma Acute Care Surg.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4}
}

@CONFERENCE{Rosanne201961,
	author = {Rosanne, Olivier and Albuquerque, Isabela and Gagnon, Jean-Francois and Tremblay, Sebastien and Falk, Tiago H.},
	title = {Performance Comparison of Automated EEG Enhancement Algorithms for Mental Workload Assessment of Ambulant Users},
	year = {2019},
	journal = {International IEEE/EMBS Conference on Neural Engineering, NER},
	volume = {2019-March},
	pages = {61 – 64},
	doi = {10.1109/NER.2019.8716977},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066748556&doi=10.1109%2fNER.2019.8716977&partnerID=40&md5=6f551364a4f4fc0643175bd06bdb775f},
	affiliations = {INRS-EMT, Université du Québec, Montreal, Canada; Thales Research and Technology, Quebec, Canada; Université Laval, Quebec, Canada},
	abstract = {Mental workload (MW) assessment is important for numerous mentally-demanding applications, including first responders, air traffic control, amongst others, as it quantifies the cognitive capabilities of the operator. Recently, there has been a push for wearables based MW monitoring for real-time feedback and human performance augmentation. Most previous studies have focused on immobile subjects. Realistic applications, however, rely on ambulant users under varying types and levels of physical activity. Movement artifacts are known to hamper the quality of signals measured by wearable devices, thus the impact on MW assessment in situ is still unknown. In this study, we compare the performance of several automated artifact removal algorithms for electroencephalograms (EEG), as well as the robustness of two classical feature sets, for MW assessment under varying physical activity levels. © 2019 IEEE.},
	keywords = {Air traffic control; Bioelectric phenomena; Wearable technology; Cognitive capability; Electro-encephalogram (EEG); Enhancement algorithms; Mental workload assessments; Performance comparison; Physical activity levels; Real-time feedback; Realistic applications; Electroencephalography},
	publisher = {IEEE Computer Society},
	issn = {19483546},
	isbn = {978-153867921-0},
	language = {English},
	abbrev_source_title = {Int. IEEE/EMBS Conf. Neural Eng., NER},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; Conference name: 9th International IEEE EMBS Conference on Neural Engineering, NER 2019; Conference date: 20 March 2019 through 23 March 2019; Conference code: 148145}
}

@CONFERENCE{Almogbil2020186,
	author = {Almogbil, Atheer and Alghofaili, Abdullah and Deane, Chelsea and Leschke, Timothy and Almogbil, Atheer and Alghofaili, Abdullah},
	title = {The Accuracy of GPS-Enabled Fitbit Activities as Evidence: A Digital Forensics Study},
	year = {2020},
	journal = {Proceedings - 2020 7th IEEE International Conference on Cyber Security and Cloud Computing and 2020 6th IEEE International Conference on Edge Computing and Scalable Cloud, CSCloud-EdgeCom 2020},
	pages = {186 – 189},
	doi = {10.1109/CSCloud-EdgeCom49738.2020.00040},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092270118&doi=10.1109%2fCSCloud-EdgeCom49738.2020.00040&partnerID=40&md5=89045a9fcb544de9665ffcb39e0921c3},
	affiliations = {Information Security Institute, Johns Hopkins University, Baltimore, United States; King AbdulAziz City for Science Technology, Center for Cybersecurity Technologies, Riyadh, Saudi Arabia; King Saud University, Information Systems Department, Riyadh, Saudi Arabia},
	abstract = {Technology is advancing rapidly and with this advancement, it has become apparent that it is nearly impossible to not leave a digital trace when committing a crime. As evidenced by multiple cases handled by law enforcement, Fitbit data has proved to be useful when determining the validity of alibis and in piecing together the timeline of a crime scene. In our paper, experiments testing the accuracy and reliability of GPS-Tracked activities logged by the Fitbit Alta tracker and Ionic smartwatch are conducted. Potential indicators of manipulated or altered GPS-Tracked activities are identified to help guide digital forensic investigators when handling such Fitbit data as evidence. © 2020 IEEE.},
	author_keywords = {application forensics; digital forensics; Fitbit; GPS-Tracking; wearable technology},
	keywords = {Computer crime; Crime; Edge computing; Electronic crime countermeasures; Security of data; Crime scenes; Potential indicators; Digital forensics},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-172816550-9},
	language = {English},
	abbrev_source_title = {Proc. - IEEE Int. Conf. Cyber Secur. Cloud Comput. IEEE Int. Conf. Edge Comput. Scalable Cloud, CSCloud-EdgeCom},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: 7th IEEE International Conference on Cyber Security and Cloud Computing and 6th IEEE International Conference on Edge Computing and Scalable Cloud, CSCloud-EdgeCom 2020; Conference date: 1 August 2020 through 3 August 2020; Conference code: 162546}
}

@ARTICLE{Toral2019,
	author = {Toral, Víctor and García, Antonio and Romero, Francisco J. and Morales, Diego P. and Castillo, Encarnación and Parrilla, Luis and Gómez-Campos, Francisco M. and Morillas, Antonio and Sánchez, Alejandro},
	title = {Wearable system for biosignal acquisition and monitoring based on reconfigurable technologies},
	year = {2019},
	journal = {Sensors (Switzerland)},
	volume = {19},
	number = {7},
	doi = {10.3390/s19071590},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064808369&doi=10.3390%2fs19071590&partnerID=40&md5=522ea7b26d8c01062f395fff1e81b734},
	affiliations = {Department of Electronics and Computer Technology, University of Granada, Granada, 18071, Spain; Hospital de Alta Resolución de Guadix, Guadix, 18500, Spain; Mando de Adiestramiento y Doctrina, Ejército de Tierra, Granada, 18010, Spain; Facultad de Ciencias, Universidad de Granada, Granada, 18071, Spain},
	abstract = {Wearable monitoring devices are now a usual commodity in the market, especially for the monitoring of sports and physical activity. However, specialized wearable devices remain an open field for high-risk professionals, such as military personnel, fire and rescue, law enforcement, etc. In this work, a prototype wearable instrument, based on reconfigurable technologies and capable of monitoring electrocardiogram, oxygen saturation, and motion, is presented. This reconfigurable device allows a wide range of applications in conjunction with mobile devices. As a proof-of-concept, the reconfigurable instrument was been integrated into ad hoc glasses, in order to illustrate the non-invasive monitoring of the user. The performance of the presented prototype was validated against a commercial pulse oximeter, while several alternatives for QRS-complex detection were tested. For this type of scenario, clustering-based classification was found to be a very robust option. © 2019 by the authors. Licensee MDPI, Basel, Switzerland.},
	author_keywords = {ECG; Oxygen saturation; Reconfigurable instrumentation; Wearable instruments},
	keywords = {Electrocardiography; Electrocardiography, Ambulatory; Humans; Monitoring, Physiologic; Oximetry; Signal Processing, Computer-Assisted; Wearable Electronic Devices; Complexation; Electrocardiography; Noninvasive medical procedures; Oximeters; Military personnels; Monitoring device; Non-invasive monitoring; Oxygen saturation; QRS complex detection; Reconfigurable; Reconfigurable devices; Reconfigurable technologies; ambulatory electrocardiography; devices; electrocardiography; electronic device; human; oximetry; physiologic monitoring; signal processing; Wearable technology},
	correspondence_address = {A. García; Facultad de Ciencias, Universidad de Granada, Granada, 18071, Spain; email: grios@ugr.es},
	publisher = {MDPI AG},
	issn = {14248220},
	pmid = {30986953},
	language = {English},
	abbrev_source_title = {Sensors},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 10; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Cai2020544,
	author = {Cai, Yang and Hackett, Sean and Alber, Florian},
	title = {Interactive indoor localization on helmet},
	year = {2020},
	journal = {Advances in Intelligent Systems and Computing},
	volume = {1217 AISC},
	pages = {544 – 551},
	doi = {10.1007/978-3-030-51828-8_71},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088741653&doi=10.1007%2f978-3-030-51828-8_71&partnerID=40&md5=9fad706b488a1fb617daa170c464a1d8},
	affiliations = {Cylab Institute and Biomedical Engineering, Carnegie Mellon University, Pittsburgh, 15213, PA, United States},
	abstract = {We present a human-sensor interaction approach for indoor navigation, where we incorporate inertial motion unit sensors, human knowledge and human-computer interaction into the navigation process. The algorithm uses semantic representations of navigational constraints such as walls, stairs, and elevators, to correct the trajectory. The objective is to reduce the IMU drifting errors. The navigation prototype is implemented on a helmet with a holographic screen that can mix the actual visible image with mapping and visualization information, voice command and tactile interface. The helmet is to assist first responders in emergency environments of fire, flood, shooting, cyberattack, and medical distress, where GSP, cellular and regular WiFi is not available. The results show that the interactive navigation reduces drifting errors and it is an affordable alternative to existing technologies such as ultrasound, RFID, UWB radios, WiFi signatures, and camera-based SLAM (simultaneous localization and mapping) algorithms where matching features are not sufficient, especially in a dark or smoking environment. © The Editor(s) (if applicable) and The Author(s), under exclusive license to Springer Nature Switzerland AG 2020.},
	author_keywords = {Augmented reality; First response; HADR; Helmet; Indoor navigation},
	keywords = {Air navigation; Human computer interaction; Human engineering; Mapping; Navigation; Safety devices; Security of data; Semantics; User experience; Wearable technology; Wireless local area networks (WLAN); First responders; Holographic screens; In-door navigations; Indoor localization; Inertial motions; Interactive navigations; Semantic representation; SLAM (simultaneous localization and mapping); Indoor positioning systems},
	correspondence_address = {Y. Cai; Cylab Institute and Biomedical Engineering, Carnegie Mellon University, Pittsburgh, 15213, United States; email: ycai@cmu.edu},
	editor = {Ahram T. and Falcão C.},
	publisher = {Springer},
	issn = {21945357},
	isbn = {978-303051827-1},
	language = {English},
	abbrev_source_title = {Adv. Intell. Sys. Comput.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: AHFE Virtual Conference on Usability and User Experience, the Virtual Conference on Human Factors and Assistive Technology,  the Virtual Conference on Human Factors and Wearable Technologies, and the Virtual Conference on Virtual Environments and Game Design, 2020; Conference date: 16 July 2020 through 20 July 2020; Conference code: 241849}
}

@ARTICLE{Burgason201762,
	author = {Burgason, Kyle A. and Drawve, Grant and Brown, Timothy C. and Eassey, John},
	title = {Close only counts in alcohol and violence: Controlling violence near late-night alcohol establishments using a routine activities approach},
	year = {2017},
	journal = {Journal of Criminal Justice},
	volume = {50},
	pages = {62 – 68},
	doi = {10.1016/j.jcrimjus.2017.04.004},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018574041&doi=10.1016%2fj.jcrimjus.2017.04.004&partnerID=40&md5=fe530e39dd31107aa12b490e3dc8c476},
	affiliations = {Department of Sociology, Iowa State University, 216 East Hall, Ames, 50011, IA, United States; Sociology and Criminal Justice, University of Arkansas, Fayetteville, 72701, AR, United States; Department of Criminal Justice, University of Arkansas at Little Rock, 2801 S. University Ave, Little Rock, 72204, AR, United States; Criminology and Criminal Justice, Missouri State University, 901 South National Avenue, Springfield, 65897, MO, United States},
	abstract = {Purpose Assess whether 5a.m. bars and nightclubs in Little Rock, AR were in fact serving to attract or generate violence in and around their premises and what impacts a new ordinance, requiring increased guardianship, served its intended purpose to reduce the incidence of violence. Methods Using violent crime data from the Little Rock Police, a series of Risk Terrain Models were utilized to examine whether the influence that proximity to a risk factor (5a.m. alcohol establishments) has on violent crime changes after the new ordinance is established. Results Support for the ordinance was found for yearlong risk assessment, in that requiring 5am alcohol establishments in Little Rock to employ a minimum of two law enforcement officers in and around the establishment acted as effective strategies to alter the guardianship and reduced the relative risk of violent crime in close proximity to these establishments. Conclusion The establishments were serving to attract/generate violent crime in and around their vicinity; however, support was found for the effectiveness risk reduction through increasing levels of guardianship and thus, reducing relative risk for violent crime. Furthermore, depending on the temporal aggregation, results varied on the potential riskiness associated with the 5a.m. alcohol establishments. © 2017},
	author_keywords = {Alcohol; Crime attractors; Crime generators; Risk reduction; Super-controller},
	correspondence_address = {K.A. Burgason; Department of Sociology, Iowa State University, Ames, 216 East Hall, 50011, United States; email: burgason@iastate.edu},
	publisher = {Elsevier Ltd},
	issn = {00472352},
	coden = {JCJUD},
	language = {English},
	abbrev_source_title = {J. Crim. Justice},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8}
}

@ARTICLE{Wang2019,
	author = {Wang, Xing and Zhang, Bob and Yang, Meng and Ke, Kangyin and Zheng, Weishi},
	title = {Robust joint representation with triple local feature for face recognition with single sample per person},
	year = {2019},
	journal = {Knowledge-Based Systems},
	volume = {181},
	doi = {10.1016/j.knosys.2019.05.033},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066779843&doi=10.1016%2fj.knosys.2019.05.033&partnerID=40&md5=ba1668143602aab84c97bbd7819f9549},
	affiliations = {School of Data and Computer Science, Sun Yat-sen University, Guangzhou, China; Department of Computer and Information Science, University of Macau, Macau, China; Key Laboratory of Machine Intelligence and Advanced Computing (SYSU), Ministry of Education, China},
	abstract = {Face recognition (FR) with a single training sample per person (SSPP) is a representative small-sample-size classification problem and occurs in many practical scenarios such as law enforcement, surveillance, identity card, e-passport, etc. By using intra-class variations extracted from an additional training set (i.e., a set excluding gallery subjects) as a generic intra-class variation dictionary, sparse representation based classification (SRC) has been extended to FR with SSPP. However, for FR with SSPP, how to achieve high robustness to gross facial variations (e.g., complex facial lighting, expression and pose variations and various outliers of corruption, occlusion and disguise) is still an open issue. In this paper, we propose a novel model, named robust joint representation with triple local feature (RJR-TLF), to address this issue from the viewpoints of feature extraction and classifier design. In feature extraction, we design robust triple local features, i.e., Gabor facial features with multiple scales and multiple orientations extracted in different facial local regions (e.g., local patches centered around dense regularly sampled points and detected particular points including nose tip, eye centers, etc.), to naturally encode the local scale, local orientation and local space information of a face image. For face images, the densely and regularly sampled facial regions can provide a comprehensive description; the sparsely and particularly detected facial regions can exploit a discriminative description because they cover the most informative facial regions and can be detected robustly. In classifier design, we propose a robust joint representation framework to exploit the distinctiveness and similarity of different local information by requiring triple local features from the same type of Gabor feature (i.e., with the same scale and orientation) to have similar representation coefficients. With the coefficient-similarity constraint and the robust representation fidelity term representing the query image on the single-sample gallery set and the generic intra-class variation dictionary, the local features with large-representation residuals actually indicate corrupted regions with gross facial variations and will be assigned low weights adaptively to reduce their effects on the representation and classification, which further strengthens the robustness of RJR-TLF. The proposed RJR-TLF is evaluated extensively on popular databases, including the AR, the large-scale CMU Multi-PIE, and the LFW databases. Experimental results demonstrate that RJR-TLF is much more robust to various facial variations than the recent FR with SSPP methods. © 2019 Elsevier B.V.},
	author_keywords = {Face recognition; Robust joint representation; Single sample per person; Triple local feature},
	keywords = {Extraction; Face recognition; Feature extraction; Intra-class variation; Local feature; Multiple orientations; Robust joint representation; Single sample; Single training sample; Small-sample-size classifications; Sparse representation based classifications; Classification (of information)},
	correspondence_address = {M. Yang; School of Data and Computer Science, Sun Yat-sen University, Guangzhou, China; email: yangmengpolyu@msn.com},
	publisher = {Elsevier B.V.},
	issn = {09507051},
	coden = {KNSYE},
	language = {English},
	abbrev_source_title = {Knowl Based Syst},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 11}
}

@ARTICLE{Nunes2018155,
	author = {Nunes, Isabel L. and Lucas, Raquel and Simões-Marques, Mário and Correia, Nuno},
	title = {Augmented Reality in Support of Disaster Response},
	year = {2018},
	journal = {Advances in Intelligent Systems and Computing},
	volume = {592},
	pages = {155 – 167},
	doi = {10.1007/978-3-319-60366-7_15},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041101877&doi=10.1007%2f978-3-319-60366-7_15&partnerID=40&md5=e9be3650ae909c56d31b417dea3b36a4},
	affiliations = {Faculdade de Ciencias e Tecnologia, Universidade NOVA de Lisboa, Caparica, 2829-516, Portugal; Faculdade de Ciencias e Tecnologia, UNIDEMI, Universidade NOVA de Lisboa, Caparica, 2829-516, Portugal; NOVA-LINCS, Faculdade de Ciencias e Tecnologia, Universidade NOVA de Lisboa, Caparica, 2829-516, Portugal; CINAV- Portuguese Navy, Alfeite, Almada, 2810-001, Portugal},
	abstract = {Disaster Management is a complex process, usually dealing with a large amount of uncertain, incomplete and vague information, which normally requires the coordination and collaboration among a variety of actors. THEMIS (disTributed Holistic Emergency Management Intelligent System) is designed as an intelligent system aimed at supporting real time disaster management activities of decision-makers in command posts, and responders in the field. It gathers information from multiple sources (e.g., users, sensors, crowdsourcing), and provides situational awareness based on a georeferenced common picture which is shared among system users This paper presents the preliminary work developed in the context of the THEMIS project addressing the use of Augmented Reality by first responders in a context of disasters relief operations. © 2018, Springer International Publishing AG.},
	author_keywords = {Disaster response; Mobile augmented reality; THEMIS},
	keywords = {Augmented reality; Coordination reactions; Decision making; Disaster prevention; Disasters; Human engineering; Intelligent systems; Risk management; Complex Processes; Disaster management; Disaster response; Emergency management; Mobile augmented reality; Relief operations; Situational awareness; THEMIS; Emergency services},
	correspondence_address = {I.L. Nunes; Faculdade de Ciencias e Tecnologia, Universidade NOVA de Lisboa, Caparica, 2829-516, Portugal; email: imn@fct.unl.pt},
	editor = {Nunes I.L.},
	publisher = {Springer Verlag},
	issn = {21945357},
	isbn = {978-331960365-0},
	language = {English},
	abbrev_source_title = {Adv. Intell. Sys. Comput.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 19; Conference name: AHFE 2017 International Conference on Human Factors and Systems Interaction, 2017; Conference date: 17 July 2017 through 21 July 2017; Conference code: 209519}
}

@CONFERENCE{Coleman2020,
	author = {Coleman, Jeff and Thirtyacre, David and Cross, David},
	title = {Remote pilot situational awareness with augmented reality glasses: An observational field study},
	year = {2020},
	journal = {AUVSI XPONENTIAL 2020},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102403044&partnerID=40&md5=e84c2196ea24baea4ce4baad6e84850e},
	affiliations = {Embry-Riddle Aeronautical University, Worldwide Campus, Daytona Beach, FL, United States; Department of Flight, Embry-Riddle Aeronautical University, Worldwide Campus, Daytona Beach, FL, United States},
	abstract = {With the use of small unmanned aerial systems (sUAS) proliferating throughout industry and public safety, it is imperative to ensure safety of flight. The Federal Aviation Administration (FAA) published regulations for commercial use of sUAS in 2016 and included the requirement to maintain visual line-of-sight with the aircraft at all times. However, due to the nature of the sUAS ground control stations (GCS), remote pilots time-share between observing the aircraft and in-teracting with the display on the GCS. Time-sharing between the aircraft and GCS can be seen as similar to the cross-check a pilot uses when flying a manned aircraft. While manned aircraft designers have invested in the ergonomics and understanding of the cognitive process to optimize situational awareness, it has not been a design requirement for sUAS. The result is that the unmanned opera-tor must change head orientation, eye focus, and remove the aircraft from pe-ripheral vision during the cross-check between the GCS and aircraft. This, cou-pled with the limited field of view of the sUAS GCS displayed camera, leads to loss of situational awareness through task saturation, and misprioritization. Mixed reality, virtual reality, and augmented reality visual devices are being adopted in the gaming and technical world. The application of these devices to the sUAS GCS could mitigate some of the degradation of situational awareness. Specifically, the incorporation of augmented reality devices where a synthetic display is overlaid on the real-world, allows the remote pilot to observe the air-craft, manipulate the camera, and interact with the GCS without changing head position. This participant observational study evaluated the difference between the remote pilot cross-check while flying with a typical GCS display and when flying with an augmented reality headset in a field setting. The results indicate a significant difference between the pilot's crosscheck when using augmented re-ality glasses allowing the pilot to maintain the aircraft in their field of view 56.7% of the time compared to 20.5% when not using the glasses. © 2020 AUVSI XPONENTIAL 2020. All rights reserved.},
	keywords = {Accident prevention; Aircraft; Antennas; Augmented reality; Cameras; Display devices; Ergonomics; Glass; Rock mechanics; Cognitive process; Federal Aviation Administration; Ground control stations; Manned aircraft; Observational study; Safety-of-flight; Situational awareness; Unmanned aerial systems; Mixed reality},
	publisher = {Association for Unmanned Vehicle Systems International},
	language = {English},
	abbrev_source_title = {AUVSI XPONENTIAL},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: AUVSI XPONENTIAL 2020; Conference date: 5 October 2020 through 8 October 2020; Conference code: 167403}
}

@ARTICLE{Oud2019161,
	author = {Oud, Floris R.W. and Kooij, Fabian O. and Burns, Brian J.},
	title = {Long-term Effectiveness of the Airway Registry at Sydney Helicopter Emergency Medical Service},
	year = {2019},
	journal = {Air Medical Journal},
	volume = {38},
	number = {3},
	pages = {161 – 164},
	doi = {10.1016/j.amj.2019.01.006},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061797155&doi=10.1016%2fj.amj.2019.01.006&partnerID=40&md5=63ba77c00ffb269fa1f1f294313d0c7b},
	affiliations = {Greater Sydney Area Helicopter Emergency Medical Service, New South Wales Ambulance, Bankstown Airport, New South Wales, Australia; Department of Anaesthesiology, Amsterdam UMC, Amsterdam-Zuidoost, Netherlands},
	abstract = {Objective: Prehospital rapid sequence intubation (RSI) is prone to suboptimal documentation. The Greater Sydney Area Helicopter Emergency Medical Service (GSA-HEMS) uses a dedicated Airway Registry (AR) to aid documentation. The AR was only evaluated shortly after its introduction. This first evaluation is followed up to assess the long-term effectiveness of the AR. The secondary objective was to compare the AR with templates in the literature. Methods: A retrospective review of electronic records was undertaken to compare completeness of documentation between an immediate postintroduction and a long-term postintroduction cohort. Differences between the two cohorts were tested for significance. Results: There was no significant difference in documentation for Cormack-Lehane laryngoscopy grade at the first intubation attempt (P = .552) and confirmation of end-tidal carbon dioxide (P = .258). A significant improvement in the documentation of laryngoscopy grade for the second attempt (P = 0) was found. The documentation of intubator details remained at 100% (165/165). The variables collected by GSA-HEMS corresponded well to the literature, but some definitions differ (eg, desaturation). Conclusion: There was no significant change in completeness of documentation for most key intubation variables eight years after the introduction of the AR. GSA-HEMS performs well in registering variables as proposed in the literature; however, variable definitions need to be synchronized. © 2019 Air Medical Journal Associates},
	keywords = {Adult; Air Ambulances; Documentation; Emergency Medical Services; Female; Humans; Male; New South Wales; Program Evaluation; Rapid Sequence Induction and Intubation; Registries; Retrospective Studies; airway; article; case report; clinical article; cohort analysis; comparative effectiveness; documentation; emergency health service; end tidal carbon dioxide tension; helicopter; intubation; laryngoscopy; retrospective study; adult; air medical transport; comparative study; emergency health service; female; human; male; New South Wales; procedures; program evaluation; register},
	correspondence_address = {F.R.W. Oud; Amsterdam, Haarlemmermeerstraat 128H, 1058KH, Netherlands; email: frwoud@gmail.com},
	publisher = {Mosby Inc.},
	issn = {1067991X},
	coden = {AMJIA},
	pmid = {31122579},
	language = {English},
	abbrev_source_title = {Air Med. J.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4}
}

@CONFERENCE{Matsuhashi20191129,
	author = {Matsuhashi, Kazuki and Noguchi, Ryo and Daimon, Tatsuru and Kasazumi, Ken'ichi and Mori, Toshiya},
	title = {Basic study on the influence of cabin vibration on the driver's depth perception and subjective conviction when using an automotive three-dimensional head-up display based on the relationship between the degree of correction and driver's recognition},
	year = {2019},
	journal = {Proceedings of the International Display Workshops},
	volume = {3},
	pages = {1129 – 1132},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105295260&partnerID=40&md5=4bf8eeb649bd547971e6372c9c8b5e16},
	affiliations = {Graduate School of Science and Technology, Keio University, Japan; Faculty of Science and Technology, Keio University, Japan; Panasonic Corporation, Automotive Company},
	abstract = {This study discusses the driver's depth perception and subjective conviction to be corrected for in the display contents of an automotive three-dimensional head-up display, such as navigation arrows, based on the levels of the basic correction method used to reduce the effect of car vibration generated by various road surfaces. © 2019 ITE and SID},
	author_keywords = {Depth perception; Head-up display; Human factors; Human machine interface; Recognition},
	keywords = {Depth perception; Head-up displays; Law enforcement; Car vibration; Correction method; Road surfaces; Three dimensional displays},
	publisher = {International Display Workshops},
	issn = {18832490},
	isbn = {978-171380630-1},
	language = {English},
	abbrev_source_title = {Proc. Int. Disp. Workshops},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 26th International Display Workshops, IDW 2019; Conference date: 27 November 2019 through 29 November 2019; Conference code: 168593}
}

@ARTICLE{Midya201865,
	author = {Midya, Manas and Bhattacharjee, Shankar and Mitra, Monojit},
	title = {Compact CPW-fed circularly polarized antenna for wlan application},
	year = {2018},
	journal = {Progress In Electromagnetics Research M},
	volume = {67},
	pages = {65 – 73},
	doi = {10.2528/PIERM18021505},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045766698&doi=10.2528%2fPIERM18021505&partnerID=40&md5=6eca983b3fb0755c2e2cf0873f661e0c},
	affiliations = {Department of Electronics & Telecommunication Engineering, Indian Institute of Engineering Science & Technology, Shibpur, India},
	abstract = {A novel compact CPW (coplanar waveguide-fed) CPSS (Circularly polarized square slot) antenna is presented. The proposed single-layer antenna is composed of a rectangular ground plane embedded with two equal-size patches along two orthogonal directions. Equal amplitudes with 90◦ phase difference values of two patches are capable of generating a resonant mode for exciting two orthogonal E vectors. Axial ratio (AR) bandwidth is significantly enhanced due to slot corner modification. The designed CPSS antenna is compact in nature with volume of 0.37λ0 × 0.34λ0 × 0.012λ0 mm3 (λ0 =free space wavelength at centre frequency of the CP bandwidth). It has impedance bandwidth between 4.65– 6.72 GHz (36.41%) and 3-dB axial-ratio bandwidth of 520 MHz (4.85–5.37 GHz), which covers 4.9 GHz (802.11j) WLAN for public safety ranging from 4.94 GHz to 4.99 GHz and WLAN (U-NII-1 and U-NII-2A) ranging from 5.150–5.350 GHz for indoor use. The gain variation for the frequencies within the CP bandwidth is also observed to be less than 0.4 dBic. The design is successfully implemented, and measured results are compared with the simulated ones, which are found good agreement. © 2018, Electromagnetics Academy. All rights reserved.},
	keywords = {Antenna grounds; Bandwidth; Circular polarization; Coplanar waveguides; Electric impedance; Microwave antennas; Slot antennas; Wireless local area networks (WLAN); Axial ratio bandwidth; Circularly polarized; Circularly polarized antennas; Coplanar waveguide fed; Corner modifications; Free-space wavelengths; Impedance bandwidths; Orthogonal directions; Antenna feeders},
	correspondence_address = {M. Midya; Department of Electronics & Telecommunication Engineering, Indian Institute of Engineering Science & Technology, Shibpur, India; email: letsmanas@gmail.com},
	publisher = {Electromagnetics Academy},
	issn = {19378726},
	language = {English},
	abbrev_source_title = {Prog. Electromagn. Res. M},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 17; All Open Access, Bronze Open Access}
}

@CONFERENCE{Tiemann2020,
	author = {Tiemann, Janis and Fuhr, Oliver and Wietfeld, Christian},
	title = {CELIDON: Supporting first responders through 3D AOA-based UWB Ad-hoc localization},
	year = {2020},
	journal = {International Conference on Wireless and Mobile Computing, Networking and Communications},
	volume = {2020-October},
	doi = {10.1109/WiMob50308.2020.9253377},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097309388&doi=10.1109%2fWiMob50308.2020.9253377&partnerID=40&md5=b0ecf99b544f20427235ea88892e47f7},
	affiliations = {TU Dortmund University, Communication Networks Institute (CNI), Otto-Hahn-Str. 6, Dortmund, 44227, Germany},
	abstract = {For many applications relative position information is critical. One particular case is the prevention of compressed air breathing accidents in operations with low visibility. Here, separation of first responders in an unknown and dangerous environment could yield a fatal outcome. The goal of this work is to introduce technology that assists firefighters in situations with no visibility to locate team members. Due to the lack of pre-installed infrastructure, a relative ad-hoc localization scheme without the need for in place infrastructure is required. We propose a three-dimensional ultra-wideband based scheme and show a functional prototype with integrated transceivers combining both, two-way ranging range finding and phase-difference of arrival direction finding. Further, we show a potential architecture for integration in firefighter equipment such as helmet and mask utilizing augmented reality technology. Through multiple experiments we could show, that in the given laboratory setup direction estimation with an accuracy of 20o and position finding with an accuracy of 30cm is possible with the proposed approach. © 2020 IEEE.},
	author_keywords = {Ad-Hoc Localization; Angle of Arrival (AOA); Firefighters; First Responders; Infrastructure-Free; Infrastructure-Less; Low Visibility; Phase-Difference of Arrival (PDOA); Ultra-wideband (UWB); Wireless Positioning},
	keywords = {Augmented reality; Compressed air; Direction of arrival; Fire extinguishers; Mobile computing; Radio transceivers; Range finding; Visibility; Arrival direction; Augmented reality technology; Direction estimation; First responders; Functional Prototypes; Laboratory set-up; Localization schemes; Relative positions; Ultra-wideband (UWB)},
	publisher = {IEEE Computer Society},
	issn = {21619646},
	isbn = {978-172819722-7},
	language = {English},
	abbrev_source_title = {Int. Conf. Wirel. Mob. Comput. Netw. Commun.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; Conference name: 16th International Conference on Wireless and Mobile Computing, Networking and Communications, WiMob 2020; Conference date: 12 October 2020 through 14 October 2020; Conference code: 165007}
}

@CONFERENCE{Francesco20202148,
	author = {Francesco, Filippone and Ciro, Bolognese and Luciano, Roncalli and Matteo, Monterosso},
	title = {The response of the rescue system to large scale emergencies a case study: The collapse of the morancli bridge part 2 of 2: Technologies for rescue service},
	year = {2020},
	journal = {Proceedings of the 30th European Safety and Reliability Conference and the 15th Probabilistic Safety Assessment and Management Conference},
	pages = {2148 – 2153},
	doi = {10.3850/978-981-14-8593-0_4326-cd},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107277638&doi=10.3850%2f978-981-14-8593-0_4326-cd&partnerID=40&md5=5585b4b5bdf3d14248cef5073a33b699},
	affiliations = {Italian National Fire and Rescue Service, Genoa Fire and Rescue Service, Italy; Italian National Fire and Rescue Service, National Headquarters, Italy},
	abstract = {When a complex scenario occurs (e.g. earthquakes, forest fires, floods), the Italian National Fire and Rescue Service 1 mobilizes a large response by local first responders and additional specialized teams. In this age of disaster, also due to climate change and critical anthropic environments, the effectiveness of the response to various scenarios is also played by the availability of proper technologies that may support the skills and the expertise of rescuers. Taking into consideration some collapses of civil engineering structures occurred in Genoa in recent years, with a particular focus on the collapse of the Morandi bridge, the paper illustrates how the interaction between humans and technology is nowadays able to facilitate both the speedy risk-based decision making in the operational activities of the emergency phase and the residual risk assessments in the early recovery phase. The issues of the paper are: the technological tools of Urban Search & Rescue teams for a fast localization of victims; the application of a search and rescue methodology according to international procedures and guidelines (INSARAG2); the structural risk management for an immediate evaluation of the collapsed structures and rubble to care the rescuer's safety and the numerical modelling of artefacts for post-emergency evaluations; a description of a monitoring alarm system - designed by experts of the scientific community and industry and installed by firefighters in a synergic role play - to ensure safety measures for rescuers and population during the activity of the asset recovery in the built environments under the residual structures of the bridge; the use of geolocalization technologies in the forensic assistance; the use of modem technologies and instruments in the aeronautics industry (drones and helicopters) as valid support in search and rescue activity, giving a different "point of view" of the scenario to be analysed; the use of artificial intelligence, augmented reality, IoT for reducing the workload of the flight rescuers and increasing their operational efficacy. New challenges: the use of humanoid robots in search & rescue activities or in industrial applications, characterized by high risk for humans, to reach inaccessible zone and to ensure shorter time response. © ESREL 2020-PSAM15 Organizers. Published by Research Publishing, Singapore.},
	author_keywords = {Disaster Management; INSARAG international guideline; Public safety. Big Data and IoT Applications; Risk Assessment; Risk Management; Risk-based Decision Making},
	keywords = {Accident prevention; Alarm systems; Anthropomorphic robots; Artificial intelligence; Augmented reality; Bridges; Climate change; Deforestation; Human resource management; Industrial robots; Population statistics; Risk assessment; Risk management; Risk perception; Aeronautics industry; Civil engineering structures; Collapsed structures; Fire and rescue services; Large-scale emergency; Operational activity; Risk based decision making; Scientific community; Emergency services},
	editor = {Baraldi P. and Di Maio F. and Zio E.},
	publisher = {Research Publishing, Singapore},
	isbn = {978-981148593-0},
	language = {English},
	abbrev_source_title = {Proc. Eur. Saf. Reliab. Conf. Probab. Saf. Assess. Manag. Conf.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 30th European Safety and Reliability Conference, ESREL 2020 and 15th Probabilistic Safety Assessment and Management Conference, PSAM15 2020; Conference date: 1 November 2020 through 5 November 2020; Conference code: 259839}
}

@CONFERENCE{Athanasiou2020,
	author = {Athanasiou, Apostolos and Salamone, Salvatore},
	title = {Acquisition and management of field inspection data using augmented reality},
	year = {2020},
	journal = {Proceedings of SPIE - The International Society for Optical Engineering},
	volume = {11426},
	doi = {10.1117/12.2558920},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089590468&doi=10.1117%2f12.2558920&partnerID=40&md5=a00d46b25544557aec63b2bb5c951455},
	affiliations = {Ferguson Structural Engineering Laboratory (FSEL), Department of Civil Architectural and Environmental Engineering, University of Texas at Austin, Building 177, 10100 Burnet Road, Austin, 78758, TX, United States},
	abstract = {Health monitoring of infrastructure systems is an important issue for public safety. Over the past decade, more structures are exhibiting signs of distress and the owners are required to perform periodic assessments of their assets. Visual inspection is the first approach employed for the assessment of a structure. The monitoring of distress evolution over time can serve as an estimator of a structure's structural performance. However, the data obtained during inspections are complex and hard to visualize on-site. Only after careful review of acquired data, the inspector can assess the condition of a structural component. The processing of field data may take several weeks before it yields any meaningful insight about the health of the structure. The procedure presented in this paper attempts to bridge this gap between the advancements of computer vision and on-site structure health monitoring, based on the utilization of Augmented Reality (AR) tools. More specifically, it includes the projection of holograms that present the reinforcement information obtained during structural inspections, data about the structural condition of the component, and 3D models including as-built details. The inspector can interact with the holograms using hand gestures. The holographic reinforcement visualization eliminates the time required to make a first assessment of a structure. Moreover, it increases efficiency and makes the inspection procedure safer, since the inspector doesn't have to carry any special equipment other than the holographic headset. Conventional approaches for the visual assessment of infrastructure systems are subjective, time consuming, and expensive to perform. Such AR systems can potentially decrease the time and cost of infrastructure inspections, by reducing the time required for post-processing and allowing the inspector to make educated estimations about the health of the structure in the field. © 2020 SPIE.},
	author_keywords = {Augmented Reality; Environmental Understanding; Spatial Computing; Structural Health Monitoring},
	keywords = {Augmented reality; Data handling; Health; Holograms; Inspection; Mixed reality; Reinforcement; Structural analysis; Conventional approach; Infrastructure systems; Inspection procedures; Structural component; Structural condition; Structural inspections; Structural performance; Structure health monitoring; Structural health monitoring},
	correspondence_address = {A. Athanasiou; Ferguson Structural Engineering Laboratory (FSEL), Department of Civil Architectural and Environmental Engineering, University of Texas at Austin, Building 177, Austin, 10100 Burnet Road, 78758, United States; email: apostolos.athanasiou@utexas.edu; S. Salamone; Ferguson Structural Engineering Laboratory (FSEL), Department of Civil Architectural and Environmental Engineering, University of Texas at Austin, Building 177, Austin, 10100 Burnet Road, 78758, United States; email: salamone@utexas.edu},
	editor = {Dennison M.S.},
	publisher = {SPIE},
	issn = {0277786X},
	isbn = {978-151063629-3},
	coden = {PSISD},
	language = {English},
	abbrev_source_title = {Proc SPIE Int Soc Opt Eng},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: Virtual, Augmented, and Mixed Reality ,XR Technology for Multi-Domain Operations 2020; Conference date: 27 April 2020 through 8 May 2020; Conference code: 161136}
}

@CONFERENCE{Hackett2019,
	author = {Hackett, Sean and Cai, Yang and Siegel, Mel},
	title = {Activity Recognition from Sensor Fusion on Fireman's Helmet},
	year = {2019},
	journal = {Proceedings - 2019 12th International Congress on Image and Signal Processing, BioMedical Engineering and Informatics, CISP-BMEI 2019},
	doi = {10.1109/CISP-BMEI48845.2019.8966005},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079177197&doi=10.1109%2fCISP-BMEI48845.2019.8966005&partnerID=40&md5=547ab195bf4df61f7265399e4f6cd126},
	affiliations = {Carnegie Mellon University, 4720 Forbes Ave., Pittsburgh, 15213, PA, United States},
	abstract = {Recognizing human activities in emergency situations is critical for first responders to ensure their safety and well-being. In many cases, the thick smoke in a burning building impairs computer vision algorithms for activity recognition. Here we present a helmet-based sensor fusion method with IMU and time-of-fly laser distance sensor. We use a Decision Tree to as a classifier and select the most significant features. Our test shows that the method can recognize over seven activities: walking, running, crawling, duck walking, standing, walking upstairs and downstairs, with an accuracy between 81.7%• and 93.6%. With limited training data and a lightweight requirement for implementation on the fireman's helmet the Decision Tree provided an accurate and reliable result. The use of the 1-D Lidar, which is not feasible in typical activity recognition application but essential for the helmet, combined with the 10-DOF IMU sensors improved the robustness of the classifier. We found this sensor fusion approach needs much less training data, compared to methods such as Deep Learning. Once implemented on the helmet the activity recognition is executed in real-time at sampling rate at 50 Hz within a 2-second window. © 2019 IEEE.},
	author_keywords = {activity recognition; augmented reality; classification; decision tree; decision-making; distance measurement; fire-fighting; first response; gesture recognition; helmet; human-computer interaction; IMU; pattern recognition; pitch; sensor; sensor fusion; time-of-fly laser; wearable sensors},
	keywords = {Augmented reality; Biomedical engineering; Classification (of information); Decision making; Decision trees; Deep learning; Distance measurement; Fire extinguishers; Gesture recognition; Human computer interaction; Image processing; Pattern recognition; Safety devices; Sensor data fusion; Sensors; Smoke; Trees (mathematics); Activity recognition; Fire fighting; first response; helmet; pitch; Sensor fusion; Time of fly laser; Wearable sensors},
	correspondence_address = {Y. Cai; Carnegie Mellon University, Pittsburgh, 4720 Forbes Ave., 15213, United States; email: ycai@cmu.edu},
	editor = {Li Q. and Wang L.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-172814852-6},
	language = {English},
	abbrev_source_title = {Proc. - Int. Congr. Image Signal Process., BioMed. Eng. Inf., CISP-BMEI},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; Conference name: 12th International Congress on Image and Signal Processing, BioMedical Engineering and Informatics, CISP-BMEI 2019; Conference date: 19 October 2019 through 21 October 2019; Conference code: 157086}
}

@ARTICLE{Sanz-Barbero2018413,
	author = {Sanz-Barbero, Belén and Linares, Cristina and Vives-Cases, Carmen and González, José Luis and López-Ossorio, Juan José and Díaz, Julio},
	title = {Heat wave and the risk of intimate partner violence},
	year = {2018},
	journal = {Science of the Total Environment},
	volume = {644},
	pages = {413 – 419},
	doi = {10.1016/j.scitotenv.2018.06.368},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049480022&doi=10.1016%2fj.scitotenv.2018.06.368&partnerID=40&md5=2644ecbc83690929b9a2387d935b31ca},
	affiliations = {National School of Public Health, Carlos III Institute of Health, Madrid, Spain; CIBER of Epidemiology and Public Health (CIBERESP), Spain; Public Health Research Group, Department of Community Nursing, Preventive Medicine and Public Health and History of Science, Alicante University, Alicante, Spain; Ministry of the Interior, Spain},
	abstract = {Background: A high number of women report experiencing intimate partner violence (IPV). It is of utmost importance to identify possible factors that precipitate IPV and incorporate them into police protocols for evaluating IPV risk. Scientific evidence shows that environmental temperature is associated with a risk of violent behavior. Objectives: To analyze the effect and impact of heat waves on the risk of IPV. Methods: Ecological, longitudinal time series study. The dependent variables are: intimate partner femicides (IPF), reports of IPV and 016 IPV telephone help line calls in the Community of Madrid from 05/01 to 09/30 in the years 2008–2016. The principal independent variable is the daily maximum temperature in Celsius (Tmax) above the heat wave threshold of 34 °C. A binomial negative regression was used for calls and reports and a Poisson regression was used for IPF. The attributable risk among those exposed (AR%) and the number of attributable cases was calculated for each variable. Results: The risk of IPF increased three days after the heat wave, [RR(IC95%):1.40(1.00–1.97)], police reports of IPV increased one day after [RR (IC95%):1.02(1.00–1.03) and help line calls increased five days after [RR(IC95%):1.01(1.00–1.03)]. The AR% was 28.8% (IC95%: 0.3%–49.2%) for IPF, 1.7% (IC95%:0.3%–3.1%) for police reports and 1.43% (IC95:0.1%;2.8%) for help line calls. Conclusions: Our results suggest that heat waves are associated with an increase in IPV. The effect of an increase in IPV is delayed in time, with differences according to the violence indicators analyzed. © 2018 Elsevier B.V.},
	author_keywords = {Femicides; Heat wave; Intimate partner violence},
	keywords = {Environmental Exposure; Female; Hot Temperature; Humans; Intimate Partner Violence; Police; Risk Factors; Madrid [Spain]; Spain; Law enforcement; Dependent variables; Environmental temperature; Femicides; Heat waves; Independent variables; Intimate partner violence; Maximum temperature; Scientific evidence; heat wave; human behavior; law enforcement; risk assessment; temperature effect; violence; womens status; Article; attributable risk; controlled study; dependent variable; environmental temperature; heat; heat wave; human; independent variable; information processing; longitudinal study; mortality; partner violence; priority journal; time series analysis; environmental exposure; female; partner violence; police; risk factor; statistics and numerical data; Climatology},
	correspondence_address = {J. Díaz; Escuela Nacional de Sanidad, Instituto de Salud Carlos III, Madrid, Avda. Monforte de Lemos n°5, pabellón 7, 28029, Spain; email: j.diaz@isciii.es},
	publisher = {Elsevier B.V.},
	issn = {00489697},
	coden = {STEVA},
	pmid = {29981991},
	language = {English},
	abbrev_source_title = {Sci. Total Environ.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 40}
}

@ARTICLE{Sacks20181464,
	author = {Sacks, Chana A. and Kamalian, Shahmir and Masiakos, Peter T. and Alba, George A. and Patalas, Eva D.},
	title = {Case 31-2018: A 37-year-old man with a self-inflicted gunshot wound},
	year = {2018},
	journal = {New England Journal of Medicine},
	volume = {379},
	number = {15},
	pages = {1464 – 1472},
	doi = {10.1056/NEJMcpc1807500},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054778594&doi=10.1056%2fNEJMcpc1807500&partnerID=40&md5=942b4e9f60ef5fada989f569cb3b925c},
	affiliations = {Massachusetts General Hospital, Departments of Medicine, Harvard Medical School, Boston, United States; Departments of Radiology, Harvard Medical School, Boston, United States; Departments of Surgery, Harvard Medical School, Boston, United States; Departments of Pathology, Harvard Medical School, Boston, United States},
	abstract = {Dr. Jordan P. Bloom (Surgery): A 37-year-old man was admitted to the surgical intensive care unit (ICU) of this hospital because of a self-inflicted gunshot wound. The patient had been in his usual state of health until 2 days before admission. That evening, while he was at home with his family, he reportedly was drinking alcohol and appeared to be upset. He left the room. Shortly after midnight, his wife heard a gunshot. She found the patient slumped forward in a chair in the kitchen, next to his AR-15 semiautomatic rifle, with severe facial injuries. He was conscious and responded appropriately to questions by nodding and shaking his head. The patient's wife called emergency medical services, and the patient was transported to the emergency department of a local hospital, where a tetanus toxoid-containing vaccine, cefazolin, fentanyl, midazolam, intravenous fluids, and a continuous infusion of propofol were administered. A cricothyroidotomy was performed, and mechanical ventilation was initiated. The blood ethanol level was 178 mg per deciliter (reference range, <10). The patient was transferred to a tertiary care center for further treatment. On examination at the second hospital, the temperature was 36.2°C, the pulse 97 beats per minute, the blood pressure 89/73 mm Hg, the respiratory rate 19 breaths per minute, and the oxygen saturation 98% while the patient was receiving full mechanical ventilatory support (fraction of inspired oxygen [Fio2], 1.00). The weight was 109 kg. There were open wounds involving the submandibular soft tissues and the bones and soft tissues of the middle portion of the left side of the face, extending from the upper lip to the nasal radix (Fig. 1). The globe of the right eye was ruptured. On examination of the lungs, breath sounds were absent on the left side. The remainder of the examination was normal. The platelet count and red-cell indexes were normal, as were the results of renal-function tests; other laboratory test results are shown in Table 1. A urine drug screen was presumptively positive for methamphetamine and negative for other drugs of abuse; confirmatory testing was not performed. A chest radiograph showed intubation of the right main bronchus; the endotracheal tube was adjusted, and a repeat image showed the tube to be well positioned. Additional imaging studies were obtained. Copyright © 2018 Massachusetts Medical Society.},
	keywords = {Adult; Advanced Cardiac Life Support; Autopsy; Face; Facial Injuries; Fatal Outcome; Femoral Vein; Firearms; Heart Arrest; Humans; Imaging, Three-Dimensional; Male; Pulmonary Artery; Pulmonary Embolism; Risk Factors; Suicide, Attempted; Tomography, X-Ray Computed; Venous Thrombosis; Wounds, Gunshot; adult; autopsy; case report; clinical observation; clinical study; complication; diagnosis; diagnostic imaging; face; face injury; fatality; femoral vein; firearm; gunshot injury; heart arrest; human; lung embolism; male; pathology; psychology; pulmonary artery; resuscitation; risk factor; suicide attempt; three dimensional imaging; vein thrombosis; x-ray computed tomography},
	publisher = {Massachussetts Medical Society},
	issn = {00284793},
	coden = {NEJMA},
	pmid = {30304661},
	language = {English},
	abbrev_source_title = {New Engl. J. Med.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Mechem2020378,
	author = {Mechem, C. Crawford and Yates, Crystal A. and Rush, Maureen S. and Alleyne, Arturo and Singleton, H. Jay and Boyle, Tabitha L.},
	title = {Deployment of Alternative Response Units in a High-Volume, Urban EMS System},
	year = {2020},
	journal = {Prehospital Emergency Care},
	volume = {24},
	number = {3},
	pages = {378 – 384},
	doi = {10.1080/10903127.2019.1657212},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073831566&doi=10.1080%2f10903127.2019.1657212&partnerID=40&md5=d66a2c7c27588dd9ed994d18c8db3465},
	abstract = {Faced with increasing demand for their services, Emergency Medical Services (EMS) agencies must find more efficient ways to use their limited resources. This includes moving beyond the traditional response and transport model. Alternative Response Units (ARUs) are one way to meet the prehospital medical needs of some members of the public while reducing ambulance transports. They are non-transport vehicles tasked with very specific medical missions. These can include acute management of low-acuity complaints, ongoing home care for chronic medical conditions, preventive medicine, and post-hospital discharge follow-up visits. Their focus can be tailored to the individual needs of the agency. The Philadelphia Fire Department (PFD) operates one of the busiest EMS systems in the country. It has added additional staff and ambulances in recent years yet continues to face an increasing call volume. In an effort to reduce ambulance transports, the PFD recently introduced two ARUs. The first unit, AR-1, is deployed on a university campus and responds to students with low acuity medical complaints or mild alcohol intoxication. It provides many of these a courtesy ride to one of two university emergency departments for further evaluation, eliminating the need for ambulance transport. The second unit, AR-2, works in an area heavily impacted by the opioid crisis. It responds to individuals who have overdosed, been revived with naloxone, and refuse ambulance transport but are interested in long-term treatment for their opioid use disorder. The staff of AR-2 has successfully placed some of these individuals in treatment programs the same day. The AR-1 program is financially supported by the university while AR-2 is funded by the PFD and a federal grant. Both have the potential to decrease ambulance transports or reduce 9-1-1 calls. Whether these or other ARU programs can be financially sustained long-term is unclear. It is also unknown if ARUs represent a better investment than using the money to purchase additional transport vehicles. However, as health care evolves, EMS must innovate and adapt so it can continue to meet the prehospital needs of the public in a timely and cost-effective manner. © 2019, © 2019 National Association of EMS Physicians.},
	author_keywords = {alcohol intoxication; emergency medical services; naloxone; opioid related disorders emergencies},
	keywords = {Ambulances; Emergency Medical Services; Emergency Service, Hospital; Hospitals; Humans; Amberlite XAD-2 resin; ambulance; emergency health service; hospital; hospital emergency service; human},
	correspondence_address = {C.C. Mechem; email: mechemc@uphs.upenn.edu},
	publisher = {Taylor and Francis Ltd},
	issn = {10903127},
	coden = {PEMCF},
	pmid = {31429618},
	language = {English},
	abbrev_source_title = {Prehosp. Emerg. Care},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 10}
}

@CONFERENCE{Wang20171771,
	author = {Wang, Johnson J. H. and Adley, John C.},
	title = {30-2000 MHz multi-band body wearable Antenna (MBWA)},
	year = {2017},
	journal = {2017 IEEE Antennas and Propagation Society International Symposium, Proceedings},
	volume = {2017-January},
	pages = {1771 – 1772},
	doi = {10.1109/APUSNCURSINRSM.2017.8072928},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042275532&doi=10.1109%2fAPUSNCURSINRSM.2017.8072928&partnerID=40&md5=07f45ed229554443aa790255ba60b1d6},
	affiliations = {Electro-Opto Corporation (WEO), Marietta, GA, United States},
	abstract = {A Multi-band Body Wearable Antenna (MBWA) has been designed to cover six communications bands: SINCGARS band (30 MHz-88 MHz), Air & Marine band (116 MHz–174 MHz), UHF band (225 MHz– 450 MHz), UHF-Public Safety band (450 MHz-512 MHz), UHF SATCOM band (225 MHz-318 MHz) and Soldier Radio Waveform (1-2 GHz). The MBWA can also be remoted from the radio and the soldier to enhance communications range in heavily forested or triple canopy jungle environments. A breadboard model has been developed and preliminary tests at WEO had fairly good results, reaching TRL-4. © 2017 IEEE.},
	author_keywords = {Antenna; Broadband antenna; Multi-band antenna; Traveling wave antenna},
	keywords = {Antennas; Marine communication; Microwave antennas; Military communications; Traveling wave antennas; Wearable technology; Breadboard model; Broad-band antenna; Multi band; Multiband antennas; Public safety; UHF band; Wave forms; Wearable antennas},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-153863284-0},
	language = {English},
	abbrev_source_title = {IEEE Antennas Propag. Soc. Int. Symp., Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: 2017 IEEE International Symposium on Antennas and Propagation and USNC-URSI Radio Science Meeting, APSURSI 2017; Conference date: 9 July 2017 through 14 July 2017; Conference code: 131256}
}

@ARTICLE{Wu2020343,
	author = {Wu, Zhi Jun and Liu, Peng Jyun},
	title = {Research on improved design of distance measuring wheel for measuring traffic accidents},
	year = {2020},
	journal = {Advances in Intelligent Systems and Computing},
	volume = {1217 AISC},
	pages = {343 – 355},
	doi = {10.1007/978-3-030-51828-8_45},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088743049&doi=10.1007%2f978-3-030-51828-8_45&partnerID=40&md5=19b9a3e80ffe2791eabd8392da9f9f78},
	affiliations = {Department of Industrial Design, Fujian University of Technology, No 3 Xueyuan Road, University Town, Minhou, Fuzhou City, Fujian Province, China; Department of Creative Product Design, Asia University, 500, Lioufeng Rd., Wufeng, Taichung, 41354, Taiwan; Institute of Applied Arts, National Chiao Tung University, 1001 University Road, Hsinchu, 300, Taiwan},
	abstract = {When a traffic accident occurs, the scene of the accident must be quickly ruled out, The most time it takes for a traffic police to handle a traffic accident is to measure the scene of the accident. The main tool for measuring traffic accidents is distance measuring wheel. The plan takes the distance measuring wheel as the research object, and intends to improve its design through research and investigation to improve the work efficiency and reduce the danger of traffic police. This research is divided into 5 stages including the first stage of observation method, the second stage of user experience interviews, the third stage of Kanano mode and satisfaction factor survey, the fourth stage of the improved design of the ranging wheel, and the fifth stage of product usability. The improved design obtained through research and investigation results is (1) telescopic storage of the measuring wheel and a spherical shaft; (2) the addition of night-time reflectivity and night-time lighting functions; (3) the use of liquid crystal optical ranging; (4) direct upload to the cloud for measurement report. The results of this study can be used as a reference for the design of R & D ranging wheels, and can improve the efficiency, convenience and reduce the danger of traffic police work. © The Editor(s) (if applicable) and The Author(s), under exclusive license to Springer Nature Switzerland AG 2020.},
	author_keywords = {Consumer satisfaction coefficient; Kano model; Measuring wheel; National highway traffic police; Product evaluation},
	keywords = {Accidents; Efficiency; Human engineering; Law enforcement; Liquid crystals; Product design; Surveys; Usability engineering; Wearable technology; Wheels; Distance measuring; Improved designs; Measurement reports; Observation method; Optical ranging; Product usability; Research object; Work efficiency; User experience},
	correspondence_address = {P.J. Liu; Department of Creative Product Design, Asia University, Taichung, 500, Lioufeng Rd., Wufeng, 41354, Taiwan; email: a804338@gmail.com},
	editor = {Ahram T. and Falcão C.},
	publisher = {Springer},
	issn = {21945357},
	isbn = {978-303051827-1},
	language = {English},
	abbrev_source_title = {Adv. Intell. Sys. Comput.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: AHFE Virtual Conference on Usability and User Experience, the Virtual Conference on Human Factors and Assistive Technology,  the Virtual Conference on Human Factors and Wearable Technologies, and the Virtual Conference on Virtual Environments and Game Design, 2020; Conference date: 16 July 2020 through 20 July 2020; Conference code: 241849}
}

@ARTICLE{Wang201895,
	author = {Wang, Shaoqian and Cheung, Sen-Ching S. and Sajid, Hasan},
	title = {Visual Bubble: Protecting Privacy in Wearable Cameras},
	year = {2018},
	journal = {IEEE Consumer Electronics Magazine},
	volume = {7},
	number = {1},
	pages = {95 – 105},
	doi = {10.1109/MCE.2017.2712797},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040095680&doi=10.1109%2fMCE.2017.2712797&partnerID=40&md5=64cb2e38415303c80fd5e43d9d9a0ddb},
	affiliations = {Electrical and Computer Engineering, University of Kentucky, Lexington, KY, United States; Robotics and Artificial Intelligence, NUST, Islamabad, Pakistan},
	abstract = {Wearable cameras are being used more frequently in many different consumer applications, including entertainment, law enforcement, and health care. To protect the privacy of the environment and bystanders, we introduce a new visual privacy paradigm called the visual bubble. In contrast to most existing visual privacy schemes, the visual bubble is based on depth estimation to determine the extent of privacy protection. To demonstrate this concept, we built a wearable privacy stereo-camera system using the Raspberry Pi platform. The effectiveness of our system in protecting privacy was demonstrated with experimental results on multiple data sets. © 2012 IEEE.},
	keywords = {Cameras; Object recognition; Stereo image processing; Consumer applications; Depth Estimation; Multiple data sets; Privacy protection; Stereo camera system; Wearable cameras; Wearable technology},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {21622248},
	language = {English},
	abbrev_source_title = {IEEE Consum. Electron. Mag.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@CONFERENCE{Wei2019,
	author = {Wei, Li and Yongbin, Zhao and Jieping, Han and Zhiru, Zhang and Hai, Yu},
	title = {Face recognition based on joint sparse representation of multiple features for public safety},
	year = {2019},
	journal = {IOP Conference Series: Materials Science and Engineering},
	volume = {563},
	number = {4},
	doi = {10.1088/1757-899X/563/4/042018},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071836254&doi=10.1088%2f1757-899X%2f563%2f4%2f042018&partnerID=40&md5=55be11b0ca131e5f169da9ae050ba8c1},
	affiliations = {State Grid Liaoning Electric Power Supply Co. Ltd, Information and Telecommunication Branch, Shenyang, 110006, China; Northeast Electric Power University, Changchun, 132012, China},
	abstract = {A face recognition method based on joint sparse representation of multiple features is proposed in this paper. First, principle component analysis (PCA), kernel PCA (KPCA), and non-negative matrix factorization (NMF) are used to extract feature vectors of face images. The three features could provide complementary descriptions for face images. Then, in the classification stage, joint sparse representation is employed to classify the three features thus considering their correlations. Finally, the total reconstruction errors of the three features on different kinds of training classes are calculated to determine the label of test sample. Experiments are conducted on AR and Yale-B databases to validate the effectiveness of the proposed method. © 2019 Published under licence by IOP Publishing Ltd.},
	keywords = {Computer programming; Factorization; Matrix algebra; Principal component analysis; Product design; Face recognition methods; Feature vectors; Multiple features; Nonnegative matrix factorization; Principle component analysis; Reconstruction error; Sparse representation; Yale B database; Face recognition},
	publisher = {Institute of Physics Publishing},
	issn = {17578981},
	language = {English},
	abbrev_source_title = {IOP Conf. Ser. Mater. Sci. Eng.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2019 2nd International Conference on Advanced Electronic Materials, Computers and Materials Engineering, AEMCME 2019; Conference date: 19 April 2019 through 21 April 2019; Conference code: 151050; All Open Access, Gold Open Access}
}

@ARTICLE{Alber20203,
	author = {Alber, Florian and Hackett, Sean and Cai, Yang},
	title = {Haptic Helmet for Emergency Responses in Virtual and Live Environments},
	year = {2020},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {12428 LNCS},
	pages = {3 – 11},
	doi = {10.1007/978-3-030-59990-4_1},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092931305&doi=10.1007%2f978-3-030-59990-4_1&partnerID=40&md5=9fa57bcc9c412fddc32b68b0712ff2a0},
	affiliations = {Carnegie Mellon University, 4720 Forbes Avenue, Pittsburgh, 15213, PA, United States},
	abstract = {Communication between team members in emergency situations is critical for first responders to ensure their safety and efficiency. In many cases, the thick smoke and noises in a burning building impair algorithms for navigational guidance. Here we present a helmet-based haptic interface with eccentric motors and communication channels. As part of the NIST PSCR Haptic Interfaces for Public Safety Challenge, our helmet with an embedded haptic interface in the headband enables communication with first responders through haptic signals about direction, measurements, and alerts. The haptic interface can be connected over LoRa for live communication or via USB to VR simulation system. With our affordable, robust, and intuitive system we took victory in the Haptic Challenge after the VR and live trials at a firefighter training facility. © 2020, Springer Nature Switzerland AG.},
	author_keywords = {Augmented reality; Firefighter; First response; Haptic interface; Haptics; Helmet; Hyper-reality; Sensor fusion; Wearable sensors},
	keywords = {Augmented reality; Human computer interaction; Mice (computer peripherals); Safety devices; Smoke; Burning buildings; Emergency response; Emergency situation; First responders; Navigational guidance; Safety and efficiencies; Training facility; VR simulation systems; Haptic interfaces},
	correspondence_address = {F. Alber; Carnegie Mellon University, Pittsburgh, 4720 Forbes Avenue, 15213, United States; email: falber@andrew.cmu.edu},
	editor = {Stephanidis C. and Chen J.Y.C. and Fragomeni G.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303059989-8},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 22nd International Conference on Human-Computer Interaction,HCII 2020; Conference date: 19 July 2020 through 24 July 2020; Conference code: 249799}
}

@CONFERENCE{Choi2019526,
	author = {Choi, Hong-Beom and Lim, Keun-Woo and Ko, Young-Bae},
	title = {Poster: Sensor localization system for AR-assisted disaster relief applications},
	year = {2019},
	journal = {MobiSys 2019 - Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
	pages = {526 – 527},
	doi = {10.1145/3307334.3328607},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069187611&doi=10.1145%2f3307334.3328607&partnerID=40&md5=00506694af8b0184ec16bc2326502653},
	affiliations = {Ajou University, Suwon, South Korea; Telecom Paristech, Paris, France},
	abstract = {In this poster, we propose a sensor localization system assisted by wireless communication and augmented reality (AR) suitable for disaster relief applications. Generally, disaster environments are considered extremely hazardous and deteriorated, with unpredictable effects to human mobility and digital devices. To maximize the safety and efficiency of first responders, deployment of wireless sensors are of utmost importance, as sensor nodes can provide sensing information as well as location information. We analyze the issues and challenges that need to be tackled for high accuracy localization of sensor nodes in such environments, and then propose a system that we plan to develop in the near future. © 2019 Copyright held by the owner/author(s).},
	author_keywords = {Disaster relief; Sensor localization; Visual odometry},
	keywords = {Augmented reality; Digital devices; Disaster prevention; Sensor nodes; Disaster relief; Issues and challenges; Localization of sensor nodes; Location information; Safety and efficiencies; Sensor localization; Visual odometry; Wireless communications; Emergency services},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {978-145036661-8},
	language = {English},
	abbrev_source_title = {MobiSys - Proc. Annu. Int. Conf. Mob. Syst., Appl., Serv.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; Conference name: 17th ACM International Conference on Mobile Systems, Applications, and Services, MobiSys 2019; Conference date: 17 June 2019 through 21 June 2019; Conference code: 148755}
}

@CONFERENCE{Wu2017365,
	author = {Wu, Xiaopei and Dunne, Robert and Yu, Zhifeng and Shi, Weisong},
	title = {STREMS: A Smart Real-Time Solution toward Enhancing EMS Prehospital Quality},
	year = {2017},
	journal = {Proceedings - 2017 IEEE 2nd International Conference on Connected Health: Applications, Systems and Engineering Technologies, CHASE 2017},
	pages = {365 – 372},
	doi = {10.1109/CHASE.2017.120},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029364542&doi=10.1109%2fCHASE.2017.120&partnerID=40&md5=a082e6788e959e7ec0e0d3228b33b9f4},
	affiliations = {Wayne State Uniersity, Detroit, United States; ÓMobihealth Technologies LLC, Detroit Fire Department, Detroit, United States},
	abstract = {Emergency medical service (EMS) systems are public services that provide quick response, transportation as well as appropriate emergency medical care to the emergent patient. For EMS, every second is critical. Unfortunately, current EMS systems have many challenges: Lack effective communication between EMS providers and hospital professionals, less attention on care quality and limited resources of medical equipment and personnel. Motivated by this, in this paper, we explore the use of wearable sensing, smart mobile device as well as video technology to propose STREMS: An efficient smart real-time prehospital communication system for EMS. Specifically, we first introduce a cost-effective wearable physiological sensing solution to support multi-dimensional telemetry monitoring for an ambulance operating at as Basic Life Support, a type of EMS service level without sophisticated medical equipment or paramedics. Then we propose to build a cloud-based real-time data sharing platform, enabling automated streaming all gathered prehospital data (e.g., vital signs, EKG and image/short videos about accident scene) to the hospital prior to ambulance arrival, thus giving a more complete figure about the incoming patient. This can significantly decrease the handoff time and improve the efficiency at the hospital. Additionally, a live point to point video communication is proposed to support EMS telemedicine to enhance prehospital care quality through directly video conversation to assist EMS providers in consultation, triage, early medical examination and treatment. We implemented STREMS as an Android mobile app and evaluated its feasibility over the broadband cellular network in the city of Detroit. In a moving context, our results demonstrate STREMS can successfully deliver 100% of emergency data to the hospital in less than 1.5s, on average 0.75s for reporting a new case and 0.05s for health data. As the live video with 1280×720 pixel resolution, STREMS only works when the vehicle speed is less than 40MPH. © 2017 IEEE.},
	author_keywords = {Emergency Medical Service (EMS); prehospital care quality; real-time prehospital communication; wearable sensing},
	keywords = {Ambulances; Cost effectiveness; Diagnosis; Health; Hospitals; Mobile devices; Wearable technology; Effective communication; Emergency medical care; Emergency medical service systems; Emergency medical services; Physiological sensing; Pre-hospital cares; Real time; Wearable sensing; Emergency services},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-150904721-5},
	language = {English},
	abbrev_source_title = {Proc. - IEEE Int. Conf. Connect. Health: Appl., Syst. Eng. Technol., CHASE},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 18; Conference name: 2nd IEEE International Conference on Connected Health: Applications, Systems and Engineering Technologies, CHASE 2017; Conference date: 17 July 2017 through 19 July 2017; Conference code: 130063}
}

@CONFERENCE{Haque2020,
	author = {Haque, Shaheryar Ehsan I. and Saleem, Shahzad},
	title = {Augmented reality based criminal investigation system (ARCRIME)},
	year = {2020},
	journal = {8th International Symposium on Digital Forensics and Security, ISDFS 2020},
	doi = {10.1109/ISDFS49300.2020.9116204},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087655276&doi=10.1109%2fISDFS49300.2020.9116204&partnerID=40&md5=775fe69f202ac0b18ca4dea6f7a2f048},
	affiliations = {NUST, Department of Software Engineering, School of Electrical Engineering and Computer Science (SEECS), Islamabad, Pakistan; NUST, Department of Information Security, School of Electrical Engineering and Computer Science (SEECS), Islamabad, Pakistan},
	abstract = {Crime scene investigation and preservation are fundamentally the pillars of forensics. Numerous cases have been discussed in this paper where mishandling of evidence or improper investigation leads to lengthy trials and even worse incorrect verdicts. Whether the problem is lack of training of first responders or any other scenario, it is essential for police officers to properly preserve the evidence. Second problem is the criminal profiling where each district department has its own method of storing information about criminals. ARCRIME intends to digitally transform the way police combat crime. It will allow police officers to create a copy of the scene of crime so that it can be presented in courts or in forensics labs. It will be in the form of wearable glasses for officers on site whereas officers during training will be wearing a headset. The trainee officers will be provided with simulations of cases which have already been resolved. Officers on scene would be provided with intelligence about the crime and the suspect they are interviewing. They would be able to create a case file with audio recording and images which can be digitally sent to a prosecution lawyer. This paper also explores the risks involved with ARCRIME and also weighs in their impact and likelihood of happening. Certain contingency plans have been highlighted in the same section as well to respond to emergency situations. © 2020 IEEE.},
	author_keywords = {augmented reality; crime investigation; digital forensics; facial recognition; virtual reality},
	keywords = {Augmented reality; Digital forensics; Electronic crime countermeasures; Case files; Contingency plans; Crime scene investigations; Criminal investigation; Emergency situation; First responders; Police officers; Crime},
	editor = {Varol A. and Karabatak M. and Varol C. and Karabatak S.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-172816939-2},
	language = {English},
	abbrev_source_title = {Int. Symp. Digit. Forensics Secur., ISDFS},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; Conference name: 8th International Symposium on Digital Forensics and Security, ISDFS 2020; Conference date: 1 June 2020 through 2 June 2020; Conference code: 161222}
}

@ARTICLE{Howard II2020205,
	author = {Howard II, James P. and Tucker IV, Arthur O. and Bailey, Stephen A. and Dean, James L. and Boyle, Michael P. and Stiles, Christopher D. and Woodcock, William C.},
	title = {Mixed Reality for Post-Disaster Situational Awareness},
	year = {2020},
	journal = {Johns Hopkins APL Technical Digest (Applied Physics Laboratory)},
	volume = {35},
	number = {3},
	pages = {205 – 215},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117237913&partnerID=40&md5=a6efe877078ba8b8f186fa4c0d342a09},
	affiliations = {Johns Hopkins University, Applied Physics Laboratory, Laurel, MD, United States},
	abstract = {When disaster strikes, what once was, no longer is; and what is, is unrecognizable. The ability to understand the way things were is critical for those working in the response, rescue, and recovery phases of disaster management, from first responders to insurance claims agents. A team at the Johns Hopkins University Applied Physics Laboratory (APL) is developing a system that uses 3-D modeling data and precise positioning data from GPS to display an image of structures "in place" using a mixed reality head-mounted display for first responders in a disaster scenario. The proof of concept revealed significant challenges that need to be solved, and we have already proposed solutions and are working to test them. This technology is designed to assist first responders but will also have applications in other areas that require real-time data presentation, such as battlefield situational awareness. © 2020 John Hopkins University. All rights reserved.},
	keywords = {3D modeling; Disaster prevention; Helmet mounted displays; Insurance; Mixed reality; Disaster management; First responders; Insurance claims; Johns Hopkins University Applied Physics Laboratory; Mixed reality; Modeling data; Post disasters; Precise positioning; Recovery phase; Situational awareness; Disasters},
	publisher = {John Hopkins University},
	issn = {02705214},
	coden = {JHADD},
	language = {English},
	abbrev_source_title = {Johns Hopkins APL Tech Dig},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Bouafif20181,
	author = {Bouafif, Hana and Kamoun, Faouzi and Iqbal, Farkhund and Marrington, Andrew},
	title = {Drone Forensics: Challenges and New Insights},
	year = {2018},
	journal = {2018 9th IFIP International Conference on New Technologies, Mobility and Security, NTMS 2018 - Proceedings},
	volume = {2018-January},
	pages = {1 – 6},
	doi = {10.1109/NTMS.2018.8328747},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051017123&doi=10.1109%2fNTMS.2018.8328747&partnerID=40&md5=01f9b3b75704656d8639c0341e24fa7d},
	affiliations = {ESPRIT School of Engineering, Z.I. Chotrana II. B.P. 160 -2083, El Ghazala, Tunis, Tunisia; Zayed University, College of Technical Innovation, United Arab Emirates},
	abstract = {Powerful information acquisition and processing capabilities, coupled with intelligent surveillance and reconnaissance features, have contributed to increased popularity of Unmanned Aerial Vehicles (UAVs), also known as drones. In addition to the numerous beneficial uses, UAVs have been misused to launch illegal and sometimes criminal activities that pose direct threats to individuals, organizations, public safety and national security. Despite its increased importance, «drone forensics» remains a relatively unexplored research topic. This paper presents important results of a forensic investigation analysis performed on a test Parrot AR drone 2.0. We present new insights into drone forensics in terms of accessing the digital containers of an intercepted drone and retrieving all the information that can help digital forensic investigators establish ownership, recover flight data and acquire content of media files. © 2018 IEEE.},
	author_keywords = {drone; Drone forensics; forensic investigation; smart device; UAV; unmanned aerial vehicle},
	keywords = {Antennas; Crime; Drones; National security; Unmanned aerial vehicles (UAV); Beneficial use; Criminal activities; Forensic investigation; Information acquisitions; Intelligent surveillance; Processing capability; Research topics; Smart devices; Digital forensics},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-153863662-6},
	language = {English},
	abbrev_source_title = {IFIP Int. Conf. New Technol., Mobil. Secur., NTMS - Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 38; Conference name: 9th IFIP International Conference on New Technologies, Mobility and Security, NTMS 2018; Conference date: 26 February 2018 through 28 February 2018; Conference code: 135563}
}

@CONFERENCE{Gong2017420,
	author = {Gong, Liang and Gong, Changyang and Ma, Zhao and Zhao, Lujie and Wang, Zhenyu and Li, Xudong and Jing, Xiaolong and Yang, Haozhe and Liu, Chengliang},
	title = {Real-time human-in-the-loop remote control for a life-size traffic police robot with multiple augmented reality aided display terminals},
	year = {2017},
	journal = {2017 2nd International Conference on Advanced Robotics and Mechatronics, ICARM 2017},
	volume = {2018-January},
	pages = {420 – 425},
	doi = {10.1109/ICARM.2017.8273199},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050633284&doi=10.1109%2fICARM.2017.8273199&partnerID=40&md5=4be26f7f89a3b43c2742aafc662bc818},
	affiliations = {School of Mechanical Engineering, Shanghai Jiao Tong University, Shanghai, 200240, China},
	abstract = {Policing of road traffic is listed in the most hazardous tasks since many traffic police personnel injured in a series of accidents at intersections. A life-size traffic cop robot called 'IWI' is invented as an alternative to human traffic police in the street for directing traffic on point duty, and this paper proposes a human-robot cooperation scheme with wearable augmented glasses as an HMI to obtain a more immersing teleoperation experience with the aid of wearable augmented reality glasses. First, a humanoid robot is tailored for mobile surveillance with raspberry pi camera based eyes and omnidirectional Mecanum wheels. Second, the real-time video stream acquired by the on-site robot is distributed to multiple terminals, such as the central sever, the wearable augmented reality glasses and the mobile control tablet. Third, with a depth of focus estimation the augmented indications are displayed to aid to understand the remote scenario. Finally, the human policing results, such as STOP, PULL OVER, TURN-LEFT, are compiled and programmed as simplified patterns to control the robot body/hand pantomime. Experimental results show that the proposed methodology and control scheme is feasible in real-time application with high real-time performance of less than 0.5s latency, and open possibilities of easing the traffic jam via simultaneously scheduling multiple traffic cop robots. © 2017 IEEE.},
	author_keywords = {augmented reality glasses; human-in-the-loop control; human-robot cooperation; life-size humanoid robot; Traffic police robot; wearable robotics},
	keywords = {Anthropomorphic robots; Augmented reality; Intelligent robots; Jamming; Law enforcement; Remote control; Security systems; Traffic congestion; Augmented reality glass; Human-in-the-loop; Human-in-the-loop control; Human-robot-cooperation; Humanoid robot; Life-size humanoid robot; Real- time; Road traffic; Traffic police robot; Wearable robotics; Glass},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-153863260-4},
	language = {English},
	abbrev_source_title = {Int. Conf. Adv. Rob. Mechatron., ICARM},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 14; Conference name: 2nd International Conference on Advanced Robotics and Mechatronics, ICARM 2017; Conference date: 27 August 2017 through 31 August 2017; Conference code: 134493}
}

@CONFERENCE{Fang201735,
	author = {Fang, Shiwei and Mayer-Patel, Ketan and Nirjon, Shahriar},
	title = {Distributed adaptive model predictive control of a cluster of autonomous and context-sensitive body cameras},
	year = {2017},
	journal = {WearSys 2017 - Proceedings of the 2017 Workshop on Wearable Systems and Applications, co-located with MobiSys 2017},
	pages = {35 – 40},
	doi = {10.1145/3089351.3089358},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025659054&doi=10.1145%2f3089351.3089358&partnerID=40&md5=a6b04d8d18d7594752738ff04d5bfb16},
	affiliations = {Department of Computer Science, University of North Carolina at Chapel Hill, Chapel Hill, NC, United States},
	abstract = {Increasing deployment of body cameras by the law enforcement agencies makes us rethink the relation between the camera and the public. In contrast to current implementations of a body camera that use a power-hungry default configuration and can only be turned on and off by an officer, we propose an idea that the camera should be autonomous and active all the time. By leveraging the information from an on-board inertial measurement unit (IMU), these autonomous cameras should dynamically adjust their configuration in order to keep the device under the desired energy budget. To enable such a system, we propose a distributed adaptive model predictive controller for a system of body cameras, which allows the collaboration between multiple cameras which is currently not available in existing implementations. © 2017 ACM.},
	author_keywords = {Body camera; Context-sensitive; Model predictive control},
	keywords = {Adaptive control systems; Budget control; Cameras; Predictive control systems; Units of measurement; Wearable technology; Adaptive model predictive control; Adaptive model predictive controllers; Context sensitive; Energy budgets; Inertial measurement unit; Law-enforcement agencies; Multiple cameras; Model predictive control},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {978-145034959-8},
	language = {English},
	abbrev_source_title = {WearSys - Proc. Workshop Wearable Syst. Appl., co-located MobiSys},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: 3rd ACM Workshop on Wearable Systems and Applications, WearSys 2017; Conference date: 19 June 2017; Conference code: 128365}
}

@CONFERENCE{Alhassoun2020,
	author = {Alhassoun, Nailah Saleh and Venkatasubramanian, Nalini},
	title = {Cross-Layer Energy Optimization for IoT-Enabled Smart Spaces},
	year = {2020},
	journal = {2020 IEEE International Conference on Pervasive Computing and Communications Workshops, PerCom Workshops 2020},
	doi = {10.1109/PerComWorkshops48775.2020.9156152},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091994874&doi=10.1109%2fPerComWorkshops48775.2020.9156152&partnerID=40&md5=97f37a4c894de70cc9943e2f696f8376},
	affiliations = {University of California, Department of Computer Science, Irvine, United States},
	abstract = {Perpetual IoT systems are essential to many safety and mission-critical applications, e.g. assisted living, healthcare and public safety, which are characterized by continuous monitoring (24/7) and ubiquitous sensing. While IoT-enabled many applications and services, several limitations arise in operating IoT deployments in a resilient manner over time; challenges include the energy cost and constraints. In our research, we aim to handle energy challenges caused by perpetual operations in each level of the system architecture (device, communication, and processing). We use a semantic approach that utilizes context of extracted activities of daily living (ADLs) and indoor space-state (normal, anomaly, and emergency) to drive energy optimized sensor activations. In addition, we are uniquely leveraging features such as: heterogeneity of IoT devices (wearable, ambient, and vision) in terms of: energy cost, energy source (battery-operated and wall-powered IoT devices), processing capability, mobility, communication technologies and transmission protocol (NB-IoT, LTE-M, LoRa, Wi-Fi, 4G/5G, Bluetooth, Zigbee, etc.), processing location (device, edge, could). To validate our approach, we developed an elderly fall detection system using multi-personal and in-situ sensing IoT devices derived from real-world deployments; using our measurements to drive larger simulations. We show that our proposed algorithms such as, Cost-Function-Gradient can achieve greater than 4X reductions in energy dissipation and doubling system-lifetime without loss of sensing accuracy.  © 2020 IEEE.},
	keywords = {Activation energy; Assisted living; Cost functions; Energy dissipation; Semantics; Ubiquitous computing; Wearable technology; Wi-Fi; Activities of daily living (ADLs); Communication technologies; Continuous monitoring; Mission critical applications; Processing capability; Real world deployment; System architectures; Transmission protocols; Internet of things},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-172814716-1},
	language = {English},
	abbrev_source_title = {IEEE Int. Conf. Pervasive Comput. Commun. Workshops, PerCom Workshops},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: 2020 IEEE International Conference on Pervasive Computing and Communications Workshops, PerCom Workshops 2020; Conference date: 23 March 2020 through 27 March 2020; Conference code: 162492}
}

@ARTICLE{Bouafif202035,
	author = {Bouafif, Hana and Kamoun, Faouzi and Iqbal, Farkhund},
	title = {Towards a better understanding of drone forensics: A case study of parrot AR drone 2.0},
	year = {2020},
	journal = {International Journal of Digital Crime and Forensics},
	volume = {12},
	number = {1},
	pages = {35 – 57},
	doi = {10.4018/IJDCF.2020010103},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074487501&doi=10.4018%2fIJDCF.2020010103&partnerID=40&md5=aba15e7f65f4c87a36415e6399262e5e},
	affiliations = {ESPRIT School of Engineering, Tunis, Tunisia; College of Technical Innovation, Zayed University, Abu Dhabi, United Arab Emirates},
	abstract = {Unmanned aerial vehicles (drones) have gained increased popularity as their innovative uses continue to expand across various fields. Despite their numerous beneficial uses, drones have unfortunately been misused, through many reported cases, to launch illegal and sometimes criminal activities that pose direct threats to individuals, organizations, public safety and national security. These threats have recently led law enforcement agencies and digital forensic investigators to pay special attention to the forensic aspects of drones. This important research topic, however, remains underexplored. This study aims to further explore drone forensics in terms of challenges, forensic investigation procedures and experimental results through a forensic investigation study performed on a Parrot AR drone 2.0. In this study, the authors present new insights on drone forensics in terms of forensic approaches, access to drone’s digital containers and the retrieval of key information that can assist digital forensic investigators establish ownership, recuperate flight data and gain access to media files. Copyright © 2020, IGI Global.},
	author_keywords = {Drone; Drone Forensics; Forensic Investigation; UAV; Unmanned Aerial System; Unmanned Aerial Vehicle},
	keywords = {Antennas; Birds; Computer crime; Crime; Drones; Electronic crime countermeasures; Electronic document exchange; National security; Unmanned aerial vehicles (UAV); Beneficial use; Criminal activities; Forensic investigation; Law-enforcement agencies; Media files; Public safety; Research topics; Unmanned aerial systems; Digital forensics},
	publisher = {IGI Global},
	issn = {19416210},
	language = {English},
	abbrev_source_title = {Int J. Digit. Crime Forensics},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8; All Open Access, Bronze Open Access}
}

@ARTICLE{2018,
	title = {4th International Conference on Modelling and Simulation for Autonomous Systems, MESAS 2017},
	year = {2018},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {10756 LNCS},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044042320&partnerID=40&md5=22a758ef72f528cb1ec72d6b1e2bcc72},
	abstract = {The proceedings contain 32 papers. The special focus in this conference is on Modelling and Simulation for Autonomous Systems. The topics include: Design of an indoor autonomous robot navigation system for unknown environments; Fractional order sliding mode control system design for nonlinear MIMO systems with time-varying delay; dynamic modelling of a streamer of hydrophones towed with an autonomous underwater vehicle; qualitative analysis of a robot control based on sub-riemannian distance; Control algorithms for rescue robot RUDA; application of augmented reality in mobile robot teleoperation; accuracy evaluation method of multispectral data fusion for robotic systems; operational scenario modelling supporting unmanned autonomous systems concept development; Modelling and simulation to support the counter drone operations (NMSG-154); autonomous 3D exploration of large areas: A cooperative frontier-based approach; advanced military robots supporting engineer reconnaissance in military operations; Decision support for wide area search in a radiological threat scenario: for intelligent reachback using complex DSS architectures; a verification, validation and accreditation process for autonomous interoperable systems; aspects of the surface-to-air missile systems modelling and simulation; Experiments with the UAS reconnaissance model in the real environment; first responders robotic network for disaster management; aspects of technical requirements for the future autonomy of military vehicles; training with and of autonomous system – modelling and simulation approach; using telemetry for maintenance of special military vehicles; possibilities of modelling and simulation in military engineering; Modelling of a group of social agents monitored by UAVs; discrete event simulation in future military logistics applications and aspects; route optimization for cooperative aerial reconnaissance.},
	editor = {Mazal J.},
	publisher = {Springer Verlag},
	issn = {03029743},
	isbn = {978-331976071-1},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 4th International Conference on Modelling and Simulation for Autonomous Systems, MESAS 2017; Conference date: 24 October 2017 through 26 October 2017; Conference code: 211629}
}

@CONFERENCE{Yi2017,
	author = {Yi, Shanhe and Hao, Zijiang and Zhang, Qingyang and Zhang, Quan and Shi, Weisong and Li, Qun},
	title = {LAVEA: Latency-Aware video analytics on edge computing platform},
	year = {2017},
	journal = {2017 2nd ACM/IEEE Symposium on Edge Computing, SEC 2017},
	doi = {10.1145/3132211.3134459},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039838778&doi=10.1145%2f3132211.3134459&partnerID=40&md5=b80078bb4d8399640173b5529ff55954},
	affiliations = {College of William and Mary, United States; Wayne State University, Anhui University, China},
	abstract = {Along the trend pushing computation from the network core to the edge where the most of data are generated, edge computing has shown its potential in reducing response time, lowering bandwidth usage, improving energy efficiency and so on. At the same time, low-latency video analytics is becoming more and more important for applications in public safety, counter-Terrorism, self-driving cars, VR/AR, etc. As those tasks are either computation intensive or bandwidth hungry, edge computing fits in well here with its ability to .exibly utilize computation and bandwidth from and between each layer. In this paper, we present LAVEA, a system built on top of an edge computing platform, which offloads computation between clients and edge nodes, collaborates nearby edge nodes, to provide low-latency video analytics at places closer to the users. We have utilized an edge-first design and formulated an optimization problem for offloading task selection and prioritized offloading requests received at the edge node to minimize the response time. In case of a saturating workload on the front edge node, we have designed and compared various task placement schemes that are tailed for inter-edge collaboration. We have implemented and evaluated our system. Our results reveal that the client-edge configuration has a speedup ranging from 1.3x to 4x (1.2x to 1.7x) against running in local (client-cloud configuration). The proposed shortest scheduling latency first scheme outputs the best overall task placement performance for inter-edge collaboration. © 2017 ACM.},
	author_keywords = {Computation offloading; Edge computing},
	keywords = {Bandwidth; Energy efficiency; Optimization; Response time (computer systems); Terrorism; Bandwidth usage; Computation intensives; Computation offloading; Counter terrorism; Edge computing; Optimization problems; Placement scheme; Video analytics; Green computing},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {978-145035087-7},
	language = {English},
	abbrev_source_title = {ACM/IEEE Symp. Edge Comput. SEC},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 168; Conference name: 2nd IEEE/ACM Symposium on Edge Computing, SEC 2017; Conference date: 12 October 2017 through 14 October 2017; Conference code: 131835}
}

@CONFERENCE{Cyders2017,
	author = {Cyders, Timothy J. and DiGiovanni, Jeffrey J. and Jay, Wilhelm},
	title = {Characterization of natural and recoil-induced vibration of an ar-15 rifle at the cheekbone-stock interface},
	year = {2017},
	journal = {Proceedings of Meetings on Acoustics},
	volume = {30},
	number = {1},
	doi = {10.1121/2.0000587},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049459033&doi=10.1121%2f2.0000587&partnerID=40&md5=66d3e01226b08db72596b3eadc14fa0e},
	affiliations = {Mechanical Engineering, Ohio University, Athens, 45701, OH, United States; Communication Sciences and Disorders, Ohio University, Athens, 45701, OH, United States},
	abstract = {Effects of sound pressure and shock on hearing loss have been widely studied. Studies involving direct assessment of sound pressure levels and influencing variables related to rifle discharge, especially with respect to standard military small arms have mostly focused on the effects of external pressure on hearing. Other studies have characterized physiological effects of external vibration on animals and humans. Shock phenomena and high-pressure waves have been linked to effects from gradual changes in tissue thickness to traumatic brain injury and other central nervous system maladies. Rifle shooters, including soldiers, law enforcement officers, and hunters, typically shoulder rifle-type firearms in a way that puts the buttstock in direct contact with the cheekbone, known as the”cheek weld.” This work experimentally characterizes the vibrations experienced by the shooter at the cheek/buttstock interface, and discusses expected physiological and acoustical effects as a result of conduction into the skull. © 2017 Acoustical Society of America.},
	keywords = {Acoustics; Audition; Brain; Guns (armament); Central nervous systems; External pressures; External vibrations; Induced vibrations; Law enforcement officers; Physiological effects; Sound pressure level; Traumatic Brain Injuries; High pressure effects},
	publisher = {Acoustical Society of America},
	issn = {1939800X},
	language = {English},
	abbrev_source_title = {Proc. Meet. Acoust.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 173rd Meeting of Acoustical Society of America, Acoustics 2017 and 8th Forum Acusticum; Conference date: 25 June 2017 through 29 June 2017; Conference code: 130560; All Open Access, Bronze Open Access}
}

@ARTICLE{Ćosić2019174873,
	author = {Ćosić, Krešimir and Popović, Siniša and Šarlija, Marko and Mijić, Igor and Kokot, Mirko and Kesedžić, Ivan and Strangman, Gary and Ivković, Vladimir and Zhang, Quan},
	title = {New Tools and Methods in Selection of Air Traffic Controllers Based on Multimodal Psychophysiological Measurements},
	year = {2019},
	journal = {IEEE Access},
	volume = {7},
	pages = {174873 – 174888},
	doi = {10.1109/ACCESS.2019.2957357},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077119843&doi=10.1109%2fACCESS.2019.2957357&partnerID=40&md5=316867170e47ba4c3b4b23e96d76281d},
	affiliations = {Laboratory for Interactive Simulation Systems, Faculty of Electrical Engineering and Computing, University of Zagreb, Zagreb, 10000, Croatia; Department of Psychiatry, Neural Systems Group, Harvard Medical School and Massachusetts General Hospital, Charlestown, 02129, MA, United States},
	abstract = {Comprehensive multimodal psychophysiological measurements and smart data analysis based on wearable and low-cost technologies could enhance traditional air traffic controller (ATC) selection process. Many recent studies in neuro-cognitive science and stress resilience illustrated effectiveness of these multimodal measurements and appropriate metrics in comprehensive assessment of ATCs' mental states, such as cognitive workload, cognitive decline, attention deficit, fatigue, emotional and behavioural problems, etc. Accordingly, this article is focused on innovation efforts in ATC selection protocols based on a set of comprehensive stimuli and corresponding multimodal psychophysiological measurements. The concept of enhancement of ATC selection process presented in this article includes complex physiological, oculometric and speech measurements and appropriate metrics. From these multimodal measurements during specific stimulation tasks, which include different versions of acoustic startle stimuli, airblasts, semantically relevant aversive images and sounds, different versions of Stroop tests, visual tracking test, a complex set of multimodal-multidimensional features is computed as predictors of ATC candidates' future performance, like: stress resilience, workload capacity, attention, visual performance, working memory etc. Such cost-effective, more objective, non-invasive preliminary measurements, lasting no longer than 45 minutes may have good discriminative power and might be used in ATC selection processes as enhancement of current selection procedures. Comprehensive analysis of presented multimodal features during different experimental conditions might also be very useful in selection processes of other stressful professional jobs, like first responders, pilots, astronauts etc. © 2013 IEEE.},
	author_keywords = {ATC selection; attention deficit; cognitive capacity; fatigue; multimodal physiology; performance assessment; resilience assessment; speech and oculometric features},
	keywords = {Air navigation; Air traffic control; Cost benefit analysis; Cost effectiveness; Fatigue of materials; Image enhancement; Manned space flight; Psychophysiology; Wearable technology; ATC selection; Attention deficit; Cognitive capacity; Multi-modal; Performance assessment; resilience assessment; Feature extraction},
	correspondence_address = {S. Popović; Laboratory for Interactive Simulation Systems, Faculty of Electrical Engineering and Computing, University of Zagreb, Zagreb, 10000, Croatia; email: sinisa.popovic@fer.hr},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {21693536},
	language = {English},
	abbrev_source_title = {IEEE Access},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 14; All Open Access, Gold Open Access}
}

@ARTICLE{Taylor2018227,
	author = {Taylor, Glenn and Deschamps, Anthony and Tanaka, Alyssa and Nicholson, Denise and Bruder, Gerd and Welch, Gregory and Guido-Sanz, Francisco},
	title = {Augmented reality for tactical combat casualty care training},
	year = {2018},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {10916 LNAI},
	pages = {227 – 239},
	doi = {10.1007/978-3-319-91467-1_19},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050464143&doi=10.1007%2f978-3-319-91467-1_19&partnerID=40&md5=1561d7ccd85974ad8f6c88e3eaccd03e},
	affiliations = {Soar Technology, Ann Arbor, 48105, MI, United States; University of Central Florida, Orlando, 32816, FL, United States},
	abstract = {Combat Life Savers, Combat Medics, Flight Medics, and Medical Corpsman are the first responders of the battlefield, and their training and skill maintenance is of preeminent importance to the military. While the instructors that train these groups are exceptional, the simulations of battlefield wounds are extremely simple and static, typically consisting of limited moulage with sprayed-on fake blood. These simple presentations often require the imagination of the trainee and the hard work of the instructor to convey a compelling scenario to the trainee. Augmented Reality (AR) tools offer a new and potentially valuable tool for portraying dynamic, high-fidelity visual representation of wounds to a trainee who is still able to see and operate in their real environment. To enhance medical training with more realistic hands-on experiences, we are working to develop the Combat Casualty Care Augmented Reality Intelligent Training System (C3ARESYS). C3ARESYS is our concept for an AR-based training system that aims to provide more realistic multi-sensory depictions of wounds that evolve over time and adapt to the trainee interventions. This paper describes our work to date in identifying requirements for such a training system, current state of the art and limitations in commercial augmented reality tools, and our technical approach in developing a portable training system for medical trainees. © Springer International Publishing AG, part of Springer Nature 2018.},
	author_keywords = {Augmented reality; Medical training; Moulage; Tactical combat casualty care},
	keywords = {Cognitive systems; Augmented reality tools; Intelligent training system; Medical training; Moulage; Real environments; State of the art; Tactical combat casualty care; Visual representations; Augmented reality},
	correspondence_address = {G. Taylor; Soar Technology, Ann Arbor, 48105, United States; email: glenn@soartech.com},
	editor = {Fidopiastis C.M. and Schmorrow D.D.},
	publisher = {Springer Verlag},
	issn = {03029743},
	isbn = {978-331991466-4},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; Conference name: 12th International Conference on Augmented Cognition, AC 2018 Held as Part of HCI International 2018; Conference date: 15 July 2018 through 20 July 2018; Conference code: 216089}
}

@CONFERENCE{Golparvar-Fard2019,
	author = {Golparvar-Fard, M. and Thomas, J. and Peña-Mora, F. and Savarese, S.},
	title = {Remote assessment of pre- And post-disaster critical physical infrastructures using mobile workstation chariot and D4AR models},
	year = {2019},
	journal = {EG-ICE 2010 - 17th International Workshop on Intelligent Computing in Engineering},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083945057&partnerID=40&md5=a5608e430cadd6f4de8d6c8f8f551fe2},
	affiliations = {University of Illinois, Urbana-Champaign, IL, United States; Columbia University, New York, NY, United States; University of Michigan, Ann Arbor, MI, United States},
	abstract = {This paper presents a new technology and a systematic approach for disaster response and recovery of Critical Physical Infrastructures (CPIs). Our suggested approach is based on using a Mobile Workstation Chariot (MWC) assembled on Segway personal transporter which supports both horizontal and vertical real-time visual data capture and transmission flow, first responders and civil engineers can quickly traverse hazardous terrain, collect and transmit photographs/videos, and communicate with the command center in real-time. Using MWC wireless communication tools, first responders and civil engineers can access disaster-survivable black boxes allowing Building Information Models (BIM), pre-disaster photographs and operational information of buildings to be collected and communicated back to the command center. Finally at the command center, using sensed visual data and image-based reconstruction techniques, the post-disaster site is reconstructed in 3D. The resulting integrated representation of the post-disaster model and the collected photographs are superimposed over the pre-disaster BIM to generate a 4D Augmented Reality (D4AR) model. By integrated representation of pre-disaster and post-disaster information, the D4AR allows damages, safety and stability of the CPIs as well as possible rescue operation routings and plans to be assessed. Critical information for disaster response and recovery can be analyzed and communicated back to the field easily and quickly. We present preliminary results of our experiments for collecting, analyzing, and visualizing sensed data using the MWC as well as the D4AR. These results demonstrate a great potential for application of MWC and D4AR for disaster response and recovery operations. The limitation and benefits of this approach plus further required developments are discussed. © 2018 Esprit. All rights reserved.},
	author_keywords = {4D; Augmented reality; Disaster preparedness; Mobile workstation; Response and recovery},
	keywords = {Architectural design; Augmented reality; Critical infrastructures; Damage detection; Disaster prevention; Engineers; Intelligent computing; Photography; Recovery; Vehicles; Building Information Model - BIM; Disaster preparedness; Integrated representations; Mobile workstations; Reconstruction techniques; Rescue operations; Safety and stabilities; Wireless communications; Emergency services},
	editor = {Tizani W.},
	publisher = {Nottingham},
	isbn = {978-190728460-1},
	language = {English},
	abbrev_source_title = {EG-ICE - Int. Workshop Intell. Comput. Eng.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 17th International Workshop on Intelligent Computing in Engineering, EG-ICE 2010; Conference date: 30 June 2010 through 2 July 2010; Conference code: 149385}
}@CONFERENCE{Sannie2015,
	author = {Sannie, G. and Kondrasov, V. and Corre, G. and Boudergui, K. and Perot, B. and Carasco, C. and Montemont, G. and Peerani, P. and Carrapico, C. and Tomanin, A. and Rosas, F. and Caviglia, M. and Eklund, G. and Tagziria, H. and Friedrich, H. and Chmel, S. and De Vita, R. and Manchini, E. and Pavan, M. and Grattarola, M. and Botta, E. and Kovács, A. and Lakosi, L. and Baumhauen, C. and Deheuninck, T. and Haddad, E. and Petrossian, G. and Ferragut, A. and Bellami, J.M. and Dermody, G. and Crossingham, G.},
	title = {Scintilla European project, the successful research results},
	year = {2015},
	journal = {2015 4th International Conference on Advancements in Nuclear Instrumentation Measurement Methods and their Applications, ANIMMA 2015},
	doi = {10.1109/ANIMMA.2015.7465619},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84974578025&doi=10.1109%2fANIMMA.2015.7465619&partnerID=40&md5=8a6db1937eafc67a70396ca50b67ed66},
	affiliations = {Commissariat À l'Énergie Atomique et Aux Énergies Alternatives, Saclay, Cadarache, Grenoble, France; European Commission, Joint Research Centre, ITU, Nuclear Security Unit, Ispra, Italy; Fraunhofer-Institut für Naturwissenschaftlich - Technische Trendanalysen (INT), Euskirchen, Germany; Istituto Nazionale di Fisica Nucleare, Sezione di Genova, Genova, Italy; Ansaldo Nucleare S.P.A, Genova, Italy; Hungarian Academy of Sciences, Centre for Energy Research, Budapest, Hungary; ARTTIC, Paris, France; SAPHYMO, Massy, France; Symetrica Security Ltd, Southampton, United Kingdom},
	abstract = {The Scintilla FP7 project is ended in December 2014, the fruitful results of 3 years development and tests will be presented. SCINTILLA offers the capacity to finding a reliable alternative to Helium-3 based detection systems since the gas which is predominantly used in nuclear safeguards and security applications has now become very expensive, rare and nearly unavailable. SCINTILLA benchmarks results are based on international standards. Radiation Portal tests were carried out at the Joint Research Centre (JRC) in Ispra (Italy). The scintilla project addresses few mains issues. The first is to develop neutron detectors for Radiation Portal Monitor (RPM) and the second is the need of new wearable integrated solutions for Spectrometric Personal Radiation Monitor (SPRM). The partners which provide technical systems of the scintilla project are INFN-ANSALDO, CEA, SYMETRICA and SAPHYMO. For RPM, the objective is to find reliable alternatives to Helium-3 historical neutron detector and provide technical solutions which cope with tests for reliable mobile and cost effective. For Spectrometric Personal Radiation Monitor (SPRM), SCINTILLA is innovating in technology areas that offer complementary capabilities for detecting and identifying gamma Two CZT (Cadmium Zinc Telluride) addressing contexts of used by first responder technologies, one is a wearable detector and the second is a gamma camera complemented by advanced image processing technologies. © 2015 IEEE.},
	author_keywords = {Helium 3; Homeland security; neutrons; Nuclear measurements; Safeguards},
	keywords = {Cadmium alloys; Cadmium telluride; Cost effectiveness; Helium; Image processing; National security; Neutron detectors; Neutrons; Nuclear instrumentation; Nuclear materials safeguards; Radiation detectors; Spectrometry; Wearable technology; Cadmium zinc tellurides; Helium-3; Image processing technology; Integrated solutions; International standards; Nuclear measurement; Radiation portal monitors; Security application; Neutron irradiation},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-147999918-7},
	language = {English},
	abbrev_source_title = {Int. Conf. Adv. Nucl. Instrum. Meas. Methods Appl., ANIMMA},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; Conference name: 4th International Conference on Advancements in Nuclear Instrumentation Measurement Methods and their Applications, ANIMMA 2015; Conference date: 20 April 2015 through 24 April 2015; Conference code: 121554; All Open Access, Green Open Access}
}

@CONFERENCE{Pola2014,
	author = {Pola, Marek and Zaplatílek, Luděk and Lauterbach, Martin and Bezoušek, Pavel and Rolecek, Jiři},
	title = {Application of spectrum analysis methods for accurate transmitter position estimation in complicated environments},
	year = {2014},
	journal = {2014 24th International Conference Radioelektronika, RADIOELEKTRONIKA 2014 - Proceedings},
	doi = {10.1109/Radioelek.2014.6828435},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84903841461&doi=10.1109%2fRadioelek.2014.6828435&partnerID=40&md5=5fae75b67e592856b14c9a0e8cb40918},
	affiliations = {Dept. of Electrical Engineering, Faculty of Electrical Engineering, University Pardubice, Pardubice, Czech Republic},
	abstract = {A new positioning system intended for localization of fire-fighters and members of rescue teams is currently developed at the University of Pardubice. The system is based on TDOA method using a wideband OFDM signal to separate the direct signal of a bundle of delayed replicas, created in a multipath channel. In the paper, the received signal model is introduced and analyzed using selected spectrum analysis methods to estimate the signal delay. Nonparametric methods like a classical periodogram and Capon estimators were compared with the Burg parametric method for AR signals. New results regarding close replicas separation and the delay evaluation accuracy are presented. © 2014 IEEE.},
	author_keywords = {Burg method; Capon; Multipath; OFDM; RTLS; Spectrum analysis},
	keywords = {Orthogonal frequency division multiplexing; Burg methods; Capon; Evaluation accuracy; Multipath; Nonparametric methods; Position estimation; Positioning system; RTLS; Spectrum analysis},
	publisher = {IEEE Computer Society},
	isbn = {978-147993715-8},
	language = {English},
	abbrev_source_title = {Int. Conf. Radioelektronika, RADIOELEKTRONIKA - Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 2014 24th International Conference Radioelektronika, RADIOELEKTRONIKA 2014; Conference date: 15 April 2014 through 16 April 2014; Conference code: 106120}
}

@ARTICLE{Gupta2016498,
	author = {Gupta, Sameer and Boehme, Jacqueline and Manser, Kelly and Dewar, Jannine and Miller, Amie and Siddiqui, Gina and Schwaitzberg, Steven D.},
	title = {Does wearable medical technology with video recording capability add value to on-call surgical evaluations?},
	year = {2016},
	journal = {Surgical Innovation},
	volume = {23},
	number = {5},
	pages = {498 – 504},
	doi = {10.1177/1553350616656278},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84988430443&doi=10.1177%2f1553350616656278&partnerID=40&md5=8b08ddb5c1e7c5fe347f8b7b50b83c22},
	affiliations = {Harvard Medical School, Boston, MA, United States; Department of Surgery, Cambridge Health Alliance, 1493 Cambridge Street, Cambridge, 02139, MA, United States; Perelman School of Medicine, Philadelphia, PA, United States},
	abstract = {Background. Google Glass has been used in a variety of medical settings with promising results. We explored the use and potential value of an asynchronous, near-real time protocol - which avoids transmission issues associated with real-time applications - for recording, uploading, and viewing of high-definition (HD) visual media in the emergency department (ED) to facilitate remote surgical consults. Study Design. First-responder physician assistants captured pertinent aspects of the physical examination and diagnostic imaging using Google Glass' HD video or high-resolution photographs. This visual media were then securely uploaded to the study website. The surgical consultation then proceeded over the phone in the usual fashion and a clinical decision was made. The surgeon then accessed the study website to review the uploaded video. This was followed by a questionnaire regarding how the additional data impacted the consultation. Results. The management plan changed in 24% (11) of cases after surgeons viewed the video. Five of these plans involved decision making regarding operative intervention. Although surgeons were generally confident in their initial management plan, confidence scores increased further in 44% (20) of cases. In addition, we surveyed 276 ED patients on their opinions regarding concerning the practice of health care providers wearing and using recording devices in the ED. The survey results revealed that the majority of patients are amenable to the addition of wearable technology with video functionality to their care. Conclusions. This study demonstrates the potential value of a medically dedicated, hands-free, HD recording device with internet connectivity in facilitating remote surgical consultation. © The Author(s) 2016.},
	author_keywords = {biomedical engineering; Evidence-based medicine/surgery; the business of surgery},
	keywords = {Adult; Attitude of Health Personnel; Biomedical Technology; Clinical Decision-Making; Cohort Studies; Emergency Service, Hospital; Female; Humans; Male; Middle Aged; Monitoring, Physiologic; Quality Control; Remote Consultation; Risk Assessment; Surgical Procedures, Operative; Surveys and Questionnaires; Video Recording; adult; Article; biomedical engineering; conservative treatment; decision making; diagnostic imaging; emergency surgery; female; health care personnel; human; major clinical study; male; medical photography; medical technology; multimedia; physical examination; physician assistant; questionnaire; surgeon; teleconsultation; videorecording; adverse effects; clinical decision making; cohort analysis; comparative study; devices; health personnel attitude; hospital emergency service; medical technology; middle aged; physiologic monitoring; procedures; quality control; questionnaire; risk assessment; surgery; teleconsultation; videorecording},
	correspondence_address = {S.D. Schwaitzberg; Department of Surgery, Cambridge Health Alliance, Cambridge, 1493 Cambridge Street, 02139, United States; email: schwaitz@buffalo.edu},
	publisher = {SAGE Publications Inc.},
	issn = {15533506},
	pmid = {27335083},
	language = {English},
	abbrev_source_title = {Surg. Innov.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 11}
}

@ARTICLE{Bruzzone2016301,
	author = {Bruzzone, Agostino and Longo, Francesco and Massei, Marina and Nicoletti, Letizia and Agresta, Matteo and Di Matteo, Riccardo and Maglione, Giovanni Luca and Murino, Giuseppina and Padovano, Antonio},
	title = {Disasters and emergency management in chemical and industrial plants: Drones simulation for education and training},
	year = {2016},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {9991 LNCS},
	pages = {301 – 308},
	doi = {10.1007/978-3-319-47605-6_25},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84995896920&doi=10.1007%2f978-3-319-47605-6_25&partnerID=40&md5=4e199648f2d33ad7dd13e0d8ee062959},
	affiliations = {DIME, University of Genoa, Via Opera Pia, Genoa, Italy; DIMEG, University of Calabria, Via P. Bucci, 45 C, Rende, 87036, Italy; Cal-Tek, Sr Via Spagna, 240, Santo Stefano, 87036, CS, Italy},
	abstract = {The use of simulation for training is proven to be extremely effective both in term of costs and in term of its flexibility for different uses and applications, such as building situation awareness and creating scenarios for training scopes. The aim of the project proposed is to demonstrate the powerful rule of simulation in UAV pilots’ cooperative training; the project presented makes use of a 3D simulation environment in order to build a realistic condition of an emergency situation in a chemical plant for the first responders. The model proposed makes use of HLA (High Level Architecture) standards in order to be potentially federated with other existing simulators. In the solution proposed, the pilot of the drone must accomplish the mission in a given time piloting a UAV; the scenario is based inside a chemical plant where a disaster is newly occurred. Then ability of the pilot is measured by the system and several constraints are reproduced to provide a realistic training scenario (such as small spaces and barriers to overcome, battery durations, risks of damages due to high temperatures zones, etc.); the system records and tracks all the actions of the pilot and gives a feedback to the user at the end of the simulation time. © Springer International Publishing AG 2016.},
	author_keywords = {3D simulation; Augmented reality; Training and education; UAV},
	keywords = {Augmented reality; Chemicals; Disasters; Drones; Industrial plants; Risk assessment; Risk management; Risk perception; Unmanned aerial vehicles (UAV); 3D simulations; Education and training; Emergency management; Emergency situation; High level architecture; Realistic conditions; Situation awareness; Training and education; Chemical plants},
	correspondence_address = {M. Agresta; DIME, University of Genoa, Genoa, Via Opera Pia, Italy; email: matteo.agresta@simulationteam.com},
	editor = {Hodicky J.},
	publisher = {Springer Verlag},
	issn = {03029743},
	isbn = {978-331947604-9},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 13; Conference name: 3rd International Workshop on Modelling and Simulation for Autonomous Systems, MESAS 2016; Conference date: 15 June 2016 through 16 June 2016; Conference code: 185719; All Open Access, Green Open Access}
}

@ARTICLE{Boffard201548,
	author = {Boffard, Rob},
	title = {Burning issue},
	year = {2015},
	journal = {Engineering and Technology},
	volume = {10},
	number = {7},
	pages = {48 – 51},
	doi = {10.1049/et.2015.0718},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84989283176&doi=10.1049%2fet.2015.0718&partnerID=40&md5=57c314f21de94ba700ef311ca2ff1b34},
	abstract = {Seth Robertson and Viet Tran, electrical engineering students at George Mason University in Virginia developed Wave Extinguisher, which uses sound waves to extinguish a fire. It is a large silver drum speaker, tethered by thick cables to a cluster of black boxes, resembling a piece of DJ equipment. When turned on, and holding it over a fire, flames vanish. The Flamesniffer is further along than the Wave Extinguisher which has 22 sensors. The sensors in each device track temperature, sample the air for smoke and chemicals, and detect flames with heat signatures. If fire is detected, the unit starts sending photographs to the fire station, along with location data. And if the fire reaches the Flamesniffer itself, its flame-resistant polymer can withstand up to 460°C. It is the brainchild of two accountants, Australian Cam McKenna and American Bill Islava. In 2011, Craig Vanderzwaag, a captain in the Santa Barbara County Fire Department, released Response Deck, a free app designed to give first responders an accurate picture of a situation, including location maps and call details. Motorola has developed a system called Next Generation Fireground Communications, which includes a head-up display inside the mask that gives firefighters data on oxygen levels, battery levels and heart rates. Wasp, or Wearable Advanced Sensor Platform, developed by Globe, is a figure-hugging, flame-resistant T-shirt with multiple physiological sensors that transmit data on heart rate, respiration rate, posture and multiple other factors. It comes with a belt-mounted tracking unit, designed to give a picture of where the firefighter is in a 3D space ideal for fighting structural fires.},
	keywords = {Fire extinguishers; Fire fighting equipment; Fires; Heart; Advanced sensors; Electrical engineering students; First responders; George Mason University; Head up displays; Physiological sensors; Respiration rate; Structural fires; Wearable sensors},
	publisher = {Institution of Engineering and Technology},
	issn = {17509637},
	language = {English},
	abbrev_source_title = {Eng. Technol.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6}
}

@CONFERENCE{Kress2014,
	author = {Kress, Bernard},
	title = {See through optical architectures for wearable displays},
	year = {2014},
	journal = {Optics InfoBase Conference Papers},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84906696719&partnerID=40&md5=5327e8fc6a7b19da0b1ecebfaf793095},
	affiliations = {Google, United States},
	abstract = {HUDs (Head Up Displays) and HMDs (Helmet Mounted Displays) have been with us for a few decades, providing exceptional optical performances for specialized defense applications. On the other hand, consumer electronics HMDs (Head Mounted Displays) have been lingering as personal gadgets for a mere decade. But recently, major companies have launched consumer compelling head mounted display solutions integrating both hardware, operating system as well as content, unlocking the decade long consumer HMD status-quo. As a result, we are witnessing today a fragmentation of the HMD market into various categories which have their very own specificity in terms of functionality, hardware and content. Such fragmentation is responsible for defining new distinct market segments such as consumer near to eye displays, social smart glasses, gaming headsets, as well as professional (engineering and technical) HMDs, specialized (medical, law enforcement, firefighting) HMDs and of course the previously existing defense market. We will be reviewing the different type of optical hardware used in such devices. © 2014 OSA.},
	keywords = {Commerce; Consumer electronics; Hardware; Optical design; Sensory perception; Units of measurement; Defense markets; Head mounted displays; Head up displays; Market segment; Near-to-Eye display; Optical architectures; Optical performance; Wearable displays; Helmet mounted displays},
	correspondence_address = {B. Kress; Google, United States; email: bernard.kress@gmail.com},
	publisher = {Optical Society of American (OSA)},
	issn = {21622701},
	isbn = {978-155752308-2},
	language = {English},
	abbrev_source_title = {Opt.InfoBase Conf. Papers},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: Applied Industrial Optics: Spectroscopy, Imaging and Metrology, AIO 2014; Conference date: 13 July 2014 through 17 July 2014; Conference code: 107129}
}

@ARTICLE{Tran2014,
	author = {Tran, Cuc H. and Sugimoto, Jonathan D. and Pulliam, Juliet R. C. and Ryan, Kathleen A. and Myers, Paul D. and Castleman, Joan B. and Doty, Rell and Johnson, Jackie and Stringfellow, Jim and Kovacevich, Nadia and Brew, Joe and Cheung, Lai Ling and Caron, Brad and Lipori, Gloria and Harle, Christopher A. and Alexer, Charles and Yang, Yang and Longini, Ira M. and Halloran, M. Elizabeth and Morris, J. Glenn and Small, Parker A.},
	title = {School-located influenza vaccination reduces community risk for influenza and influenza-like illness emergency care visits},
	year = {2014},
	journal = {PLoS ONE},
	volume = {9},
	number = {12},
	doi = {10.1371/journal.pone.0114479},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84916599387&doi=10.1371%2fjournal.pone.0114479&partnerID=40&md5=f7c70565ba224d20f971f420b0404178},
	affiliations = {Department of Environmental and Global Health, College of Public Health and Health Professions, University of Florida, Gainesville, FL, United States; Emerging Pathogens Institute, University of Florida, Gainesville, FL, United States; Clinical Translational Science Institute, University of Florida, Gainesville, FL, United States; Department of Epidemiology, College of Public Health and Health Professions, University of Florida, Gainesville, FL, United States; Department of Epidemiology, College of Medicine, University of Florida, Gainesville, FL, United States; Vaccine and Infectious Disease Division, Fred Hutchinson Cancer Research Center, Seattle, WA, United States; Department of Biology, College of Liberal Arts and Sciences, University of Florida, Gainesville, FL, United States; Fogarty International Center, National Institutes of Health, Bethesda, MD, United States; Department of Pediatrics, College of Medicine, University of Florida, Gainesville, FL, United States; Florida Department of Health in Alachua County, Gainesville, FL, United States; College of Nursing, University of Florida, Gainesville, FL, United States; College of Pharmacy, University of Florida, Gainesville, FL, United States; Alachua County Public Schools, Gainesville, FL, United States; Partnership for Strong Families, Gainesville, FL, United States; University of Florida Health Integrated Data Repository, UF Health, Gainesville, FL, United States; Department of Health Services Research, College of Public Health and Health Professions, University of Florida, Gainesville, FL, United States; Florida Department of Health, Tallahassee, FL, United States; Department of Biostatistics, College of Public Health and Health Professions, University of Florida, Gainesville, FL, United States; Department of Biostatistics, Colleges of Medicine, University of Florida, Gainesville, FL, United States; Department of Biostatistics, University of Washington, Seattle, WA, United States; Department of Medicine, College of Medicine, University of Florida, Gainesville, FL, United States; Department of Pathology, College of Medicine, University of Florida, Gainesville, FL, United States},
	abstract = {Background: School-located influenza vaccination (SLIV) programs can substantially enhance the sub-optimal coverage achieved under existing delivery strategies. Randomized SLIV trials have shown these programs reduce laboratoryconfirmed influenza among both vaccinated and unvaccinated children. This work explores the effectiveness of a SLIV program in reducing the community risk of influenza and influenza-like illness (ILI) associated emergency care visits.; Methods: For the 2011/12 and 2012/13 influenza seasons, we estimated agegroup specific attack rates (AR) for ILI from routine surveillance and census data. Age-group specific SLIV program effectiveness was estimated as one minus the AR ratio for Alachua County versus two comparison regions: the 12 county region surrounding Alachua County, and all non-Alachua counties in Florida.; Results: Vaccination of , 50% of 5-17 year-olds in Alachua reduced their risk of ILI-associated visits, compared to the rest of Florida, by 79% (95% confidence interval: 70, 85) in 2011/12 and 71% (63, 77) in 2012/13. The greatest indirect effectiveness was observed among 0-4 year-olds, reducing AR by 89% (84, 93) in 2011/12 and 84% (79, 88) in 2012/13. Among all non-school age residents, the estimated indirect effectiveness was 60% (54, 65) and 36% (31, 41) for 2011/12 and 2012/13. The overall effectiveness among all age-groups was 65% (61, 70) and 46% (42, 50) for 2011/12 and 2012/13.; Conclusion: Wider implementation of SLIV programs can significantly reduce the influenza-associated public health burden in communities. ©2014 Tran et al.},
	keywords = {Adolescent; Ambulatory Care Facilities; Child; Child, Preschool; Emergency Medical Services; Emergency Service, Hospital; Female; Florida; Humans; Immunization Programs; Influenza, Human; Male; Residence Characteristics; Risk; Schools; Vaccination; influenza vaccine; adolescent; Article; child; community care; controlled study; drug efficacy; emergency care; groups by age; health program; human; infant; influenza; influenza vaccination; major clinical study; preschool child; public health; risk reduction; school child; school located influenza vaccination; United States; demography; emergency health service; female; Influenza, Human; male; outpatient department; preventive health service; procedures; risk; school; statistics and numerical data; vaccination},
	publisher = {Public Library of Science},
	issn = {19326203},
	coden = {POLNC},
	pmid = {25489850},
	language = {English},
	abbrev_source_title = {PLoS ONE},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 22; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Sajid2015,
	author = {Sajid, Hasan and Cheung, Sen-Ching S.},
	title = {VSig: Hand-gestured signature recognition and authentication with wearable camera},
	year = {2015},
	journal = {2015 IEEE International Workshop on Information Forensics and Security, WIFS 2015 - Proceedings},
	doi = {10.1109/WIFS.2015.7368566},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964746606&doi=10.1109%2fWIFS.2015.7368566&partnerID=40&md5=801f053e1d45d089b561991483048401},
	affiliations = {Department of Electrical and Computer Engineering, University of Kentucky, KY, United States},
	abstract = {Wearable camera is gaining popularity not only as a recording device for law enforcement and hobbyists, but also as a human-computer interface for the next generation wearable technology. It provides a more convenient and portable platform for gesture input than stationary camera, but poses unique challenges due to user movement and scene variation. In this paper, we describe a robust wearable camera based system called VSig for hand-gestured signature recognition and authentication. The proposed method asks the user to virtually sign within the field of the view of the wearable camera. Fingertip is segmented out and tracked to reconstruct the signature. This is followed by signature matching for authentication with the pre-stored signatures of the individual. A dataset named SIGAIR comprising of hand-gestured signatures from 10 individuals has been created and used for testing. An average accuracy of 97.5% is achieved by the proposed method. © 2015 IEEE.},
	author_keywords = {hand gesture recognition; signature authentication; visual segmentation and tracking; wearable cameras},
	keywords = {Authentication; Cameras; Gesture recognition; Human computer interaction; Network security; Palmprint recognition; Statistical tests; Hand-gesture recognition; Human computer interfaces; Signature authentication; Signature recognition; Signature-matching; Stationary cameras; Visual segmentation; Wearable cameras; Wearable technology},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-146736802-5},
	language = {English},
	abbrev_source_title = {IEEE Int. Workshop Inf. Forensics Secur., WIFS - Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 17; Conference name: IEEE International Workshop on Information Forensics and Security, WIFS 2015; Conference date: 16 November 2015 through 19 November 2015; Conference code: 118936}
}

@CONFERENCE{Ometov2016,
	author = {Ometov, Aleksandr and Masek, Pavel and Malina, Lukas and Florea, Roman and Hosek, Jiri and Andreev, Sergey and Hajny, Jan and Niutanen, Jussi and Koucheryavy, Yevgeni},
	title = {Feasibility characterization of cryptographic primitives for constrained (wearable) IoT devices},
	year = {2016},
	journal = {2016 IEEE International Conference on Pervasive Computing and Communication Workshops, PerCom Workshops 2016},
	doi = {10.1109/PERCOMW.2016.7457161},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84966546696&doi=10.1109%2fPERCOMW.2016.7457161&partnerID=40&md5=93a799cb9a2dfdd5e90af38ae813fc57},
	affiliations = {Tampere University of Technology, Korkeakoulunkatu 10, Tampere, FIN-33720, Finland; Brno University of Technology, Technicka 3082/12, Brno, Czech Republic; Intel Finland, Insinoorinkatu 7, Tampere, FIN-33720, Finland},
	abstract = {The Internet of Things (IoT) employs smart devices as its building blocks for developing a ubiquitous communication framework. It thus supports a wide variety of application domains, including public safety, healthcare, education, and public transportation. While offering a novel communication paradigm, IoT finds its requirements closely connected to the security issues. The role of security following the fact that a new type of devices known as wearables constitute an emerging area. This paper delivers an applicability study of the state-of-the-art cryptographic primitives for wearable IoT devices, including the pairing-based cryptography. Pairing-based schemes are well-recognized as fundamental enablers for many advanced cryptographic applications, such as privacy protection and identity-based encryption. To deliver a comprehensive view on the computational power of modern wearable devices (smart phones, watches, and embedded devices), we perform an evaluation of a variety of them utilizing bilinear pairing for real-time communication. In order to deliver a complete picture, the obtained bilinear pairing results are complemented with performance figures for classical cryptography (such as block ciphers, digital signatures, and hash functions). Our findings show that wearable devices of today have the needed potential to efficiently operate with cryptographic primitives in real time. Therefore, we believe that the data provided during this research would shed light on what devices are more suitable for certain cryptographic operations. © 2016 IEEE.},
	author_keywords = {Bilinear Pairing; Cryptography; Group Signatures; IoT; Performance evaluation; Wearables},
	keywords = {Cryptography; Hash functions; Network security; Public key cryptography; Smartphones; Ubiquitous computing; Wearable technology; Bilinear pairing; Cryptographic applications; Cryptographic primitives; Group signatures; Identity Based Encryption; Pairing-based cryptography; Performance evaluation; Wearables; Internet of things},
	correspondence_address = {A. Ometov; Tampere University of Technology, Tampere, Korkeakoulunkatu 10, FIN-33720, Finland; email: aleksandr.ometov@tut.fi},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-150901941-0},
	language = {English},
	abbrev_source_title = {IEEE Int. Conf. Pervasive Comput. Commun. Workshops, PerCom Workshops},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 62; Conference name: 13th IEEE International Conference on Pervasive Computing and Communication Workshops, PerCom Workshops 2016; Conference date: 14 March 2016 through 18 March 2016; Conference code: 121284}
}

@CONFERENCE{Johnson2009,
	author = {Johnson, Mark and Melton, Gene},
	title = {Life support breathing system for: "SubPack" - Rebreather system},
	year = {2009},
	journal = {MTS/IEEE Biloxi - Marine Technology for Our Future: Global and Local Challenges, OCEANS 2009},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-77951584178&partnerID=40&md5=6b403b47ba0c8962fe0f87d60ebb904b},
	affiliations = {O2 Dive Technologies Inc., United States; HydroSpace Engineering Inc., Greece},
	abstract = {In response to requirements by OceanWorks International, a Rescue Rebreather, called "SubPack" was designed and built by O2 Dive Technologies of TX, under contract for the REMORA rescue submarine for the Australian Navy. Operational requirements sometimes required entering or transiting an area, which may be contaminated with toxic industrial chemicals, fire by-products or chemical or biological agents. Depending on the situation, it may not be acceptable or operationally suitable for the personnel to use 'open loop' or negative pressure filtered respirators due to the nature of the contaminant or even its physical state (e.g. super heated air). In these situations a closed circuit breathing system is required. SubPack Rebreather, is capable of 180 minutes of life support, is ergonomically small, lightweight (weighing less then 20 lbs.), rapidly donnable, low cost, and interface with existing full-face masks with standard NATO interfaces. Additionally, it is to be easy to maintain, and have a short training period for first responders. Besides these fundamental requirements, OceanWorks provided valuable meetings that their various needs were also incorporated into the design. SubPack is a closed circuit rebreather unit and is expected to go on for NIOSH testing and approval. Its many design features allow it to be adapted for all capabilities including meeting NFPA requirements of passive alarm and heads up display. A second unit was designed and built to meet Long duration, high exertion, and environment. Originally, designed for search and rescue for miners, the Miners Rescue ReBreather System has a low breathing resistance, no aftermarket requirements for gas cooling and has six hour duration. Further adaptations will include and other rigorous environments and applications. This device will be of commercial interest to DOD/SOCOM, FBI, and USSS, other federal, state and local Law Enforcement Agencies, fire fighters, urban and rural rescue teams and industrial First Responders. The SubPack unit, and all components herein are prototype proprietary O2 Dive Technologies Inc. ©2009 MTS.},
	keywords = {Agents; Indicators (chemical); Marine engineering; Miners; Oceanography; Technology; Australian Navy; Biological agents; Closed circuit; Closed circuit breathing systems; Design features; Face masks; Fire fighters; First responders; Gas cooling; Heads-up display; Heated air; Law-enforcement agencies; Life supports; Long duration; Low costs; Negative pressures; Open loops; Operational requirements; Physical state; Rescue submarines; Search and rescue; Toxic industrial chemical; Industrial chemicals},
	isbn = {978-142444960-6},
	language = {English},
	abbrev_source_title = {MTS/IEEE Biloxi - Mar. Technol. Future: Global Local Chall., OCEANS},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: MTS/IEEE Biloxi - Marine Technology for Our Future: Global and Local Challenges, OCEANS 2009; Conference date: 26 October 2009 through 29 October 2009; Conference code: 80013}
}

@ARTICLE{Sousa201265,
	author = {Sousa, Raquel and Alves, Marco and Gonçalves, Gil},
	title = {Health care management with KeepCare},
	year = {2012},
	journal = {Studies in Health Technology and Informatics},
	volume = {177},
	pages = {65 – 70},
	doi = {10.3233/978-1-61499-069-7-65},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84866757735&doi=10.3233%2f978-1-61499-069-7-65&partnerID=40&md5=96a1f1c81660769725ad741beefa257f},
	affiliations = {IncreaseTime, 4450-007 Matosinhos, Rua Dr. Afonso Cordeiro, 877 - 204, Portugal; FreedomGrow, Matosinhos, Portugal; Inovamais, Matosinhos, Portugal; Dept. of Inf. Eng., School of Engineering, Porto University (FEUP), Porto, Portugal},
	abstract = {Wireless sensing is part of our lives; major technological breakthroughs in the areas of sensors, integrated circuits, and also on wireless communications, led to the creation of wireless sensor networks (WSNs). Such networks have multiple uses, from monitoring and tracking of people and goods, to the coordination and processing of activities in different contexts; they are used in industry, defence and healthcare applications. As part of this use in healthcare applications KeepCare, a solution based on monitoring, tracking and processing of healthcare related information, is presented in this paper. This solution uses a WSN based application to monitor peoples' health and quality of life through vital signs and activity information received via wireless sensors. This solution monitors users such as elderly, people suffering from chronic conditions in their home environment, but can as well be used in athletes or other professionals (e.g. first responders) that need to be monitored under hazardous conditions. © 2012 The authors and IOS Press. All rights reserved.},
	author_keywords = {Healthcare and quality of life; Monitoring vital signs; Wireless sensor networks},
	keywords = {Delivery of Health Care; Home Care Services; Individualized Medicine; Medical Informatics; Monitoring, Ambulatory; Systems Integration; Telemedicine; Health care; Nanosensors; Nanotechnology; Wearable technology; Wireless telecommunication systems; Health care application; Health-care managements; Monitoring and tracking; Quality of life; Technological breakthroughs; Vital sign; Wireless communications; Wireless sensor network (WSNs); ambulatory monitoring; article; health care delivery; home care; medical informatics; methodology; organization and management; personalized medicine; system analysis; telemedicine; Wireless sensor networks},
	correspondence_address = {R. Sousa; IncreaseTime, 4450-007 Matosinhos, Rua Dr. Afonso Cordeiro, 877 - 204, Portugal; email: raquel.sousa@itime.pt},
	publisher = {IOS Press},
	issn = {09269630},
	isbn = {978-161499068-0},
	pmid = {22942032},
	language = {English},
	abbrev_source_title = {Stud. Health Technol. Informatics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: 9th International Conference on Wearable Micro and Nano Technologies for Personalized Health, pHealth 2012; Conference date: 26 June 2012 through 28 June 2012; Conference code: null}
}

@CONFERENCE{Mentler2016,
	author = {Mentler, Tilo and Berndt, Henrik and Herczeg, Michael},
	title = {Optical head-mounted displays for medical professionals: Cognition-supporting human-computer interaction design},
	year = {2016},
	journal = {ACM International Conference Proceeding Series},
	volume = {06-08-September-2016},
	doi = {10.1145/2970930.2970957},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84990041376&doi=10.1145%2f2970930.2970957&partnerID=40&md5=451f86e09c1be38c82abdbff93cbe3b5},
	affiliations = {University of Luebeck, Ratzeburger Allee 160, Luebeck, D-23562, Germany},
	abstract = {Optical head-mounted displays are an emerging digital technology in domains like healthcare where computer usage in mobile contexts is required but hand-held devices are not particularly suited for practical reasons (e.g. hygienic regulations). As the work of paramedics, nurses and physicians is not only physically but also mentally challenging, the promise of hands-free interaction alone will not ensure efficient and safe usage. Rather, various aspects of cognitive ergonomics have to be carefully considered. Best practices for designing wearable interactive systems have to be evaluated. Based on the results of different user-centered system design projects and studies with members of Emergency Medical Services, nurses and clinical physicians, we will discuss optical head-mounted displays with respect to human-computer interaction. Interaction design as well as lessons learned concerning tasks and workflows will be summarized. Transmodal consistency is introduced as a general design principle for digital technologies supporting multiple input and output modalities like touch, gestures and speech. © 2016 ACM.},
	author_keywords = {Google Glass; Interaction Design; Interface Design; Optical Head-Mounted Displays; Usability},
	keywords = {Digital devices; Emergency services; Ergonomics; Helmet mounted displays; Medical computing; Nursing; User centered design; Emergency medical services; Hands-free interactions; Human computer interaction design; Interaction design; Interface designs; Optical heads; Usability; User-centered systems; Human computer interaction},
	publisher = {Association for Computing Machinery},
	isbn = {978-145034244-5},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; Conference name: 34th European Conference on Cognitive Ergonomics, ECCE 2016; Conference date: 6 September 2016 through 8 September 2016; Conference code: 123836}
}

@CONFERENCE{Boddhu2013,
	author = {Boddhu, Sanjay K. and Dave, Rakesh P. and McCartney, Matt and West, James A. and Williams, Robert L.},
	title = {Context-aware event detection smartphone application for first responders},
	year = {2013},
	journal = {Proceedings of SPIE - The International Society for Optical Engineering},
	volume = {8742},
	doi = {10.1117/12.2016352},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84884140127&doi=10.1117%2f12.2016352&partnerID=40&md5=abe198c1de0ef639e21c8819964b4e82},
	affiliations = {Qbase, United States; Wright State University, United States; Tec-Edge Innovation and Collaboration Ctr., United States; Air Force Research Lab, United States},
	abstract = {The rise of social networking platforms like Twitter, Facebook, etc-, have provided seamless sharing of information (as chat, video and other media) among its user community on a global scale. Further, the proliferation of the smartphones and their connectivity networks has powered the ordinary individuals to share and acquire information regarding the events happening in his/her immediate vicinity in a real-time fashion. This human-centric sensed data being generated in human-as-sensor approach is tremendously valuable as it delivered mostly with apt annotations and ground truth that would be missing in traditional machine-centric sensors, besides high redundancy factor (same data thru multiple users). Further, when appropriately employed this real-time data can support in detecting localized events like fire, accidents, shooting, etc-, as they unfold and pin-point individuals being affected by those events. This spatiotemporal information, when made available for first responders in the event vicinity (or approaching it) can greatly assist them to make effective decisions to protect property and life in a timely fashion. In this vein, under SATE and YATE programs, the research team at AFRL Tec^Edge Discovery labs had demonstrated the feasibility of developing Smartphone applications, that can provide a augmented reality view of the appropriate detected events in a given geographical location (localized) and also provide an event search capability over a large geographic extent. In its current state, the application thru its backend connectivity utilizes a data (Text and Image) processing framework, which deals with data challenges like; identifying and aggregating important events, analyzing and correlating the events temporally and spatially and building a search enabled event database. Further, the smartphone application with its backend data processing workflow has been successfully field tested with live user generated feeds. © 2013 SPIE.},
	author_keywords = {collaborative cloud architecture; event clustering; Geotag extraction; MongoDB; NLP; real-time event detection; situational awareness; smartphones},
	keywords = {Augmented reality; Data processing; Distributed computer systems; Interoperability; Sensors; Smartphones; Social networking (online); Cloud architectures; Event clustering; Event detection; Geo-tags; MongoDB; NLP; Situational awareness; Applications},
	issn = {1996756X},
	isbn = {978-081949533-4},
	coden = {PSISD},
	language = {English},
	abbrev_source_title = {Proc SPIE Int Soc Opt Eng},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 12; Conference name: Ground/Air Multisensor Interoperability, Integration, and Networking for Persistent ISR IV; Conference date: 29 April 2013 through 2 May 2013; Conference code: 99204}
}

@ARTICLE{Sankaralingam201053,
	author = {Sankaralingam, S. and Gupta, B.},
	title = {Development of textile antennas for body wearable applications and investigations on their performance under bent conditions},
	year = {2010},
	journal = {Progress In Electromagnetics Research B},
	number = {22},
	pages = {53 – 71},
	doi = {10.2528/PIERB10032705},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-77955504626&doi=10.2528%2fPIERB10032705&partnerID=40&md5=094248fe7ba98624f43c7ed1e61dfbd9},
	affiliations = {Department of Electronics and Tele-Communication Engineering, Jadavpur University, Kolkata 700 032, India},
	abstract = {Utilization of wearable textile materials for the development of microstrip antenna segment has been rapid due to the recent miniaturization of wireless devices. A wearable antenna is meant to be a part of the clothing used for communication purposes, which includes tracking and navigation, mobile computing and public safety. This paper describes design and development of four rectangular patch antennas employing different varieties of cotton and polyester clothing for on-body wireless communications in the 2.45 GHz WLAN band. The impedance and radiation characteristics are determined experimentally when the antennas are kept in flat position. The performance deterioration of a wearable antenna is analyzed under bent conditions too to check compatibility with wearable applications. Results demonstrate the suitability of these patch antennas for on-body wireless communications.},
	keywords = {Directional patterns (antenna); Microstrip antennas; Microwave antennas; Slot antennas; Textiles; Wearable technology; Wireless telecommunication systems; Design and Development; Performance deterioration; Radiation characteristics; Rectangular patch antenna; Textile materials; Wearable applications; Wireless communications; Wireless devices; Wearable antennas},
	correspondence_address = {S. Sankaralingam; Department of Electronics and Tele-Communication Engineering, Jadavpur University, Kolkata 700 032, India; email: slingam.nec@gmail.com},
	publisher = {Electromagnetics Academy},
	issn = {19376472},
	language = {English},
	abbrev_source_title = {Prog. Electromagn. Res. B},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 148; All Open Access, Bronze Open Access}
}

@CONFERENCE{Haeuslschmid20165076,
	author = {Haeuslschmid, Renate and Pfleging, Bastian and Alt, Florian},
	title = {A design space to support the development of windshield applications for the car},
	year = {2016},
	journal = {Conference on Human Factors in Computing Systems - Proceedings},
	pages = {5076 – 5091},
	doi = {10.1145/2858036.2858336},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011990959&doi=10.1145%2f2858036.2858336&partnerID=40&md5=7ac1dc4f0a0729c5e5201d7835e24dab},
	affiliations = {University of Munich (LMU), Munich, Germany},
	abstract = {In this paper we present a design space for interactive windshield displays in vehicles and discuss how this design space can support designers in creating windshield applications for drivers, passengers, and pedestrians. Our work is motivated by numerous examples in other HCI-related areas where seminal design space papers served as a valuable basis to evolve the respective field - most notably mobile devices, automotive user interfaces, and interactive public displays. The presented design space is based on a comprehensive literature review. Furthermore we present a classification of 211 windshield applications, derived from a survey of research projects and commercial products as well as from focus groups. We showcase the utility of our work for designers of windshield applications through two scenarios. Overall, our design space can help building applications for diverse use cases. This includes apps inside and outside the car as well as applications for specific domains such as fire fighters, police, ambulance.},
	author_keywords = {Automotive interfaces; Design space; Head-up display; In-vehicle interfaces; Windshield display},
	keywords = {Display devices; Human computer interaction; Human engineering; User interfaces; Windshields; Building applications; Commercial products; Design spaces; Head up displays; Interactive public displays; Literature reviews; Vehicle interface; Windshield displays; Fighter aircraft},
	publisher = {Association for Computing Machinery},
	isbn = {978-145033362-7},
	language = {English},
	abbrev_source_title = {Conf Hum Fact Comput Syst Proc},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 69; Conference name: 34th Annual Conference on Human Factors in Computing Systems, CHI 2016; Conference date: 7 May 2016 through 12 May 2016; Conference code: 121621}
}

@ARTICLE{Cortez2017175,
	author = {Cortez, Eric J. and Panchal, Ashish R. and Davis, James E. and Keseg, David P.},
	title = {The Effect of Ambulance Staffing Models in a Metropolitan, Fire-Based EMS System},
	year = {2017},
	journal = {Prehospital and Disaster Medicine},
	volume = {32},
	number = {2},
	pages = {175 – 179},
	doi = {10.1017/S1049023X16001539},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85009745503&doi=10.1017%2fS1049023X16001539&partnerID=40&md5=57f2ba439c29e7a421861b06e3b4cde0},
	affiliations = {City of Columbus, Division of Fire, 3639 South Parsons Ave, Columbus, 43207, OH, United States; Ohio Health Doctors Hospital, Columbus, OH, United States; Center for EMS, Department of Emergency Medicine, Ohio State University Wexner Medical Center, Columbus, OH, United States},
	abstract = {Introduction The staffing of ambulances with different levels of Emergency Medical Service (EMS) providers is a difficult decision with evidence being mixed on the benefit of each model. Hypothesis/Problem The objective of this study was to describe a pilot program evaluating alternative staffing on two ambulances utilizing the paramedic-basic (PB) model (staffed with one paramedic and one emergency medical technician[EMT]). Methods This was a retrospective study conducted from September 17, 2013 through December 31, 2013. The PB ambulances were compared to geographically matched ambulances staffed with paramedic-paramedic (PP ambulances). One PP and one PB ambulance were based at Station A; one PP and one PB ambulance were based at Station B. The primary outcome was total on-scene time. Secondary outcomes included time-to-electrocardiogram (EKG), time-to-intravenous (IV) line insertion, IV-line success rate, and percentage of protocol violations. Inclusion criteria were all patients requesting prehospital services that were attended to by these teams. Patients were excluded if they were not attended to by the study ambulance vehicles. Descriptive statistics were reported as medians and interquartile ranges (IQR). Proportions were reported with 95% confidence intervals (CI). The Mann-Whitley U test was used for significance testing (P<.05). Results Median on-scene times at Station A for the PP ambulance were shorter than the PB ambulance team (PP: 10.1 minutes, IQR 6.0-15; PB: 13.0 minutes, IQR 8.1-18; P=.01). This finding also was noted at Station B (PP: 13.5 minutes, IQR 8.5-19; PB: 14.3 minutes, IQR 9.9-20; P=.01). There were no differences between PP and PB ambulance teams at Station A or Station B in time-to-EKG, time-to-IV insertion, IV success rate, and protocol violation rates. Conclusion In the setting of a well-developed EMS system utilizing an all-Advanced Life Support (ALS) response, this study suggests that PB ambulance teams may function well when compared to PP ambulances. Though longer scene times were observed, differences in time to ALS interventions and protocol violation rates were not different. Hybrid ambulance teams may be an effective staffing alternative, but decisions to use this model must address clinical and operational concerns. Cortez EJ, Panchal AR, Davis JE, Keseg DP. © 2017 World Association for Disaster and Emergency Medicine.},
	author_keywords = {ambulance; Emergency Medical Service; emergency medical technician},
	keywords = {Adult; Ambulances; Efficiency, Organizational; Emergency Medical Services; Female; Humans; Male; Middle Aged; Ohio; Retrospective Studies; ambulance; confidence interval; disaster; electrocardiogram; emergency health service; human; model; retrospective study; statistics; adult; ambulance; comparative study; emergency health service; female; male; manpower; middle aged; Ohio; organization and management},
	correspondence_address = {E.J. Cortez; City of Columbus, Division of Fire, Columbus, 3639 South Parsons Ave, 43207, United States; email: ejcortez@columbus.gov},
	publisher = {Cambridge University Press},
	issn = {1049023X},
	pmid = {28095934},
	language = {English},
	abbrev_source_title = {Prehospital Disaster Med.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@CONFERENCE{Shaoqian2016,
	author = {Shaoqian, Wang and Cheung, Sen-Ching S. and Luo, Ying},
	title = {Wearable privacy protection with visual bubble},
	year = {2016},
	journal = {2016 IEEE International Conference on Multimedia and Expo Workshop, ICMEW 2016},
	doi = {10.1109/ICMEW.2016.7574712},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992047707&doi=10.1109%2fICMEW.2016.7574712&partnerID=40&md5=aff1ee9cb4fc6f1922c20d30c8463569},
	affiliations = {Department of Electrical and Computer Engineering, University of Kentucky, Lexington, 40506, United States},
	abstract = {Wearable cameras are increasingly used in many different applications from law enforcement to medicine. In this paper1, we consider an application of using a wearable camera to record one-on-one therapy with a child in a classroom or clinic. To protect the privacy of other individuals in the same environment, we introduce a new visual privacy paradigm called privacy bubble. Privacy bubble is a virtual zone centered around the camera for observation whereas the rest of the environment and people are obfuscated. In contrast to most existing visual privacy systems that rely on visual classifier, privacy bubble is based on depth estimation to determine the extent of privacy protection. To demonstrate this concept, we construct a wearable stereo-camera for depth estimation on the Raspberry Pi platform. We also propose a novel framework to quantify the uncertainty in depth measurements so as to minimize a statistical privacy risk in constructing the depth-based privacy bubble. The effectiveness of the proposed scheme is demonstrated with preliminary experimental results. © 2016 IEEE.},
	author_keywords = {Depth uncertainty; Privacy bubble; Privacy protection; Stereo quantization; Wearable camera},
	keywords = {Cameras; Stereo image processing; Uncertainty analysis; Depth Estimation; Depth measurements; Depth uncertainty; Privacy protection; Privacy systems; Statistical privacy; Stereo quantization; Wearable cameras; Wearable technology},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-150901552-8},
	language = {English},
	abbrev_source_title = {IEEE Int. Conf. Multimed. Expo Workshop, ICMEW},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; Conference name: 2016 IEEE International Conference on Multimedia and Expo Workshop, ICMEW 2016; Conference date: 11 July 2016 through 15 July 2016; Conference code: 123953}
}

@ARTICLE{Kurillo2016502,
	author = {Kurillo, Gregorij and Yang, Allen Y. and Shia, Victor and Bair, Aaron and Bajcsy, Ruzena},
	title = {New emergency medicine paradigm via augmented telemedicine},
	year = {2016},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {9740},
	pages = {502 – 511},
	doi = {10.1007/978-3-319-39907-2_48},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978919835&doi=10.1007%2f978-3-319-39907-2_48&partnerID=40&md5=bdf63615d26450146070f5ce2aae4722},
	affiliations = {University of California at Berkeley, Berkeley, CA, United States; University of California Davis Medical Center, Sacramento, CA, United States},
	abstract = {In many emergency scenarios, medical care is initially provided by first responders in the field and later by physicians at designated centers. In the setting of traumatic injury, the so-called “golden hour,” the efficiency of patient triage and medical transport may greatly affect the outcomes of emergency treatment. In current practice, the initial communication and interaction between physician and first responders is limited to voice or, in rare instances, video conferencing, while the attending physicians cannot receive other more comprehensive, critical patient information. This paper proposes to address these fundamental technology gaps and information bottlenecks by leveraging the state-ofthe- art 3D teleimmersion and augmented reality (AR) technologies. © Springer International Publishing Switzerland 2016.},
	author_keywords = {Augmented reality; Collaboration; Emergency medicine; Remote interaction; Telemedicine; Virtual reality},
	keywords = {Augmented reality; Medicine; Patient treatment; Telemedicine; Video conferencing; Virtual reality; Collaboration; Communication and interaction; Emergency medicine; Emergency scenario; Emergency treatment; Information bottleneck; Patient information; Remote interactions; Human computer interaction},
	correspondence_address = {A.Y. Yang; University of California at Berkeley, Berkeley, United States; email: yang@eecs.berkeley.edu},
	editor = {Lackey S. and Shumaker R.},
	publisher = {Springer Verlag},
	issn = {03029743},
	isbn = {978-331939906-5},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 12; Conference name: 8th International Conference on Virtual, Augmented and Mixed Reality, VAMR 2016 and Held as Part of 18th International Conference on Human-Computer Interaction, HCI International 2016; Conference date: 17 July 2016 through 22 July 2016; Conference code: 177789}
}

@CONFERENCE{Gallagher2015,
	author = {Gallagher, Dennis G. and Manley, Richard J.},
	title = {Diver's full face mask head-up display system using waveguide optical display technology OSJ - 140214-001},
	year = {2015},
	journal = {2014 Oceans - St. John's, OCEANS 2014},
	doi = {10.1109/OCEANS.2014.7002976},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84921748618&doi=10.1109%2fOCEANS.2014.7002976&partnerID=40&md5=46609ec3bc570230248ab5b7d46e7950},
	affiliations = {Naval Surface Warfare Center-Panama City Division, Underwater Systems Development Branch (E15), Panama City, United States; Naval Surface Warfare Center-Panama City Division Line, Intelligent Sensing and Irregular Warfare Branch (X12), Panama City, United States},
	abstract = {Military, public safety and science divers conduct operations in what can be one of the most inhospitable environments on the planet characterized by extreme temperature, pressure, and extremely poor visibility. Handheld displays and gauges can be virtually useless in an environment frequently characterized by zero visibility, and this has been a serious limitation to underwater manned diving operations [1]. Waveguide optical display technology has the potential to radically transform diver visual display systems by enabling the diver's face mask itself to become a see-through head-up display, similar to something from an Iron Man or Star Trek movie. Under a recent international government sponsored program, the Naval Surface Warfare Center-Panama City Division (NSWC PCD) developed a concept prototype binocular see-through head-up display inside a diver's full face mask using waveguide optical display technology. This paper will describe diver visual display systems, waveguide optical display technology, development of the concept prototype, results of diver evaluations, and recommendations for follow-on research and development. © 2014 IEEE.},
	author_keywords = {diving; optics; see through; visibility; waveguide},
	keywords = {Naval warfare; Optical waveguides; Optics; Visibility; Waveguides; Concept prototype; diving; Extreme temperatures; Handheld displays; Head-up display systems; Naval Surface Warfare Center; Research and development; see through; Head-up displays},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-147994918-2},
	language = {English},
	abbrev_source_title = {Ocean. - St. John's, OCEANS},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 2014 Oceans - St. John's, OCEANS 2014; Conference date: 14 September 2014 through 19 September 2014; Conference code: 109975; All Open Access, Green Open Access}
}

@ARTICLE{Dong2017461,
	author = {Dong, Lanfang and Yu, Jiakui and Wang, Jianfu and Gao, Weinan},
	title = {Research of a framework for flow objects detection and tracking in video},
	year = {2017},
	journal = {Lecture Notes in Electrical Engineering},
	volume = {399},
	pages = {461 – 480},
	doi = {10.1007/978-981-10-2404-7_36},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992643435&doi=10.1007%2f978-981-10-2404-7_36&partnerID=40&md5=99d800bbe7c49c45ac0ecaf4f14eea0b},
	affiliations = {Vision Computing and Visualization Laboratory, University of Science and Technology of China, Hefei, 230027, China; The State Key Laboratory of Fluid Power Transmission and Control, Zhejiang University, Hangzhou, 310027, China},
	abstract = {The flow objects are ubiquitous in nature, and the detection and tracking of flow objects is very important in the field of machine vision and public safety, so building a framework for the detection and tracking is more advantageous for this research. For this demand, a systematic framework is proposed. First, the foreground can be detected by GMM (gaussian mixture model) and SNP (statistical nonparametric) algorithm, and candidate regions can be determined by static features extracted in the foreground. Second, all these candidate regions should be combined and tracked. At last, dynamic features of the tracked regions should be extracted and whether it is flow objects or not should be confirmed. To solve the problem of combination of adjacent small regions and the multi-objects matching, similar regional growth algorithm and the method for tracking multiple targets are put forward. To verify the effect of the framework, a lot of experiments about smoke, fire, and rain are implemented. © Zhejiang University Press and Springer Science+Business Media Singapore 2017.},
	author_keywords = {Common framework; Detecting and tracking flow objects; GMM; Matching degree},
	keywords = {Computer vision; Gaussian distribution; Object detection; Robots; Tracking (position); Wearable technology; Common framework; Detecting and tracking flow objects; Detection and tracking; Gmm (gaussian mixture model); Growth algorithms; Matching degree; Objects detection; Systematic framework; Wearable sensors},
	correspondence_address = {W. Gao; Vision Computing and Visualization Laboratory, University of Science and Technology of China, Hefei, 230027, China; email: gwny@mail.ustc.edu.cn},
	editor = {Virk G.S. and Yang C. and Yang H.},
	publisher = {Springer Verlag},
	issn = {18761100},
	isbn = {978-981102403-0},
	language = {English},
	abbrev_source_title = {Lect. Notes Electr. Eng.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: International Conference on Wearable Sensors and Robots, ICWSR 2015; Conference date: 16 October 2015 through 18 October 2015; Conference code: 185189}
}

@ARTICLE{Lobarinas2016S59,
	author = {Lobarinas, Edward and Scott, Ryan and Spankovich, Christopher and Le Prell, Colleen G.},
	title = {Differential effects of suppressors on hazardous sound pressure levels generated by AR-15 rifles: Considerations for recreational shooters, law enforcement, and the military},
	year = {2016},
	journal = {International Journal of Audiology},
	volume = {55},
	pages = {S59 – S71},
	doi = {10.3109/14992027.2015.1122241},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84957064507&doi=10.3109%2f14992027.2015.1122241&partnerID=40&md5=76137139a88ca5de001bbcbc1b6beb54},
	affiliations = {School of Behavioral and Brain Sciences, University of Texas at Dallas, 1966 Inwood Road, Dallas, 75235, TX, United States; Alachua County Sheriffs Department, Gainesville, FL, United States; The University of Mississippi Medical Center, Jackson, MS, United States},
	abstract = {Objective: Firearm discharges produce hazardous levels of impulse noise that can lead to permanent hearing loss. In the present study, we evaluated the effects of suppression, ammunition, and barrel length on AR-15 rifles. Design: Sound levels were measured left/right of a users head, and 1-m left of the muzzle, per MIL-STD-1474-D, under both unsuppressed and suppressed conditions. Study sample: Nine commercially available AR-15 rifles and 14 suppressors were used. Results: Suppressors significantly decreased peak dB SPL at the 1-m location and the left ear location. However, under most rifle/ammunition conditions, levels remained above 140 dB peak SPL near a users right ear. In a subset of conditions, subsonic ammunition produced values near or below 140 dB peak SPL. Overall suppression ranged from 7-32 dB across conditions. Conclusions: These data indicate that (1) suppressors reduce discharge levels to 140 dB peak SPL or below in only a subset of AR-15 conditions, (2) shorter barrel length and use of muzzle brake devices can substantially increase exposure level for the user, and (3) there are significant left/right ear sound pressure differences under suppressed conditions as a function of the AR-15 direct impingement design that must be considered during sound measurements to fully evaluate overall efficacy. © 2016 British Society of Audiology, International Society of Audiology, and Nordic Audiological Society.},
	author_keywords = {AR-15; permanent hearing loss; rifle fire; silencers; suppressors},
	keywords = {Equipment Design; Firearms; Hearing Loss, Noise-Induced; Humans; Military Personnel; Noise; Occupational Diseases; Occupational Exposure; Police; Recreation; Sound; Sound Spectrography; adverse effects; equipment design; firearm; Hearing Loss, Noise-Induced; human; noise; Occupational Diseases; occupational exposure; police; prevention and control; recreation; soldier; sound; sound detection},
	correspondence_address = {C.G. Le Prell; School of Behavioral and Brain Sciences, University of Texas at Dallas, Dallas, 1966 Inwood Road, 75235, United States; email: colleen.leprell@utdallas.edu},
	publisher = {Taylor and Francis Ltd.},
	issn = {14992027},
	coden = {IJANG},
	pmid = {26821935},
	language = {English},
	abbrev_source_title = {Int. J. Audiol.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 24}
}

@CONFERENCE{Maamar2010,
	author = {Maamar, Haifa Raja and Pazzi, Richard W. and Boukerche, Azzedine and Petriu, Emil},
	title = {A supplying partner strategy for mobile networks-based 3D streaming - Proof of concept},
	year = {2010},
	journal = {Proceedings of the 2010 IEEE International Symposium on Parallel and Distributed Processing, Workshops and Phd Forum, IPDPSW 2010},
	doi = {10.1109/IPDPSW.2010.5470795},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-77954071976&doi=10.1109%2fIPDPSW.2010.5470795&partnerID=40&md5=2725ff634fedea293cd15169e69f78f1},
	affiliations = {PARADISE Research Laboratory, SITE, University of Ottawa, Canada; SMR Research Laboratory, SITE, University of Ottawa, Canada},
	abstract = {With the advances of wireless communication and mobile computing, there is a growing interest among researchers about augmented reality and streaming 3D graphics on mobile devices for training first responders to be better prepared in a case of disaster scenarios. However, several challenges need to be resolved before this technology become a commodity. One of the major difficulties in 3D streaming over thin mobile devices is related to the supplying partner strategy as it is not easy to discover the peer that has the correct information and that posses enough bandwidth to send the required data quickly and efficiently to the peers in need. In this paper, we propose a new supplying partner strategy for mobile networks-based 3D streaming. The primary goal of the work presented in this paper is first to address the thin mobile devices low storage capabilities; and second to avoid the flooding problem that most wireless mobile networks suffer from. Our proposed protocol is based on the quick discovery of multiple supplying partners, by optimizing the time required by peers to acquire data, avoiding unnecessary messages propagation and network congestion, and decreasing the latency and the network bandwidth over utilization. © 2010 IEEE.},
	author_keywords = {3D streaming; Supplying partners; Thin moble devices; Wireless networks},
	keywords = {Augmented reality; Data flow analysis; Distributed parameter networks; Mobile devices; Mobile telecommunication systems; Network protocols; Portable equipment; Three dimensional; Virtual reality; Wireless networks; Wireless telecommunication systems; 3D graphics; 3D streaming; Disaster scenario; First responders; Low-storage; Mobile networks; Network bandwidth; Network congestions; Proof of concept; Wireless communications; Wireless mobile networks; Peer to peer networks},
	correspondence_address = {H. R. Maamar; PARADISE Research Laboratory, SITE, University of Ottawa, Canada; email: hmaam026@site.uottawa.ca},
	isbn = {978-142446534-7},
	language = {English},
	abbrev_source_title = {Proc. IEEE Int. Symp. Parallel Distrib. Process., Workshops Phd Forum, IPDPSW},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; Conference name: 2010 IEEE International Symposium on Parallel and Distributed Processing, Workshops and Phd Forum, IPDPSW 2010; Conference date: 19 April 2010 through 23 April 2010; Conference code: 80842}
}

@CONFERENCE{Munteanu20132383,
	author = {Munteanu, Cosmin and Fournier, Hélène and Lapointe, Jean-François and Kondratova, Irina and Emond, Bruno},
	title = {We'll Take it from Here: Letting the Users Take Charge of the Evaluation and Why that Turned Out Well},
	year = {2013},
	journal = {Conference on Human Factors in Computing Systems - Proceedings},
	volume = {2013-April},
	pages = {2383 – 2384},
	doi = {10.1145/2468356.2468778},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84951184013&doi=10.1145%2f2468356.2468778&partnerID=40&md5=3547dbb37630138510e4dc98ec5653d4},
	affiliations = {National Research Council, United States; Fredericton, E3B 9W4, NB, Austria; Moncton, E1A 7R1, NB, Austria; Ottawa, K1A 0R6, ON, Canada},
	abstract = {The operational challenges faced by law enforcement and public safety personnel are constantly evolving, while the training and certification process has stayed the same. New technologies such as virtual reality, mixed reality, or game-based simulators are being researched as promising enhancements to traditional training methods. However, their widespread adoption, particularly by smaller units, faces barriers such as cost – due in no small part to the difficulties of developing and especially evaluating such large-scale interactive systems. In this case study, we present MINT – a low-cost mixed-reality Multimodal INteractive Training system, aimed at supporting the training of small- and medium-sized law enforcement and infantry units. We discuss the challenges and approaches taken in the participatory design of the training system, its agile-based development and implementation, and its qualitative evaluation with users and subject-matter experts.},
	author_keywords = {Evaluation methodology; Immersive gaming; Mixed-reality interaction; User studies},
	keywords = {Human computer interaction; Human engineering; Law enforcement; Personnel testing; Virtual reality; Certification process; Evaluation methodologies; Immersive gaming; Mixed reality; Operational challenges; Qualitative evaluations; Subject matter experts; User study; Personnel training},
	editor = {Beaudouin-Lafon M. and Baudisch P. and Mackay W.E.},
	publisher = {Association for Computing Machinery},
	isbn = {978-145031899-0},
	language = {English},
	abbrev_source_title = {Conf Hum Fact Comput Syst Proc},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: 31st Annual CHI Conference on Human Factors in Computing Systems:, CHI EA 2013; Conference date: 27 April 2013 through 2 May 2013; Conference code: 132953; All Open Access, Green Open Access}
}

@ARTICLE{Krum201217,
	author = {Krum, David M. and Suma, Evan A. and Bolas, Mark},
	title = {Augmented reality using personal projection and retroreflection},
	year = {2012},
	journal = {Personal and Ubiquitous Computing},
	volume = {16},
	number = {1},
	pages = {17 – 26},
	doi = {10.1007/s00779-011-0374-4},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027945350&doi=10.1007%2fs00779-011-0374-4&partnerID=40&md5=b43f35a1540c919119ef33c36af22cd2},
	affiliations = {Institute for Creative Technologies, University of Southern California, Playa Vista, CA 90094-2536, 12015 Waterfront Drive, United States; USC School of Cinematic Arts, University of Southern California, Los Angeles, CA 90089-2211, 900 West 34th Street, United States},
	abstract = {The support of realistic and flexible training simulations for military, law enforcement, emergency response, and other domains has been an important motivator for the development of augmented reality technology. An important vision for achieving this goal has been the creation of a versatile "stage" for physical, emotional, and cognitive training that combines virtual characters and environments with real world elements, such as furniture and props. This paper presents REFLCT, a mixed reality projection framework that couples a near-axis personal projector design with tracking and novel retroreflective props and surfaces. REFLCT provides multiple users with personalized, perspective-correct imagery that is uniquely composited for each user directly into and onto a surrounding environment, without any optics positioned in front of the user's eyes or face. These characteristics facilitate team training experiences which allow users to easily interact with their teammates while wearing their standard issue gear. REFLCT can present virtual humans who can make deictic gestures and establish eye contact without the geometric ambiguity of a typical projection display. It can also display perspective-correct scenes that require a realistic approach for detecting and communicating potential threats between multiple users in disparate locations. In addition to training applications, this display system appears to be well matched with other user interface and application domains, such as asymmetric collaborative workspaces and personal information guides. © Springer-Verlag London Limited 2011.},
	author_keywords = {Augmented reality; Head-mounted projection; Pico-projector; Retroreflective screens; Training},
	keywords = {Display devices; Personnel training; User interfaces; Virtual reality; Augmented reality technology; Collaborative workspace; Head-mounted projections; Personal projections; Pico projectors; Retroreflective screens; Surrounding environment; Training applications; Augmented reality},
	correspondence_address = {D.M. Krum; Institute for Creative Technologies, University of Southern California, Playa Vista, CA 90094-2536, 12015 Waterfront Drive, United States; email: krum@ict.usc.edu},
	publisher = {Springer London},
	issn = {16174909},
	language = {English},
	abbrev_source_title = {Pers. Ubiquitous Comp.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 27}
}

@CONFERENCE{Melzer2011132,
	author = {Melzer, James E.},
	title = {Invited paper: Image source evaluation and selection for rugged near-eye displays},
	year = {2011},
	journal = {49th Annual SID Symposium, Seminar, and Exhibition 2011, Display Week 2011},
	volume = {1},
	pages = {132 – 134},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84860725076&partnerID=40&md5=b2d45f3009d617a189e2f3040448c3c7},
	affiliations = {Rockwell Collins Optronics, Carlsbad, CA, United States},
	abstract = {There are many high-quality image source technologies to choose from when designing a near-eye or head-mounted display and they can provide excellent imagery. However, when you impose requirements for this same performance under extreme conditions of temperature, shock, and direct sunlight exposure - conditions which might be experienced by military personnel or first responders, the number of options gets smaller. This paper will address the impact of imposing these very stringent environmental conditions on choices for image sources.},
	keywords = {Environmental conditions; Extreme conditions; First responders; Head mounted displays; High quality images; Image source; Military personnels; Sunlight exposure; Exhibitions},
	isbn = {978-161839096-7},
	language = {English},
	abbrev_source_title = {Annu. SID Symp., Semin., Exhib., Disp. Week},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 49th Annual SID Symposium, Seminar, and Exhibition 2011, Display Week 2011; Conference date: 15 May 2011 through 20 May 2011; Conference code: 89585}
}

@CONFERENCE{Siu201336,
	author = {Siu, Teresa and Herskovic, Valeria},
	title = {SidebARs: Improving awareness of off-screen elements in mobile augmented reality},
	year = {2013},
	journal = {ACM International Conference Proceeding Series},
	pages = {36 – 41},
	doi = {10.1145/2535597.2535608},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84893441125&doi=10.1145%2f2535597.2535608&partnerID=40&md5=36dd01d8cdc53ba0ec6501eed51b72fc},
	affiliations = {Pontificia Universidad Católica, Santiago, Chile},
	abstract = {In a high-stress situation, such as an emergency, first responders (e.g. police, firefighters) require relevant information to be delivered in a timely, efficient way. Augmented reality seems like a natural way for emergency responders to find relevant information that is close to them. However, due to the limited angle and distance seen through the camera, many relevant points will be off-screen, making it difficult to quickly find the needed information. Several approaches for this problem have been proposed in previous works, however, most are designed for 2D maps, and those proposed for augmented reality do not allow users to quickly find a certain type of point of interest. We studied the emergency response scenario through a development project and several focus groups. Then, we implemented SidebARs: a prototype that implements two sidebars that allow users to quickly find the relevant information they are interested in, combined with layer filters and a slide bar to set a radius of interest. This visualization technique not only gives users awareness about the distance and direction of relevant points of interest, but also about their type. This paper presents the design and implementation of this prototype. A preliminary evaluation with firefighters found it to be a promising mechanism to find information during an emergency. © 2013 ACM.},
	author_keywords = {augmented reality; awareness; emergency response; off-screen POIs},
	keywords = {Augmented reality; Fire extinguishers; Human computer interaction; awareness; Design and implementations; Development project; Emergency responders; Emergency response; Mobile augmented reality; off-screen POIs; Visualization technique; Emergency services},
	isbn = {978-145032200-3},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 26; Conference name: 2013 Chilean Conference on Human - Computer Interaction, ChileCHI 2013; Conference date: 11 November 2013 through 15 November 2013; Conference code: 102311}
}

@CONFERENCE{Schönauer2013202,
	author = {Schönauer, Christian and Vonach, Emanuel and Gerstweiler, Georg and Kaufmann, Hannes},
	title = {3D building reconstruction and thermal mapping in fire brigade operations},
	year = {2013},
	journal = {ACM International Conference Proceeding Series},
	pages = {202 – 205},
	doi = {10.1145/2459236.2459271},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84875986281&doi=10.1145%2f2459236.2459271&partnerID=40&md5=51b59ce211a41ea48e8d638aed782e9f},
	affiliations = {Vienna University of Technology, Austria},
	abstract = {Fire fighting remains a dangerous profession despite many recent technological and organizational measures. Sensors and technical systems can augment the performance of fire fighters to increase safety and efficiency during operation. An important aspect in that context is the awareness of location, structure and thermal properties of the environment. This paper focuses on the design and development of a mobile system, which can reconstruct a 3d model of a building's interior structure in real-time and fuses the visualization with the image of a thermal camera. In addition the position and viewing direction of the fire fighter within the model is determined and a thermal map can be generated from the gathered data, which could help an operational commander to guide his men during a mission. First tests with our system in different situations showed good results, being able to reconstruct different larger scenes and create thermal maps thereof. Copyright 2013 ACM.},
	author_keywords = {Augmented reality; Fire fighter safety; Real-time dense reconstruction; Thermal camera},
	keywords = {Augmented reality; Fires; Infrared devices; Three dimensional computer graphics; 3-d building reconstruction; Design and Development; Fire fighters; Interior structure; Safety and efficiencies; Structure and thermal properties; Thermal camera; Viewing directions; Three dimensional},
	correspondence_address = {C. Schönauer; Vienna University of Technology, Austria; email: schoenauer@ims.tuwien.ac.at},
	isbn = {978-145031904-1},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 19; Conference name: 4th Augmented Human International Conference, AH 2013; Conference date: 7 March 2013 through 8 March 2013; Conference code: 96522; All Open Access, Green Open Access}
}

@ARTICLE{Hawes2017421,
	author = {Hawes, Breanne K. and Brunyé, Tad T. and Westgate, Brian P.},
	title = {Visual psychophysical thresholds for perceiving objects and letters on monocular head-up displays in indoor and outdoor lighting conditions},
	year = {2017},
	journal = {Advances in Intelligent Systems and Computing},
	volume = {488},
	pages = {421 – 432},
	doi = {10.1007/978-3-319-41691-5_36},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84986278270&doi=10.1007%2f978-3-319-41691-5_36&partnerID=40&md5=bd074291ea3cc6c530492649692a38e7},
	affiliations = {Cognitive Science Team, U.S. Army Natick Soldier Research, Development and Engineering Center, 15 General Greene Ave, Natick, 01760, MA, United States},
	abstract = {Monocular and binocular head-up displays (HUD) can enhance situational awareness by providing hands-free, real-time information to users on the move. These displays hold the potential for enhancing human experience in many activities, including ambulatory first responders or military personnel. The present study involved a visual psychophysics assessment of three commercially available HUD systems: Vuzix M2000AR, Epson BT-200, and Google Glass. Testing involved 36 participants viewing 112 trials of shape and letter stimuli, presented using the Ascending Methods of Limits psychophysics approach. Half of the trials were completed indoors and half completed outdoors for each HUD. Results demonstrated that participants were able to reliably perceive smaller stimulus sizes with the Epson and Google devices, relative to the Vuzix. This was especially the case in outdoor environments. Results demonstrate the importance of identifying perceptual thresholds for reliably perceiving and interpreting visual stimuli, with large implications for conveying information to the HUD user. Findings of this study demonstrate important practical considerations for selecting commercially-available HUD systems, with particular emphasis on understanding system-specific resolution in tandem with the inherent perceptual capabilities and limitations of human users. © Springer International Publishing Switzerland 2017.},
	author_keywords = {Cognition; Head-up display; Psychophysics},
	keywords = {Aircraft manufacture; Optical design; Psychophysiology; Cognition; Head up displays; Perceptual threshold; Psychophysical thresholds; Psychophysics; Real-time information; Situational awareness; Visual psychophysics; Cognitive systems},
	correspondence_address = {B.K. Hawes; Cognitive Science Team, U.S. Army Natick Soldier Research, Development and Engineering Center, Natick, 15 General Greene Ave, 01760, United States; email: Breanne.k.Hawes.civ@mail.mil},
	editor = {Hale K.S. and Stanney K.M.},
	publisher = {Springer Verlag},
	issn = {21945357},
	isbn = {978-331941690-8},
	language = {English},
	abbrev_source_title = {Adv. Intell. Sys. Comput.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: International Conference on Neuroergonomics and Cognitive Engineering, 2016; Conference date: 27 July 2016 through 31 July 2016; Conference code: 180599}
}

@CONFERENCE{Kress2014,
	author = {Kress, Bernard},
	title = {See through optical architectures for wearable displays},
	year = {2014},
	journal = {Optics InfoBase Conference Papers},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84906709267&partnerID=40&md5=f95aa5db46f6e171404634fb5fff1e38},
	affiliations = {Google, United States},
	abstract = {HUDs (Head Up Displays) and HMDs (Helmet Mounted Displays) have been with us for a few decades, providing exceptional optical performances for specialized defense applications. On the other hand, consumer electronics HMDs (Head Mounted Displays) have been lingering as personal gadgets for a mere decade. But recently, major companies have launched consumer compelling head mounted display solutions integrating both hardware, operating system as well as content, unlocking the decade long consumer HMD status-quo. As a result, we are witnessing today a fragmentation of the HMD market into various categories which have their very own specificity in terms of functionality, hardware and content. Such fragmentation is responsible for defining new distinct market segments such as consumer near to eye displays, social smart glasses, gaming headsets, as well as professional (engineering and technical) HMDs, specialized (medical, law enforcement, firefighting) HMDs and of course the previously existing defense market. We will be reviewing the different type of optical hardware used in such devices. © 2014 OSA.},
	keywords = {Commerce; Consumer electronics; Hardware; Optical design; Sensory perception; Signal reconstruction; Defense markets; Head mounted displays; Head up displays; Market segment; Near-to-Eye display; Optical architectures; Optical performance; Wearable displays; Helmet mounted displays},
	correspondence_address = {B. Kress; Google, United States; email: bernard.kress@gmail.com},
	publisher = {Optical Society of American (OSA)},
	issn = {21622701},
	isbn = {978-155752308-2},
	language = {English},
	abbrev_source_title = {Opt.InfoBase Conf. Papers},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: Signal Recovery and Synthesis, SRS 2014; Conference date: 13 July 2014 through 17 July 2014; Conference code: 107127}
}

@CONFERENCE{Pallauf20116009,
	author = {Pallauf, J. and Gomes, P. and Brás, S. and Cunha, J.P.S. and Coimbra, M.},
	title = {Associating ECG features with firefighter's activities},
	year = {2011},
	journal = {Proceedings of the Annual International Conference of the IEEE Engineering in Medicine and Biology Society, EMBS},
	pages = {6009 – 6012},
	doi = {10.1109/IEMBS.2011.6091485},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84862291992&doi=10.1109%2fIEMBS.2011.6091485&partnerID=40&md5=dc24aed5b97b066d4cd1389b87c11845},
	affiliations = {Instituto de Telecomunicações, Department of Computer Science, Universidade Do Porto, Portugal; IEETA, Universidade de Aveiro, Portugal; IEETA, Department of Electronics, Telecommunications and Informatics, University of Aveiro, Portugal},
	abstract = {In this paper we associate features obtained from ECG signals with the expected levels of stress of real firefighters in action when facing specific events such as fires or car accidents. Five firefighters were monitored using wearable technology collecting ECG signals. Heart rate and heart rate variability features were analyzed in consecutive 5-min intervals during several types of events. A questionnaire was used to rank these types of events according to stress and fatigue and a measure of association was applied to compare this ranking to the ECG features. Results indicate associations between this ranking and both heart rate and heart rate variability features extracted in the time domain. Finally, an example of differences in inter personal responses to stressful events is shown and discussed, motivating future challenges within this research field. © 2011 IEEE.},
	keywords = {Adult; Diagnosis, Computer-Assisted; Electrocardiography; Firefighters; Humans; Male; Middle Aged; Occupational Diseases; Stress, Psychological; Accidents; Electrocardiography; Fire extinguishers; Car accidents; ECG signals; Future challenges; Heart rate variability; Heart rates; Research fields; Time domain; Wearable technology; adult; article; computer assisted diagnosis; electrocardiography; fire fighter; human; male; mental stress; methodology; middle aged; occupational disease; pathophysiology; Heart},
	correspondence_address = {J. Pallauf; Instituto de Telecomunicações, Department of Computer Science, Universidade Do Porto, Portugal; email: johannes.pallauf@mytum.de},
	issn = {1557170X},
	isbn = {978-142444121-1},
	pmid = {22255709},
	language = {English},
	abbrev_source_title = {Proc. Annu. Int. Conf. IEEE Eng. Med. Biol. Soc. EMBS},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; Conference name: 33rd Annual International Conference of the IEEE Engineering in Medicine and Biology Society, EMBS 2011; Conference date: 30 August 2011 through 3 September 2011; Conference code: 87843}
}

@CONFERENCE{Garg2017138,
	author = {Garg, Shubham and Joshi, Pradumn},
	title = {Integrated Wearable Police Module for Fine Management and Law Enforcement},
	year = {2017},
	journal = {Proceedings - 2014 Texas Instruments India Educators Conference, TIIEC 2014},
	pages = {138 – 143},
	doi = {10.1109/TIIEC.2014.031},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018395351&doi=10.1109%2fTIIEC.2014.031&partnerID=40&md5=bcc53fa2be895fc4a503302f9e1fd046},
	affiliations = {Sardar Vallabhbhai National Institute of Technology, Surat, India},
	abstract = {The technological advancement in recent decades has revolutionized law enforcement and security. The police and several other agencies have adopted tons of these technologies and methods to enhance their efficiency. While there are a lot of equipment available, the problem is the discreet nature of these devices which increases its cost. Implementing these too is a complex process due to the irregularity of traffic in India. We condensed the equipment to a single platform to increase mobility. We were successful in integrating Tint Meter, metal detector, PUC check, breath analyzer and digital fine management. New modules can also be added in the future. To control irregular traffic we have used hand gloves and were also successful in making public displays which can be controlled by traffic police in real time by using a Smartphone. © 2014 IEEE.},
	author_keywords = {Breath analyser; Flex sensor; Hand gloves; nrf24l01; Public displays; PUC check; SLE4442; Tintmeter; TKinter; Traffic lights},
	keywords = {Education; Street traffic control; Wearable technology; Breath analyser; Flex sensor; Hand gloves; Nrf24l01; Public display; PUC check; SLE4442; Tintmeter; TKinter; Traffic light; Law enforcement},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-146738922-8},
	language = {English},
	abbrev_source_title = {Proc. -Texas Instruments India Educ.' Conf., TIIEC},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2nd Texas Instruments India Educators Conference, TIIEC 2014; Conference date: 4 April 2014 through 5 April 2014; Conference code: 127391}
}

@CONFERENCE{Umlauft2017,
	author = {Umlauft, Martina and Raffelsberger, Christian and Kercek, Andreas and Almer, Alexander and Schnabel, Thomas and Luley, Patrick and Ladstaetter, Stefan},
	title = {A communication and multi-sensor solution to support dynamic generation of a situational picture},
	year = {2017},
	journal = {Proceedings of the 2016 3rd International Conference on Information and Communication Technologies for Disaster Management, ICT-DM 2016},
	doi = {10.1109/ICT-DM.2016.7857205},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016038959&doi=10.1109%2fICT-DM.2016.7857205&partnerID=40&md5=65085a128c6625ecf7cc4afc11e92af7},
	affiliations = {Lakeside Labs, Lakeside B04, Klagenfurt, 9020, Austria; Joanneum Research, Steyrergasse 17, Graz, 8010, Austria},
	abstract = {This paper provides an overview of a novel system architecture to support first responders in coping with dynamically changing situations, as well as help them to allocate human resources more efficiently. The system supports the collection and fusion of multi-sensor data for the generation of a near real-Time situational picture. We employ a context-sensitive augmented reality (AR) assistance and feedback system and a role-based data distribution module, to enable more efficient interaction between command center and mobile teams and to reduce the risk of information overload. Our system integrates TETRA, since it is a widely used radio standard for first responders, and complements it with other broadband systems like LTE and WiFi to enable broadband multimedia services.},
	author_keywords = {Broadband communication; Communication manager; First responder; Mobile command center; Near realtime situational picture; Tetra; Wearable multi-sensor solution},
	keywords = {Augmented reality; Disaster prevention; Disasters; Multimedia services; Sensor data fusion; Broadband Communication; Communication manager; First responders; Mobile command center; Multi sensor; Real time; Tetra; Wearable sensors},
	editor = {Duro R. and Pielorz J. and Preinerstorfer A.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-150905234-9},
	language = {English},
	abbrev_source_title = {Proc. Int. Conf. Inf. Commun. Technol. Disaster Manag., ICT-DM},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: 3rd International Conference on Information and Communication Technologies for Disaster Management, ICT-DM 2016; Conference date: 13 December 2016 through 15 December 2016; Conference code: 126500}
}

@CONFERENCE{Newaz2015,
	author = {Newaz, Fahd Bin Malek and Eide, Aslak Wegner and Pultier, Antoine},
	title = {Supporting first responder in-field communication and navigation using head-mounted displays},
	year = {2015},
	journal = {ISCRAM 2015 Conference Proceedings - 12th International Conference on Information Systems for Crisis Response and Management},
	volume = {2015-January},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84947771538&partnerID=40&md5=c58566c26b3af7c9aead225c763fb1be},
	affiliations = {Institute for Informatics, University of Oslo, Norway; SINTEF ICT, Norway},
	abstract = {This paper explores the added-value of using interactive head-mounted displays to support command and control of first responders during emergency response. Specifically, it describes and evaluates a prototype system that makes use of Google Glass to enable in-field receiving of information from a command center, as well as in-field navigation and video streaming. The viability and usefulness of the concept was evaluated through a set of end-user workshops and interviews. A small-scale experiment was also conducted to assess the efficiency of using head-mounted displays for in-field navigation, as compared to handheld devices. Findings from workshops and interviews suggest that head-mounted displays could be a valuable supplement to radio communication, with potential for reducing information misinterpretation, and for enhancing information quality. Results from the experiment indicate that head-mounted displays have the same level of efficiency as handheld devices when used for basic navigation tasks.},
	author_keywords = {C2; Communication; Emergency management; Head-mounted display; Navigation},
	keywords = {Communication; Display devices; Efficiency; Hand held computers; Information management; Information systems; Navigation; Radio communication; Risk management; Sensory perception; Street traffic control; Video streaming; C2; Command and control; Emergency management; Emergency response; Hand held device; Head mounted displays; Information quality; Small-scale experiment; Helmet mounted displays},
	editor = {Palen L.A. and Comes T. and Buscher M. and Hughes A.L. and Palen L.A.},
	publisher = {Information Systems for Crisis Response and Management, ISCRAM},
	isbn = {978-827117788-1},
	language = {English},
	abbrev_source_title = {ISCRAM Conf. Proc. - Int. Conf. Inf. Syst. Crisis Response Manag.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: 12th International Conference on Information Systems for Crisis Response and Management, ISCRAM 2015; Conference date: 24 May 2015 through 27 May 2015; Conference code: 115530}
}

@CONFERENCE{Chan2016489,
	author = {Chan, Edwin and Wang, Yuxi and Seyed, Teddy and Maurer, Frank},
	title = {ERWear: Wearables system design through the lens of first responders},
	year = {2016},
	journal = {Proceedings of the 2016 ACM International Conference on Interactive Surfaces and Spaces: Nature Meets Interactive Surfaces, ISS 2016},
	pages = {489 – 492},
	doi = {10.1145/2992154.2996880},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006013013&doi=10.1145%2f2992154.2996880&partnerID=40&md5=5f5b945e82722daad40e74304c35aced},
	affiliations = {University of Calgary, 2500 University Drive NW, Calgary, AB, Canada},
	abstract = {We explore the design of a wearable computing solution for first responders. Wearable devices have many uses, but commercial devices are not suitable for emergency response. First responders face high risk and volatile situations, and wearables possess significant potential to keep responders safe. A lack of understanding exists when designing wearables for first responders. Existing research focuses on the physical implementation of various sensors, rather than usability. Combining literature and extensive interviews, we devise design guidelines for responder-oriented wearable systems. We propose a prototype system, and discuss early feedback from responders. Copyright is held by the owner/author(s).},
	author_keywords = {Emergency management; First responder; Head-mounted display; Wearable devices},
	keywords = {Display devices; Helmet mounted displays; Risk management; Wearable technology; Commercial Devices; Emergency management; Emergency response; First responders; Head mounted displays; Prototype system; Wearable computing; Wearable devices; Emergency services},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {978-145034248-3},
	language = {English},
	abbrev_source_title = {Proc. ACM Int. Conf. Interact. Surfaces Spaces: Nat. Meets Interact. Surfaces, ISS},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; Conference name: 11th Annual ACM International Conference on Interactive Surfaces and Spaces, ISS 2016; Conference date: 6 November 2016 through 9 November 2016; Conference code: 124750}
}

@ARTICLE{Calavalle2013769,
	author = {Calavalle, Anna R. and Sisti, Davide and Mennelli, Giacomina and Andolina, Giuseppe and Del Sal, Marta and Rocchi, Marco B.L. and Benelli, Piero and Stocchi, Vilberto},
	title = {A simple method to analyze overall individual physical fitness in firefighters},
	year = {2013},
	journal = {Journal of Strength and Conditioning Research},
	volume = {27},
	number = {3},
	pages = {769 – 775},
	doi = {10.1519/JSC.0b013e3182600554},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84877977990&doi=10.1519%2fJSC.0b013e3182600554&partnerID=40&md5=2c2edcbecce55c378336a7e6bd78dc54},
	affiliations = {Department of Bio Molecular Sciences, Sport Sciences Section, Carlo Bo University, Urbino, Italy},
	abstract = {Calavalle, AR, Sisti, D, Mennelli, G, Andolina, G, Del Sal, M, Rocchi, MBL, Benelli, P, and Stocchi, V. A simple method to analyze overall individual physical fitness in firefighters. J Strength Cond Res 27(3): 769-775, 2013-The aim of this study was to identify the main components that determine firefighters' level of physical fitness using a stair-climbing test. The age, weight, height, body fat, and V?O2max of the firefighters were recorded before the trial, and percentage of heart rate reserve (%HRR) was recorded during the stair climbing. Nonlinear modeling of HRR time series and Principal Component Analysis (PCA) was applied to the data to isolate a small number of variables that quantify overall individual physical fitness. The HRR was represented as a function of time using the sum of linear and trigonometric functions. Four main factors that influence performance, obtained from PCA analysis, emerged (78.2% of total explained variance): the capacity to carry the extra load (22.8% of total variance); the effect of body fat (19.6% of total variance); the influence of age in the task (19.3% of total variance); and the overall fitness level (16.4% of total variance). This approach allowed us to make a rapid assessment of each subject's fitness level. Such an assessment could be used in planning individualized functional training programs to improve each firefighter's job performance and reduce injuries and hence save time, energy, and financial resources. © 2013 National Strength and Conditioning Association.},
	author_keywords = {Heart rate; Heart rate modeling; Public safety; Stair-climbing test},
	keywords = {Adult; Age Factors; Body Fat Distribution; Exercise Test; Firefighters; Heart Rate; Humans; Male; Middle Aged; Oxygen Consumption; Physical Fitness; Principal Component Analysis; adult; age; article; body fat distribution; exercise test; fire fighter; fitness; heart rate; human; male; methodology; middle aged; oxygen consumption; physiology; principal component analysis},
	correspondence_address = {A.R. Calavalle; Department of Bio Molecular Sciences, Sport Sciences Section, Carlo Bo University, Urbino, Italy; email: anna.calavalle@uniurb.it},
	issn = {15334295},
	pmid = {22706575},
	language = {English},
	abbrev_source_title = {J. Strength Cond. Res.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 16; All Open Access, Bronze Open Access}
}

@ARTICLE{Aldunate20126380,
	author = {Aldunate, Roberto G. and Schmidt, Klaus Nicholas and Herrera, Oriel},
	title = {Enabling communication in emergency response environments},
	year = {2012},
	journal = {Sensors (Switzerland)},
	volume = {12},
	number = {5},
	pages = {6380 – 6394},
	doi = {10.3390/s120506380},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84861557094&doi=10.3390%2fs120506380&partnerID=40&md5=1f5bbfb54e2c5d1d3e3f3f8c449fa384},
	affiliations = {Department of Computer Science, Catholic University of Temuco, Temuco, Chile; Applied Research Associates, Inc, Champaign, IL 61820, United States; Department of Technology, Illinois State University, Normal, IL 61761, United States},
	abstract = {Effective communication among first responders during response to natural and human-made large-scale catastrophes has increased tremendously during the last decade. However, most efforts to achieve a higher degree of effectiveness in communication lack synergy between the environment and the technology involved to support first responders operations. This article presents a natural and intuitive interface to support Stigmergy; or communication through the environment, based on intuitively marking and retrieving information from the environment with a pointer. A prototype of the system was built and tested in the field, however the pointing activity revealed challenges regarding accuracy due to limitations of the sensors used. The results obtained from these field tests were the basis for this research effort and will have the potential to enable communication through the environment for first responders operating in highly dynamical and inhospitable disaster relief environments. © 2012 by the authors; licensee MDPI, Basel, Switzerland.},
	author_keywords = {Augmented reality; Emergency response; Intuitive interface; Natural interface},
	keywords = {Emergency Medical Service Communication Systems; User-Computer Interface; article; computer interface; emergency health service},
	correspondence_address = {R. G. Aldunate; Department of Computer Science, Catholic University of Temuco, Temuco, Chile; email: raldunate@uct.cl},
	issn = {14248220},
	pmid = {22778647},
	language = {English},
	abbrev_source_title = {Sensors},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Coyne2009,
	author = {Coyne, T. and Balshaw, N. and Brennan, D. and Miller, A. and Whitehead, C. and Davies, S. and Robertson, C.},
	title = {De-convolution of complex residual gas spectra at JET},
	year = {2009},
	journal = {Proceedings - Symposium on Fusion Engineering},
	doi = {10.1109/FUSION.2009.5226395},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-70350722060&doi=10.1109%2fFUSION.2009.5226395&partnerID=40&md5=64aec653025900549fbd9b7d5a06a399},
	affiliations = {Euratom/UKAEA Fusion Association, United Kingdom; Plasma and Gas Division, Hiden Analytical Ltd., Warrington. WA5 7UN, 420 Europa Boulevard, United Kingdom},
	abstract = {Spectral analysis of the vacuum conditions within the JET tokamak provides unique challenges due to the complex interactions of Hydrogen, Deuterium and Tritium with the large amounts of Carbon forming the plasma facing first wall. Overlapping masses and low resolution of the quadrupole Residual Gas Analyzer (qRGA) means discrimination of individual species is not possible operating in a conventional mode. Baking the vessel to temperatures in excess of 300 degrees Celsius further complicates an already difficult task. Here, we present and demonstrate a complimentary technique operating the qRGA in a mode where the energy of the electrons emitted within the ionization source is variable. Different elements have defined ionization energies required to remove an orbiting electron, this energy is dependent on the electron orbital, i.e. outer shell electrons generally have weaker ionization energies due to the greater distance and lower electrostatic forces from the nucleus. Using this technique known as "Soft Ionization" de-convolution of the mass spectra obtained at JET could lead the way to providing a better understanding of the chemistry within the vacuum vessel as well as providing invaluable diagnostic information during vessel conditioning. Initial experimental data has proved encouraging demonstrating ionization energy discrimination of D 2 and 4He at 4amu and D 2O /Ne /Ar ++ at 20amu. De-convolution of hydrocarbon and deuterated hydrocarbon molecules in the mass spectrum is also currently ongoing, with initial results revealing clear discrimination of CH 4 and CD 2 molecular ions at 16amu. Using electron ionization cross-section theory we also demonstrate the generation of algorithms within the qRGA software to automatically discriminate quantitatively between overlapping peaks in the mass spectra. This technique can be applied to historical as well as real time data. 2010 brings the installation of the Beryllium plasma facing wall at JET and an opportunity to accurately determine the vessel chemistry during commissioning. The results from this phase of JET operations and further applications of the technique including leak detection and cryogenic pumping regeneration inventory determination could prove valuable for ITER commissioning and operations. ©2009 Crown.},
	author_keywords = {De-convolution; Deuterium; Fusion fuel; Helium; JET; Mass spectra; qRGA; Threshold ionization mass spectrometry(TIMS)},
	keywords = {Beryllium; Convolution; Deuterium; Electrons; Fusion reactors; Helium; Hydrocarbons; Ion beams; Ionization potential; Jets; Law enforcement; Mass spectrometers; Mass spectrometry; Neon; Particle detectors; Spectrum analysis; Spectrum analyzers; Thermal insulating materials; Tritium; Vacuum; Beryllium plasma; Carbon forming; Complex interaction; Cryogenic pumping; Diagnostic information; Electron ionization; Electron orbital; Experimental data; First wall; Fusion fuel; Hydrocarbon molecules; Ionization energies; Ionization sources; Jet operations; JET tokamak; Low resolution; Mass spectra; Molecular ions; Outer shell electrons; Overlapping peaks; Plasma facing; qRGA; Quadrupoles; Real-time data; Residual gas; Residual gas analyzers; Soft ionization; Spectral analysis; Threshold ionization mass spectrometry(TIMS); Vacuum condition; Vacuum vessel; Ionization of gases},
	isbn = {978-142442636-2},
	coden = {PSFEE},
	language = {English},
	abbrev_source_title = {Proc Symp Fusion Eng},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: 2009 23rd IEEE/NPSS Symposium on Fusion Engineering, SOFE 2009; Conference date: 1 June 2009 through 5 June 2009; Conference code: 78122}
}

@CONFERENCE{Yu20118199,
	author = {Yu, Xunyi and Ganz, Aura},
	title = {MiRTE: Mixed Reality Triage and Evacuation game for Mass Casualty information systems design, testing and training},
	year = {2011},
	journal = {Proceedings of the Annual International Conference of the IEEE Engineering in Medicine and Biology Society, EMBS},
	pages = {8199 – 8202},
	doi = {10.1109/IEMBS.2011.6092022},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84861688079&doi=10.1109%2fIEMBS.2011.6092022&partnerID=40&md5=adab15e31df99cfbe8dfa8dbdb7b4ce5},
	affiliations = {Electrical and Computer Engineering Department, University of Massachusetts, Amherst, United States},
	abstract = {In this paper we introduce a Mixed Reality Triage and Evacuation game, MiRTE, that is used in the development, testing and training of Mass Casualty Incident (MCI) information systems for first responders. Using the Source game engine from Valve software, MiRTE creates immersive virtual environments to simulate various incident scenarios, and enables interactions between multiple players/first responders. What distinguishes it from a pure computer simulation game is that it can interface with external mass casualty incident management systems, such as DIORAMA. The game will enable system developers to specify technical requirements of underlying technology, and test different alternatives of design. After the information system hardware and software are completed, the game can simulate various algorithms such as localization technologies, and interface with an actual user interface on PCs and Smartphones. We implemented and tested the game with the DIORAMA system. © 2011 IEEE.},
	keywords = {Allied Health Personnel; Computer Simulation; Disaster Planning; Education; Humans; Information Systems; Mass Casualty Incidents; Software; Triage; User-Computer Interface; Management information systems; Systems analysis; User interfaces; Virtual reality; CAN interface; First responders; Game Engine; Immersive virtual environments; Incident management systems; Mass casualty; Mixed reality; Smartphones; System developers; System hardware; Technical requirement; article; computer interface; computer program; computer simulation; disaster planning; education; emergency health service; human; information system; mass disaster; methodology; organization and management; paramedical personnel; Information systems},
	issn = {1557170X},
	isbn = {978-142444121-1},
	pmid = {22256245},
	language = {English},
	abbrev_source_title = {Proc. Annu. Int. Conf. IEEE Eng. Med. Biol. Soc. EMBS},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; Conference name: 33rd Annual International Conference of the IEEE Engineering in Medicine and Biology Society, EMBS 2011; Conference date: 30 August 2011 through 3 September 2011; Conference code: 87843}
}

@ARTICLE{Carlson2016667,
	author = {Carlson, Jestin N. and Das, Samarjit and De la Torre, Fernando and Frisch, Adam and Guyette, Francis X. and Hodgins, Jessica K. and Yealy, Donald M.},
	title = {A Novel Artificial Intelligence System for Endotracheal Intubation},
	year = {2016},
	journal = {Prehospital Emergency Care},
	volume = {20},
	number = {5},
	pages = {667 – 671},
	doi = {10.3109/10903127.2016.1139220},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84961213500&doi=10.3109%2f10903127.2016.1139220&partnerID=40&md5=825ed3be223970d4e074c79696f28bf1},
	affiliations = {Saint Vincent Health System, Emergency Medicine, Erie, PA, United States; Carnegie Mellon University, Robotics Institute, Pittsburgh, PA, United States; Albany Medical Center, Albany, NY, United States; University of Pittsburgh, Emergency Medicine, Pittsburgh, PA, United States},
	abstract = {Objective: Adequate visualization of the glottic opening is a key factor to successful endotracheal intubation (ETI); however, few objective tools exist to help guide providers’ ETI attempts toward the glottic opening in real-time. Machine learning/artificial intelligence has helped to automate the detection of other visual structures but its utility with ETI is unknown. We sought to test the accuracy of various computer algorithms in identifying the glottic opening, creating a tool that could aid successful intubation. Methods: We collected a convenience sample of providers who each performed ETI 10 times on a mannequin using a video laryngoscope (C-MAC, Karl Storz Corp, Tuttlingen, Germany). We recorded each attempt and reviewed one-second time intervals for the presence or absence of the glottic opening. Four different machine learning/artificial intelligence algorithms analyzed each attempt and time point: k-nearest neighbor (KNN), support vector machine (SVM), decision trees, and neural networks (NN). We used half of the videos to train the algorithms and the second half to test the accuracy, sensitivity, and specificity of each algorithm. Results: We enrolled seven providers, three Emergency Medicine attendings, and four paramedic students. From the 70 total recorded laryngoscopic video attempts, we created 2,465 time intervals. The algorithms had the following sensitivity and specificity for detecting the glottic opening: KNN (70%, 90%), SVM (70%, 90%), decision trees (68%, 80%), and NN (72%, 78%). Conclusions: Initial efforts at computer algorithms using artificial intelligence are able to identify the glottic opening with over 80% accuracy. With further refinements, video laryngoscopy has the potential to provide real-time, direction feedback to the provider to help guide successful ETI. © 2016, Copyright © Taylor & Francis Group, LLC.},
	author_keywords = {augmented reality; computer vision; intubation; signal processing},
	keywords = {Adult; Algorithms; Artificial Intelligence; Cross-Sectional Studies; Emergency Medical Services; Emergency Medicine; Glottis; Humans; Intubation, Intratracheal; Laryngoscopes; Laryngoscopy; Manikins; Video Recording; Young Adult; adult; algorithm; artificial intelligence; cross-sectional study; emergency health service; emergency medicine; endotracheal intubation; glottis; human; laryngoscope; laryngoscopy; manikin; procedures; videorecording; young adult},
	correspondence_address = {J.N. Carlson; Saint Vincent Health System, Emergency Medicine, Erie, 232 West 25th St, 16544, United States; email: JCarlson@svhs.org},
	publisher = {Taylor and Francis Ltd},
	issn = {10903127},
	coden = {PEMCF},
	pmid = {26986814},
	language = {English},
	abbrev_source_title = {Prehosp. Emerg. Care},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 15}
}

@CONFERENCE{Berrahal2016222,
	author = {Berrahal, Sarra and Boudriga, Noureddine and Bagula, Antoine},
	title = {Cooperative sensor-clouds for public safety services in infrastructure-less areas},
	year = {2016},
	journal = {Proceedings - Asia-Pacific Conference on Communications, APCC 2016},
	pages = {222 – 229},
	doi = {10.1109/APCC.2016.7581490},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994589055&doi=10.1109%2fAPCC.2016.7581490&partnerID=40&md5=f8b91c2c3794889eadc36994cdf1c591},
	affiliations = {Communication Networks and Security Research Lab., University of Carthage, Tunisia; Department of Computer Science, University of the Western Cape, South Africa},
	abstract = {The integration of wearable and integrated sensing technologies with cloud computing has the potential to promote the development of large-scale monitoring applications and to provide public safety as a service to end-users. In this paper, we proposed a system that relies on the integration of heterogeneous sensor networks and cloud computing to build distributed public safety databases and to provide cooperative composite services provisioning in infrastructure-less areas. The contributions are three fold. The first contribution consists in designing a Sensor-Clouds based architecture that integrates different WSNs and cloud computing and aims to report on the evolution of a particular set of public safety threats. The second contribution focuses on describing a system model for composite Sensor-Cloud services provisioning that allows to identify and classify the sensor-cloud services that can be made available to end-users regardless of the geographical distribution of sensor networks. The third contribution describes a two-layer composite service delivery in order to efficiently cover several services requested by end-users. While, the first level defines a static composite service delivery the second level defines dynamic composite services that are delivered and versioned based on a set of heuristics to address users' requirements and expectation. The proposed approach is evaluated through a simulation. © 2016 IEEE.},
	author_keywords = {composite services; infrastructure-less areas; query; sensor-cloud},
	keywords = {Cloud computing; Distributed computer systems; Geographical distribution; Sensor networks; Wearable technology; Web services; Composite services; Dynamic composites; Heterogeneous sensor networks; infrastructure-less areas; Integrated sensing; Large-scale monitoring; Public-safety threats; query; Distributed database systems},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-150900676-2},
	language = {English},
	abbrev_source_title = {Proc. - Asia-Pac. Conf. Commun., APCC},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8; Conference name: 22nd Asia-Pacific Conference on Communications, APCC 2016; Conference date: 25 August 2016 through 27 August 2016; Conference code: 124197}
}

@CONFERENCE{Williamson2015,
	author = {Williamson, James R. and Dumas, Andrew and Ciccarelli, Greg and Hess, Austin R. and Telfer, Brian A. and Buller, Mark J.},
	title = {Estimating load carriage from a body-worn accelerometer},
	year = {2015},
	journal = {2015 IEEE 12th International Conference on Wearable and Implantable Body Sensor Networks, BSN 2015},
	doi = {10.1109/BSN.2015.7299356},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84961591628&doi=10.1109%2fBSN.2015.7299356&partnerID=40&md5=aa58a256ed776ca5dfe6dad1f255269a},
	affiliations = {MIT Lincoln Laboratory, Lexington, 02421, MA, United States; U.S. Army Research Institute of Environmental Medicine, Natick, 01760, MA, United States},
	abstract = {Heavy loads increase the risk of musculoskeletal injury for foot soldiers and first responders. Continuous monitoring of load carriage in the field has proven difficult. We propose an algorithm for estimating load from a single body-worn accelerometer. The algorithm utilizes three different methods for characterizing torso movement dynamics, and maps the extracted dynamics features to load estimates using two machine learning multivariate regression techniques. The algorithm is applied, using leave-one-subject-out cross-validation, to two field collections of soldiers and civilians walking with varying loads. Rapid, accurate estimates of load are obtained, demonstrating robustness to changes in equipment configuration, walking conditions, and walking speeds. On soldier data with loads ranging from 45 to 89 lbs, load estimates result in mean absolute error (MAE) of 6.64 lbs and correlation of r = 0.81. On combined soldier and civilian data, with loads ranging from 0 to 89 lbs, results are MAE = 9.57 lbs and r = 0.91. © 2015 IEEE.},
	keywords = {Accelerometers; Artificial intelligence; Body sensor networks; Learning systems; Regression analysis; Walking aids; Wearable technology; Body-worn accelerometers; Continuous monitoring; Cross validation; Equipment configuration; First responders; Mean absolute error; Multivariate regression; Musculo-skeletal injuries; Wearable sensors},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-146737201-5},
	language = {English},
	abbrev_source_title = {IEEE Int. Conf. Wearable Implant. Body Sens. Netw., BSN},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 12; Conference name: 12th IEEE International Conference on Wearable and Implantable Body Sensor Networks, BSN 2015; Conference date: 9 June 2015 through 12 June 2015; Conference code: 118456}
}

@ARTICLE{Parker201734,
	author = {Parker, Richard and Vitalis, Antonios and Walker, Robyn and Riley, David and Pearce, H. Grant},
	title = {Measuring wildland fire fighter performance with wearable technology},
	year = {2017},
	journal = {Applied Ergonomics},
	volume = {59},
	pages = {34 – 44},
	doi = {10.1016/j.apergo.2016.08.018},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84986328047&doi=10.1016%2fj.apergo.2016.08.018&partnerID=40&md5=c4ca1071a3449302dc1b7dc3a4e5cabf},
	affiliations = {Scion, Christchurch, New Zealand; Massey University, Palmerston North, New Zealand; Health & Safety Laboratory, United Kingdom},
	abstract = {Wildland (rural) fire fighting is a physically demanding and hazardous occupation. An observational study was conducted to explore the use of new technologies for the field study of fire fighters at wildfires and to understand the work pressures of wildland fire fighting. The research was carried out with two fire fighters at real fires wearing microphones, miniature video cameras, heart rate monitors and GPS units to record their actions and location at wildfire events. The fire fighters were exposed to high physiological workloads (heart rates of up to 180 beats per minute) and walked considerable distances at the fires. Results from this study have been used in presentations to fire fighters and non-operational fire personnel to understand the pressures fire fighters are under and how others complete the fire fighting tasks. © 2016 Elsevier Ltd},
	author_keywords = {Fire fighting; Performance monitoring; Wearable technology; Wildland fire},
	keywords = {Adult; Firefighters; Fires; Geographic Information Systems; Heart Rate; Humans; Male; Monitoring, Ambulatory; Physical Exertion; Tape Recording; Task Performance and Analysis; Video Recording; Walking; Wireless Technology; Workload; Employment; Fire extinguishers; Fire fighting equipment; Heart; Patient monitoring; Video cameras; Wearable technology; Field studies; Fire fighters; Fire fighting; Heart-rate monitors; Observational study; Performance monitoring; Wildland fire; Work pressures; adult; Article; cardiovascular monitoring device; data collection method; energy expenditure; field study; fire; fire fighter; global positioning system; heart rate; heart rate monitor; human; human experiment; information processing device; job performance; male; microphone; observational study; occupational exposure; physiologic monitoring; productivity; task performance; videorecorder; walking; wildland fire; work pressure; workload; ambulatory monitoring; exercise; fire; geographic information system; physiology; prevention and control; recording; videorecording; wireless communication; workload; Fires},
	correspondence_address = {R. Parker; Scion, Christchurch, PO Box 29237, Riccarton, 8440, New Zealand; email: richard.parker@scionresearch.com},
	publisher = {Elsevier Ltd},
	issn = {00036870},
	coden = {AERGB},
	pmid = {27890146},
	language = {English},
	abbrev_source_title = {Appl. Ergon.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 16}
}

@ARTICLE{Jonassaint2009274,
	author = {Jonassaint, C.R. and Why, Y.P. and Bishop, G.D. and Tong, E.M. and Diong, S.M. and Enkelmann, H.C. and Khader, M. and Ang, J.},
	title = {The effects of Neuroticism and Extraversion on cardiovascular reactivity during a mental and an emotional stress task},
	year = {2009},
	journal = {International Journal of Psychophysiology},
	volume = {74},
	number = {3},
	pages = {274 – 279},
	doi = {10.1016/j.ijpsycho.2009.09.012},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-70449705851&doi=10.1016%2fj.ijpsycho.2009.09.012&partnerID=40&md5=ee7ba3a34705e52dce370fea686ac2fe},
	affiliations = {Duke University, United States; National University of Singapore, Singapore; Police Psychological Services Division, Singapore Police Force, Singapore},
	abstract = {Evidence suggests that physiological reactivity to mental and emotional stress may be influenced by personality traits. Objectives: This study aimed to examine the relationship between, emotionally based personality traits, Neuroticism (N) and Extraversion (E), and cardiovascular reactivity (CVR) during mental arithmetic (MA) and anger recall (AR). Methods: Heart rate, blood pressure, cardiac output and total peripheral resistance were measured in 114 Singaporean male patrol officers from the Singapore Police Force while they performed MA and AR tasks. N and E were assessed using the NEO PI-R. Results: Higher N was associated with lower DBP and TPRI reactivity during MA as compared to lower N, but higher TPRI reactivity during AR. Lower E scores were associated with heightened CVR while higher E scores were associated with lower CVR. For SBP and HR, E was associated with a reduction in reactivity across tasks; whereas, for DBP and TPRI this reduction was found only during AR. Conclusion: In this population, N had differential effects on CVR depending upon the nature of the stress task, cognitive or emotional. However, higher E was consistently linked to lower CVR during stress tasks and appeared to influence how individuals express and cope with anger. © 2009 Elsevier B.V. All rights reserved.},
	author_keywords = {Cardiovascular reactivity; Emotion; Extraversion; Neuroticism; Stress},
	keywords = {Adult; Anger; Blood Pressure; Extraversion (Psychology); Heart Rate; Humans; Male; Middle Aged; Neurotic Disorders; Personality; Psychomotor Performance; Stress, Psychological; Young Adult; adult; anger; arithmetic; article; blood pressure; cardiovascular response; controlled study; coping behavior; emotional stress; extraversion; heart output; heart rate; human; male; mental stress; neurosis; personality; police; questionnaire; recall; scoring system; Singapore; task performance; vascular resistance},
	correspondence_address = {G.D. Bishop; National University of Singapore, Singapore; email: psygb@nus.edu.sg},
	issn = {01678760},
	coden = {IJPSE},
	pmid = {19818369},
	language = {English},
	abbrev_source_title = {Int. J. Psychophysiol.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 43}
}

@CONFERENCE{Carapezza2015,
	author = {Carapezza, Edward M. and Sandy, Matt and Goldburt, Tim},
	title = {Mobile, portable lightweight wireless video recording solutions for homeland security, defense, and law enforcement applications},
	year = {2015},
	journal = {Proceedings of SPIE - The International Society for Optical Engineering},
	volume = {9456},
	doi = {10.1117/12.2193820},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84948845853&doi=10.1117%2f12.2193820&partnerID=40&md5=b369a60421d32f6de31146edc391c9c5},
	affiliations = {General Sensing Systems LLC, 250 Clearbrook Road, Suite 260, Elmsford, 10523, NY, United States; EMC Consulting LLC, 900 N. Stafford Street, Arlington, 22203, VA, United States},
	abstract = {It is desirable for executive officers of law enforcement agencies and other executive officers in homeland security and defense, as well as first responders, to have some basic information about the latest trend on mobile, portable lightweight wireless video recording solutions available on the market. This paper reviews and discusses a number of studies on the use and effectiveness of wireless video recording solutions. It provides insights into the features of wearable video recording devices that offer excellent applications for the category of security agencies listed in this paper. It also provides answers to key questions such as: how to determine the type of video recording solutions most suitable for the needs of your agency, the essential features to look for when selecting a device for your video needs, and the privacy issues involved with wearable video recording devices. © COPYRIGHT SPIE. Downloading of the abstract is permitted for personal use only.},
	keywords = {Law enforcement; National security; Security systems; Wearable technology; Essential features; Executive officers; First responders; Law-enforcement agencies; Privacy issue; Recording devices; Security agencies; Video recording},
	editor = {Carapezza E.M.},
	publisher = {SPIE},
	issn = {0277786X},
	isbn = {978-162841572-8},
	coden = {PSISD},
	language = {English},
	abbrev_source_title = {Proc SPIE Int Soc Opt Eng},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: Sensors, and Command, Control, Communications, and Intelligence (C3I) Technologies for Homeland Security, Defense, and Law Enforcement XIV; Conference date: 20 April 2015 through 22 April 2015; Conference code: 112732}
}

@ARTICLE{Maragh-Bass2017148,
	author = {Maragh-Bass, Allysha C. and Fields, Julie C. and McWilliams, Junette and Knowlton, Amy R.},
	title = {Challenges and Opportunities to Engaging Emergency Medical Service Providers in Substance Use Research: A Qualitative Study},
	year = {2017},
	journal = {Prehospital and Disaster Medicine},
	volume = {32},
	number = {2},
	pages = {148 – 155},
	doi = {10.1017/S1049023X16001424},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010901175&doi=10.1017%2fS1049023X16001424&partnerID=40&md5=0ad9fce387bde25f6ad89590f7290dcb},
	affiliations = {Center for Surgery and Public Health, Brigham and Women's Hospital, Harvard Schools of Medicine and Public Health, 2213 McElderry Street, Boston, 21205, MA, United States; Johns Hopkins Bloomberg School of Public Health, Department of Health Behavior and Society, Baltimore, MD, United States},
	abstract = {Introduction Research suggests Emergency Medical Services (EMS) over-use in urban cities is partly due to substance users with limited access to medical/social services. Recent efforts to deliver brief, motivational messages to encourage these individuals to enter treatment have not considered EMS providers. Problem Little research has been done with EMS providers who serve substance-using patients. The EMS providers were interviewed about participating in a pilot program where they would be trained to screen their patients for substance abuse and encourage them to enter drug treatment. Methods Qualitative interviews were conducted with Baltimore City Fire Department (BCFD; Baltimore, Maryland USA) EMS providers (N=22). Topics included EMS misuse, work demands, and views on participating in the pilot program. Interviews were transcribed and analyzed using grounded theory and constant-comparison. Results Participants were mostly white (68.1%); male (68.2%); with Advanced Life Skills training (90.9%). Mean age was 37.5 years. Providers described the frequent flyer problem (eg, EMS over-use by a few repeat non-emergent cases). Providers expressed disappointment with local health delivery due to resource limitations and being excluded from decision making within their administration, leading to reduced team morale and burnout. Nonetheless, providers acknowledged they are well-positioned to intervene with substance-using patients because they are in direct contact and have built rapport with them. They noted patients might be most receptive to motivational messages immediately after overdose revival, which several called hitting their bottom. Several stated that involvement with the proposed study would be facilitated by direct incorporation into EMS providers' current workflow. Many recommended that research team members accompany EMS providers while on-call to observe their day-to-day work. Barriers identified by the providers included time constraints to intervene, limited knowledge of substance abuse treatment modalities, and fearing negative repercussions from supervisors and/or patients. Despite reservations, several EMS providers expressed inclination to deliver brief motivational messages to encourage substance-using patients to consider treatment, given adequate training and skill-building. Conclusions Emergency Medical Service providers may have many demands, including difficult case time/resource limitations. Even so, participants recognized their unique position as first responders to deliver motivational, harm-reduction messages to substance-using patients during transport. With incentivized training, implementing this program could be life- and cost-saving, improving emergency and behavioral health services. Findings will inform future efforts to connect substance users with drug treatment, potentially reducing EMS over-use in Baltimore. Maragh-Bass AC, Fields JC, McWilliams J, Knowlton AR. © 2017 World Association for Disaster and Emergency Medicine.},
	author_keywords = {Emergency Medical Services; health care utilization; minority health; socioeconomic status; substance use; urban health},
	keywords = {Adult; Drug Overdose; Emergency Medical Technicians; Female; Humans; Interviews as Topic; Male; Naloxone; Narcotic Antagonists; Pilot Projects; Research Design; Substance Abuse, Intravenous; naloxone; narcotic antagonist; adult; drug overdose; female; human; interview; male; methodology; pilot study; prevention and control; rescue personnel; substance abuse},
	correspondence_address = {A.C. Maragh-Bass; Center for Surgery and Public Health, Brigham and Women's Hospital, Harvard Schools of Medicine and Public Health, Boston, 2213 McElderry Street, 21205, United States; email: arobin52@jhu.edu},
	publisher = {Cambridge University Press},
	issn = {1049023X},
	pmid = {28122657},
	language = {English},
	abbrev_source_title = {Prehospital Disaster Med.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6}
}

@CONFERENCE{Kress2014,
	author = {Kress, Bernard},
	title = {See through optical architectures for wearable displays},
	year = {2014},
	journal = {Optics InfoBase Conference Papers},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84906673748&partnerID=40&md5=353d9f11f7798254c9d54b38a3953d5f},
	affiliations = {Google, United States},
	abstract = {HUDs (Head Up Displays) and HMDs (Helmet Mounted Displays) have been with us for a few decades, providing exceptional optical performances for specialized defense applications. On the other hand, consumer electronics HMDs (Head Mounted Displays) have been lingering as personal gadgets for a mere decade. But recently, major companies have launched consumer compelling head mounted display solutions integrating both hardware, operating system as well as content, unlocking the decade long consumer HMD status-quo. As a result, we are witnessing today a fragmentation of the HMD market into various categories which have their very own specificity in terms of functionality, hardware and content. Such fragmentation is responsible for defining new distinct market segments such as consumer near to eye displays, social smart glasses, gaming headsets, as well as professional (engineering and technical) HMDs, specialized (medical, law enforcement, firefighting) HMDs and of course the previously existing defense market. We will be reviewing the different type of optical hardware used in such devices. © 2014 OSA.},
	keywords = {Commerce; Consumer electronics; Hardware; Optical design; Sensory perception; Turbulence; Defense markets; Head mounted displays; Head up displays; Market segment; Near-to-Eye display; Optical architectures; Optical performance; Wearable displays; Helmet mounted displays},
	correspondence_address = {B. Kress; Google, United States; email: bernard.kress@gmail.com},
	publisher = {Optical Society of American (OSA)},
	issn = {21622701},
	isbn = {978-155752308-2},
	language = {English},
	abbrev_source_title = {Opt.InfoBase Conf. Papers},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: Propagation Through and Characterization of Distributed Volume Turbulence, pcDVT 2014; Conference date: 13 July 2014 through 17 July 2014; Conference code: 107124}
}

@CONFERENCE{Backlund2013483,
	author = {Backlund, Per and Heldal, Ilona and Engstrom, Henrik and Johannesson, Mikael and Lebram, Mikael},
	title = {Collaboration patterns in mixed reality environments for a new emergency training center},
	year = {2013},
	journal = {Proceedings - UKSim-AMSS 7th European Modelling Symposium on Computer Modelling and Simulation, EMS 2013},
	pages = {483 – 488},
	doi = {10.1109/EMS.2013.81},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84899518844&doi=10.1109%2fEMS.2013.81&partnerID=40&md5=878761fa34759559f740d3d99820d1db},
	affiliations = {Informatics Research Centre, University of Skövde, Skövde, Sweden},
	abstract = {Training actors from public safety agencies (PSA), e.g. emergency medical services, fire departments, police departments involves different technologies and communication and collaboration activities. New technologies promise better support, not only for training, but also for logging relevant information for future analysis and learning. However, choosing the right technologies, defining proper set-ups for the training activities, and identifying premises for long-term use of technical facilities is both difficult and time consuming. Applying earlier lessons from evaluating work in Virtual Environments (VEs) [1], our aim is to develop a better understanding of the impact of new technologies by identifying collaboration patterns influencing training. Collaboration is examined via social, technical, and task related interaction, distinguishable in the different phases of training, from starting an alarm to ending the emergency activities. Our main results illustrate the benefits of (1) building scenarios, and training whole activity chains for certain rescue or other emergency activities, (2) using simulations for better understanding physical places, the task, and (3) distinguishing technical, social and task focused characteristics for factors influencing emergency focused collaboration. Moreover, the results also contribute to understanding the benefits of considering specific simulation technologies when training for emergency and rescue activities. © 2013 IEEE.},
	author_keywords = {collaboration; emergency; long-term; mixed reality environments; patterns; shared virtual environments; simulations; training},
	keywords = {Circuit simulation; Computer science; Computers; Personnel training; Software engineering; collaboration; emergency; long-term; Mixed-reality environment; patterns; Shared virtual environments; simulations; Virtual reality},
	publisher = {IEEE Computer Society},
	language = {English},
	abbrev_source_title = {Proc. - UKSim-AMSS Eur. Model. Symp. Comput. Model. Simul., EMS},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 12; Conference name: UKSim-AMSS 7th European Modelling Symposium on Computer Modelling and Simulation, EMS 2013; Conference date: 20 November 2013 through 22 November 2013; Conference code: 104642}
}

@ARTICLE{Chakraborty2017484,
	author = {Chakraborty, Anirban and Mandal, Bappaditya and Yuan, Junsong},
	title = {Person Reidentification Using Multiple Egocentric Views},
	year = {2017},
	journal = {IEEE Transactions on Circuits and Systems for Video Technology},
	volume = {27},
	number = {3},
	pages = {484 – 498},
	doi = {10.1109/TCSVT.2016.2615445},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015153080&doi=10.1109%2fTCSVT.2016.2615445&partnerID=40&md5=dc06bddbda1c54a841aaa3fde9720472},
	affiliations = {Rapid-Rich Object Search Laboratory, School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore, 639798, Singapore; Institute for Infocomm Research, Agency for Science Technology and Research, Singapore, 138632, Singapore},
	abstract = {Development of a robust and scalable multicamera surveillance system is the need of the hour to ensure public safety and security. Being able to reidentify and track one or more targets over multiple nonoverlapping camera field of views in a crowded environment remains an important and challenging problem because of occlusions, large change in the viewpoints, and illumination across cameras. However, the rise of wearable imaging devices has led to new avenues in solving the reidentification (re-id) problem. Unlike static cameras, where the views are often restricted or low resolution and occlusions are common scenarios, egocentric/first person views (FPVs) mostly get zoomed in, unoccluded face images. In this paper, we present a person re-id framework designed for a network of multiple wearable devices. The proposed framework builds on commonly used facial feature extraction and similarity computation methods between camera pairs and utilizes a data association method to yield globally optimal and consistent re-id results with much improved accuracy. Moreover, to ensure its utility in practical applications where a large amount of observations are available every instant, an online scheme is proposed as a direct extension of the batch method. This can dynamically associate new observations to already observed and labeled targets in an iterative fashion. We tested both the offline and online methods on realistic FPV video databases, collected using multiple wearable cameras in a complex office environment and observed large improvements in performance when compared with the state of the arts. © 2016 IEEE.},
	author_keywords = {Egocentric videos; face recognition; multicamera surveillance; person reidentification (re-id); wearable devices},
	keywords = {Cameras; Complex networks; Face recognition; Feature extraction; Iterative methods; Wearable technology; Egocentric videos; Facial feature extraction; Multi-camera surveillance; Multi-camera surveillance systems; Multiple nonoverlapping cameras; Person re identifications; Public safety and securities; Wearable devices; Security systems},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {10518215},
	coden = {ITCTE},
	language = {English},
	abbrev_source_title = {IEEE Trans Circuits Syst Video Technol},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; All Open Access, Green Open Access}
}

@ARTICLE{Lee2016,
	author = {Lee, Jaewoon and Kim, Dongho and Ryoo, Han-Young and Shin, Byeong-Seok},
	title = {Sustainable wearables: Wearable technology for enhancing the quality of human life},
	year = {2016},
	journal = {Sustainability (Switzerland)},
	volume = {8},
	number = {5},
	doi = {10.3390/su8050466},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84971320800&doi=10.3390%2fsu8050466&partnerID=40&md5=81a3503c21ef32aab4abc19e5518f446},
	affiliations = {Department of Digital Media, Graduate School, Soongsil University, 369 Sangdo-ro, Dongjak-gu, Seoul, 06978, South Korea; Division of Digital Media, Graduate School, Ewha Woman's University, 52 Ewhayeodae-gil, Seodaemun-gu, Seoul, 03760, South Korea; Department of Computer Science and Information Engineering, Inha University, 100 Inha-ro, Nam-gu, Incheon, 22212, South Korea},
	abstract = {This paper aims to elicit insights about sustainable wearables by investigating recent advancements in wearable technology and their applications. Wearable technology has advanced considerably from a technical perspective, but it has stagnated due to barriers without penetrating wider society despite early positive expectations. This situation is the motivation behind the focus on studies by many research groups in recent years into wearable applications that can provide the best value from a human-oriented perspective. The expectation is that a new means to resolve the issue can be found from a viewpoint of sustainability; this is the main point of this paper. This paper first focuses on the trend of wearable technology like bodily status monitoring, multi-wearable device control, and smart networking between wearable sensors. Second, the development intention of such technology is investigated. Finally, this paper discusses about the applications of current wearable technology from the sustainable perspective, rather than detailed description of the component technologies employed in wearables. In this paper, the definition of sustainable wearables is discussed in the context of improving the quality of individual life, social impact, and social public interest; those wearable applications include the areas of wellness, healthcare, assistance for the visually impaired, disaster relief, and public safety. In the future, wearables will not be simple data trackers or fun accessories but will gain extended objectives and meanings that play a valuable role for individuals and societies. Successful and sustainable wearables will lead to positive changes for both individuals and societies overall. © 2016 by the authors.},
	author_keywords = {Public interest; Sustainable wearables; The quality of life; Wearable technology},
	keywords = {health care; networking; public service; quality of life; research work; sensor; social impact; sustainable development; technical efficiency; technology policy},
	correspondence_address = {B.-S. Shin; Department of Computer Science and Information Engineering, Inha University, Nam-gu, Incheon, 100 Inha-ro, 22212, South Korea; email: bsshin@inha.ac.kr},
	publisher = {MDPI},
	issn = {20711050},
	language = {English},
	abbrev_source_title = {Sustainability},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 127; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Rais2009225,
	author = {Rais, N.H.M. and Soh, P.J. and Malek, F. and Ahmad, S. and Hashim, N.B.M. and Hall, P.S.},
	title = {A review of wearable antenna},
	year = {2009},
	journal = {Loughborough Antennas and Propagation Conference, LAPC 2009 - Conference Proceedings},
	pages = {225 – 228},
	doi = {10.1109/LAPC.2009.5352373},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-76149099904&doi=10.1109%2fLAPC.2009.5352373&partnerID=40&md5=cd468d73d6f379d39a367db3a3555960},
	affiliations = {School of Computer and Communication, University Malaysia Perlis (UniMAP), Kompleks Pengajian UniMAP Seberang Ramai, 02000 Kuala Perlis, Perlis, No. 12 and 14, Jln Satu, Malaysia; University of Birmingham, School of Engineering Electronic, Electrical and Computer Engineering, Edgbaston, Birmingham, B15 2TT, United Kingdom},
	abstract = {Utilization of wearable textiles in the antenna segment has been seen on the rise due to the recent miniaturization of wireless devices. A wearable antenna is meant to be a part of the clothing used for communication purposes, which includes tracking and navigation, mobile computing and public safety. This literature review intend to disclose this unconventional antenna technology and provides readers with the background of the wearable antenna that would include about specification of the antenna, material for the antenna and analysis that must be done to design proper wearable antennas. All the designs presented are of the recent development in wearable technology. ©2009 IEEE.},
	author_keywords = {Conductive textile antenna; Embody communication; Wearable antennas},
	keywords = {Textiles; Antenna technology; Conductive textile antenna; Conductive textiles; Literature reviews; Public safety; Wearable antennas; Wearable technology; Wireless devices; Mobile antennas},
	correspondence_address = {N. H. M. Rais; School of Computer and Communication, University Malaysia Perlis (UniMAP), Kompleks Pengajian UniMAP Seberang Ramai, 02000 Kuala Perlis, Perlis, No. 12 and 14, Jln Satu, Malaysia; email: nh_husna@yahoo.com.my},
	isbn = {978-142442720-8},
	language = {English},
	abbrev_source_title = {Loughborough Antennas Propag. Conf., LAPC - Conf. Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 239; Conference name: Loughborough Antennas and Propagation Conference, LAPC 2009; Conference date: 16 November 2009 through 17 November 2009; Conference code: 79283}
}

@CONFERENCE{Colunas20112157,
	author = {Colunas, Márcio F.M. and Fernandes, José M. Amaral and Oliveira, Ilídio C. and Silva Cunha, Joaõ P.},
	title = {Droid Jacket: Using an Android based smartphone for team monitoring},
	year = {2011},
	journal = {IWCMC 2011 - 7th International Wireless Communications and Mobile Computing Conference},
	pages = {2157 – 2161},
	doi = {10.1109/IWCMC.2011.5982868},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-80052461607&doi=10.1109%2fIWCMC.2011.5982868&partnerID=40&md5=e7aea678c4741b9b32ec03fb68ab9037},
	affiliations = {Institute of Electronics Engineering and Telematics (IEETA), Dep. of Electronics, Telecommunications and Informatics, University of Aveiro, Aveiro, Portugal},
	abstract = {Professionals such as First Responders are frequently exposed to extreme environmental conditions, which induce stress and fatigue during extensive periods of time. In this scenario, the main issues are the quantification and evaluation of stress and fatigue, since uncontrolled levels have a profound and negative impact on human health and performance. Based on an existing wearable monitoring solution - the Vital Jacket- we propose an individual and team monitoring mobile solution called DroidJacket. DroidJacket is based on Android mobile devices and provides data aggregation, processing, visualization and optionally relaying services. The DroidJacket design is plugin oriented, integrating analysis modules, namely an online ECG plugin for both real time pulse and arrhythmia detection. © 2011 IEEE.},
	author_keywords = {alarm detection; mobile computing; monitoring system; wearable technologies},
	keywords = {Data handling; Data visualization; Mobile devices; Visualization; Wireless telecommunication systems; Alarm detection; Arrhythmia detection; Data aggregation; Environmental conditions; First responders; Human health; Mobile solutions; monitoring system; Negative impacts; Plug-ins; Real time; Smart phones; Wearable technology; Mobile computing},
	correspondence_address = {M.F.M. Colunas; Institute of Electronics Engineering and Telematics (IEETA), Dep. of Electronics, Telecommunications and Informatics, University of Aveiro, Aveiro, Portugal; email: marcio@ua.pt},
	isbn = {978-142449539-9},
	language = {English},
	abbrev_source_title = {IWCMC - Int. Wirel. Commun. Mob. Comput. Conf.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 14; Conference name: 7th International Wireless Communications and Mobile Computing Conference, IWCMC 2011; Conference date: 4 July 2011 through 8 July 2011; Conference code: 86373}
}

@ARTICLE{Sokoloff2014,
	author = {Sokoloff, Catalina and Daoust, Raoul and Paquet, Jean and Chauny, Jean-Marc},
	title = {Is adequate pain relief and time to analgesia associated with emergency department length of stay? A retrospective study},
	year = {2014},
	journal = {BMJ Open},
	volume = {4},
	number = {3},
	doi = {10.1136/bmjopen-2013-004288},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84897511200&doi=10.1136%2fbmjopen-2013-004288&partnerID=40&md5=e5f7f6dbbb6818f6c981f70f74b6c2f8},
	affiliations = {Department of Emergency Medicine, Research Centre, Hôpital du Sacré-Cœur de Montréal, Montréal, QC, Canada; Faculty of Medicine, Université de Montréal, Montréal, QC, Canada; Department of Surgery, Centre for Advanced Research in Sleep Medicine, Hôpital du Sacré-Cœur de Montréal, Montreal, QC, Canada},
	abstract = {Objectives: Evaluate the association of adequate analgesia and time to analgesia with emergency department (ED) length of stay (LOS). Setting and Design: Post hoc analysis of real-time archived data. Participants: We included all consecutive ED patients ≥18 years with pain intensity >6 (verbal numerical scale from 0 to 10), assigned to an ED bed, and whose pain was re-evaluated less than 1 h after receiving analgesic treatment. Outcome measures: The main outcome was ED-LOS in patients who had adequate pain relief (AR=↓50% pain intensity) compared with those who did not have such relief (NR). Results: A total of 2033 patients (mean age 49.5 years; 51% men) met our inclusion criteria; 58.3% were discharged, and 41.7% were admitted. Among patients discharged or admitted, there was no significant difference in ED-LOS between those with AR (median (25th-75th centile): 9.6 h (6.3-14.8) and 18.2 h (11.6-25.7), respectively) and NR (median (25th-75th centile): 9.6 h (6.6-16.0) and 17.4 h (11.3-26.5), respectively). After controlling for confounding factors, rapid time to analgesia (not AR) was associated with shorter ED-LOS of discharged and admitted patients (p<0.001 and <0.05, respectively). When adjusting for confounding variables, ED-LOS is shortened by 2 h (95% CI 1.1 to 2.8) when delay to receive analgesic is <90 min compared with >90 min for discharged and by 2.3 h (95% CI 0.17 to 4.4) for admitted patients. Conclusions: In our study, AR was not linked with short ED-LOS. However, rapid administration of analgesia was associated with short ED-LOS.},
	keywords = {Adult; Aged; Ambulatory Care; Analgesia; Emergency Medical Services; Emergency Service, Hospital; Female; Hospitalization; Humans; Length of Stay; Male; Middle Aged; Pain; Pain Management; Patient Admission; Patient Discharge; Practice Patterns, Physicians'; Retrospective Studies; Severity of Illness Index; Time Factors; analgesic agent; abdominal pain; adult; analgesia; article; emergency care; emergency health service; emergency ward; female; hospital discharge; human; length of stay; major clinical study; male; pain; pain assessment; retrospective study; aged; ambulatory care; clinical practice; emergency health service; hospital admission; hospital discharge; hospitalization; middle aged; pain; severity of illness index; time factor},
	correspondence_address = {R. Daoust; Department of Emergency Medicine, Research Centre, Hôpital du Sacré-Cœur de Montréal, Montréal, QC, Canada; email: raoul.daoust@umontreal.ca},
	publisher = {BMJ Publishing Group},
	issn = {20446055},
	pmid = {24667382},
	language = {English},
	abbrev_source_title = {BMJ Open},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 33; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Mentler2015534,
	author = {Mentler, T. and Wolters, C. and Herczeg, M.},
	title = {Use cases and usability challenges for head-mounted displays in healthcare},
	year = {2015},
	journal = {Current Directions in Biomedical Engineering},
	volume = {1},
	number = {1},
	pages = {534 – 537},
	doi = {10.1515/cdbme-2015-0127},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84965171186&doi=10.1515%2fcdbme-2015-0127&partnerID=40&md5=625df729605adc6d1f0be17a66ba838e},
	affiliations = {Institute for Multimedia and Interactive Systems (IMIS), University of Lübeck, Ratzeburger Allee 160, Lübeck, 23562, Germany},
	abstract = {In the healthcare domain, head-mounted displays (HMDs) with augmented reality (AR) modalities have been reconsidered for application as a result of commercially available products and the needs for using computers in mobile context. Within a user-centered design approach, interviews were conducted with physicians, nursing staff and members of emergency medical services. Additionally practitioners were involved in evaluating two different head-mounted displays. Based on these measures, use cases and usability considerations according to interaction design and information visualization were derived and are described in this contribution.  © 2015 by Walter de Gruyter GmbH, Berlin/Boston 2015.},
	author_keywords = {Augmented Reality; Head-Mounted Display; Healthcare; Usability},
	keywords = {Augmented reality; Emergency services; Health care; Information systems; Medical computing; User centered design; Emergency medical services; Head mounted displays; Healthcare domains; Information visualization; Interaction design; Mobile context; Nursing staff; User-centered design approaches; Helmet mounted displays},
	correspondence_address = {T. Mentler; Institute for Multimedia and Interactive Systems (IMIS), University of Lübeck, Lübeck, Ratzeburger Allee 160, 23562, Germany; email: mentler@imis.uni-luebeck.de},
	publisher = {Walter de Gruyter GmbH},
	issn = {23645504},
	language = {English},
	abbrev_source_title = {Curr. Dir. Biomed. Eng.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; All Open Access, Gold Open Access}
}

@CONFERENCE{2012,
	title = {2012 International Conference on Telecommunications and Multimedia, TEMU 2012},
	year = {2012},
	journal = {2012 International Conference on Telecommunications and Multimedia, TEMU 2012},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84867774053&partnerID=40&md5=2a37c38d758d04611bf7af204a22d25b},
	abstract = {The proceedings contain 43 papers. The topics discussed include: a radio resource management framework for TVWS exploitation under the RTSSM policy; a spectrum aware routing protocol for public safety applications over cognitive radio networks; design of primary and composite routing metrics for RPL-compliant wireless sensor networks; geographical routing in wireless sensor networks; virtual router migration and infrastructure sleeping for energy management of IP over WDM networks; energy efficient load balancing in self organized share network; case study of a dimmable outdoor lighting system with intelligent management and remote control; a novel content-aware multipath routing concept exploiting random utility theory principles; towards 3D video delivery over heterogeneous networks: the ROMEO approach; connecting the dots: networked mixed reality applications and transmission quality; and network media ecosystems: the opportunity for network providers.},
	isbn = {978-146732781-7},
	language = {English},
	abbrev_source_title = {Int. Conf. Telecommun. Multimedia, TEMU},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2012 International Conference on Telecommunications and Multimedia, TEMU 2012; Conference date: 30 July 2012 through 1 August 2012; Conference code: 93298}
}

@ARTICLE{Cunha2012185,
	author = {Cunha, João Paulo Silva},
	title = {PHealth and wearable technologies: A permanent challenge},
	year = {2012},
	journal = {Studies in Health Technology and Informatics},
	volume = {177},
	pages = {185 – 195},
	doi = {10.3233/978-1-61499-069-7-185},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84866750867&doi=10.3233%2f978-1-61499-069-7-185&partnerID=40&md5=ff47ff406ab3dae8aba2b5e08399e841},
	affiliations = {DEEC, Faculty of Engineering, University of Porto, Portugal; IEETA, University of Aveiro, 3810-193, Aveiro, Campus Universitario de Santiago, Portugal},
	abstract = {Wearable technologies have been evolving towards daily usage and are a major player in the personalized health challenge. In this paper we present a personal view of their evolution, how one of them developed within our lab went to the international market and how this type of technology is being used in pHealth projects for first responder professionals and public transportation drivers. © 2012 The authors and IOS Press. All rights reserved.},
	author_keywords = {Firefighters; Professional drivers; Vital jacket; Vital signs monitoring; Wearable technologies},
	keywords = {Biotechnology; Diagnosis, Computer-Assisted; Equipment Design; Equipment Failure Analysis; Individualized Medicine; Monitoring, Ambulatory; Telemedicine; Telemetry; Health; International trade; Nanotechnology; Patient monitoring; Firefighters; International markets; Personalized healths; Professional drivers; Public transportation; Type of technology; Vital jacket; Vital signs monitoring; ambulatory monitoring; article; biotechnology; computer assisted diagnosis; equipment; equipment design; instrumentation; personalized medicine; telemedicine; telemetry; Wearable technology},
	correspondence_address = {J.P.S. Cunha; IEETA, University of Aveiro, 3810-193, Aveiro, Campus Universitario de Santiago, Portugal; email: jcunha@ieee.org},
	publisher = {IOS Press},
	issn = {09269630},
	isbn = {978-161499068-0},
	pmid = {22942053},
	language = {English},
	abbrev_source_title = {Stud. Health Technol. Informatics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 12; Conference name: 9th International Conference on Wearable Micro and Nano Technologies for Personalized Health, pHealth 2012; Conference date: 26 June 2012 through 28 June 2012; Conference code: null}
}

@CONFERENCE{Brandao2017297,
	author = {Brandao, William Losina and Pinho, Marcio Sarroglia},
	title = {Using augmented reality to improve dismounted operators' situation awareness},
	year = {2017},
	journal = {Proceedings - IEEE Virtual Reality},
	pages = {297 – 298},
	doi = {10.1109/VR.2017.7892294},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018405308&doi=10.1109%2fVR.2017.7892294&partnerID=40&md5=3298df32d37804de5468aee525ad4789},
	affiliations = {Virtual Reality Group, Computer Science School, PUCRS, Brazil},
	abstract = {Whether it in the military, law enforcement or private security, dismounted operators tend to deal with a large amount of volatile information that may or may not be relevant according to a variety of factors. In this paper we draft some ideas on the building blocks of an augmented reality system aimed to improve the situational awareness of dismounted operators by filtering, organizing, and displaying this information in a way that reduces the strain over the operator. © 2017 IEEE.},
	author_keywords = {Augmented Reality; Situation Awareness},
	keywords = {Augmented reality; Virtual reality; Augmented reality systems; Building blockes; Large amounts; Situation awareness; Situational awareness; Information filtering},
	publisher = {IEEE Computer Society},
	isbn = {978-150906647-6},
	language = {English},
	abbrev_source_title = {Proc. IEEE Virtual Real.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 10; Conference name: 19th IEEE Virtual Reality, VR 2017; Conference date: 18 March 2017 through 22 March 2017; Conference code: 127242}
}

@CONFERENCE{Abbas2016,
	author = {Abbas, Syed Muzahir and Ranga, Yogesh and Esselle, Karu P. and Hay, Stuart G.},
	title = {Recent developments in antennas with full ground planes for Wireless Body Area Networks (Invited Paper)},
	year = {2016},
	journal = {2015 International Symposium on Antennas and Propagation, ISAP 2015},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84966784025&partnerID=40&md5=2e222c7d7597f24db49d974d1953e1ce},
	affiliations = {Department of Engineering, Macquarie University, North Ryde, 2109, NSW, Australia; CSIRO Digital Productivity Flagship, PO Box 76, Epping, 1710, NSW, Australia},
	abstract = {This paper highlights recent developments in antennas with full ground planes, which have been designed for Wireless Body Area Networks (WBANs). These antennas are designed to provide single/dual band operation in 2.4GHz industrial, scientific and medical (ISM) band and 4.9GHz public safety wireless local area network (WLAN)/5GHz IEEE 802.11 WLAN bands. They have significant advantages of compactness, wide radiation pattern over the body surface, and less sensitivity to the variation of the gap between the antenna and the human body. These advantages make them suitable for on-body communications and wearable applications. © 2015 The Institute of Electronics, Information and Comm.},
	author_keywords = {Electromagnetically-coupled feed; Full ground plane; ISM; On-body communication; Printed antenna; Wearable antenna; Wireless body area network; Wireless body centric communication; WLAN},
	keywords = {Accident prevention; Antenna grounds; Chip scale packages; Directional patterns (antenna); Local area networks; Microstrip antennas; Networks (circuits); Sensitivity analysis; Standards; Wearable antennas; Wearable technology; Wireless networks; Body-centric communications; Ground planes; On-body; Wireless body area network; WLAN; Wireless local area networks (WLAN)},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-488552303-8},
	language = {English},
	abbrev_source_title = {Int. Symp. Antennas Propag., ISAP},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: International Symposium on Antennas and Propagation, ISAP 2015; Conference date: 9 November 2015 through 12 November 2015; Conference code: 121140}
}

@CONFERENCE{Chroust20091037,
	author = {Chroust, G. and Schönhacker, S. and Rainer, K. and Roth, M. and Ziehesberger, P.},
	title = {Training and supporting first responders by mixed reality environments},
	year = {2009},
	journal = {53rd Annual Conference of the International Society for the Systems Sciences 2009: Making Liveable, Sustainable Systems Unremarkable},
	volume = {2},
	pages = {1037 – 1054},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84865643031&partnerID=40&md5=a346c380ef4f9adfdf8ec43660c924bb},
	affiliations = {Inst. of Telecooperation, J. Kepler University, Linz, Austria; Research Institute, Red Cross Austria, Austria; Creative Bits, Traun, Austria; Ziehesberger Electronik, Neuhofen, Austria},
	abstract = {The perception and awareness of the possibilities of chemical, biological, radiological, and nuclear ("CBRN") emergencies is constantly growing. These dangers are in most cases not directly detectable by human senses and as a consequence no inborn or trained reflexes of reaction exist. One has to explicitly design and validate(!) special procedures ('Best Practices') to detect and to counter such dangers. These Best Practices have to be specifically trained, especially under near-realistic yet safe conditions. Modern technology allows to simulate actual situations (including the use of simulated tools) and the consequences of various courses of action in a realistic way. The overall goal of the SimRad.NCB project is the development and utilization of training tools for First Responders for all aspects of an intervention in emergency situations, including technical procedures, management, team coordination, etc. By taking a process view these interventions can be dissected into individual emergency processes and their subprocesses. This allows a pin-pointed substitution of some individual activities by a simulation, ranging from coarse approximations up to near-realistic simulations using Mixed Reality technology. This paper is an evolution and expansion of [Chroust et al., 2008] and will specifically emphasize the process point of view of these response actions and the corresponding simulation possibilities.},
	keywords = {Biology; Management; Radiology; Courses of actions; Emergency situation; First responders; Human sense; Mixed reality technologies; Mixed-reality environment; Modern technologies; Process view; Team coordination; Training tools; Virtual reality},
	correspondence_address = {G. Chroust; Inst. of Telecooperation, J. Kepler University, Linz, Austria; email: gc@sea.uni-linz.ac.at},
	isbn = {978-161567833-4},
	language = {English},
	abbrev_source_title = {Annu. Conf. Int. Soc. Syst. Sci.: Mak. Liveable, Sustainable Syst. Unremarkable},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; Conference name: 53rd Annual Conference of the International Society for the Systems Sciences 2009: Making Liveable, Sustainable Systems Unremarkable; Conference date: 12 July 2009 through 17 July 2009; Conference code: 92245}
}

@CONFERENCE{Holliman20161083,
	author = {Holliman, John and Zhivich, Michael and Khazan, Roger and Swiston, Albert and Telfer, Brian},
	title = {Building low-power trustworthy systems: Cyber-security considerations for Real-Time Physiological Status Monitoring},
	year = {2016},
	journal = {Proceedings - IEEE Military Communications Conference MILCOM},
	pages = {1083 – 1089},
	doi = {10.1109/MILCOM.2016.7795474},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011857412&doi=10.1109%2fMILCOM.2016.7795474&partnerID=40&md5=890480052e37acecc89a8446d1469ff8},
	affiliations = {MIT Lincoln Laboratory, Lexington, MA, United States},
	abstract = {Real-time monitoring of physiological data can reduce the likelihood of injury in noncombat military personnel and first-responders. MIT Lincoln Laboratory is developing a tactical Real-Time Physiological Status Monitoring (RT-PSM) system architecture and reference implementation named OBAN (Open Body Area Network), the purpose of which is to provide an open, government-owned framework for integrating multiple wearable sensors and applications. The OBAN implementation accepts data from various sensors enabling calculation of physiological strain information which may be used by squad leaders or medics to assess the team's health and enhance safety and effectiveness of mission execution. Security in terms of measurement integrity, confidentiality, and authenticity is an area of interest because OBAN system components exchange sensitive data in contested environments. In this paper, we analyze potential cyber-security threats and their associated risks to a generalized version of the OBAN architecture and identify directions for future research. The threat analysis is intended to inform the development of secure RT-PSM architectures and implementations. © 2016 IEEE.},
	author_keywords = {Biomedical monitoring; Hardware; Monitoring; Real-time systems; Security; Sensors; Software},
	keywords = {Computer hardware; Computer software; Electric power system security; Interactive computer systems; Military communications; Monitoring; Network architecture; Physiology; Sensors; Wearable sensors; Wearable technology; Biomedical monitoring; Measurement integrity; Physiological status; Physiological strains; Real time monitoring; Reference implementation; Security; System architectures; Real time systems},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-150903781-0},
	coden = {PMICE},
	language = {English},
	abbrev_source_title = {Proc IEEE Mil Commun Conf MILCOM},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 35th IEEE Military Communications Conference, MILCOM 2016; Conference date: 1 November 2016 through 3 November 2016; Conference code: 125573}
}

@ARTICLE{Desai2015187,
	author = {Desai, Soham Jayesh and Shoaib, Mohammed and Raychowdhury, Arijit},
	title = {An Ultra-Low Power, "Always-On" Camera Front-End for Posture Detection in Body Worn Cameras Using Restricted Boltzman Machines},
	year = {2015},
	journal = {IEEE Transactions on Multi-Scale Computing Systems},
	volume = {1},
	number = {4},
	pages = {187 – 194},
	doi = {10.1109/TMSCS.2015.2513741},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84975263676&doi=10.1109%2fTMSCS.2015.2513741&partnerID=40&md5=817241e65367a5889dc8e20ab11d051b},
	affiliations = {School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, 30332, GA, United States; Microsoft Research, Microsoft Corporation, Redmond, 98052-6399, WA, United States},
	abstract = {The Internet of Things (IoTs) has triggered rapid advances in sensors, surveillance devices, wearables and body area networks with advanced Human-Computer Interfaces (HCI). One such application area is the adoption of Body Worn Cameras (BWCs) by law enforcement officials. The need to be "always-on" puts heavy constraints on battery usage in these camera front-ends, thus limiting their widespread adoption. Further, the increasing number of such cameras is expected to create a data deluge, which requires large processing, transmission and storage capabilities. Instead of continuously capturing and streaming or storing videos, it is prudent to provide "smartness" to the camera front-end. This requires hardware assisted image recognition and template matching in the front-end, capable of making judicious decisions on when to trigger video capture or streaming. Restricted Boltzmann Machines (RBMs) based neural networks have been shown to provide high accuracy for image recognition and are well suited for low power and re-configurable systems. In this paper we propose an RBM based "always-on" camera front-end capable of detecting human posture. Aggressive behavior of the human being in the field of view will be used as a wake-up signal for further data collection and classification. The proposed system has been implemented on a Xilinx Virtex 7 XC7VX485T platform. A minimum dynamic power of 19.18 mW for a target recognition accuracy while maintaining real time constraints has been measured. The hardware-software co-design illustrates the trade-offs in the design with respect to accuracy, resource utilization, processing time and power. The results demonstrate the possibility of a true 'always-on' body-worn camera system in the IoT environment. © 2015 IEEE.},
	author_keywords = {Algorithms implemented in hardware; Object recognition; Reconfigurability},
	keywords = {Behavioral research; Computer hardware; Digital storage; Economic and social effects; Hardware; Hardware-software codesign; Human computer interaction; Image matching; Image recognition; Low power electronics; Network security; Networks (circuits); Object recognition; Reconfigurable hardware; Template matching; Wearable technology; Algorithms implemented-in-hardware; Human computer interfaces; Internet of thing (IoTs); Real time constraints; Reconfigurability; Resource utilizations; Restricted boltzmann machine; Surveillance devices; Cameras},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {23327766},
	language = {English},
	abbrev_source_title = {IEEE Trans. Multi-Scale Comput. Syst.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 14}
}

@ARTICLE{Tomich2013499,
	author = {Tomich, Jennifer and Retrouvey, Michele and Shaves, Sarah},
	title = {Emergency imaging discrepancy rates at a level 1 trauma center: Identifying the most common on-call resident "misses"},
	year = {2013},
	journal = {Emergency Radiology},
	volume = {20},
	number = {6},
	pages = {499 – 505},
	doi = {10.1007/s10140-013-1146-4},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84890551034&doi=10.1007%2fs10140-013-1146-4&partnerID=40&md5=12aa5fb72d899de06e3e133d7093a68d},
	affiliations = {Department of Radiology, Eastern Virginia Medical School, Norfolk, VA 23501, P.O. Box 1980, United States},
	abstract = {The focus of our research is to identify the most frequently reported on-call discrepancies at our hospital by modality and level of resident training. Our intent is to identify specific areas of concern that may be amenable to improvement through initiation of dedicated resident training in the field of emergency radiology. Our study included 648 significant discrepancies from 193,722 studies ordered through the emergency department over a 7-year period. The overall discrepancy rates were calculated for each resident level of training and modality type. Significance was determined using χ2 testing with α = 0.05. The most common types of discrepancies were identified. The overall rate of reported discrepancies was low for all levels of training (0.23-0.42 %) with a small, but statistically significant, decrease in rate for the senior residents. Common categories of discrepancies for all residents included fractures on radiographs (XR) and computed tomography (CT), masses and hemorrhage on CT, and lung nodules and pulmonary infiltrates on radiographs. Specific discrepancies reported more frequently for new call-takers included phalangeal fractures on XR as well as white matter disease, hepatic lacerations, pyelonephritis, peritoneal fluid, lymphadenopathy, and pneumothoraces on CT. It is our recommendation that radiology resident training programs ensure that the common discrepancies illustrated herein are specifically addressed as part of a dedicated emergency radiology course. © 2013 Am Soc Emergency Radiol.},
	author_keywords = {Discrepancy; Emergency; Error; Resident},
	keywords = {Diagnostic Errors; Educational Measurement; Emergency Medical Services; Emergency Medicine; Fractures, Malunited; Humans; Internship and Residency; Radiology; abscess; article; bleeding; bone lesion; bone radiography; brain infarction; cervical spine fracture; computer assisted tomography; echography; emergency health service; face fracture; finger fracture; fluoroscopy; health care disparity; human; liver injury; lung embolism; lung infiltrate; lung nodule; lymphadenopathy; nuclear medicine; peritoneal fluid; pneumothorax; priority journal; pyelonephritis; residency education; skull fracture; thorax radiography; white matter lesion},
	correspondence_address = {J. Tomich; Department of Radiology, Eastern Virginia Medical School, Norfolk, VA 23501, P.O. Box 1980, United States; email: j.tomich@hotmail.com},
	issn = {14381435},
	coden = {EMRAF},
	pmid = {23887692},
	language = {English},
	abbrev_source_title = {Emerg. Radiol.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 12}
}

@CONFERENCE{Sanni20171152,
	author = {Sanni, S. and Sharples, J.J. and Gill, A.M. and Jovanoski, Z. and Sidhu, H.S. and Towers, I.N.},
	title = {A stochastic differential equation approach to modelling the growth phase of fire spread},
	year = {2017},
	journal = {Proceedings - 22nd International Congress on Modelling and Simulation, MODSIM 2017},
	pages = {1152 – 1158},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85080868986&partnerID=40&md5=110289cd918c9bd6f07a632264681f55},
	affiliations = {School of Physical, Environmental and Mathematical Sciences, UNSW, Canberra, 2600, ACT, Australia},
	abstract = {From a point source, landscape fires accelerate until they reach a quasi-equilibrium rate of spread. The rate at which a fire accelerates from its ignition affects the time first responders have to attack a fire in its initial stages when it is more easily suppressed. As such, knowledge of the rate of acceleration of a fire from ignition can be valuable from a fire management perspective. However, the majority of studies in wildland fire science have been dedicated to development of models for the quasi-equilibrium rate of spread attained by the fire after its acceleration phase. Comparatively little attention has been given to the development of models that specifically account for the growth phase of a fires development. The rate of acceleration depends on many factors including variations in ambient and induced wind speed and direction, variation in moisture content of the fuel, fuel stratification and slope variation. Present models of fire growth from a point ignition are expressed as deterministic algebraic equations, thereby neglecting variability. The numerous variables involved make predictions of rate of spread from a point source very difficult. In this paper we consider two approaches to model the acceleration phase of a fire. The first considers fitting a sigmoidal function to experimental data using a nonlinear curve-fitting procedure. The model takes the following functional form: R0 Re R(t) = (R0 + (Re − R0) exp (−at)) , where R(t) is the rate of spread at any time t. The parameters R0 and Re are the initial and quasi-equilibrium rate of spread respectively, and a is the growth rate. In the second approach we propose the use of stochastic differential equations to investigate the growth of a fire to quasi-equilibrium. Specifically, the model is given by the following stochastic differential equation: dR = aR ( 1 − RRe) dt + σR dW, subject to the initial condition R(0) = R0. Here, W is a Wiener process. In addition to providing a more realistic portrayal of the time series data relating to fire growth, t his second approach allows for better discrimination of the mechanisms driving the growth phase of fire spread. The models are assessed by appealing to observations of experimental fire growth. Specifically the data relate to fires growing from a point ignition under the influence of a uniform wind. The results indicate that both approaches can provide an accurate representation of the observed data, but that the approach based on stochastic differential equations yields 95% confidence bounds that are higher than those obtained from the nonlinear curve-fitting. The difference in confidence bounds indicates that the way stochasticity is incorporated into fire growth models has implications for how models inform decisions about the likelihood of a fire self-extinguishing before it reaches quasi-equilibrium, and the magnitude of the rates of spread it is likely to exhibit during the initial stages of growth. © 2017 Proceedings - 22nd International Congress on Modelling and Simulation, MODSIM 2017. All rights reserved.},
	author_keywords = {Fire acceleration; Fire growth; Rate of spread; Stochastic differential equations; Stochastic processes},
	keywords = {Acceleration; Curve fitting; Differential equations; Fire protection; Nonlinear equations; Operations research; Random processes; Risk assessment; Stochastic models; Stochastic systems; Wind; Acceleration phase; Algebraic equations; Fire growth; Fuel stratification; Nonlinear curve fitting; Sigmoidal functions; Stochastic differential equations; Wind speed and directions; Fires},
	editor = {Syme G. and MacDonald D.H. and Fulton B. and Piantadosi J.},
	publisher = {Modelling and Simulation Society of Australia and New Zealand Inc. (MSSANZ)},
	isbn = {978-098721437-9},
	language = {English},
	abbrev_source_title = {Proc. - Int. Congr. Model. Simul., MODSIM},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 22nd International Congress on Modelling and Simulation: Managing Cumulative Risks through Model-Based Processes, MODSIM 2017 - Held jointly with the 25th National Conference of the Australian Society for Operations Research and the DST Group led Defence Operations Research Symposium, DORS 2017; Conference date: 3 December 2017 through 8 December 2017; Conference code: 157783}
}

@CONFERENCE{Rahnama2011489,
	author = {Rahnama, Hossein and Jamshidi, Sina and Johns, Stephen and Shepard, Alan},
	title = {CAMPUS: Context aware mobile platform for uniformed security},
	year = {2011},
	journal = {UbiComp'11 - Proceedings of the 2011 ACM Conference on Ubiquitous Computing},
	pages = {489 – 490},
	doi = {10.1145/2030112.2030185},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-80054066397&doi=10.1145%2f2030112.2030185&partnerID=40&md5=19d38a1cee66ebd80a6054a05878a72a},
	affiliations = {Ryerson University, Toronto, ON, Canada},
	abstract = {The Context Aware Mobile Platform for Uniformed Security (CAMPUS) system was developed with the aim of using ambient intelligence and mobile communications to information sources as an aid to field security and law enforcement personnel. The system is centered on a context aware information distribution framework and a client operating on a head mounted display. The system allows field service personnel to receive information relevant to their current operations, review information from sensors, and communicate with colleagues while remaining vigilant during security and law enforcement operations. Sensor integration and mapping technologies are the key elements in provisioning of appropriate information services. © 2011 Authors.},
	author_keywords = {context awareness; field security; law enforcement; mobile systems; ubiquitous computing},
	keywords = {Display devices; Human computer interaction; Information services; Law enforcement; Mobile phones; Sensors; Ubiquitous computing; Ambient intelligence; Context- awareness; Context-Aware; field security; Field services; Head mounted displays; Information distributions; Information sources; Key elements; Law enforcement personnel; Mobile communications; Mobile platform; Mobile systems; Sensor integration; Mobile telecommunication systems},
	correspondence_address = {H. Rahnama; Ryerson University, Toronto, ON, Canada; email: hossein@ryerson.ca},
	isbn = {978-145030910-3},
	language = {English},
	abbrev_source_title = {UbiComp - Proc. ACM Conf. Ubiquitous Comput.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 13th International Conference on Ubiquitous Computing, UbiComp'11 and the Co-located Workshops; Conference date: 17 September 2011 through 21 September 2011; Conference code: 86942}
}

@CONFERENCE{You2017385,
	author = {You, Zhenwei and Liu, Jian and Hou, Wenjun and Wang, Xiaochun and Liu, Wei and Song, Wu},
	title = {A wearable system designed for Chinese traffic police based on gesture recognition},
	year = {2017},
	journal = {Advances in Transdisciplinary Engineering},
	volume = {5},
	pages = {385 – 393},
	doi = {10.3233/978-1-61499-779-5-385},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032871804&doi=10.3233%2f978-1-61499-779-5-385&partnerID=40&md5=29c77321744ca0a7608dfdde0fd3b7e3},
	affiliations = {Beijing University of Posts and Telecommunications, China; Beijing University of Technology, China; Beijing Normal University, China; Huaqiao University, China},
	abstract = {The body language and gestures of the traffic police can be difficult to identify accurately, especially in China, where there is often fog and haze. Poor judgment and slow recognition will reduce the efficiency of traffic management, and can even cause traffic accidents. To solve this problem, a wearable system has been designed for the traffic police. This wearable system consists of two main parts: a pair of data gloves and a vest with a light-emitting diode (LED) display. The data gloves were utilized to recognize and record the gestures of the traffic police. The gesture signals were converted into traffic instructions and displayed on the vest. The effectiveness of this wearable system was verified through a comparison experiment between only gesture and gesture plus displaying text on the vest. To achieve best effects of recognition, according to the results of further experiment, the simple instructions (stop, move straight, turn left waiting, turn right, and change lane) should be displayed in the form of an image, whereas the complex instructions (turn left, wait, slow down, and pull over) should be displayed in text form. © 2017 The authors and IOS Press.},
	author_keywords = {Data gloves; Efficiency of text and image; Gesture recognition; Traffic control; Traffic instructions; Vest with LED display; Wearable system},
	keywords = {Character recognition; Efficiency; Law enforcement; Light emitting diodes; Traffic control; Wearable technology; Body language; Change lane; Chinese traffic polices; Data glove; Fog and haze; LED display; Traffic management; Wearable systems; Gesture recognition},
	correspondence_address = {J. Liu; Beijing University of Technology, China; email: ljym66@163.com},
	editor = {Peruzzini M. and Wognum N. and Stjepandic J. and Chen C.-H. and Wognum N. and Trappey A.C.},
	publisher = {IOS Press BV},
	isbn = {978-161499439-8},
	language = {English},
	abbrev_source_title = {Adv. Transdiscipl. Eng.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 24th ISPE Inc. International Conference on Transdisciplinary Engineering, TE 2017; Conference date: 10 July 2017 through 14 July 2017; Conference code: 128611}
}

@ARTICLE{De Wulf2015553,
	author = {De Wulf, Annelies and Aluisio, Adam R. and Muhlfelder, Dana and Bloem, Christina},
	title = {Emergency Care Capabilities in North East Haiti: A Cross-sectional Observational Study},
	year = {2015},
	journal = {Prehospital and Disaster Medicine},
	volume = {30},
	number = {6},
	pages = {553 – 559},
	doi = {10.1017/S1049023X15005221},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959572704&doi=10.1017%2fS1049023X15005221&partnerID=40&md5=3d1fe3ece770c5bb7b93deba9134b101},
	affiliations = {Section of Emergency Medicine, Division of International Emergency Medicine, Louisiana State University Health Sciences Center, 2000 Canal Street, New Orleans, 70112, LI, United States; Department of Emergency Medicine, Division of International Emergency Medicine, SUNY Downstate Medical Center, Brooklyn, NY, United States},
	abstract = {Introduction The North East Department is a resource-limited region of Haiti. Health care is provided by hospitals and community clinics, with no formal Emergency Medical System and undefined emergency services. As a paucity of information exists on available emergency services in the North East Department of Haiti, the objective of this study was to assess systematically the existing emergency care resources in the region. Methods This cross-sectional observational study was carried out at all Ministry of Public Health and Population (MSPP)-affiliated hospitals in the North East Department and all clinics within the Fort Liberté district. A modified version of the World Health Organization (WHO) Tool for Situational Analysis to Assess Emergency and Essential Surgical Care and Generic Essential Emergency Equipment Lists were completed for each facility. Results Three MSPP hospitals and five clinics were assessed. Among hospitals, all had a designated emergency ward with 24 hour staffing by a medical doctor. All hospitals had electricity with backup generators and access to running water; however, none had potable water. All hospitals had x-ray and ultrasound capabilities. No computed tomography scanners existed in the region. Invasive airway equipment and associated medications were not present consistently in the hospitals' emergency care areas, but they were available in the operating rooms. Pulse oximetry was unavailable uniformly. One hospital had intermittently functioning defibrillation equipment, and two hospitals had epinephrine. Basic supplies for managing obstetrical and traumatic emergencies were available at all hospitals. Surgical services were accessible at two hospitals. No critical care services were available in the region. Clinics varied widely in terms of equipment availability. They uniformly had limited emergency medical equipment. The clinics also had inconsistent access to basic assessment tools (sphygmomanometers 20% and stethoscopes 60%). A protocol for transferring patients requiring a higher level of care was present in most (80%) clinics and one of the hospitals. However, no facility had a written protocol for transferring patients to other facilities. One hospital reported intermittent access to an ambulance for transfers. Conclusions Deficits in the supply of emergency equipment and limited protocols for inter-facility transfers exist in North East Department of Haiti. These essential areas represent appropriate targets for interventions aimed at improving access to emergency care within the North East region of Haiti. De Wulf A, Aluisio AR, Muhlfelder D, Bloem C. © World Association for Disaster and Emergency Medicine 2015.},
	author_keywords = {Developing countries; Emergency treatment; Haiti; Needs assessment; World Health Organization},
	keywords = {Cross-Sectional Studies; Emergency Medical Services; Equipment and Supplies, Hospital; Haiti; Health Resources; Health Services Accessibility; Hospitals; Humans; World Health Organization; cross-sectional study; emergency health service; Haiti; health care delivery; health care planning; hospital; hospital equipment; human; statistics and numerical data; supply and distribution; world health organization},
	correspondence_address = {A. De Wulf; Section of Emergency Medicine, Division of International Emergency Medicine, Louisiana State University Health Sciences Center, New Orleans, 2000 Canal Street, 70112, United States; email: annelies_de_wulf@hotmail.com},
	publisher = {Cambridge University Press},
	issn = {1049023X},
	pmid = {26487267},
	language = {English},
	abbrev_source_title = {Prehospital Disaster Med.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 12}
}

@ARTICLE{Finigan2011288,
	author = {Finigan, Michael W. and Perkins, Tamara and Zold-Kilbourn, Phyllis and Parks, Joseph and Stringer, Mark},
	title = {Preliminary evaluation of extended-release naltrexone in Michigan and Missouri drug courts},
	year = {2011},
	journal = {Journal of Substance Abuse Treatment},
	volume = {41},
	number = {3},
	pages = {288 – 293},
	doi = {10.1016/j.jsat.2011.04.003},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-80052328435&doi=10.1016%2fj.jsat.2011.04.003&partnerID=40&md5=6db701827962652bc548ba591ea315aa},
	affiliations = {Northwest Professional Consortium, Inc., Portland OR, United States; Under contract to Northwest Professional Consortium, Inc., Portland OR, United States; Missouri Department of Mental Health, Jefferson City, MO, United States},
	abstract = {This pilot study, a retrospective case series analysis, examined the feasibility and effectiveness of treating alcohol dependence with extended-release naltrexone (XR-NTX) in the drug court setting. In two Michigan courts and in one Missouri court, 32 clients were treated with XR-NTX and were matched with 32 clients with standard care in an open-label, voluntary recruitment design. Treatment with XR-NTX was associated with relative risk reductions (RRRs; p = ns) of 57% fewer missed drug court sessions, a 35% reduction in the monthly ratio of positive drug and alcohol tests to total tests, and 35% fewer individuals with greater than 25% overall positive alcohol or drug tests. In the principal end-point analysis of annualized number of new arrests, 26% of standard-care clients were rearrested versus 8% on XR-NTX (RRR = 69%; p <.05). Treatment with XR-NTX appeared to be feasible and was associated with a consistently large treatment effect across multiple outcomes relevant to the drug court setting. © 2011.},
	author_keywords = {Alcohol dependence; Criminal justice; Law enforcement; Naltrexone; Vivitrol},
	keywords = {Adult; Alcohol Drinking; Alcoholism; Automobile Driving; Criminal Law; Delayed-Action Preparations; Female; Humans; Injections, Intramuscular; Male; Michigan; Missouri; Naltrexone; Narcotic Antagonists; Pilot Projects; Retrospective Studies; Substance Abuse Detection; Substance Withdrawal Syndrome; Temperance; naltrexone; alcoholism; article; clinical article; controlled study; court; drug efficacy; drug screening; female; human; male; priority journal; United States},
	correspondence_address = {M.W. Finigan; Northwest Professional Consortium, Inc., Portland, OR 97239, 4380 SW Macadam Ave., Ste. 530, United States; email: finigan@npcresearch.com},
	issn = {18736483},
	coden = {JSATE},
	pmid = {21696912},
	language = {English},
	abbrev_source_title = {J. Subst. Abuse Treat.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 28; All Open Access, Bronze Open Access}
}

@ARTICLE{201741,
	title = {High visibility apparel: Providing protection, safety, comfort and style},
	year = {2017},
	journal = {Performance Apparel Markets},
	volume = {1},
	number = {58},
	pages = {41 – 95},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017814226&partnerID=40&md5=e91cad4f9aae5e807021699451aabcc7},
	abstract = {High visibility apparel plays a critical role in making the jobs of those who work in hazardous environments safer. As such, it is especially appropriate for workers such as airport ground crews, firefighters, highway maintenance workers, railway workers and utility workers as well as first responders and other emergency services personnel. High visibility apparel is also used increasingly to minimise the risk of traffic accidents among members of the public who use the roads-including vehicle drivers and cyclists. Within the market for high visibility apparel, the most important area is that of high visibility protective apparel, and demand for such apparel is expected to grow as a result of higher levels of safety awareness worldwide and rapid industrialisation in developing countries. High visibility materials have also found their way into an increasing number of apparel categories, including casualwear, fashionwear, sportswear and even pet wear. This increase in the number of apparel categories is particularly important for producers of retroreflective materials-including retroreflective sewing threads-which are being used to add attractive design details to garments. Also aiding the development of high visibility materials have been advances in wearable technology-which has been embraced by a number of providers of high visibility workwear as well as providers of cycling apparel. These advances have led, for example, to the development of washable high visibility garments which incorporate light emitting diodes (LEDs). © Textiles Intelligence Limited 2017.},
	publisher = {Textiles Intelligence Ltd.},
	issn = {14776456},
	language = {English},
	abbrev_source_title = {Perform. Apparel Mark.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4}
}

@CONFERENCE{Kress2014,
	author = {Kress, Bernard},
	title = {See through optical architectures for wearable displays},
	year = {2014},
	journal = {Optics InfoBase Conference Papers},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84906664123&partnerID=40&md5=d356dab1342369820de621802ee749f7},
	affiliations = {Google, United States},
	abstract = {HUDs (Head Up Displays) and HMDs (Helmet Mounted Displays) have been with us for a few decades, providing exceptional optical performances for specialized defense applications. On the other hand, consumer electronics HMDs (Head Mounted Displays) have been lingering as personal gadgets for a mere decade. But recently, major companies have launched consumer compelling head mounted display solutions integrating both hardware, operating system as well as content, unlocking the decade long consumer HMD status-quo. As a result, we are witnessing today a fragmentation of the HMD market into various categories which have their very own specificity in terms of functionality, hardware and content. Such fragmentation is responsible for defining new distinct market segments such as consumer near to eye displays, social smart glasses, gaming headsets, as well as professional (engineering and technical) HMDs, specialized (medical, law enforcement, firefighting) HMDs and of course the previously existing defense market. We will be reviewing the different type of optical hardware used in such devices. © 2014 OSA.},
	keywords = {Commerce; Consumer electronics; Hardware; Imaging systems; Optical design; Sensory perception; Defense markets; Head mounted displays; Head up displays; Market segment; Near-to-Eye display; Optical architectures; Optical performance; Wearable displays; Helmet mounted displays},
	correspondence_address = {B. Kress; Google, United States; email: bernard.kress@gmail.com},
	publisher = {Optical Society of American (OSA)},
	issn = {21622701},
	isbn = {978-155752308-2},
	language = {English},
	abbrev_source_title = {Opt.InfoBase Conf. Papers},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: Imaging Systems and Applications, ISA 2014; Conference date: 13 July 2014 through 17 July 2014; Conference code: 107130}
}

@ARTICLE{Rainer2009297,
	author = {Rainer, Karin and Sturm, Nadine and Schönhacker, Stefan and Chroust, Gerhard},
	title = {SimRad.NBC - Simulation and information system for rescue units at CBRN disasters},
	year = {2009},
	journal = {Studies in Computational Intelligence},
	volume = {237},
	pages = {297 – 303},
	doi = {10.1007/978-3-642-03214-1_34},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-78049280666&doi=10.1007%2f978-3-642-03214-1_34&partnerID=40&md5=76ade144449d0fbb599eaf78a0cfef65},
	affiliations = {Research Institute of the Red Cross, Vienna 1030, Nottendorfer Gasse 21, Austria; Institute of Telecooperation, J. Kepler Univ. Linz, Linz 4040, Altenbergerstr. 69, Austria},
	abstract = {The importance of effective response to chemical, biological, radiological and nuclear (CBRN) dangers is growing constantly. These hazards are not directly detectable by human senses and thus no inborn reactions exist. As a consequence, special tools to detect these dangers have to be utilized. Although some "simulation games" try to portray certain levels of management of CBRN incidents, there is a substantial lack of realistic and holistic training instruments for First Responders. The project SimRad creates the basis for a user centered, systematic technology for training and communication in emergency situations using a process view. This includes real life Best Practices of effective management of CBRN crises and First Responder education. It provides the foundation for near-realistic simulations for training of individual subprocesses and communication methods by the use of software intensive simulation technologies such as Mixed Reality. © 2009 Springer-Verlag Berlin Heidelberg.},
	correspondence_address = {K. Rainer; Research Institute of the Red Cross, Vienna 1030, Nottendorfer Gasse 21, Austria; email: karin.rainer@w.roteskreuz.at},
	editor = {Papadopoulos G.A. and University of Cyprus, Department of Computer Science, Nicosia, CY-1678},
	issn = {1860949X},
	isbn = {978-364203213-4},
	language = {English},
	abbrev_source_title = {Stud. Comput. Intell.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5}
}

@CONFERENCE{Sesay20174266,
	author = {Sesay, Abdul and Ramirez, Ronald and Oh, On-Ook},
	title = {Digital transformation in police work: A sociomaterial perspective on police body worn cameras (BWC)},
	year = {2017},
	journal = {Proceedings of the Annual Hawaii International Conference on System Sciences},
	volume = {2017-January},
	pages = {4266 – 4275},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072964330&partnerID=40&md5=70bf647c281411990f1ab48f4b27551c},
	affiliations = {University of Colorado, Denver, United States},
	abstract = {The need to augment human capabilities through computer-based technologies, and a belief in the “objectivity” of data has contributed to the popularity of wearables. Such is the case with BWCs and their proliferation in police organizations. Unfortunately, BWCs have not been studied from an IS perspective, using specific or complementary theories applied in IS. We address this gap with a case study of a mid-sized police department, using a sociomaterial lens. We find that BWCs have triggered significant unanticipated changes in police practice. The impacts of these changes are not uniformly distributed. Rank-and-file patrol officers carry the burden upfront, while evidence technicians are burdened on the backend. We contribute by providing an actual account of the changes and impacts of BWCs in policing; providing initial evidence of how BWCs meet policing goals; and demonstrating the applicability of sociomateriality in explicating wearable technologies in general, and BWCs in particular. © 2017 Proceedings of the Annual Hawaii International Conference on System Sciences. All rights reserved.},
	keywords = {Wearable technology; Complementary theories; Computer based technologies; Digital transformation; Human capability; Patrol officer; Socio materialities; Law enforcement},
	editor = {Bui T.X. and Sprague R.},
	publisher = {IEEE Computer Society},
	issn = {15301605},
	isbn = {978-099813310-2},
	language = {English},
	abbrev_source_title = {Proc. Annu. Hawaii Int. Conf. Syst. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; Conference name: 50th Annual Hawaii International Conference on System Sciences, HICSS 2017; Conference date: 3 January 2017 through 7 January 2017; Conference code: 169515}
}

@CONFERENCE{Platt2014,
	author = {Platt, Don and Boy, Guy A.},
	title = {Participatory design of the Virtual Camera for deep space exploration},
	year = {2014},
	journal = {HCI-Aero 2014 - Proceedings of the International Conference on Human-Computer Interaction in Aerospace},
	doi = {10.1145/2669592.2669653},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962921448&doi=10.1145%2f2669592.2669653&partnerID=40&md5=ea04b751fa36d36dfe05c56a3e1b2d6a},
	affiliations = {Micro Aerospace Solutions, Inc., Human-Centered Design Institute Florida Institute of Technology, 907 East Strawbridge Ave, Melbourne, 32901, FL, United States; Human-Centered Design Institute Florida Institute of Technology, Melbourne, 32901, FL, United States},
	abstract = {In this paper, a new Virtual Camera (VC) system is described that has been developed to assist astronauts in deep space exploration. Participatory design, involving users and stakeholders in all aspects of the design was used to make a system that provides a mediation environment. This environment, implemented on a tablet computer system, allows explorers in the field to share data and knowledge with those in remote command and control centers. There are other applications for this system design such as disaster response, law enforcement and aviation cockpits. © 2014 ACM.},
	author_keywords = {Augmented reality; Human-computer interaction (HCI); Situation awareness (SA); Space exploration; Tablet computing; Usability testing},
	keywords = {Augmented reality; Cameras; Command and control systems; Computer control systems; Design; Interplanetary flight; Manned space flight; Space flight; Space research; Systems analysis; Human computer interaction (HCI); Situation awareness; Space explorations; Tablet computing; Usability testing; Human computer interaction},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {978-145032560-8},
	language = {English},
	abbrev_source_title = {HCI-Aero - Proc. Int. Conf. Hum.-Comput. Interact. Aerosp.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: International Conference on Human-Computer Interaction in Aerospace, HCI-Aero 2014; Conference date: 30 July 2014 through 1 August 2014; Conference code: 119100}
}

@CONFERENCE{Steckel20112549,
	author = {Steckel, Jan and Vanduren, Wouter and Peremans, Herbert},
	title = {3D localization by a biomimetic sonar system in a fire-fighting application},
	year = {2011},
	journal = {Proceedings - 4th International Congress on Image and Signal Processing, CISP 2011},
	volume = {5},
	pages = {2549 – 2553},
	doi = {10.1109/CISP.2011.6100671},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84855590127&doi=10.1109%2fCISP.2011.6100671&partnerID=40&md5=924c57ab843dfc551b5ff20904350666},
	affiliations = {University of Antwerp, FTEW MTT Department, B-2000 Antwerpen, Prinsstraat 13, Belgium; Artesis Hogeschool Antwerpen, Productontwikkeling, B-2000 Antwerpen, Ambtmanstraat 1, Belgium},
	abstract = {In this study we investigate the effects of medium disturbances on the usability of a biomimetic sonar system in a target localization application. In particular, we concentrate on a fire-fighting application giving rise to specific types of medium disturbances. We determine experimentally the effects of these medium disturbances: undisturbed air (reference), the presence of small water droplets, large convective air-currents and flames, on the received echo spectra. As the echo spectra are used to estimate the target location, these different conditions by disturbing to varying extents sound propagation through the medium will have an effect on the sonar system's localization performance. Using an information theoretic model of the spectrum based localization mechanism we characterize the loss in localization accuracy due to the different medium disturbances. We conclude that an echolocation system based on the sonar system of the bat Phyllostomus discolor allows for robust localization even in highly disturbed media. However, while the need for replacing the emission pattern of the bat by that of a standard transducer in the biomimetic sonar system makes little difference in the 'reference' and 'water spray' conditions it limits echolocation performance in the 'air-currents' condition and makes the use of the proposed system very difficult in the 'flames' condition. © 2011 IEEE.},
	author_keywords = {Bat echolocation; Fire-Fighter Augmented Reality; Ultrasonics},
	keywords = {Acoustic wave propagation; Augmented reality; Biomimetics; Excitons; Fire extinguishers; Information theory; Signal processing; Ultrasonics; Underwater acoustics; Underwater audition; 3D localization; Bat echolocation; Echo spectra; Emission pattern; Fire fighting; Localization accuracy; Localization performance; Sonar system; Sound propagation; System-based; Target localization; Target location; Theoretic model; Water droplets; Water sprays; Sonar},
	correspondence_address = {J. Steckel; University of Antwerp, FTEW MTT Department, B-2000 Antwerpen, Prinsstraat 13, Belgium; email: Jan.Steckel@ua.ac.be},
	isbn = {978-142449306-7},
	language = {English},
	abbrev_source_title = {Proc. - Int. Congr. Image Signal Process., CISP},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: 4th International Congress on Image and Signal Processing, CISP 2011; Conference date: 15 October 2011 through 17 October 2011; Conference code: 88002}
}

@CONFERENCE{Scanlon201710,
	author = {Scanlon, Mark},
	title = {Battling the digital forensic backlog through data deduplication},
	year = {2017},
	journal = {2016 6th International Conference on Innovative Computing Technology, INTECH 2016},
	pages = {10 – 14},
	doi = {10.1109/INTECH.2016.7845139},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011260208&doi=10.1109%2fINTECH.2016.7845139&partnerID=40&md5=10595152ce6c732bf51ed6d32c93ec92},
	affiliations = {School of Computer Science, University College Dublin, Ireland},
	abstract = {In recent years, technology has become truly pervasive in everyday life. Technological advancement can be found in many facets of life, including personal computers, mobile devices, wearables, cloud services, video gaming, web-powered messaging, social media, Internet-connected devices, etc. This technological influence has resulted in these technologies being employed by criminals to conduct a range of crimes - both online and offline. Both the number of cases requiring digital forensic analysis and the sheer volume of information to be processed in each case has increased rapidly in recent years. As a result, the requirement for digital forensic investigation has ballooned, and law enforcement agencies throughout the world are scrambling to address this demand. While more and more members of law enforcement are being trained to perform the required investigations, the supply is not keeping up with the demand. Current digital forensic techniques are arduously time-consuming and require a significant amount of man power to execute. This paper discusses a novel solution to combat the digital forensic backlog. This solution leverages a deduplication-based paradigm to eliminate the reacquisition, redundant storage, and reanalysis of previously processed data. © 2016 IEEE.},
	keywords = {Digital forensics; Digital storage; Electronic crime countermeasures; Gears; Law enforcement; Personal computers; Wearable technology; Cloud services; Data de duplications; De duplications; Digital forensic analysis; Forensic investigation; Forensic Techniques; Law-enforcement agencies; Technological advancement; Computer crime},
	correspondence_address = {M. Scanlon; School of Computer Science, University College Dublin, Ireland; email: mark.scanlon@ucd.ie},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-150902000-3},
	language = {English},
	abbrev_source_title = {Int. Conf. Innov. Comput. Technol., INTECH},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 39; Conference name: 6th International Conference on Innovative Computing Technology, INTECH 2016; Conference date: 24 August 2016 through 26 August 2016; Conference code: 126400; All Open Access, Green Open Access}
}

@CONFERENCE{Dave2013133,
	author = {Dave, Rakesh and Boddhu, Sanjay K. and McCartney, Matt and West, James},
	title = {Augmenting situational awareness for first responders using social media as a sensor},
	year = {2013},
	journal = {IFAC Proceedings Volumes (IFAC-PapersOnline)},
	volume = {12},
	number = {PART 1},
	pages = {133 – 140},
	doi = {10.3182/20130811-5-US-2037.00088},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84885827243&doi=10.3182%2f20130811-5-US-2037.00088&partnerID=40&md5=7546555d4a90daec38859708edc8ca8f},
	affiliations = {Qbase, Springfield, OH 45505, United States; TecEdge Innovation and Collaboration Ctr., Air Force Research Lab, United States; Wright State University, Dayton, OH 45435, United States},
	abstract = {First responders to an emergency situation rely on ground truths measured by various sensing mechanisms for effective decision making. The sensors are typically airborne or ground based. Seamless sharing of information among users using Social networking provides for a unique type of sensor. This human-as-a sensor is already deployed in the field and only requires harvesting of the information to glean ground truth. Further, the proliferation of the smartphones and their connectivity networks has powered the ordinary individuals to share and acquire information regarding the events happening in his/her immediate vicinity in a real-time fashion. The information provided by these sensors is already annotated with descriptions such as "urgency" "critically wounded" which normally would not be found in traditional machine based sensors. Further, when appropriately employed this real-time data can support in detecting localized events like fire, accidents, shooting, etc..., as they unfold and pin-point individuals being affected by those events. The spatio-temporal information can be indexed, grouped and deployed on Smartphones and other devices that first responders can use in the field to augment decision making. In this vein, under SATE and YATE programs, the research team at AFRL Tec^Edge Discovery labs had demonstrated the feasibility of developing Smartphone applications, that can provide a augmented reality view of the appropriate detected events in a given geographical location (localized) and also provide an event search capability over a large geographic extent. In its current state, the application thru its backend connectivity utilizes a data (Text & Image) processing framework, which deals with data challenges like; identifying and aggregating important events, analyzing and correlating the events temporally and spatially and building a search enabled event database. Further, the smartphone application with its backend data processing workflow has been successfully field tested with live user generated feeds. Copyright © 2013 IFAC.},
	keywords = {Application programs; Augmented reality; Data handling; Decision making; Man machine systems; Smartphones; Social networking (online); Emergency situation; Geographical locations; Localized events; Search capabilities; Sensing mechanism; Situational awareness; Smart-phone applications; Spatiotemporal information; Information dissemination},
	publisher = {IFAC Secretariat},
	issn = {14746670},
	isbn = {978-390282341-0},
	language = {English},
	abbrev_source_title = {IFAC Proc. Vol. (IFAC-PapersOnline)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; Conference name: 12th IFAC/IFIP/IFORS/IEA Symposium on Analysis, Design, and Evaluation of Human - Machine Systems, HMS 2013; Conference date: 11 August 2013 through 14 August 2013; Conference code: 99954; All Open Access, Bronze Open Access}
}

@ARTICLE{Barbosa2015265,
	author = {Barbosa, Silvia Maria de Macedo and Farhat, Sylvia Costa Lima and Martins, Lourdes Conceição and Pereira, Luiz Alberto Amador and Saldiva, Paulo Hilário Nascimento and Zanobetti, Antonella and Braga, Alfésio Luís Ferreira},
	title = {Air pollution and children's health: Sickle cell disease; [Poluição do ar e a saúde das crianças: A doença falciforme]; [Contaminación atmosférica y salud de los niños: La enfermedad de células falciformes]},
	year = {2015},
	journal = {Cadernos de Saude Publica},
	volume = {31},
	number = {2},
	pages = {265 – 275},
	doi = {10.1590/0102-311X00013214},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84924327768&doi=10.1590%2f0102-311X00013214&partnerID=40&md5=e745e2e65776740a4b1fbb52a317d175},
	affiliations = {Universidade de São Paulo, São Paulo, Brazil; Universidade Católica de Santos, Santos, Brazil; Harvard School of Public Health, Boston, United States},
	abstract = {The hallmarks of sickle cell disease are anemia and vasculopathy. The aim of this study was to assess the association between air pollution and children’s emergency room visits of sickle cell patients. We adopted a case-crossover design. Daily counts of children’s and adolescents’ sickle cell disease emergency room visits from the pediatric emergency unit in São Paulo, Brazil, were evaluated from September 1999 to December 2004, matching by temperature, humidity and controlling for day of the week. Interquartile range increases of the four-day moving averages of PM10, NO2, SO2, CO, and O3 were associated with increases of 18.9% (95%CI: 11.2-26.5), 19% (95%CI: 8.3-29.6), 14.4% (95%CI: 6.5-22.4), 16,5% (95%CI: 8.9-24.0), and 9.8% (95%CI: 1.1- 18.6) in total sickle cell emergency room visits, respectively. When the analyses were stratified by pain, PM10 was found to be 40.3% higher than in sickle cell patients without pain symptoms. Exposure to air pollution can affect the cardiovascular health of children and may promote a significant health burden in a sensitive group. © 2015, Fundacao Oswaldo Cruz. All rights reserved.},
	author_keywords = {Air pollution; Emergency medical services; Sickle cell disease},
	keywords = {Adolescent; Air Pollution; Anemia, Sickle Cell; Brazil; Cardiovascular Diseases; Child; Child, Preschool; Cross-Over Studies; Emergency Service, Hospital; Environmental Exposure; Female; Humans; Infant; Male; adolescent; adverse effects; air pollution; analysis; Brazil; Cardiovascular Diseases; child; complication; crossover procedure; emergency health service; environmental exposure; female; human; infant; male; pathophysiology; preschool child; sickle cell anemia; utilization},
	publisher = {Fundacao Oswaldo Cruz},
	issn = {0102311X},
	pmid = {25760161},
	language = {English},
	abbrev_source_title = {Cad. Saude Publica},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 24; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Mossel201523,
	author = {Mossel, Annette and Peer, Andreas and Goellner, Johannes and Kaufmann, Hannes},
	title = {Towards an immersive virtual reality training system for CBRN disaster preparedness},
	year = {2015},
	journal = {5th International Defense and Homeland Security Simulation Workshop, DHSS 2015},
	pages = {23 – 32},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84949482797&partnerID=40&md5=19bd864d89ca0198ce62fbdb2911a7cb},
	affiliations = {Vienna University of Technology Institute of Software Technology and Interac Tive Systems, Favoritenstraße 9-11/188/2, Vienna, A-1040, Austria; National Defence Academyo of the Austrian Federal Ministry of Defence and Sports, Stiftgasse 2a, Vienna, A-1070, Austria},
	abstract = {Over the past decade, training in virtual reality for military and disaster preparedness has been increasingly recognized as an important adjunct to traditional modalities of real-life drills. However, there are only a few existing solutions that provide immersive virtual reality training that implies improved learning through an increased amount of presence. In this paper, we present a thorough analysis of the state of the art of virtual reality training systems and outline the requirements of two peer stakeholders for disaster relief with an explicit focus on CBRN disaster preparedness. We compare both analyses to specify if-and to which extent-existing virtual reality training solutions meet the stakeholder requirements. Based on the comparison, we present an outlook on existing and upcoming virtual reality components that have the potential to fulfil the stakeholders' requirements of a flexible multi-user immersive virtual reality training system.},
	author_keywords = {CBRN Disaster Preparedness; First Responder; Scenario and Decision Simulation; Virtual and Augmented Reality},
	keywords = {Augmented reality; Disaster prevention; Disasters; National security; Security systems; Virtual reality; Disaster preparedness; Disaster relief; First responders; Immersive virtual reality; Scenario and Decision Simulation; State of the art; Virtual and augmented reality; Virtual reality training; E-learning},
	editor = {Longo F. and Sottilare R. and Bruzzone A.G.},
	publisher = {Dime University of Genoa},
	isbn = {978-889799951-5},
	language = {English},
	abbrev_source_title = {Int. Def. Homel. Secur. Simul. Workshop, DHSS},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: 5th International Defense and Homeland Security Simulation Workshop, DHSS 2015; Conference date: 21 September 2015 through 23 September 2015; Conference code: 116185}
}

@ARTICLE{Ilori2017199,
	author = {Ilori, Adedapo and Li, Yueqing and Mahesh, Vishnu and Craig, Brian},
	title = {Effect of position: An ergonomics evaluation of police’s wearable equipment},
	year = {2017},
	journal = {Advances in Intelligent Systems and Computing},
	volume = {486},
	pages = {199 – 207},
	doi = {10.1007/978-3-319-41685-4_18},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992561467&doi=10.1007%2f978-3-319-41685-4_18&partnerID=40&md5=6792843a36e0cccfb3492dc354add077},
	affiliations = {Department of Industrial Engineering, Lamar Univerity, Beaumont, TX, United States},
	abstract = {The importance of wearable equipment in certain profession for the purpose of safety and communication cannot be overemphasized. However, the number, size and positons of these equipment raise questions concerning ergonomics and human factors. This study examines the effect of the police body camera in conjunction with the walkie-talkie speaker on the ergonomics of an active duty police officer. Two additional alternatives to the current set up were provided. Result showed a significant effect of position on task performance and workload. The research should give insights to other wearable equipment. © Springer International Publishing Switzerland 2017.},
	author_keywords = {Body camera; Ergonomics; Human factors; Walkie-talkie; Wearable equipment},
	keywords = {Cameras; Human engineering; Law enforcement; Wearable technology; Ergonomics evaluations; Police officers; Positons; Task performance; Walkie talkies; Ergonomics},
	correspondence_address = {Y. Li; Department of Industrial Engineering, Lamar Univerity, Beaumont, United States; email: yueqing.li@lamar.edu},
	editor = {Soares M. and Ahram T.Z. and Falcao C.},
	publisher = {Springer Verlag},
	issn = {21945357},
	isbn = {978-331941684-7},
	language = {English},
	abbrev_source_title = {Adv. Intell. Sys. Comput.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: International Conference on Ergonomics Modeling, Usability and Special Populations, AHFE 2016; Conference date: 27 July 2016 through 31 July 2016; Conference code: 184909}
}

@CONFERENCE{Fortin2009,
	author = {Fortin, M. and Noiseux, I. and Mouslinkina, L. and Vernon, M.L. and Laflamme, C. and Filion, G. and Duchaine, C. and Ho, J.},
	title = {System for rapid detection of antibiotic resistance of airborne pathogens},
	year = {2009},
	journal = {Proceedings of SPIE - The International Society for Optical Engineering},
	volume = {7312},
	doi = {10.1117/12.818783},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-69649093682&doi=10.1117%2f12.818783&partnerID=40&md5=2fb5194d7562c33a772d4f09c1b3f9f8},
	affiliations = {INO, Biophotonics, QC, G1P 4S4, 2740 Einstein St., Canada; Centre de recherche de l'Hopital Laval, Institut universitaire de cardiologie et de pneumologie de l'Universite Laval, Quebec city, QC, Canada; Biological Detection Group, Defence Research Establishment Suffield, CFB Suffield, Ralston, AB, Canada; Departement de biochimie et de microbiologie, Faculte des sciences et de genie, Universite Laval, Quebec city, QC, Canada},
	abstract = {This project uses function-based detection via a fundamental understanding of the genetic markers of AR to distinguish harmful organisms from innocuous ones. This approach circumvents complex analyses to unravel the taxonomic details of 1399 pathogen species, enormously simplifying detection requirements. Laval Hospital's fast permeabilization strategy enables AR revelation in <1hr. Packaging the AR protocols in liquid-processing cartridges and coupling these to our in-house miniature fiber optic flow cell (FOFC) provides first responders with timely information on-site. INO's FOFC platform consists of a specialty optical fiber through which a hole is transversally bored by laser micromachining. The analyte solution is injected into the hole of the fiber and the particles are detected and counted. The advantage with respect to classic free space FC is that alignment occurs in the fabrication process only and complex excitation and collection optics are replaced by optical fibers. Moreover, we use a shea hless configuration which has the advantage of increase the portability of the system, to reduce excess biohazard material and the need for weekly maintenance. In this paper we present the principle of our FOFC along with a, demonstration of the basic capability of the platform for detection of bacillus cereus spores using permeabilized staining. ©2009 SPIE.},
	author_keywords = {Bacillus cereus; Fiber optics; FISH; Flow cytometry; Quantum dots; Sheathless; Spores},
	keywords = {Bacteriology; Bioinformatics; Cell membranes; Flow cytometry; Light transmission; Optical fiber fabrication; Optical fibers; Optical materials; Optoelectronic devices; Pathogens; Semiconductor quantum dots; Airborne pathogens; Analytes; Antibiotic resistance; Bacillus cereus; Bacillus cereus spores; Complex analysis; Fabrication process; First responders; Free space; Genetic markers; Harmful organisms; Laser micro-machining; Pathogen species; Permeabilization; Quantum dots; Rapid detection; Sheathless; Specialty optical fibers; Spores; Fibers},
	issn = {0277786X},
	isbn = {978-081947578-7},
	coden = {PSISD},
	language = {English},
	abbrev_source_title = {Proc SPIE Int Soc Opt Eng},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: Advanced Environmental, Chemical, and Biological Sensing Technologies VI; Conference date: 13 April 2009 through 14 April 2009; Conference code: 76795}
}

@ARTICLE{Kim2016287,
	author = {Kim, W. and Kerle, N. and Gerke, M.},
	title = {Mobile augmented reality in support of building damage and safety assessment},
	year = {2016},
	journal = {Natural Hazards and Earth System Sciences},
	volume = {16},
	number = {1},
	pages = {287 – 298},
	doi = {10.5194/nhess-16-287-2016},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84957597875&doi=10.5194%2fnhess-16-287-2016&partnerID=40&md5=d20ada59293d9e94d4afc3a09ea0a531},
	affiliations = {Faculty of Geo-Information Science and Earth Observation, University of Twente, Enschede, Netherlands},
	abstract = {Rapid and accurate assessment of the state of buildings in the aftermath of a disaster event is critical for an effective and timely response. For rapid damage assessment of buildings, the utility of remote sensing (RS) technology has been widely researched, with focus on a range of platforms and sensors. However, RS-based approaches still have limitations to assess structural integrity and the specific damage status of individual buildings. Structural integrity refers to the ability of a building to hold the entire structure. Consequently, ground-based assessment conducted by structural engineers and first responders is still required. This paper demonstrates the concept of mobile augmented reality (mAR) to improve performance of building damage and safety assessment in situ. Mobile AR provides a means to superimpose various types of reference or pre-disaster information (virtual data) on actual post-disaster building data (real buildings). To adopt mobile AR, this study defines a conceptual framework based on the level of complexity (LOC). The framework consists of four LOCs, and for each of these, the data types, required processing steps, AR implementation and use for damage assessment are described. Based on this conceptualization we demonstrate prototypes of mAR for both indoor and outdoor purposes. Finally, we conduct a user evaluation of the prototypes to validate the mAR approach for building damage and safety assessment. © Author(s) 2016.},
	keywords = {assessment method; building; complexity; damage mechanics; disaster; ground-based measurement; remote sensing; safety; structural analysis; technology adoption},
	correspondence_address = {W. Kim; Faculty of Geo-Information Science and Earth Observation, University of Twente, Enschede, Netherlands; email: jinsilto@gmail.com},
	publisher = {Copernicus GmbH},
	issn = {15618633},
	language = {English},
	abbrev_source_title = {Nat. Hazards Earth Syst. Sci.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 33; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Hackett2016158,
	author = {Hackett, Timothy M. and Bilén, Sven G.},
	title = {Implementation of a rapidly deployable, mobile communications system prototype for disadvantaged environments},
	year = {2016},
	journal = {Procedia Engineering},
	volume = {159},
	pages = {158 – 166},
	doi = {10.1016/j.proeng.2016.08.149},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84993940960&doi=10.1016%2fj.proeng.2016.08.149&partnerID=40&md5=df6c192d871dbcdd9e3424f235e5e07c},
	affiliations = {School of Electrical Engineering and Computer Science, Pennsylvania State University, University Park, 16801, PA, United States},
	abstract = {Large-scale natural disasters present complex challenges for disaster relief communications. Fixed infrastructures, such as cell towers or radio base stations, may be completely destroyed during a disaster or this infrastructure may never have existed. In a disaster situation, having unreliable communications systems can put a relief personnel's safety at risk as well as make the effort much less effective. Furthermore, emergency situations require time-sensitive communications that could mean the difference between life and death. The communications system described in this paper provides a rapidly deployable, data-centric mobile communications system for all organizations engaged in disaster relief: first responders, search-and-rescue, emergency medical and health services, etc. Utilizing the IEEE 802.11b/g standard, this system creates a mobile wireless local area network through a series of "wearable routers". The routers provide local Wi-Fi access to all users within of their respective ranges, and then all of these routers are connected to each other through an ultra-high-frequency backhaul network. Ultimately, from the user's perspective the network appears to be a standard Wi-Fi network with enhanced range. The purpose of this network is to provide communications between both local and widespread users until more traditional communications systems are restored. A proof-of-concept prototype using commercial-off-the-shelf components has been realized, and the real-world performance of the system has been characterized in Boston, MA and Pittsburgh, PA. The results show that this system provides a viable solution, but requires further attention to antenna design and in-band interference. © 2016 The Authors.},
	author_keywords = {80211b/g/n; commercial-off-the-shelf; disaster relief communications; OpenWrt; ultra-high frequency; wearable technology; wireless local area network},
	keywords = {Base stations; Complex networks; Disaster prevention; Disasters; Mobile telecommunication systems; Partial discharges; Routers; Search engines; Wearable technology; Wi-Fi; Wireless local area networks (WLAN); 80211b/g/n; Commercial off the shelves; Disaster relief; Openwrt; Ultra-high frequency; Emergency services},
	correspondence_address = {T.M. Hackett; School of Electrical Engineering and Computer Science, Pennsylvania State University, University Park, 16801, United States; email: tmh5344@psu.edu},
	editor = {Vidan A. and Shoag D.},
	publisher = {Elsevier Ltd},
	issn = {18777058},
	language = {English},
	abbrev_source_title = {Procedia Eng.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: Humanitarian Technology: Science, Systems and Global Impact 2016, HumTech2016; Conference date: 7 June 2016 through 9 June 2016; Conference code: 131740; All Open Access, Gold Open Access}
}

@CONFERENCE{Gallagher2015,
	author = {Gallagher, Dennis G. and Manley, Richard J.},
	title = {Diver's full face mask head-up display system using waveguide optical display technology},
	year = {2015},
	journal = {Underwater Intervention Conference, UI 2015},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962671592&partnerID=40&md5=46030e2747fce3e78a37f4a5a622cd9f},
	affiliations = {Naval Surface Warfare Center-Panama City Division, Underwater Systems Development Branch (E15), Panama City, United States; Naval Surface Warfare Center-Panama City Division Line, Intelligent Sensing and Irregular Warfare Branch (X12), Panama City, United States},
	abstract = {Military, public safety and science divers conduct operations in what can be one of the most inhospitable environments on the planet characterized by extreme temperature, pressure, and extremely poor visibility. Handheld displays and gauges can be virtually useless in an environment frequently characterized by zero visibility, and this has been a serious limitation to underwater manned diving operations [1]. Waveguide optical display technology has the potential to radically transform diver visual display systems by enabling the diver's face mask itself to become a see-through head-up display, similar to something from an Iron Man or Star Trek movie. Under a recent international government sponsored program, the Naval Surface Warfare Center-Panama City Division (NSWC PCD) developed a concept prototype binocular see-through head-up display inside a diver's full face mask using waveguide optical display technology. This paper will describe diver visual display systems, waveguide optical display technology, development of the concept prototype, results of diver evaluations, and recommendations for follow-on research and development.},
	keywords = {Naval warfare; Visibility; Waveguides; Concept prototype; Extreme temperatures; Handheld displays; Head up displays; Head-up display systems; Naval Surface Warfare Center; Optical displays; Research and development; Display devices},
	publisher = {Underwater Intervention},
	language = {English},
	abbrev_source_title = {Underw. Interv. Conf., UI},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: Underwater Intervention Conference, UI 2015; Conference date: 10 February 2015 through 12 February 2015; Conference code: 112955}
}

@CONFERENCE{Schonauer2013,
	author = {Schonauer, Christian and Vonach, Emanuel and Gerstweiler, Georg and Kaufmann, Hannes},
	title = {3D building reconstruction and thermal mapping in fire brigade operations},
	year = {2013},
	journal = {Proceedings - IEEE Virtual Reality},
	doi = {10.1109/VR.2013.6549445},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84884891697&doi=10.1109%2fVR.2013.6549445&partnerID=40&md5=4595a91fcda0744922c6e35291c91e11},
	affiliations = {Interactive Media Systems Group, Vienna University of Technology, Austria},
	abstract = {Fire fighting remains a dangerous profession despite many recent technological and organizational measures. Sensors and technical systems can augment the performance of fire fighters and increase safety and efficiency during operation. An important aspect in that context is the awareness of location, structure and thermal properties of the environment. This work focuses on the design and development of a mobile system, which can reconstruct a 3d model of a building's interior structure in real-time and fuses the visualization with the image of a thermal camera. In addition, the position and viewing direction of the fire fighter within the model is determined and a thermal map can be generated from the gathered data. This helps an operational commander to provide accurate instructions to his men during a mission. First tests with our system in different situations showed good results, being able to reconstruct different larger scenes and create thermal maps thereof. © 2013 IEEE.},
	author_keywords = {Augmented Reality; Dense Reconstruction; Fire Fighter; Real-Time; Safety; Thermal Cameras; Tracking; Volumetric Representation},
	keywords = {Accident prevention; Augmented reality; Fires; Infrared devices; Surface discharges; Three dimensional computer graphics; Virtual reality; 3-d building reconstruction; Design and Development; Fire fighters; Real-Time; Safety and efficiencies; Structure and thermal properties; Thermal camera; Volumetric representation; Three dimensional},
	isbn = {978-146734795-2},
	language = {English},
	abbrev_source_title = {Proc. IEEE Virtual Real.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 20th IEEE Virtual Reality Conference, VR 2013; Conference date: 16 March 2013 through 20 March 2013; Conference code: 99673; All Open Access, Green Open Access}
}

@ARTICLE{Ünlüer2013367,
	author = {Ünlüer, Erden Erol and Karagöz, Arif and Bayata, Serdar and Akoǧlu, Haldun},
	title = {An alternative approach to the bedside assessment of left ventricular systolic function in the emergency department: Displacement of the aortic root},
	year = {2013},
	journal = {Academic Emergency Medicine},
	volume = {20},
	number = {4},
	pages = {367 – 373},
	doi = {10.1111/acem.12114},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84876396227&doi=10.1111%2facem.12114&partnerID=40&md5=d258e13a27749c93e60e16d4da5e0cee},
	affiliations = {Department of Emergency Medicine, Izmir Ataturk Research and Training Hospital, Izmir, Turkey; Department of Cardiology, Izmir Ataturk Research and Training Hospital, Izmir, Turkey; Department of Emergency Medicine, Kartal Lütfi Kirdar Research and Training Hospital, Istanbul, Turkey},
	abstract = {Objectives Left ventricular ejection fraction (LVEF) is a crucial parameter in the management of patients with dyspnea in the emergency department (ED). The use of techniques other than echocardiography such as nuclear or magnetic resonance imaging to measure LVEF is unsuitable in the ED because of time constraints. This study aimed to compare echocardiographic aortic root (AR) excursion and LVEF measurement using the modified Simpson's method (biplane method of disks) as recommended by the American Society of Echocardiography. Methods After 2 hours of theoretical video and hands-on training with 20 patients by an experienced echocardiographer, two emergency physicians prospectively evaluated patients with dyspnea. Two-dimensional echocardiograms of the parasternal long-axis view were obtained, and the displacement of the aortic root (DAR) was studied. M-mode DAR recordings were obtained, and distances were measured as the maximized anterior displacement of the AR from the horizontal axis at end-systole by using the leading-edge methodology. LVEF was measured by an experienced cardiologist using the modified Simpson's rule. The sensitivity, specificity, positive and negative likelihood ratios (LR+, LR-), and positive and negative predictive values (PPV, NPV) were analyzed. A new formula for the prediction of the ejection fraction (EF) with the aid of DAR was then created. Results The mean (±SD) age with of the 70 study patients was 69.7 (±11.91) years. In these patients, DAR was highly correlated with EF (point biserial correlation coefficient = 0.79, p < 0.001) and one-way analysis of variance (ANOVA) results were significant (F = 115.9; p < 0.001). The sensitivity was 94.4; specificity, 94.1; LR+, 16.6; LR-, 0.059; PPV, 94.4; and NPV, 94.1. Conclusions The results indicate that DAR is a sensitive index of left ventricular systolic function (SF) and can be used to reliably predict EF values using the rough formula of EF = 20 + 44 (DAR). © 2013 by the Society for Academic Emergency Medicine.},
	keywords = {Aged; Aged, 80 and over; Analysis of Variance; Aorta; Cross-Sectional Studies; Diagnosis, Differential; Dyspnea; Echocardiography, Three-Dimensional; Emergency Medical Services; Female; Heart Failure; Heart Ventricles; Humans; Male; Middle Aged; Pneumonia; Point-of-Care Systems; Prospective Studies; Pulmonary Disease, Chronic Obstructive; Pulmonary Embolism; Sensitivity and Specificity; Stroke Volume; Systole; Ventricular Function, Left; adult; aged; aorta root; article; cardiologist; clinical article; clinical assessment tool; clinical evaluation; cohort analysis; cross-sectional study; dyspnea; emergency physician; emergency ward; heart left ventricle ejection fraction; human; M mode echocardiography; medical society; modified simpson method; predictive value; priority journal; prospective study; sensitivity and specificity; two dimensional echocardiography},
	correspondence_address = {E.E. Ünlüer; Department of Emergency Medicine, Izmir Ataturk Research and Training Hospital, Izmir, Turkey; email: erolerdenun@yahoo.com},
	issn = {15532712},
	coden = {AEMEF},
	pmid = {23701344},
	language = {English},
	abbrev_source_title = {Acad. Emerg. Med.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8; All Open Access, Bronze Open Access}
}

@CONFERENCE{Beringer20136,
	author = {Beringer, Dennis B. and Drechsler, Gena},
	title = {Head-mounted displays for civil helicopter navigation and obstacle avoidance: Is what you see what you don't get, or is seeing not believing?},
	year = {2013},
	journal = {Proceedings of the Human Factors and Ergonomics Society},
	pages = {6 – 10},
	doi = {10.1177/1541931213571004},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84889849698&doi=10.1177%2f1541931213571004&partnerID=40&md5=cdaaf1439518deb6fd8edd712d91060d},
	affiliations = {Civil Aerospace Medical Institute, Oklahoma City, OK, United States},
	abstract = {Civilian helicopter pilots flew simulated Helicopter Emergency Medical Service (HEMS) scenari-os using a head-mounted display (HMD) with guidance and/or obstruction imagery. Obstructions were detected and avoided earlier when shown in the HMD than those shown only out the win-dow, and highway-in-the-sky (HITS) guidance reduced subsequent maneuvering in the terminal phase of arrival. The HMD depictions of power lines (passive representation) reduced wire strikes but did not eliminate them. An active warning presentation (red warning fence) overlaid on the power-line graphic at the point it transected the flight path completely eliminated flights in-to that obstruction. Pilots preferred the active warning representation, indicating that the passive one was ambiguous. Pilots' preference tended towards the simplified representations of power lines but towards the complex "realistic" representations of broadcast towers. A strong prefer-ence was also expressed for integrated cockpit systems (HMD, MFD, PFD) that depicted the same obstruction information and warnings on each display. Copyright 2013 by Human Factors and Ergonomics Society, Inc.},
	keywords = {Cockpits (aircraft); Collision avoidance; Electric lines; Graph theory; Helicopters; Human engineering; Civil helicopters; Cockpit systems; Emergency medical services; Head mounted displays; Power lines; Helmet mounted displays},
	issn = {10711813},
	isbn = {978-094528943-2},
	coden = {PHFSD},
	language = {English},
	abbrev_source_title = {Proc Hum Factors Ergon Soc},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; Conference name: 57th Human Factors and Ergonomics Society Annual Meeting - 2013, HFES 2013; Conference date: 30 September 2013 through 4 October 2013; Conference code: 101162}
}

@CONFERENCE{Melzer2011132,
	author = {Melzer, James E.},
	title = {12. 1: Invited paper: Image source evaluation and selection for rugged near-eye displays},
	year = {2011},
	journal = {Digest of Technical Papers - SID International Symposium},
	volume = {42 1},
	pages = {132 – 134},
	doi = {10.1889/1.3621084},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84863223155&doi=10.1889%2f1.3621084&partnerID=40&md5=9dee7b7007981a097b382766b76c4f00},
	affiliations = {Manager of Research and Technology, Rockwell Collins Optronics, Carlsbad, CA, United States},
	abstract = {There are many high-quality image source technologies to choose from when designing a near-eye or head-mounted display and they can provide excellent imagery. However, when you impose requirements for this same performance under extreme conditions of temperature, shock, and direct sunlight exposure-conditions which might be experienced by military personnel or first responders, the number of options gets smaller. This paper will address the impact of imposing these very stringent environmental conditions on choices for image sources. © 2011 SID.},
	keywords = {Chemicals; Display devices; Environmental conditions; Extreme conditions; First responders; Head mounted displays; High quality images; Image source; Military personnels; Sunlight exposure; Helmet mounted displays},
	publisher = {Blackwell Publishing Ltd},
	issn = {0097966X},
	language = {English},
	abbrev_source_title = {Dig. Tech. Pap. SID Int. Symp.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Mizumoto2012740,
	author = {Mizumoto, Teruhiro and Imazu, Shinya and Sun, Weihua and Shibata, Naoki and Yasumoto, Keiichi},
	title = {Emergency medical support system for visualizing locations and vital signs of patients in Mass Casualty Incident},
	year = {2012},
	journal = {2012 IEEE International Conference on Pervasive Computing and Communications Workshops, PERCOM Workshops 2012},
	pages = {740 – 745},
	doi = {10.1109/PerComW.2012.6197611},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84861546164&doi=10.1109%2fPerComW.2012.6197611&partnerID=40&md5=3c4bd6c04e8900f8bf8254929c67e5d8},
	affiliations = {Graduate School of Information Science, Nara Institute of Science and Technology, Ikoma, Nara 630-0192, Japan; Department of Information Processing and Management, Shiga University, Hikone, Shiga 522-8522, Japan; Japan Science and Technology Agency, CREST, Japan},
	abstract = {The triage tag is used in Mass Casualty Incident (MCI) to check the priority of patients treatments and conditions. However, it is difficult to grasp a change in the patient's information since it is a paper tag. In this paper, we propose a system using the electronic triage tag (eTriage) that facilitates emergency medical technicians to grasp patients locations and conditions through visualization. This system provides the following three views of the patients information: (1) Inter-site view which shows on a map an overview of the latest status in multiple first-aid stations including the number of technicians and patients of each triage category; (2) Intra-site view which shows detailed status of each first-aid station including the location, triage category, and vital signs of each patient on a 3D map created based on the environment mapping technique; and (3) Individual view which shows vital information of patients on a tablet PC according to its orientation using the augmented reality technique. In this paper, we describe the design and implementation of the proposed system with some preliminary evaluation results. © 2012 IEEE.},
	author_keywords = {electronic triage tag; emergency medical support system; visualization; vital signs},
	keywords = {Augmented reality; Flow visualization; Personal computers; Visualization; electronic triage tag; Emergency medical technicians; Environment mapping; Evaluation results; Mass casualty; Support systems; Tablet PCs; Three views; Vital sign; Ubiquitous computing},
	correspondence_address = {T. Mizumoto; Graduate School of Information Science, Nara Institute of Science and Technology, Ikoma, Nara 630-0192, Japan; email: teruhiro-m@is.naist.jp},
	isbn = {978-146730907-3},
	language = {English},
	abbrev_source_title = {IEEE Int. Conf. Pervasive Comput. Commun. Workshops, PERCOM Workshops},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 9; Conference name: 2012 IEEE International Conference on Pervasive Computing and Communications Workshops, PERCOM Workshops 2012; Conference date: 19 March 2012 through 23 March 2012; Conference code: 89907}
}

@CONFERENCE{Stelios2016,
	author = {Stelios, M. and Mitilineos, Stelios A. and Chatzistamatis, Panagiotis and Vassiliadis, Savvas and Primentas, Antonios and Kogias, Dimitris and Michailidis, Emmanouel T. and Rangoussi, Maria and Bahadir, Senem Kurşun and Atalay, Özgür and Kalaoǧlu, Fatma and Saǧlam, Yusuf},
	title = {Physiological parameters monitoring of fire-fighters by means of a wearable wireless sensor system},
	year = {2016},
	journal = {IOP Conference Series: Materials Science and Engineering},
	volume = {108},
	number = {1},
	doi = {10.1088/1757-899X/108/1/012011},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964770180&doi=10.1088%2f1757-899X%2f108%2f1%2f012011&partnerID=40&md5=e857d632de897db5b697e3807acc560c},
	affiliations = {Department of Electronics Engineering, Piraeus University of Applied Sciences (TEI of Piraeus), 250 Thivon and P. Ralli, Aigalao, Athens, GR-12244, Greece; Istanbul Technical University, Faculty of Textile Technologies and Design, Inönü cd. No.65, Gümüşsuyu, Beyoǧlu, Istanbul, TR-34437, Turkey; Kivanç Group, Ziyagökalp Mh., Başakşehir, Istanbul, TR-34490, Turkey},
	abstract = {Physiological parameter monitoring may be useful in many different groups of the population, such as infants, elderly people, athletes, soldiers, drivers, fire-fighters, police etc. This can provide a variety of information ranging from health status to operational readiness. In this article, we focus on the case of first responders and specifically fire-fighters. Firefighters can benefit from a physiological monitoring system that is used to extract multiple indications such as the present position, the possible life risk level, the stress level etc. This work presents a wearable wireless sensor network node, based on low cost, commercial-off- the-self (COTS) electronic modules, which can be easily attached on a standard fire-fighters' uniform. Due to the low frequency wired interface between the selected electronic components, the proposed solution can be used as a basis for a textile system where all wired connections will be implemented by means of conductive yarn routing in the textile structure, while some of the standard sensors can be replaced by textile ones. System architecture is described in detail, while indicative samples of acquired signals are also presented. © Published under licence by IOP Publishing Ltd.},
	keywords = {Fighter aircraft; Fires; Integrated circuits; Patient monitoring; Physiological models; Physiology; Sensor nodes; Textiles; Tracking (position); Transducers; Wearable technology; Wireless sensor networks; Commercial off the selves; Electronic component; Electronic modules; Operational readiness; Physiological monitoring systems; Physiological parameters; System architectures; Wireless sensor system; Wearable sensors},
	correspondence_address = {M. Stelios; Department of Electronics Engineering, Piraeus University of Applied Sciences (TEI of Piraeus), Aigalao, Athens, 250 Thivon and P. Ralli, GR-12244, Greece; email: spoti@teipir.gr},
	editor = {Vlachos D.S. and Potirakis S. and Giouroudi I. and Kar-Narayan S. and Hristoforou E.},
	publisher = {Institute of Physics Publishing},
	issn = {17578981},
	language = {English},
	abbrev_source_title = {IOP Conf. Ser. Mater. Sci. Eng.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; Conference name: 5th International Conference on Materials and Applications for Sensors and Transducers, IC-MAST 2015; Conference date: 27 September 2015 through 30 September 2015; Conference code: 120064; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Kress2014,
	author = {Kress, Bernard},
	title = {See through optical architectures for wearable displays},
	year = {2014},
	journal = {Optics InfoBase Conference Papers},
	doi = {10.1364/aio.2014.jtu1a.1},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074234957&doi=10.1364%2faio.2014.jtu1a.1&partnerID=40&md5=f3a7ce21e0cc8ec128c2b291494a65df},
	affiliations = {Google, United States},
	abstract = {HUDs (Head Up Displays) and HMDs (Helmet Mounted Displays) have been with us for a few decades, providing exceptional optical performances for specialized defense applications. On the other hand, consumer electronics HMDs (Head Mounted Displays) have been lingering as personal gadgets for a mere decade. But recently, major companies have launched consumer compelling head mounted display solutions integrating both hardware, operating system as well as content, unlocking the decade long consumer HMD status-quo. As a result, we are witnessing today a fragmentation of the HMD market into various categories which have their very own specificity in terms of functionality, hardware and content. Such fragmentation is responsible for defining new distinct market segments such as consumer near to eye displays, social smart glasses, gaming headsets, as well as professional (engineering and technical) HMDs, specialized (medical, law enforcement, firefighting) HMDs and of course the previously existing defense market. We will be reviewing the different type of optical hardware used in such devices. © 2014 OSA.},
	keywords = {Chemical analysis; Commerce; Head-up displays; Laser applications; Network security; Street traffic control; Wearable technology; Defense markets; Head mounted displays; Market segment; Near-to-Eye display; Optical architectures; Optical performance; Smart glass; Wearable displays; Helmet mounted displays},
	correspondence_address = {B. Kress; Google, United States; email: bernard.kress@gmail.com},
	publisher = {Optical Society of America (OSA)},
	issn = {21622701},
	isbn = {978-155752308-2; 978-155752308-2},
	language = {English},
	abbrev_source_title = {Opt.InfoBase Conf. Papers},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: Laser Applications to Chemical, Security and Environmental Analysis, LACSEA 2014; Conference date: 13 July 2014 through 17 July 2014; Conference code: 107131; All Open Access, Bronze Open Access}
}

@CONFERENCE{Colunas2011,
	author = {Colunas, Márcio F.M. and Amaral Fernandes, José M. and Oliveira, Ilídio C. and Silva Cunha, João P.},
	title = {DroidJacket: An android-based application for first responders monitoring},
	year = {2011},
	journal = {Proceedings of the 6th Iberian Conference on Information Systems and Technologies, CISTI 2011},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-80052484501&partnerID=40&md5=944d9e26ae835919ebf2ac7c63e15abd},
	affiliations = {Institute of Electronics and Telematics Engineering, Dep. of Electronics, Telecommunications and Informatics, University of Aveiro, Aveiro, Portugal},
	abstract = {The Vital Responder project aims at exploring the synergies between wearable technologies, scattered sensor network, intelligent building technology and precise localization services to provide secure, reliable and effective first-response systems in emergency scenarios. One of the components required in this technological setting is the ability to monitor biosignals from first responders in the field. In this paper we present a mobile monitoring system called DroidJacket to address the Vital Responder requirements. DroidJacket uses a Android-based smartphone as a base station for vital signs acquired with the Vital Jacket® garment, enabling visualization and simple real time processing. © 2011 AISTI.},
	author_keywords = {mobile computing; monitoring system; vital signs; wearable technologies},
	keywords = {Information systems; Intelligent buildings; Sensor networks; Technology; Visualization; Biosignals; Emergency scenario; First responders; Localization services; Mobile monitoring system; monitoring system; Realtime processing; Scattered sensors; Smart phones; Vital sign; Wearable technology; Monitoring},
	correspondence_address = {M.F.M. Colunas; Institute of Electronics and Telematics Engineering, Dep. of Electronics, Telecommunications and Informatics, University of Aveiro, Aveiro, Portugal; email: marcio@ua.pt},
	isbn = {978-989962475-7},
	language = {English},
	abbrev_source_title = {Proc. Iberian Conf. Inf. Syst. Technol., CISTI},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; Conference name: 6th Iberian Conference on Information Systems and Technologies, CISTI 2011; Conference date: 15 June 2011 through 18 June 2011; Conference code: 86321}
}

@ARTICLE{Coimbra201245,
	author = {Coimbra, Miguel and Silva Cunha, João Paulo},
	title = {Vital responder - Wearable sensing challenges in uncontrolled critical environments},
	year = {2012},
	journal = {Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering},
	volume = {102 LNICST},
	pages = {45 – 62},
	doi = {10.1007/978-3-642-32778-0_4},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84869598118&doi=10.1007%2f978-3-642-32778-0_4&partnerID=40&md5=e8d4d33697c852b2064b986d215dc157},
	affiliations = {Instituto de Telecomunicações, Faculdade de Ciências, Universidade Do Porto, Portugal; IEETA, Universidade de Aveiro, Portugal; DEEC, Fac. Engenharia, Universidade Do Porto, Portugal},
	abstract = {The goal of the Vital Responder research project is to explore the synergies between innovative wearable technologies, scattered sensor networks, intelligent building technology and precise localization services to provide secure, reliable and effective first-response systems in critical emergency scenarios. Critical events, such as natural disaster or other large-scale emergency, induce fatigue and stress in first responders, such as fire fighters, policemen and paramedics. There are distinct fatigue and stress factors (and even pathologies) that were identified among these professionals. Nevertheless, previous work has uncovered a lack of real-time monitoring and decision technologies that can lead to in-depth understanding of the physiological stress processes and to the development of adequate response mechanisms. Our "silver bullet" to address these challenges is a suite of non-intrusive wearable technologies, as inconspicuous as a t-shirt, capable of gathering relevant information about the individual and disseminating this information through a wireless sensor network. In this paper we will describe the objectives, activities and results of the first two years of the Vital Responder project, depicting how it is possible to address wearable sensing challenges even in very uncontrolled environments. © 2012 ICST Institute for Computer Science, Social Informatics and Telecommunications Engineering.},
	author_keywords = {biomedical signal processing; sensor networks; Wearable sensing},
	keywords = {Intelligent buildings; Physiological models; Sensor networks; Signal processing; Technology; Biomedical signal processing; Critical environment; Critical events; Decision technology; Emergency scenario; Fire fighters; First responders; In-depth understanding; Large-scale emergency; Localization services; Natural disasters; Non-intrusive; Physiological stress; Real time monitoring; Response mechanisms; Scattered sensors; Stress factors; T-shirts; Wearable sensing; Wearable technology; Innovation},
	correspondence_address = {M. Coimbra; Instituto de Telecomunicações, Faculdade de Ciências, Universidade Do Porto, Portugal; email: mcoimbra@fc.up.pt},
	issn = {18678211},
	isbn = {978-364232777-3},
	language = {English},
	abbrev_source_title = {Lect. Notes Inst. Comput. Sci. Soc. Informatics Telecommun. Eng.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 3rd International ICST Conference on Sensor Systems and Software, S-Cube 2012; Conference date: 4 June 2012 through 5 June 2012; Conference code: 92485}
}

@ARTICLE{Piszczek201145,
	author = {Piszczek, Marek},
	title = {New possibilities of the anti-terrorist protection systems with using augmented reality; [Nowe możliwości systemów ochrony antyterrorystycznej z wykorzystaniem rozszerzonej rzeczywistości]},
	year = {2011},
	journal = {Przeglad Elektrotechniczny},
	volume = {87},
	number = {9 A},
	pages = {45 – 48},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-81155137958&partnerID=40&md5=aa74717f9f2b92a997708e44c1df22bb},
	affiliations = {Wojskowa Akademia Techniczna, Instytut Optoelektroniki, 00-908 Warszawa, Ul. gen. S. Kaliskiego 2, Poland},
	abstract = {The technique of Augmented Reality offers new possibilities of the public safety systems in the area of distribution of information.The action of security officers on critical situations is determined among others by the topicality of the knowledge about different aspects of the threat. The suggested solution is paying attention to the possibility of automating and individualizing the way of the coordination of action.},
	author_keywords = {Augmented reality; HMD; Navigational sensors; Public safety},
	correspondence_address = {M. Piszczek; Wojskowa Akademia Techniczna, Instytut Optoelektroniki, 00-908 Warszawa, Ul. gen. S. Kaliskiego 2, Poland; email: mpiszczek@wat.edu.pl},
	issn = {00332097},
	language = {English},
	abbrev_source_title = {Prz. Elektrotech.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@CONFERENCE{Chang20151531,
	author = {Chang, Jack Shen-Kuen and Henry, Michael J. and Burtner, Russ and Love, Oriana and Corley, Courtney},
	title = {The Heroes' problems: Exploring the potentials of Google glass for biohazard handling professionals},
	year = {2015},
	journal = {Conference on Human Factors in Computing Systems - Proceedings},
	volume = {18},
	pages = {1531 – 1536},
	doi = {10.1145/2702613.2732698},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84954228129&doi=10.1145%2f2702613.2732698&partnerID=40&md5=a50fd540277435119598b499faf3d2c5},
	affiliations = {Purdue University, United States; Pacific Northwest National Laboratory, United States},
	abstract = {In "white powder incidents" or other suspicious and risky situations relating to deadly diseases or chemicals (e.g., Ebola investigation), those who handle the potentially hazardous materials are the heroes who spearhead the first responder's operations. Although well trained, these heroes need to manage complex problems and make life-or-death decisions while handling the unknown and dangerous. We are motivated to explore how Google Glass can facilitate those heroes' missions. To this end, we conducted contextual inquiry on six biohazard-handling, Personal Protective Equipment (PPE)-wearing professionals. With an inductive thematic analysis, we summarized the heroes' workflow and four groups of "Heroes' Problems". A unique "A3 Model" (Awareness, Analysis, Action) was generated to encapsulate our qualitative findings and proposed Glass features. The findings serve as the groundwork for our future development. Copyright is held by the author/owner(s).},
	author_keywords = {Biohazard; Contextual inquiry; Google Glass; HazMat suit; Personal protective equipment; PPE; Thematic analysis; User study; Wearable technology},
	keywords = {Biohazards; Glass; Human computer interaction; Human engineering; Protective clothing; Wearable technology; Contextual inquiry; HazMat suit; Personal protective equipment; PPE; Thematic analysis; User study; Wearable computers},
	publisher = {Association for Computing Machinery},
	isbn = {978-145033146-3},
	language = {English},
	abbrev_source_title = {Conf Hum Fact Comput Syst Proc},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; Conference name: 33rd Annual CHI Conference on Human Factors in Computing Systems, CHI EA 2015; Conference date: 18 April 2015 through 23 April 2015; Conference code: 116996}
}

@CONFERENCE{Chroust2010514,
	author = {Chroust, Gerhard and Rainer, Karin and Sturm, Nadine and Roth, Markus and Ziehesberger, Peter},
	title = {Improving resilience of critical human systems in CBRN-emergencies: Challenges for first responders},
	year = {2010},
	journal = {54th Annual Conference of the International Society for the Systems Sciences 2010: Governance for a Resilient Planet},
	pages = {514 – 531},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84865620364&partnerID=40&md5=425ee5ed928cd1c9ee5fe4a2730a2659},
	affiliations = {Johannes Kepler University Linz, 4040 Linz, Austria; Research Institute of the Red Cross Austria, 1030 Wien, Austria; Creative Bits, 4050 Traun, Austria; Ziehesberger Elektronik, 4501 Neuhofen/Krems, Austria},
	abstract = {Today's catastrophes (many of them man-made or at least triggered by human activities) usually endanger a growing number of humans and larger areas in more diversified ways, creating a need for dependability and resilience of our environment. Experience tells us that no matter what precautions and quality approaches we take we will always encounter systems which initially were dependable and 'suddenly' turn untrustworthy due to some unexpected, unknown cause. A system which in itself is unable to reestablish its dependability, i.e. it is not rewsilient (any more) needs an outside intervention: For humans a physician acts as an intervention system for re-establishing dependability. A complex system can be made resilient by the inclusion of an Intervention System which intervenes in the case of loss of dependability. In this paper we investigate the role of First Responders (i.e. fire brigade, ambulance services, police forces) as an Intervention System in the case of CBRN-incidents, aimed at providing resilience. Taking a process view of such interventions we analyze key processes especially with respect to supporting them by Information and Communication Technology. We identify properties of CBRN incidents and their implications for the activities of First Responders both in training and real assignments.},
	author_keywords = {CBRN-emergencies; Dependability; First responders; Intervention system; Mixed reality; Process modelling; Resilience; Simulation},
	keywords = {Information technology; CBRN-emergencies; Dependability; First responders; Intervention system; Mixed reality; Process modelling; Resilience; Simulation; Virtual reality},
	correspondence_address = {G. Chroust; Johannes Kepler University Linz, 4040 Linz, Austria; email: Gerhard.Chroust@jku.at},
	isbn = {978-161782061-8},
	language = {English},
	abbrev_source_title = {Annu. Conf. Int. Soc. Syst. Sci.: Governance Resilient Planet},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: 54th Annual Conference of the International Society for the Systems Sciences 2010: Governance for a Resilient Planet; Conference date: 18 July 2010 through 23 July 2010; Conference code: 92273}
}

@CONFERENCE{Sturm2009159,
	author = {Sturm, Nadine and Rainer, Karin and Chroust, Gerhard and Roth, Markus},
	title = {Simulation as a new approach to first responders training},
	year = {2009},
	journal = {CSSim 2009 - 1st International Conference on Computational Intelligence, Modelling, and Simulation},
	pages = {159 – 163},
	doi = {10.1109/CSSim.2009.43},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-74549213094&doi=10.1109%2fCSSim.2009.43&partnerID=40&md5=9897569e88491272f6dd27e4ef3acc0d},
	affiliations = {Research Institute of the Red Cross, Vienna, Austria; Johannes Kepler University, Linz, Austria; Creative BITS Group, Traun, Austria},
	abstract = {The perception and awareness of chemical, biological, radiological and nuclear ("CBRN")1 emergencies is rising. These hazards are not directly detectable by human senses and thus no inborn reactions exist. As a consequence, special tools to detect these dangers have to be utilized. Since these dangers tend to affect large areas, it is necessary to establish standardized, coherent "Best Practices", which have to be specifically trained under realistic but safe conditions. Modern technology allows simulating complex scenarios. The goal of the SimRad project is the user centered development and utilization of training and communication tools for all aspects of effective management of emergency situations, including team coordination. Regarding the process flow of First Responders intervention, emergency activities can be dissected into individual sub processes. This provides the basis for a purposeful optimization of individual activities through simulations, ranging from rough approximations to realistic simulations using Mixed Reality technology. © 2009 IEEE.},
	author_keywords = {CBRN; Emergency response; First responder; Simulation},
	keywords = {Artificial intelligence; Virtual reality; Best practice; Communication tools; Effective management; Emergency response; Emergency situation; First responders; Human sense; Mixed reality technologies; Modern technologies; New approaches; Process flows; Realistic simulation; Rough approximations; Sub process; Team coordination; User-centered development; Coordination reactions},
	correspondence_address = {N. Sturm; Research Institute of the Red Cross, Vienna, Austria; email: nadine.sturm@w.roteskreuz.at},
	isbn = {978-076953795-5},
	language = {English},
	abbrev_source_title = {CSSim - Int. Conf. Comput. Intell., Model., Simul.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: CSSim 2009 - 1st International Conference on Computational Intelligence, Modelling, and Simulation; Conference date: 7 September 2009 through 9 September 2009; Conference code: 79089}
}

@CONFERENCE{Nilsson20093,
	author = {Nilsson, Susanna and Johansson, Björn and Jönsson, Arne},
	title = {Using AR to support cross-organisational collaboration in dynamic tasks},
	year = {2009},
	journal = {Science and Technology Proceedings - IEEE 2009 International Symposium on Mixed and Augmented Reality, ISMAR 2009},
	pages = {3 – 12},
	doi = {10.1109/ISMAR.2009.5336522},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-74549159124&doi=10.1109%2fISMAR.2009.5336522&partnerID=40&md5=9d1e3e11cbee632b65d6c8e1102d2d96},
	affiliations = {Department of Computer and Information Science, Linköping University, Sweden; Swedish Defence Research Institute, Linköping, Sweden; Santa Anna IT Research Institute, Linköping, Sweden},
	abstract = {This paper presents a study where Augmented Reality (AR) technology has been used as a tool for supporting collaboration between the rescue services, the police and military personnel in a crisis management scenario. There are few studies on how AR systems should be designed to improve cooperation between actors from different organizations while at the same time support individual needs. In the present study an AR system was utilized for supporting joint planning tasks by providing organisation-specific views of a shared working. The study involved a simulated emergency event conducted in close to real settings with representatives from the organisations for which the system is developed. As a baseline, a series of trials without the AR system was carried out. Results show that the users were positive towards the AR system, and would like to use it in real work. They also experience some performance benefits of using the AR system compared to their traditional tools. Finally, the problem of designing for collaborative work as well as the benefits of using an iterative design processes is discussed. ©2009 IEEE.},
	keywords = {Augmented reality; Law enforcement; Virtual reality; AR system; Collaborative Work; Crisis management; Dynamic tasks; Iterative design; Joint planning; Military personnels; Performance benefits; Rescue services; Argon},
	correspondence_address = {S. Nilsson; Department of Computer and Information Science, Linköping University, Sweden; email: susni@ida.liu.se},
	isbn = {978-142445390-0},
	language = {English},
	abbrev_source_title = {Sci. Technol. Proc. - IEEE Int. Symp. Mix. Augmented Real.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 48; Conference name: 8th IEEE 2009 International Symposium on Mixed and Augmented Reality, ISMAR 2009 - Science and Technology; Conference date: 19 October 2009 through 22 October 2009; Conference code: 78865; All Open Access, Green Open Access}
}

@ARTICLE{Wilson2009675,
	author = {Wilson, J. and Wright, P.},
	title = {Head-mounted display efficacy study to aid first responder indoor navigation},
	year = {2009},
	journal = {Proceedings of the Institution of Mechanical Engineers, Part C: Journal of Mechanical Engineering Science},
	volume = {223},
	number = {3},
	pages = {675 – 688},
	doi = {10.1243/09544062JMES1213},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-63149160630&doi=10.1243%2f09544062JMES1213&partnerID=40&md5=0a63e53d4eff26bbef14946210fd03a2},
	affiliations = {UC Berkeley Mechanical Engineering, Center for Information Technology Research in the Interest of Society (CITRIS), Berkeley, CA, United States; Berkeley Mechanical Engineering, Center for Information Technology Research in the Interest of Society (CITRIS), Berkeley, CA 94720, United States},
	abstract = {A custom head-mounted display (HMD) integrated into a firefighter's facemask was evaluated for its ability to aid in navigating through large buildings in low-visibility conditions. The HMD was a monocular occluded design with a colour 640 × 480 pixel LCD mounted low in one's field of view. It showed the subject their real-time location on a floor plan. Subject location was found with an 802.15.4 wireless sensor network by using the received signal strength indicator localization method. The study consisted of two different courses of similar difficulty in different buildings in the campus of the University of California, Berkeley. There were 21 subjects, of which eight of them were firefighters and five of them were female. The subjects completed the courses in the same order, but alternated in treatment condition. Subjects with the HMD returned on average a 38 per cent faster course completion time, a 44 per cent shorter distance travelled, 60 per cent fewer navigation errors, and 60 per cent more accurate map marking. A follow-up questionnaire showed a strong preference for use of the HMD in navigation tasks, and unanimous approval of the occluded optical design and low mounting location. © IMechE 2009.},
	author_keywords = {Cognitive map; Emergency first response; Fire-fighting; Head-mounted display; Navigation efficiency; Orientation; Situation awareness; Spatial cognition; Wayfinding aid},
	keywords = {Conformal mapping; Fire extinguishers; Navigation; Optical design; Telecommunication networks; Wireless sensor networks; Cognitive map; Emergency first response; Fire-fighting; Head-mounted display; Orientation; Situation awareness; Spatial cognition; Wayfinding aid; Helmet mounted displays},
	correspondence_address = {J. Wilson; Berkeley Mechanical Engineering, Center for Information Technology Research in the Interest of Society (CITRIS), Berkeley, CA 94720, United States; email: jwilson@me.berkeley.edu},
	issn = {09544062},
	coden = {PMCSE},
	language = {English},
	abbrev_source_title = {Proc. Inst. Mech. Eng. Part C J. Mech. Eng. Sci.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6}
}

@ARTICLE{Thompson2009227,
	author = {Thompson, Tonya and Lyle, Kristen and Mullins, S Hope and Dick, Rhonda and Graham, James},
	title = {A state survey of emergency department preparedness for the care of children in a mass casualty event.},
	year = {2009},
	journal = {American journal of disaster medicine},
	volume = {4},
	number = {4},
	pages = {227 – 232},
	doi = {10.5055/ajdm.2009.0034},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-79958175171&doi=10.5055%2fajdm.2009.0034&partnerID=40&md5=a400ec41205aa04923ce4b6167e4e34d},
	affiliations = {Department of Pediatrics, University of Arkansas for Medical Sciences, Little Rock, Arkansas, United States},
	abstract = {The Institute of Medicine has issued two reports over the past 10 years raising concerns about the care of children in the emergency medical care system of the United States. Given that children are involved in most mass casualty events and there are deficiencies in the day-to-day emergency care of children, this project was undertaken to document the preparedness of hospitals in AR for the care of children in mass casualty or disaster situations. Mailed survey to all emergency department medical directors in AR. Nonresponders received a second mailed survey and an attempt at survey via phone. Medical directors of the emergency departments of the 80 acute care hospitals in AR. Seventy-two of 80 directors responded (90 percent response rate). Only 13 percent of hospitals reported they have pediatric mass casualty protocols and in only 28 percent of hospitals the disaster plan includes pediatric-specific issues such as parental reunification. Most hospitals hold mass casualty training events (94 percent), at least annually, but only 64 percent report including pediatric patients in their disaster drills. Most hospitals include local fire (90 percent), police (82 percent), and emergency medical services (77 percent) in their drills, but only 23 percent report involving local schools in the disaster planning process. Eighty-three percent of hospitals responding reported their staff is trained in decontamination procedures. Thirty-five percent reported having warm water showers available for infant/children decontamination. Ninety-four percent of hospitals have a plan for calling in extra staff in a disaster situation, which most commonly involves a phone tree (43 percent). Ninety-three percent reported the availability of Ham Radios, walkie-talkie, or Arkansas Wireless Information Network (AWIN) units for communication in case of land line loss, but only 16 percent reported satellite phone or Tandberg units. Twelve percent reported reliance on cell phones in this situation. This survey demonstrated important deficiencies in the preparedness of hospitals in AR for the care of children in disaster. Although many hospitals are relatively well prepared for the care of adults in disaster situations, the needs of children are different and hospitals in AR are not as well prepared for pediatric disaster care.},
	keywords = {Arkansas; Attitude of Health Personnel; Disaster Planning; Emergency Service, Hospital; Health Care Surveys; Humans; Inservice Training; Mass Casualty Incidents; Pediatrics; Physician Executives; MLCS; MLOWN; administrative personnel; article; disaster planning; education; emergency health service; health care survey; health personnel attitude; human; in service training; mass disaster; organization and management; pediatrics; United States},
	issn = {1932149X},
	pmid = {19860165},
	language = {English},
	abbrev_source_title = {Am J Disaster Med},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 18}
}

@CONFERENCE{2009,
	title = {Proceedings of the 2009 Canadian Conference on Computer and Robot Vision, CRV 2009},
	year = {2009},
	journal = {Proceedings of the 2009 Canadian Conference on Computer and Robot Vision, CRV 2009},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-71049116478&partnerID=40&md5=bbf94ed7ef076b093b774f83b0cb4680},
	abstract = {The proceedings contain 45 papers. The topics discussed include: optical flow from motion blurred color images; a multiple hypothesis tracking method with fragmentation handling; efficient target recovery using stage for mean-shift tracking; scalable near-optimal recursive structure from motion; a robot control and augmented reality interface for multiple robots; canine pose estimation: a computing for public safety solution; a generic moment invariants based supervised learning framework for classification using partial object information; face classification using Gabor wavelets and random forest; near-real-time image matting with known background; towards navigation summaries: automated production of a synopsis of a robot trajectories; JEDI: adaptive stochastic estimation for joint enhancement and despeckling of images for SAR; adaptive Monte Carlo retinex method for illumination and reflectance separation and color image enhancement; and simple 3D reconstruction of single indoor image with perspective cues.},
	isbn = {978-076953651-4},
	language = {English},
	abbrev_source_title = {Proc. Can. Conf. Comput. Robot Vis.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2009 Canadian Conference on Computer and Robot Vision, CRV 2009; Conference date: 25 May 2009 through 27 May 2009; Conference code: 78011}
}

@CONFERENCE{Hatem2015122,
	author = {Hatem, Ghufran M. and Salim, Ali J. and Ali, Jawad K.},
	title = {An accurate technique to model the substrate of wearable textile antennas},
	year = {2015},
	journal = {Progress in Electromagnetics Research Symposium},
	volume = {2015-January},
	pages = {122 – 124},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84947269614&partnerID=40&md5=5e7a1f7518d44c1dc6500b1b38bd1a1e},
	affiliations = {Microwave Research Group, Department of Electrical Engineering, University of Technology, Iraq},
	abstract = {The utilization of wearable textiles in the antennas has shown a dramatic increase due to the recent challenges imposed on wireless devices to be miniaturized. For RFID purposes, a wearable antenna is meant to be a part of the clothing used. This includes tracking and navigation, mobile computing and public safety applications. Investigating the wearable textile antennas reported in the literature, it has been noted that when modeling the antenna using the commercially available EM simulators, the substrate (textile) has been dealt with as a solid homogenous material. This is fact is not the case, since the textile as a substrate is composed of woven threads (fibers). As a result, this adds some inaccuracy when comparing the simulated results with measured ones. In this paper, the textile antenna material, as a substrate, has been modeled in a way closer to the real practice. It has been modeled as horizontal and vertical fibers with different thread levels. A case study, representing a wearable textile antenna structure, has been investigated and the relevant textile material is being modeled using the proposed modeling technique. Simulation results of the antenna return loss responses using the proposed modeling technique; have shown to be more accurate than those obtained using the conventional modelling technique in that they are more close to measured results relevant to the antennas involved in the case study.},
	keywords = {Antennas; Mobile antennas; Substrates; Textiles; Wearable technology; Weaving; Antenna return loss; Measured results; Modeling technique; Modelling techniques; Public Safety Applications; Simulated results; Textile materials; Wireless devices; Wearable antennas},
	publisher = {Electromagnetics Academy},
	issn = {15599450},
	isbn = {978-193414230-1},
	language = {English},
	abbrev_source_title = {Prog. Electromagn. Res. Symp.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Ramchurn201682,
	author = {Ramchurn, Sarvapali D. and Wu, Feng and Jiang, Wenchao and Fischer, Joel E. and Reece, Steve and Roberts, Stephen and Rodden, Tom and Greenhalgh, Chris and Jennings, Nicholas R.},
	title = {Human–agent collaboration for disaster response},
	year = {2016},
	journal = {Autonomous Agents and Multi-Agent Systems},
	volume = {30},
	number = {1},
	pages = {82 – 111},
	doi = {10.1007/s10458-015-9286-4},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84953638302&doi=10.1007%2fs10458-015-9286-4&partnerID=40&md5=ccd3b6e9adcd32237f81066d343ca97a},
	affiliations = {Department of Electronics and Computer Science, University of Southampton, Southampton, United Kingdom; Mixed Reality Lab, University of Nottingham, Nottingham, United Kingdom; Pattern Recognition Group, University of Oxford, Oxford, United Kingdom},
	abstract = {In the aftermath of major disasters, first responders are typically overwhelmed with large numbers of, spatially distributed, search and rescue tasks, each with their own requirements. Moreover, responders have to operate in highly uncertain and dynamic environments where new tasks may appear and hazards may be spreading across the disaster space. Hence, rescue missions may need to be re-planned as new information comes in, tasks are completed, or new hazards are discovered. Finding an optimal allocation of resources to complete all the tasks is a major computational challenge. In this paper, we use decision theoretic techniques to solve the task allocation problem posed by emergency response planning and then deploy our solution as part of an agent-based planning tool in real-world field trials. By so doing, we are able to study the interactional issues that arise when humans are guided by an agent. Specifically, we develop an algorithm, based on a multi-agent Markov decision process representation of the task allocation problem and show that it outperforms standard baseline solutions. We then integrate the algorithm into a planning agent that responds to requests for tasks from participants in a mixed-reality location-based game, called AtomicOrchid, that simulates disaster response settings in the real-world. We then run a number of trials of our planning agent and compare it against a purely human driven system. Our analysis of these trials show that human commanders adapt to the planning agent by taking on a more supervisory role and that, by providing humans with the flexibility of requesting plans from the agent, allows them to perform more tasks more efficiently than using purely human interactions to allocate tasks. We also discuss how such flexibility could lead to poor performance if left unchecked. © 2015, The Author(s).},
	author_keywords = {Disaster response; Human–agent collectives; Human–agent interaction},
	keywords = {Disasters; Hazards; Markov processes; Multi agent systems; Virtual reality; Agent interaction; Computational challenges; Disaster response; Dynamic environments; Emergency response planning; Location based games; Multi-agent markov decision process; Search and rescue tasks; Emergency services},
	correspondence_address = {S.D. Ramchurn; Department of Electronics and Computer Science, University of Southampton, Southampton, United Kingdom; email: sdr1@soton.ac.uk},
	publisher = {Springer New York LLC},
	issn = {13872532},
	language = {English},
	abbrev_source_title = {Auton. Agents Multi-Agent Syst.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 60; All Open Access, Green Open Access}
}@CONFERENCE{Johnson2008516,
	author = {Johnson, Mark and Melton, Gene},
	title = {Life support breathing system for submarine rescue vehicle: "SUBPACK"-Rebreather system},
	year = {2008},
	journal = {Underwater Intervention Conference 2009, UI 2009},
	volume = {1},
	pages = {516 – 523},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84881606627&partnerID=40&md5=52ca099f3505ff8a4120af70cec82f66},
	affiliations = {O2 Dive Technologies Inc., United States; Hydrospace Engineering Inc., United States},
	abstract = {In response to requirements by OceanWorks International, a Rescue Rebreather, called "SubPack" was designed and built by O2 Dive Technologies of Houston, TX, under contract for the REMORA rescue submarine for the Australian Navy. Operational requirements required to dock for transfer of submariners into the rescue vehicle REMORA. Upon opening the hatches between the two subs, an area which may be contaminated with toxic chemicals, fire by-products or chemical or biological agents or high concentrations of CO2 REMORA operators would be required to have donned a breathing device that could not be contaminated. Depending on the situation, it may not be acceptable or operationally suitable for the personnel to use 'open loop' or negative pressure filtered respirators due to the nature of the contaminant or even its physical state (e.g. super heated air). In these situations a CBR is required. SUBPACK Rebreather, is capable of six (6) hours of life support, and is ergonomically small, lightweight (weighing less then 20 lbs.), rapidly donnable, low cost, and interface with existing oral nasal face masks with standard interfaces. Additionally, it is to be easy to maintain, and have a short training period. Besides these fundamental requirements, OceanWorks provided valuable meetings that their various needs were also incorporated into the design. SUBPACK is a CBR unit and was tested and witnessed with DNV approval. Its many future design features allow it to be adapted for all capabilities including meeting NFPA requirements of passive alarm and heads up display. Further adaptations will include and other rigorous environments and applications. This device will be of commercial interest to DOD/SOCOM, FBI, and USSS, Coast Guard and other federal, state and local Law Enforcement Agencies, fire fighters, urban and rural rescue teams and industrial First Responders. The SUBPACK unit, and all components herein are prototype proprietary O2 Dive Technologies Inc.},
	keywords = {Indicators (chemical); Biological agents; First responders; Law-enforcement agencies; Negative pressures; Operational requirements; Rescue submarines; Standard interface; Submarine rescue vehicles; Submarines},
	isbn = {978-161567004-8},
	language = {English},
	abbrev_source_title = {Underw. Intervention Conf., UI},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: Underwater Intervention Conference 2009, UI 2009; Conference date: 3 March 2009 through 5 March 2009; Conference code: 98416}
}

@CONFERENCE{Guennoun200870,
	author = {Guennoun, Mouhcine and Khattak, Saad and Kapralos, Bill and El-Khatib, Khalil},
	title = {Augmented reality-based audio/visual surveillance system},
	year = {2008},
	journal = {HAVE 2008 - IEEE International Workshop on Haptic Audio Visual Environments and Games Proceedings},
	pages = {70 – 74},
	doi = {10.1109/HAVE.2008.4685301},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-58049158977&doi=10.1109%2fHAVE.2008.4685301&partnerID=40&md5=4843ef8028e60d844225406be1067479},
	affiliations = {Dpartement Math-Info., Facult des Sciences de Rabat, Universite Mohammed V Agdal, Rabat, 4 Avenue Ibn Battouta, Morocco; Faculty of Business and Information Technology, University of Ontario Institute of Technology, Oshawa, ON L1H 7K4, Canada; Health Education Technology Research Unit, University of Ontario Institute of Technology, Oshawa, ON L1H 7K4, 2000 Simcoe St. North, Canada},
	abstract = {There are immediate needs for audio/visual surveillance systems in a large number of areas including law enforcement, military, commercial, and personal security. A series of cameras connected to a local "monitoring center" via a wireless mesh network can provide instantaneous ad-hoc monitoring of several environments. However, there are several issues that must be resolved particularly when considering a large number of cameras monitoring a large area. In particular, it is difficult to monitor and control such a large number of cameras and as a result, important events may be missed altogether. In addition, some of these surveillance systems are set up in an instant ad-hoc manner, which means that any operator monitoring the system can easily lose the sense of direction when switching between different camera views. To overcome these limitations, in this paper we describe an ongoing project that seeks the development of an instantaneous ad-hoc audio/visual-based mesh network surveillance system which incorporates an augmented-reality-based three-dimensional graphical user interface to efficiently control and monitor a large number of video surveillance cameras. The system also employs "intelligent vision" and "intelligent audio" techniques to automatically detect and monitor particular events (e.g., intruders entering the scene being monitored) in both the audio and video domain. ©2008 IEEE.},
	author_keywords = {Audio/visual surveillance; Augmented reality; Mesh-network; Security},
	keywords = {Ad hoc networks; Cameras; Game theory; Graphical user interfaces; Laws and legislation; Local area networks; Technical presentations; Three dimensional; Virtual reality; Wireless local area networks (WLAN); Wireless networks; Audio/visual surveillance; Augmented reality; Camera views; Cameras monitoring; Control and monitors; Do-mains; Mesh networks; Mesh-network; Monitor and controls; Monitoring centers; Personal securities; Security; Surveillance systems; Video surveillance cameras; Wireless mesh networks; Security systems},
	correspondence_address = {M. Guennoun; Dpartement Math-Info., Facult des Sciences de Rabat, Universite Mohammed V Agdal, Rabat, 4 Avenue Ibn Battouta, Morocco; email: mguennoun@gmail.com},
	isbn = {978-142442669-0},
	language = {English},
	abbrev_source_title = {HAVE - IEEE Int. Workshop Haptic Audio Vis. Environ. Games Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; Conference name: 7th Edition IEEE International Workshop on Haptic Audio Visual Environments and Games, HAVE 2008; Conference date: 18 October 2008 through 19 October 2008; Conference code: 74857}
}

@CONFERENCE{Beigi2008977,
	author = {Beigi, Majid M. and Zell, Andreas},
	title = {FIR-based classifiers for animal behavior classification},
	year = {2008},
	journal = {Proceedings of the International Joint Conference on Neural Networks},
	pages = {977 – 983},
	doi = {10.1109/IJCNN.2008.4633917},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-56349091407&doi=10.1109%2fIJCNN.2008.4633917&partnerID=40&md5=6bbbdde8f69f588d89b69064c3128471},
	affiliations = {Department of Computer Science, University ot Tuebingen, 72076 Tuebingen, Germany},
	abstract = {In this paper, we implement a new method for classification of biological signals in general, and use it in the animal behavior classification as an example. The forced swimming test of rats or mice is a frequently used behavioral test to evaluate the efficacy of drugs in rats or mice. Frequently used features for that evaluation are obtained through observing three states: immobility, struggling/climbing and swimming in activity profiles. We consider that those activity profiles (signals) inherently contain undesired and interference noise that should be removed before feature extraction and classification. We use a Finite Impulse Response (FIR) filter to filter out that additive noise from the activity profile. The parameters of the FIR filter are obtained via maximizing the accuracy of a classifier that tries to make a discrimination between two classes of the activity profiles (e.g. drug vs. control). We use the kernel Fisher discriminant criterion as a criterion for the discrimination, the Dividing RECTangles (DIRECT) search method for solving the optimization problem and Support Vector Machines (SVMs) for the classification task. We show that Autoregressive (AR) coefficients are suitable features for the extraction of the dynamic behavior of rats and also the classification of activity profiles. Our proposed behavior classification method provides a reliable discrimination of different classes of antidepressant drugs (imipramine and desipramine) administered to rats versus a vehicle-treated group. © 2008 IEEE.},
	keywords = {Classifiers; Face recognition; FIR filters; Impulse response; Law enforcement; Learning systems; Neural networks; Rats; Support vector machines; Vectors; Wave filters; Activity profiles; Animal behaviors; Antidepressant drugs; Autoregressive; Behavior classifications; Biological signals; Classification tasks; Desipramine; Dividing rectangles; Dynamic behaviors; Feature extraction and classifications; Finite impulse responses; Interference noises; Kernel Fisher discriminants; Optimization problems; Search methods; Support vectors; Feature extraction},
	correspondence_address = {M. M. Beigi; Department of Computer Science, University ot Tuebingen, 72076 Tuebingen, Germany; email: majid.beigi@uni-tuebingen.de},
	isbn = {978-142441821-3},
	coden = {85OFA},
	language = {English},
	abbrev_source_title = {Proc Int Jt Conf Neural Networks},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2008 International Joint Conference on Neural Networks, IJCNN 2008; Conference date: 1 June 2008 through 8 June 2008; Conference code: 74129; All Open Access, Green Open Access}
}

@ARTICLE{Laurent2005290,
	author = {Laurent, Christophe and Beaucourt, Luc},
	title = {Instant electronic patient data input during emergency response in major disaster setting: Report on the use of a rugged wearable (handheld) device and the concept of information flow throughout the deployment of the disaster response upon hospital admission},
	year = {2005},
	journal = {Studies in Health Technology and Informatics},
	volume = {111},
	pages = {290 – 293},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-23844457696&partnerID=40&md5=4c91222be6bdb4114d5d4e9691c6f7f2},
	affiliations = {Monica General Hospital, Antwerp, Belgium; University Hospital Antwerp (UZA), Antwerp, Belgium},
	abstract = {A hard- and software solution has been conceived, realized, produced and used to gather clinical information about disaster victims in the field in such a way that it makes the different efforts made by mass casualty incident management managers and first responders work more efficient, ergonomic, safe and useful for further scientific and statistic analysis.},
	keywords = {Data Collection; Disasters; Emergency Medical Service Communication Systems; Emergency Medical Services; Humans; Patient Admission; Hospital data processing; Medical computing; Virtual reality; Wearable technology; Clinical information; Disaster response; Emergency response; Hospital admissions; Information flows; Mass casualty incidents; Software solution; Statistic analysis; article; disaster; emergency health service; hospital admission; human; information processing; instrumentation; Emergency services},
	correspondence_address = {C. Laurent; Monica General Hospital, Antwerp, Belgium; email: spoedman@skynet.be},
	publisher = {IOS Press},
	issn = {09269630},
	isbn = {1586034987; 978-158603498-6},
	pmid = {15718747},
	language = {English},
	abbrev_source_title = {Stud. Health Technol. Informatics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8; Conference name: 13th Annual Conference on Medicine Meets Virtual Reality: The Magical Next Becomes the Medical Now, MMVR 2005; Conference date: 26 January 2005 through 29 January 2005; Conference code: null}
}

@CONFERENCE{Moh1997394,
	author = {Moh, W. Melody and Jorapur, Neela},
	title = {Advanced traffic policing mechanisms for VBR traffic over ATM networks},
	year = {1997},
	journal = {Proceedings of SPIE - The International Society for Optical Engineering},
	volume = {3231},
	pages = {394 – 405},
	doi = {10.1117/12.290428},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-26444571986&doi=10.1117%2f12.290428&partnerID=40&md5=ebf61aea23c2dc8985bec6dd629e5079},
	affiliations = {Department of Mathematics and Computer Science, San Jose State University, San Jose, CA 95192-0103, United States; Siemens Business Communications System, Santa Clara, CA, United States},
	abstract = {One major function of the ATM (Asynchronous Transfer Mode) networks is to provide real-time, low-loss, and minimum-delay transmission of VBR (variable bit rate) video traffic. The Leaky Bucket (LB) mechanism has been proposed and adopted at the ATM Forum to police network traffic. In this work, we enhance and integrate the ideas of (1) soft multiplexing and (2) multi-level rate policing, to design an advanced traffic policing mechanism: the Multi-Level Leaky Bucket with Token Passing (MLLB-TP). The new mechanism has an efficient mechanism to estimate the current bit-rate and burst-duration of a VBR source. Based on the estimation, fe allows sources to transmit at different bit rates for restricted amounts of time. It also allows interactions among the Leaky Buckets of the input streams of the same virtual path. We use simulation to evaluate the performance of the new mechanism and to compare it with three existing methods. Two VBR traffic source models are used: (1) MMPP (Markov Modulated Poisson Process) with parameters set according to a HDTV model, and (2) an Autoregressive Markovian model of order 2, AR(2). We compare bandwidth utilization, cell-loss probability, and queueing delay for all methods, by varying the offered traffic load and the size of cell buffers and token buckets. We found that, due to different traffic characteristics possessed by different VBR sources, using token passing or multi-rate policing alone does not improve the original LB on certain VBR sources. We found that the new mechanism achieves better performance than the three existing schemes in all the scenarios.},
	author_keywords = {ATM network; Leaky Bucket; Multiplexing; Traffic policing; VBR traffic},
	keywords = {Air traffic control; Asynchronous transfer mode; Automatic teller machines; Bits; Communication channels (information theory); Control systems; Digital television; Internet; Internet protocols; Law enforcement; Machine design; Multiplexing; Poisson distribution; Telecommunication traffic; Television broadcasting; ATM network; Atm networks; Autoregressive; Band-width utilizations; Bit rates; Delay transmissions; Existing methods; Input streams; Leaky Bucket; Leaky buckets; Loss probabilities; Markov modulated poisson processes; Markovian models; Network traffics; New mechanisms; Queueing delays; Token buckets; Token passings; Traffic characteristics; Traffic loads; Traffic policing; VBR traffic; Vbr traffics; Video traffics; Virtual paths; Computer networks},
	correspondence_address = {W. M. Moh; Department of Mathematics and Computer Science, San Jose State University, San Jose, CA 95192-0103, United States; email: moh@cs.sjsu.edu},
	issn = {0277786X},
	coden = {PSISD},
	language = {English},
	abbrev_source_title = {Proc SPIE Int Soc Opt Eng},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: Performance and Control of Network Systems; Conference date: 3 November 1997 through 3 November 1997; Conference code: 74617}
}

@ARTICLE{Ilsaas2008313,
	author = {Ilsaas, Per Albert},
	title = {Blair on rodin: Rejoinder},
	year = {2008},
	journal = {Res Publica},
	volume = {14},
	number = {4},
	pages = {313 – 316},
	doi = {10.1007/s11158-008-9076-9},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-57349154227&doi=10.1007%2fs11158-008-9076-9&partnerID=40&md5=16ab8ead1b01be188d740f9bebbde025},
	affiliations = {St Antony's College, Oxford OX2 6JF, 62 Woodstock Road, United Kingdom},
	abstract = {The article is a brief response to Jacob Blair's critique of David Rodin's argument in War and Self-Defense that there are circumstances in which war conceivably could be justified not as self-defence, but as law enforcement or punishment. It argues that while Rodin's position potentially is less dilemmatic than Blair suggests, Blair nevertheless usefully highlights tensions within it. Blair's own argument in favour of ar as law-enforcement is suggestive, but in no way conclusive. © 2008 Springer Science+Business Media B.V.},
	author_keywords = {Aggression; David Rodin; Ethics of war; National defense; Self-defense},
	correspondence_address = {P. A. Ilsaas; St Antony's College, Oxford OX2 6JF, 62 Woodstock Road, United Kingdom; email: per.ilsaas@gmail.com},
	issn = {15728692},
	language = {English},
	abbrev_source_title = {Res Publica},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Pavlopoulos1997286,
	author = {Pavlopoulos, S. and Dembeyiotis, S. and Koutsouris, D.},
	title = {An augmented reality system for health care provision via telematics support},
	year = {1997},
	journal = {Studies in Health Technology and Informatics},
	volume = {39},
	pages = {286 – 288},
	doi = {10.3233/978-1-60750-883-0-286},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-0030629538&doi=10.3233%2f978-1-60750-883-0-286&partnerID=40&md5=2ad82554417ec11474faf4ee1767cc73},
	affiliations = {Biomedical Engineering Laboratory, Dept. of Electrical and Computer Engineering, National Technical University of Athens, Athens 15773, Zografou Campus, Greece},
	abstract = {We are developing a prototype portable health care support device for Emergency Telemedicine. This device can telematically "bring" a specialist doctor at the site of a medical emergency, allow him to evaluate patient data and issue directions to the emergency personnel on treatment procedures until the patient is brought to hospital. The portable device is carried by a paramedic technician in "wearable" form, allowing the technician to perform his normal duties while communicating with the specialist at the hospital site. This augmented reality system allows for maximum utilisation of available resources and offers a complete, practical solution for increasing survival rates before and during the transportation of accident victims to hospital. © 1997 The authors.},
	keywords = {Emergency Medical Services; Equipment Design; Greece; Humans; Remote Consultation; Systems Integration; User-Computer Interface; Hospital data processing; Hospitals; Patient treatment; Wireless telecommunication systems; Augmented reality systems; Emergency telemedicine; Medical emergency; Patient data; Portable device; Practical solutions; Support devices; Survival rate; article; computer interface; emergency health service; equipment design; Greece; human; methodology; system analysis; teleconsultation; Augmented reality},
	publisher = {IOS Press},
	issn = {09269630},
	pmid = {1997114689},
	language = {English},
	abbrev_source_title = {Stud. Health Technol. Informatics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Chute1998226,
	author = {Chute, Dennis J. and Smialek, John E.},
	title = {Injury patterns in a plastic (AR-1) baton fatality},
	year = {1998},
	journal = {American Journal of Forensic Medicine and Pathology},
	volume = {19},
	number = {3},
	pages = {226 – 229},
	doi = {10.1097/00000433-199809000-00005},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-0031752551&doi=10.1097%2f00000433-199809000-00005&partnerID=40&md5=2e5f0e28120bf98cad1435ebdf7deab9},
	affiliations = {Office of the Chief Medical Examiner, State of Maryland, Baltimore, MD, United States; Baltimore, MD 21201, 111 Penn Street, United States},
	abstract = {Rubber and plastic bullets or batons have been used in countries outside the United States for several years. These devices were designed to inflict nonlethal force in riot control. The authors report a case of fatal injury sustained by an elderly woman struck in the chest by a plastic baton, including the circumstances surrounding this unusual incident, the autopsy findings and a review of the literature.},
	author_keywords = {Chest injuries; Death; Electrical (Taser) gun; Plastic baton; Plastic bullets},
	keywords = {Fatal Outcome; Female; Firearms; Humans; Middle Aged; Plastics; Police; Thoracic Injuries; Wounds, Gunshot; Wounds, Nonpenetrating; adult; article; autopsy; blunt trauma; bullet; case report; civil disorder; electric burn; female; hematopneumothorax; human; immobilization; law enforcement; penetrating trauma; rib fracture; skin abrasion; weapon},
	issn = {01957910},
	coden = {AJFPD},
	pmid = {9760086},
	language = {English},
	abbrev_source_title = {Am. J. Forensic Med. Pathol.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 18}
}

@CONFERENCE{2000,
	title = {IEEE/AFCEA - EUROCOMM 2000: Information Systems for Enhanced Public Safety and Security},
	year = {2000},
	journal = {IEEE/AFCEA - EUROCOMM 2000: Information Systems for Enhanced Public Safety and Security},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84952881412&partnerID=40&md5=286a9cce90c27cb2a0148ba46fa24407},
	abstract = {The proceedings contain 86 papers. The topics discussed include: a simple adaptive up-link power control algorithm for DSKDMA system; the position location system using IS-95 CDMA networks; a software defined radio architecture with power control for 36 W-CDMA systems; software defined radios - Motorola's wireless information transfer system (WITS); a multiprovider, universal, e-mail service for the secure exchange of legally-binding multimedia documents; OFDM bandwith estimation using Morlet's wavelet decomposition; new schemes for improving non data-aided symbol timing recovery for QAM receivers in flat fading channels; reliable data processing in an integrated GPS-based airborne navigational equipment; realization of mobile augmented reality based personal navigation services in 3rd generation cellular networks; a direct digitization spread-spectrum architecture for GNSS receivers; general non-stationary models for short-term and long-term fading channels; and channel modeling for wideband data communication in a maritime mobile environment.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {078036323X; 978-078036323-6},
	language = {English},
	abbrev_source_title = {IEEE/AFCEA - EUROCOMM: Inf. Syst. Enhanc. Public Saf. Secur.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: IEEE/AFCEA Information Systems for Enhanced Public Safety and Security, EUROCOMM 2000; Conference date: 19 May 2000; Conference code: 116606}
}

@ARTICLE{Donnelly196290,
	author = {Donnelly, Richard C.},
	title = {Police Authority and Practices},
	year = {1962},
	journal = {The Annals of the American Academy of Political and Social Science},
	volume = {339},
	number = {1},
	pages = {90 – 110},
	doi = {10.1177/000271626233900108},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964161021&doi=10.1177%2f000271626233900108&partnerID=40&md5=2119ea495834ab25907dfefff1834e30},
	affiliations = {Yale Law School, United States},
	abstract = {Law enforcement requires a sensitive and wise discretion in police decisions whether or not to invoke the criminal process when law violators are uncovered. As an administrative and moral necessity, the policeman informally judges and settles more cases than he takes to court. There are many rules of law limiting the power of arrest and impos ing duties on police officers after arrests are made. Arrests with and without warrant raise constitutional questions as to probable cause and reasonable cause respectively. After ar rest, appearance before a magistrate must follow without un necessary or unreasonable delay, requirements variously de fined by the different jurisdictions. Police practices sometimes depart from prevailing rules of arrest, and the courts must exer cise particular vigilance, especially in such matters involving individual liberties as search and seizure, wire tapping and eavesdropping, use of informers, interrogation of suspects, and the like. Generally, the federal courts tend to be stricter than the state courts about the admissibility of evidence, giving rise to wide divergencies and ambiguities. Technological sophisti cation has increased in scope and reliability the means of ob taining evidence. In the use of these techniques, controls must be exercised to protect individual and other democratic guaran tees at the same time that civil order is maintained.—Ed. © 1962, SAGE Publications. All rights reserved.},
	issn = {00027162},
	language = {English},
	abbrev_source_title = {Ann. Am. Acad. Polit. Soc. Sci.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@CONFERENCE{Tadokoro2000303,
	author = {Tadokoro, Satoshi and Kitano, Hiroaki and Takahashi, Tomoichi and Noda, Itsuki and Matsubara, Hitoshi and Shinjoh, Atsushi and Koto, Tetsuo and Takeuchi, Ikuo and Takahashi, Hironao and Matsuno, Fumitoshi and Hatayama, Mitsunori and Nobe, Jun and Shimada, Susumu},
	title = {RoboCup-Rescue: An international cooperative research project of robotics and AI for the disaster mitigation problem},
	year = {2000},
	journal = {Proceedings of SPIE - The International Society for Optical Engineering},
	volume = {4024},
	pages = {303 – 312},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-0033719709&partnerID=40&md5=e66d0b8de02ddfb222242e11023b9513},
	affiliations = {Kobe Univ, Kobe, Japan},
	abstract = {This paper introduces the RoboCup-Rescue Simulation Project, a contribution to the disaster mitigation, search and rescue problem. A comprehensive urban disaster simulator is constructed on distributed computers. Heterogeneous intelligent agents such as fire fighters, victims and volunteers conduct search and rescue activities in this virtual disaster world. A real world interface integrates various sensor systems and controllers of infrastructures in the real cities with the virtual world. Real-time simulation is synchronized with actual disasters, computing complex relationship between various damage factors and agent behaviors. A mission-critical man-machine interface provides portability and robustness of disaster mitigation centers, and augmented-reality interfaces for rescue parties in real disasters. It also provides a virtual-reality training function for the public. This diverse spectrum of RoboCup-Rescue contributes to the creation of the safer social system.},
	keywords = {Artificial intelligence; Intelligent robots; Man machine systems; Sensors; User interfaces; Virtual reality; Search and rescue robots; Mobile robots},
	publisher = {Society of Photo-Optical Instrumentation Engineers},
	issn = {0277786X},
	coden = {PSISD},
	language = {English},
	abbrev_source_title = {Proc SPIE Int Soc Opt Eng},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; Conference name: Unmanned Ground Vehicle Technology II; Conference date: 24 January 2000 through 25 January 2000; Conference code: 57284}
}

@ARTICLE{200059,
	title = {Working party on the harmonisation of autopsy rules (CDBI-AR): Compilation of replies from interpol member States to Questionnaire on national legislation concerning medico-legal autopsy procedures},
	year = {2000},
	journal = {Forensic Science International},
	volume = {111},
	number = {1-3},
	pages = {59 – 86},
	doi = {10.1016/S0379-0738(00)00188-2},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-0034601147&doi=10.1016%2fS0379-0738%2800%2900188-2&partnerID=40&md5=feb11a2ad0941552f877cdee1ba79db0},
	keywords = {accident; autopsy; cause of death; conference paper; crime; decision making; Europe; forensic medicine; general practitioner; human; law enforcement; medicolegal aspect; pathologist; priority journal; register; regulatory mechanism; standard},
	publisher = {Elsevier Ireland Ltd},
	issn = {03790738},
	coden = {FSIND},
	language = {English},
	abbrev_source_title = {Forensic Sci. Int.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Vincent20081160,
	author = {Vincent, Dale S. and Sherstyuk, Andrei and Burgess, Lawrence and Connolly, Kathleen K.},
	title = {Teaching mass casualty triage skills using immersive three-dimensional virtual reality},
	year = {2008},
	journal = {Academic Emergency Medicine},
	volume = {15},
	number = {11},
	pages = {1160 – 1165},
	doi = {10.1111/j.1553-2712.2008.00191.x},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-56849084300&doi=10.1111%2fj.1553-2712.2008.00191.x&partnerID=40&md5=0fa9fcc9cfef5ce1fc711c1c61137fea},
	affiliations = {Telehealth Research Institute, University of Hawaii, John A. Burns School of Medicine, Honolulu, HI, United States},
	abstract = {Objectives: Virtual reality (VR) environments offer potential advantages over traditional paper methods, manikin simulation, and live drills for mass casualty training and assessment. The authors measured the acquisition of triage skills by novice learners after exposing them to three sequential scenarios (A, B, and C) of five simulated patients each in a fully immersed three-dimensional VR environment. The hypothesis was that learners would improve in speed, accuracy, and self-efficacy. Methods: Twenty-four medical students were taught principles of mass casualty triage using three short podcasts, followed by an immersive VR exercise in which learners donned a head-mounted display (HMD) and three motion tracking sensors, one for their head and one for each hand. They used a gesture-based command system to interact with multiple VR casualties. For triage score, one point was awarded for each correctly identified main problem, required intervention, and triage category. For intervention score, one point was awarded for each correct VR intervention. Scores were analyzed using one-way analysis of variance (ANOVA) for each student. Before and after surveys were used to measure self-efficacy and reaction to the training. Results: Four students were excluded from analysis due to participation in a recent triage research program. Results from 20 students were analyzed. Triage scores and intervention scores improved significantly during Scenario B (p < 0.001). Time to complete each scenario decreased significantly from A (8:10 minutes) to B (5:14 minutes; p < 0.001) and from B to C (3:58 minutes; p < 0.001). Self-efficacy improved significantly in the areas of prioritizing treatment, prioritizing resources, identifying high-risk patients, and beliefs about learning to be an effective first responder. Conclusions: Novice learners demonstrated improved triage and intervention scores, speed, and self-efficacy during an iterative, fully immersed VR triage experience. © 2008 by the Society for Academic Emergency Medicine.},
	author_keywords = {Educational technology; Immersive virtual reality; Patient simulation; Task performance and analysis; Triage},
	keywords = {Adult; Clinical Competence; Educational Technology; Humans; Mass Casualty Incidents; Patient Simulation; Task Performance and Analysis; Triage; User-Computer Interface; conference paper; disaster planning; health hazard; human; medical practice; medical student; patient care; priority journal; self concept; teaching; training; virtual reality},
	correspondence_address = {D. S. Vincent; Telehealth Research Institute, University of Hawaii, John A. Burns School of Medicine, Honolulu, HI, United States; email: dvincent@hawaii.edu},
	issn = {10696563},
	coden = {AEMEF},
	pmid = {18699829},
	language = {English},
	abbrev_source_title = {Acad. Emerg. Med.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 70; All Open Access, Bronze Open Access}
}

@CONFERENCE{Davidson Sr.1997308,
	author = {Davidson Sr., James E.},
	title = {Infrared imaging-based combat casualty care system},
	year = {1997},
	journal = {Proceedings of SPIE - The International Society for Optical Engineering},
	volume = {3061},
	pages = {308 – 316},
	doi = {10.1117/12.280349},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-58149265086&doi=10.1117%2f12.280349&partnerID=40&md5=4111c3b67d8e0f4d21ff12f0edea442b},
	affiliations = {Medical Thermal Diagnostics, Louisiana Business and Technology Center, Baton Rouge, LA 70803-6100, South Stadium Drive, United States},
	abstract = {A Small Business Innovative Research (SBIR) contract was recently awarded to a start up company for the development of an infrared (IR) image based combat casualty care system. The company, Medical Thermal Diagnostics, or MTD, is developing a light weight, hands free, energy efficient uncooled IR imaging system based upon a Texas Instruments design which will allow emergency medical treatment of wounded soldiers in complete darkness without any type of light enhancement equipment. The principal investigator for this effort, Dr. Gene Luther, DVM, Ph.D., Professor Emeritus, LSU School of Veterinary Medicine, will conduct the development and testing of this system with support from Thermalscan, Inc., a nondestructive testing company experienced in IR thermography applications. Initial research has been done with surgery on a cat for feasibility of the concept as well as forensic research on pigs as a close representation of human physiology to determine time of death. Further such studies will be done later as well as trauma studies. IR images of trauma injuries will be acquired by imaging emergency room patients to create an archive of emergency medical situations seen with an infrared imaging camera. This archived data will then be used to develop training material for medical personnel using the system. This system has potential beyond military applications. Firefighters and emergency medical technicians could directly benefit from the capability to triage and administer medical care to trauma victims in low or no light conditions. ©2005 Copyright SPIE - The International Society for Optical Engineering.},
	author_keywords = {Casualty treatment; EMS; Head mounted displays; Head mounted sensors; HMTI; Medical thermography; Trauma care; Triage; Uncooled FPA},
	keywords = {Applications; Contracts; Energy efficiency; Helmet mounted displays; Imaging systems; Infrared devices; Infrared imaging; Infrared radiation; Magnetic properties; Magnetic susceptibility; Medical imaging; Military applications; Military photography; Nondestructive examination; Optoelectronic devices; Personnel training; Physiology; Remote sensing; Sensors; Thermography (temperature measurement); Veterinary medicine; Casualty treatment; EMS; Head mounted displays; Head mounted sensors; HMTI; Medical thermography; Trauma care; Triage; Uncooled FPA; Thermography (imaging)},
	correspondence_address = {J. E. Davidson Sr.; Medical Thermal Diagnostics, Louisiana Business and Technology Center, Baton Rouge, LA 70803-6100, South Stadium Drive, United States; email: thermalscan@earthlink.net},
	issn = {0277786X},
	coden = {PSISD},
	language = {English},
	abbrev_source_title = {Proc SPIE Int Soc Opt Eng},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: Infrared Technology and Applications XXIII; Conference date: 20 April 1997 through 20 April 1997; Conference code: 74560}
}

@CONFERENCE{Johnson2005172,
	author = {Johnson, Mark},
	title = {Life support breathing system for first responders and homeland security: "TACR" - Tactical Rebreather},
	year = {2005},
	journal = {Marine Technology Society - Conference on Underwater Intervention, UI 2005},
	pages = {172 – 180},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84881451771&partnerID=40&md5=83e0ca4a786eb83ef6209f8e448edb8d},
	affiliations = {O2 Dive Technologies, Houston, TX 77009, 859 E. 25th St., United States},
	abstract = {In response to requirements by the Counter Terrorism Tactical Support Office's, (CTTSO), Technical Support Working Group, (TSWG), a Tactical Rebreather, called "TACR" was designed and built by ESS of CA and O2 Dive Technologies of TX, under contract with TPI of MA. The increasing threat of international and domestic terrorism has expanded the need for protective equipment within and beyond traditional boundaries. Tactical security, law enforcement and other response units are sometimes required to enter or transit an area which may be contaminated with toxic industrial chemicals, fire by-products or chemical or biological agents. Depending on the situation, it may not be acceptable or operationally suitable for the personnel to use 'open loop' or negative pressure filtered respirators due to the nature of the contaminant or even its physical state (e.g. super heated air). In these situations a CBR is required. TACR - or TACtical Rebreather, is capable of 180 minutes of life support, is ergonomically small, lightweight (weighing less then 20 lbs.), rapidly donnable, low cost, and interface with existing full-face masks with standard NATO interfaces. Additionally, it is to be easy to maintain, and have a short training period for first responders. Besides these fundamental requirements, TSWG provided valuable meetings with field first responders so that their various needs were also incorporated into the design. TACR is a CBR unit and is expected to go on for NIOSH testing and approval. Its many design features allow it to be adapted for all capabilities including meeting NFPA requirements of passive alarm and heads up display. Further adaptations will include environmental HAZMET "bunny" suits and other rigorous environments and applications. This device will be of commercial interest to DOD/SOCOM, FBI, and USSS, other federal, state and local Law Enforcement Agencies, fire fighters, urban and rural rescue teams and industrial First Responders. The TACR unit and ADAR second stage regulator, and all components herein are prototype proprietary by ESS and O2 Dive Technologies. This unit is currently not for sale.},
	keywords = {Marine engineering; Terrorism; Domestic terrorisms; Home land security; Law-enforcement agencies; Negative pressures; Protective equipment; Technical Support Working Group; Toxic industrial chemical; Traditional boundaries; Law enforcement},
	isbn = {978-160560129-8},
	language = {English},
	abbrev_source_title = {Mar. Technol. Soc. - Conf. Underw. Intervention, UI},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: Conference on Underwater Intervention, UI 2005; Conference date: 14 February 2005 through 16 February 2005; Conference code: 98437}
}

@CONFERENCE{Everett2004267,
	author = {Everett, H.R. and Pacis, E.B. and Kogut, G. and Farrington, N. and Khurana, S.},
	title = {Towards a warfighter's associate: Eliminating the operator control unit},
	year = {2004},
	journal = {Proceedings of SPIE - The International Society for Optical Engineering},
	volume = {5609},
	pages = {267 – 279},
	doi = {10.1117/12.571458},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-17644365127&doi=10.1117%2f12.571458&partnerID=40&md5=e9f5c26e1e54107e4bca0f2236d8158b},
	affiliations = {Space and Nav. Warfare Syst. Center, San Diego, United States; University of Southern California, United States},
	abstract = {In addition to the challenges of equipping a mobile robot with the appropriate sensors, actuators, and processing electronics necessary to perform some useful function, there coexists the equally important challenge of effectively controlling the system's desired actions. This need is particularly critical if the intent is to operate in conjunction with human forces in a military application, as any low-level distractions can seriously reduce a warfighter's chances of survival in hostile environments. Historically there can be seen a definitive trend towards making the robot smarter in order to reduce the control burden on the operator, and while much progress has been made in laboratory prototypes, all equipment deployed in theatre to date has been strictly teleoperated. There exists a definite tradeoff between the value added by the robot, in terms of how it contributes to the performance of the mission, and the loss of effectiveness associated with the operator control unit. From a command-and-control perspective, the ultimate goal would be to eliminate the need for a separate robot controller altogether, since it represents an unwanted burden and potential liability from the operator's perspective. This paper introduces the long-term concept of a supervised autonomous Warfighter's Associate, which employs a natural-language interface for communication with (and oversight by) its human counterpart. More realistic near-term solutions to achieve intermediate success are then presented, along with actual results to date. The primary application discussed is military, but the concept also applies to law enforcement, space exploration, and search-and-rescue scenarios.},
	author_keywords = {Augmented reality; Autonomous systems; Collision avoidance; Machine vision; Natural language understanding; Robotics; Sign interpretation; Simultaneous localization and mapping; Speech recognition; Target acquisition; World modeling},
	keywords = {Collision avoidance; Computer simulation; Computer vision; Mapping; Natural language processing systems; Naval warfare; Robotics; Sensors; Speech recognition; Virtual reality; Autonomous reality; Natural language understanding; Sign interpretation; Simultaneous localization and mapping; Target acquisition; World modeling; Mobile robots},
	issn = {0277786X},
	coden = {PSISD},
	language = {English},
	abbrev_source_title = {Proc SPIE Int Soc Opt Eng},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 16; Conference name: Mobile Robots XVII; Conference date: 26 October 2004 through 28 October 2004; Conference code: 64630}
}

@ARTICLE{Dickinson2003363,
	author = {Dickinson, Edward T. and Bevilacqua, John J. and Hill, Jessica D. and Sites, Frank D. and Wurster, Fred W. and Mechem, C. Crawford},
	title = {The utility of tympanic versus oral temperature measurements of firefighters in emergency incident rehabilitation operations},
	year = {2003},
	journal = {Prehospital Emergency Care},
	volume = {7},
	number = {3},
	pages = {363 – 367},
	doi = {10.1080/10903120390936572},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-0038161055&doi=10.1080%2f10903120390936572&partnerID=40&md5=de743c8447aab599fabb6577e3f5b418},
	affiliations = {Department of Emergency Medicine, Hosp. of the Univ. of Pennsylvania, Philadelphia, PA, United States; Midway Fire Department, Colonie, NY, United States; Philadelphia Fire Department, Philadelphia, PA, United States; Department of Emergency Medicine, Hosp. of the Univ. of Pennsylvania, Philadelphia, PA 19104-4283, 3400 Spruce Street, United States},
	abstract = {Objectives. Emergency incident rehabilitation (AR) is the process by which firefighters receive medical screening and monitoring as well as oral rehydration while on the scene of intense or extended fire or rescue operations. A crucial parameter in EIR medical monitoring is temperature determination because heat-related illnesses are common. The objective of this study was to compare the use of oral temperature versus infrared tympanic temperature determinations of firefighters in the outdoor environment of EIR operations. Methods. This was a prospective observational study of firefighters participating in training scenarios involving heavy smoke and fire conditions at municipal fire training facilities. Outdoor temperature and relative humidity were obtained for each training session. Subjects were outfitted fully for fire fighting duties including full protective clothing and self-contained breathing apparatus (SCBA). Immediately on exiting the fire building, firefighters removed their SCBA masks, protective hoods, and helmets, and had simultaneous oral and tympanic temperatures taken (time 0). The subjects then sat outdoors for 10 minutes and their temperatures were again obtained (time 10). Oral and tympanic temperatures for both time points were calculated as means ± SD. An intraclass correlation coefficient was calculated to determine how closely the simultaneously obtained oral and tympanic temperatures determinations at T-0 and T-10 correlated with each other. Results. Forty-two firefighters (mean age, 44.6 years; SD 9.6) were enrolled during four separate training days. There was poor correlation between oral and tympanic temperatures in firefighters both at time 0 (r = 0.10) and at time 10 (r = 0.18). Conclusions. There is poor correlation between tympanic and oral temperature determinations in the EIR setting. Oral temperature determinations may be preferable to tympanic temperature determination in the EIR setting.},
	author_keywords = {Emergency incident rehabilitation; Firefighters; Tympanic temperature},
	keywords = {adult; article; body temperature; breathing apparatus; calculation; controlled study; correlation analysis; eardrum; emergency health service; environmental temperature; fire fighter; health care utilization; heat; helmet; human; humidity; mask; medical examination; mouth; normal human; observation; patient monitoring; protective clothing; screening test; smoke; temperature measurement; thermography; training},
	correspondence_address = {E.T. Dickinson; Department of Emergency Medicine, Hosp. of the Univ. of Pennsylvania, Philadelphia, PA 19104-4283, 3400 Spruce Street, United States; email: eddickin@mail.med.upenn.edu},
	publisher = {Hanley and Belfus Inc.},
	issn = {10903127},
	coden = {PEMCF},
	pmid = {12879387},
	language = {English},
	abbrev_source_title = {Prehosp. Emerg. Care},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 9}
}

@ARTICLE{Abate2008143,
	author = {Abate, Andrea F. and De Marsico, Maria and Levialdi, Stefano and Mastronardi, Vincenzo and Ricciardi, Stefano and Tortora, Genoveffa},
	title = {Gesture based interface for crime scene analysis: A proposal},
	year = {2008},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {5073 LNCS},
	number = {PART 2},
	pages = {143 – 154},
	doi = {10.1007/978-3-540-69848-7_13},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-54249106053&doi=10.1007%2f978-3-540-69848-7_13&partnerID=40&md5=4c5e42d64f4edd22a00ff0307884b05a},
	affiliations = {Dipartimento di Matematica e Informatica, Università degli Studi di Salerno, 20186, Fisciano (SA), Italy; Dipartimento di Informatica, Università degli Studi di Roma La Sapienza, 00198 Roma, Via Salaria 113, Italy; Dipartimento di Scienze Psichiatriche e Medicina Psicologica, Università degli Studi di Roma La Sapienza, 00185 Roma, Piazzale Aldo Moro, 5, Italy},
	abstract = {Within crime scene analysis, a framework providing interactive visualization and gesture based manipulation of virtual objects, while still seeing the real environment, seems a useful approach for the interpretation of cues and for instructional purposes as well. This paper presents a framework providing a collection of techniques to enhance reliability, accuracy and overall effectiveness of gesture-based interaction, applied to an interactive interpretation and evaluation of a crime scene in an augmented reality environment. The interface layout is visualized via a stereoscopic see-through capable Head Mounted Display (HMD), projecting graphics in the central region of the user's field of view, floating in a close-at-hand volume. The interaction paradigm concurrently exploits both hands to perform precise manipulation of 3D models of objects, eventually present on the crime scene, or even distance/angular measurements, allowing to formulate visual hypothesis with the lowest interaction effort. A real-time adaptation of interaction to the user's needs is performed by monitoring hands and fingers' dynamics, in order to allow both complex actions (like the above mentioned manipulation or measurement) and conventional keyboard-like operations. © 2008 Springer-Verlag Berlin Heidelberg.},
	keywords = {Flow interactions; Helmet mounted displays; Three dimensional; Virtual reality; 3d models; Augmented realities; Central regions; Complex actions; Crime scenes; Field of views; Gesture based interfaces; Graphics; Head Mounted displays; Instructional purposes; Interaction paradigms; Interactive; Interactive visualizations; Precise manipulations; Real environments; Virtual objects; Law enforcement},
	issn = {16113349},
	isbn = {354069840X; 978-354069840-1},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: International Conference on Computational Science and Its Applications, ICCSA 2008; Conference date: 30 June 2008 through 3 July 2008; Conference code: 73953}
}

@CONFERENCE{Wendelken2004325,
	author = {Wendelken, Suzanne M. and McGrath, Susan P. and Akay, Metin and Blike, George T.},
	title = {Using a forehead reflectance pulse oximeter to detect changes in sympathetic tone},
	year = {2004},
	journal = {Annual International Conference of the IEEE Engineering in Medicine and Biology - Proceedings},
	volume = {26 I},
	pages = {325 – 328},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-11044233755&partnerID=40&md5=9192f31f5a58845ea3cb1db4cce1299e},
	affiliations = {Thayer School of Engineering, Dartmouth College, Hanover, NH, United States; Department of Anesthesiology, Dartmouth Hitchcock Medical Center, Hanover, NH, United States},
	abstract = {The extreme conditions of combat and multi-casualty rescue often make field triage difficult and put the medic or first responder at risk. In an effort to improve field triage, we have developed an automated remote triage system called ARTEMIS (Automated Remote Triage and Emergency Management Information System) for use in the battlefield or disaster zone. Common to field injuries is a sudden change in arterial pressure resulting from massive blood loss or shock. In effort to stabilize the arterial pressure, the sympathetic system is strongly activated and sympathetic tone is increased. This preliminary research seeks to empirically demonstrate that a forehead reflectance pulse oximeter is a viable sensor for detecting sudden changes in sympathetic tone. We performed the classic supine-standing experiment and collected the raw waveform, the photoplethysmogram (PPG), continuously using a forehead reflectance pulse oximter. The resulting waveform was processed in Matlab using various spectral analysis techniques (FFT and AR). Our preliminary results show that a relative ratio analysis (low frequency power/high frequency power) for both the raw PPG signal and its derived pulse statistics (height, beat-to-beat interval) is a useful technique for detecting change in sympathetic tone resulting from positional change.},
	author_keywords = {Photoplethysmogram spectral analysis},
	keywords = {Biological organs; Blood; Light emitting diodes; Oximeters; Oxygen; Pressure effects; Respiratory system; Blood pressure; Heart rate variability (HRV); Oxygenated hemoglobin; Patient monitoring},
	issn = {05891019},
	coden = {CEMBA},
	language = {English},
	abbrev_source_title = {Annu Int Conf IEEE Eng Med Biol Proc},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: Conference Proceedings - 26th Annual International Conference of the IEEE Engineering in Medicine and Biology Society, EMBC 2004; Conference date: 1 September 2004 through 5 September 2004; Conference code: 64132}
}

@CONFERENCE{Girolamo200143,
	author = {Girolamo, H.},
	title = {A decade of progress 1991-2001: HMD technology ready for platform integration},
	year = {2001},
	journal = {Proceedings of SPIE - The International Society for Optical Engineering},
	volume = {4361},
	pages = {43 – 70},
	doi = {10.1117/12.438007},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-0035151836&doi=10.1117%2f12.438007&partnerID=40&md5=acaf0d695fcd6ecbc946a3eba09e855d},
	affiliations = {U.S. Army Soldier Systems Center, Natick, MA 01760-5020, Kansas Street, United States},
	abstract = {In 1991, the Defense Advanced Research Projects Agency (DARPA) established a head-mounted display (HMD) program as part of their High Definition Systems Program. The goals were to investigate, and then develop revolutionary new display technologies that would overcome the technical challenges of cathode-ray tubes (CRT) and satisfy DoD needs for improved HMDs. A Joint Services Working Group was formed to identify and define miniature display specifications through common program goals. These display technologies have had a profound impact on HMD designs and have led to revolutionary optical solutions, densely packaged electronics and miniaturized integrated packaging. These technologies have initiated compact HMDs that demonstrate exceptionally wide fields of view, greatly improved acuity, reduced weight, low power consumption, high bandwidth interfaces, and test subject acceptance through Human Factors and Biodynamic analyses. The dual-use applications of these technologies comply with many DoD and commercial user goals and have resulted in HMD systems that meet many operational capabilities and needs of the military, medical, commercial, and consumer markets. HMD systems have been demonstrated in operational tests and evaluations in combat vehicles, dismounted operations (infantry, medical, maintenance, special operations, military police/law enforcement and others), rotorcraft and fixed wing. DoD has established many simulation programs and it has been concluded that an integrated HMD system can enhance situational awareness and augment operational performance of military units in the aforementioned fields. This paper will highlight the accomplishments of the advanced research, development, operational experiments and demonstrations over the past decade and will report on the current status of HMD integration.},
	author_keywords = {DARPA; Dual use; Human factors; Integrated HMDs; Microdisplays},
	keywords = {Accident prevention; Cathode ray tubes; Liquid crystal displays; Military applications; Ordnance; Sensor data fusion; Sustainable development; Biodynamics; Cathod ray tubes (CRT); Helmet mounted displays},
	issn = {0277786X},
	coden = {PSISD},
	language = {English},
	abbrev_source_title = {Proc SPIE Int Soc Opt Eng},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; Conference name: Helmet- and Head-Mounted Displays VI; Conference date: 16 April 2001 through 17 April 2001; Conference code: 58798}
}

@ARTICLE{Davis2002121,
	author = {Davis, Larry and Ha, Yonggang and Frolich, Seth and Martin, Glenn and Meyer, Catherine and Pettitt, Beth and Norfleet, Jack and Lin, Kuo-Chi and Rolland, Jannick P.},
	title = {Augmented reality and training for airway management procedures},
	year = {2002},
	journal = {Studies in Health Technology and Informatics},
	volume = {85},
	pages = {121 – 126},
	doi = {10.3233/978-1-60750-929-5-121},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-6944237313&doi=10.3233%2f978-1-60750-929-5-121&partnerID=40&md5=bb264f5890311935399a634a5e0eedf1},
	affiliations = {School of Optics, CREOL University of Central, Orlando, FL 32816-2700, Florida 4000 Central Florida Blvd, United States; Institute for Simulation and Training, Orlando, FL 32826, 3280 Progress Drive, United States; U.S. Army Simulation, Training, and Instrumentation Command, Orlando, FL 32826, 12350 Research Parkway, United States},
	abstract = {Augmented reality is often used for interactive, three-dimensional visualization within the medical community. To this end, we present the integration of an augmented reality system that will be used to train military medics in airway management. The system demonstrates how a head-mounted projective display can be integrated with a desktop PC to create an augmented reality visualization. Furthermore, the system, which uses a lightweight optical, tracker, demonstrates the low cost and the portability of the application. © 2002, The authors.},
	keywords = {Allied Health Personnel; Cardiopulmonary Resuscitation; Emergency Medical Services; Humans; Intubation, Intratracheal; Microcomputers; Military Medicine; Models, Anatomic; User-Computer Interface; Three dimensional computer graphics; Virtual reality; Visualization; Airway management; Augmented reality systems; Head-mounted projective displays; Low costs; Medical community; Reality visualization; Three dimensional visualization; article; audiovisual equipment; computer interface; education; emergency health service; endotracheal intubation; human; microcomputer; military medicine; paramedical personnel; resuscitation; Augmented reality},
	publisher = {IOS Press},
	issn = {09269630},
	isbn = {1586032038; 978-158603203-6},
	pmid = {2004169087},
	language = {English},
	abbrev_source_title = {Stud. Health Technol. Informatics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8; Conference name: 10th Annual Medicine Meets Virtual Reality Conference, MMVR 2002; Conference date: 23 January 2002 through 26 January 2002; Conference code: null}
}

@CONFERENCE{Kreitmair-Steck200143,
	author = {Kreitmair-Steck, W. and Haisch, S.},
	title = {All-weather capability for rescue helicopters},
	year = {2001},
	journal = {Proceedings of SPIE - The International Society for Optical Engineering},
	volume = {4363},
	pages = {43 – 50},
	doi = {10.1117/12.438031},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-0035148905&doi=10.1117%2f12.438031&partnerID=40&md5=abde6054781253ed6162cb7db5583dc6},
	affiliations = {Eurocopter Deutschland GmbH, 81663 Munich, Germany},
	abstract = {In Germany as well as in numerous other countries the air rescue system has been extended significantly since the first operation of the rescue helicopter Christoph 1. The primary target of the air rescue system was to guarantee fast and efficient emergency medical services for victims of accidents. During the years, the scope of the helicopter operations has been extended not only to other types of emergency medical services, but also to secondary medical services like the displacement of patients from hospitals to special service hospitals. While in general the displacement of patients is operated from well known and registered helipads, the primary rescue service currently has to rely on available onboard systems only. Those operations are risky and challenging for the pilots because of time pressure and the danger of obstacles in the environment of the helicopter. In addition, reduced visibility due to fog, rainfall or low light levels can further increase the risks or can make the services unavailable at all. Almost one decade ago, Eurocopter started the investigation of technologies and systems that could help the pilots to perform their tasks with reduced workload and risk, and to allow for a 24 h operation of helicopters irrespective of the weather conditions. After a number of preliminary studies, in 1995 the research program "All-weather helicopter" has been started as a joint effort of Eurocopter and the supplier industry in Europe. The first phase of the program has been successfully completed in 1999 and the second phase is currently in progress.},
	author_keywords = {3D map; Aircraft; Enhanced vision; Head-up display; Helicopter; Image fusion; Imaging sensors; Low visibility; Obstacle warning; Synthetic vision},
	keywords = {Collision avoidance; Computer vision; Health care; Heliports; Image sensors; Visibility; Air rescue systems; Helicopter rescue services},
	issn = {0277786X},
	coden = {PSISD},
	language = {English},
	abbrev_source_title = {Proc SPIE Int Soc Opt Eng},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: Enhanced and Synthetic Vision 2001; Conference date: 16 April 2001 through 17 April 2001; Conference code: 58797}
}

@CONFERENCE{Tadokoro20004089,
	author = {Tadokoro, Satoshi and Kitano, Hiroaki and Takahashi, Tomoichi and Noda, Itsuki and Matsubara, Hitoshi and Shinjoh, Atsushi and Koto, Tetsuo and Takeuchi, Ikuo and Takahashi, Hironao and Matsuno, Fumitoshi and Hatayama, Mitsunori and Nobe, Jun and Shimada, Susumu},
	title = {RoboCup-Rescue project: a robotic approach to the disaster mitigation problem},
	year = {2000},
	journal = {Proceedings - IEEE International Conference on Robotics and Automation},
	volume = {4},
	pages = {4089 – 4094},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-0033707015&partnerID=40&md5=fac39540f48ab2818cd883dd5c62eed0},
	affiliations = {Kobe Univ, Kobe, Japan},
	abstract = {This paper introduces the RoboCup-Rescue Simulation Project, a contribution to the disaster mitigation, search and rescue problem. A comprehensive urban disaster simulator is constructed on distributed computers. Heterogeneous intelligent agents such as fire fighters, victims and volunteers conduct search and rescue activities in this virtual disaster world. A real world interface integrates various sensor systems and controllers of infrastructures in the real cities with the virtual world. Real-time simulation is synchronized with actual disasters, computing complex relationship between various damage factors and agent behaviors. A mission-critical man-machine interface provides portability and robustness of disaster mitigation centers, and augmented-reality interfaces for rescue parties in real disasters. It also provides a virtual-reality training function for the public. This diverse spectrum of RoboCup-Rescue contributes to the creation of the safer social system.},
	keywords = {Artificial intelligence; Computer simulation; Disasters; Distributed computer systems; Earthquakes; Management information systems; Sensors; User interfaces; Virtual reality; Disaster mitigation; Mission critical man machine interface; Real time simulation; RoboCup rescue project; Robotics},
	issn = {10504729},
	coden = {PIIAE},
	language = {English},
	abbrev_source_title = {Proc IEEE Int Conf Rob Autom},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 102; Conference name: ICRA 2000: IEEE International Conference on Robotics and Automation; Conference date: 24 April 2000 through 28 April 2000; Conference code: 57053}
}

@CONFERENCE{Chaudhari2007,
	author = {Chaudhari, Jayashri and Cheung, Sen-Ching S. and Venkatesh, M. Vijay},
	title = {Privacy protection for life-log video},
	year = {2007},
	journal = {Proceedings - SAFE 2007: Workshop on Signal Processing Applications for Public Security and Forensics},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84969248210&partnerID=40&md5=3ccb66a132edbb9f55fefc1ea86e8a5b},
	affiliations = {Center for Visualization and Virtual Environments, Department of Electrical and Computer Engineering, University of Kentucky, Lexington, 40507, KY, United States},
	abstract = {Recent advances in wearable cameras and storage devices allow us to record the holistic human experience for an extended period of time. Such a life-log system can capture audio-visual data anywhere and at any time. It has a wide range of applications from law enforcement, journalism, medicine to personal archival. On the other hand, there is a natural apprehension towards such an intrusive system as the audiovisual information of unsuspecting subjects captured in the life-log video may be misused. Thus, along with the technical challenges, the privacy and legal issues arising in such recordings must be carefully addressed. In this paper, we describe a wearable life-log system that combines real-time audio distortion and visual blocking to protect the privacy of the subjects captured in life-log video. For audio, our system automatically isolates the subject's speech and distorts it using a pitch-shifting algorithm to conceal the identity. For video, our system uses a real-time face detection, tracking and blocking algorithm to obfuscate the faces of the subjects. Extensive experiments have been conducted on interview videos to demonstrate the ability of our system in protecting the identity of the subject while maintaining the usability of the life-log video. © 2007 IEEE.},
	keywords = {Continuous speech recognition; Digital storage; Face recognition; Laws and legislation; Virtual storage; Wearable technology; Audio-visual data; Audio-visual information; Blocking algorithms; Interview video; Privacy protection; Real-time face detection; Technical challenges; Wearable cameras; Signal processing},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {1424412269; 978-142441226-6},
	language = {English},
	abbrev_source_title = {Proc. - SAFE : Workshop Signal Process. Appl. Public Secur. Forensics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 19; Conference name: Workshop on Signal Processing Applications for Public Security and Forensics, SAFE 2007; Conference date: 11 April 2007 through 13 April 2007; Conference code: 119057}
}

@CONFERENCE{Ruffner2004120,
	author = {Ruffner, John W. and Fulbrook, Jim E. and Foglia, Marc},
	title = {Near-to-eye display concepts for air traffic controllers},
	year = {2004},
	journal = {Proceedings of SPIE - The International Society for Optical Engineering},
	volume = {5442},
	pages = {120 – 131},
	doi = {10.1117/12.541645},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-11844286393&doi=10.1117%2f12.541645&partnerID=40&md5=609ce90ae2dc79189e747365b314476b},
	affiliations = {DCS Corporation, Alexandria, VA 22314, 1330 Braddock Place, United States; NVIS, Inc., Reston, VA 20190, 11495 Sunset Hills Road, United States},
	abstract = {Tower controllers are responsible for maintaining safe separation between airborne aircraft in the airport traffic control area, and separation between aircraft, equipment, and personnel on the airport surface. The objective of this project was to develop and demonstrate an out-the-window, augmented viewing system concept for Air Force air traffic control tower personnel to reduce look-down time within the tower and to optimize visual airfield operations, particularly during limited visibility conditions. We characterized controller tasks where a near-to-eye display greatly aids performance and identified form factor variables that influence user acceptability of hardware configurations. We developed an "out-the-window concept of operation" and analyzed the hardware requirements and feasibility of three near-to-eye viewing systems: two head-mounted monocular displays (HMMD) and a held-to-head binocular display (HHBD). When fully developed, these display prototypes should enhance tower controller situation awareness, and reduce such distractions as having to frequently attend to and respond to head-down (console) display information. There are potential users of this display concept in all branches of the military services, and in the commercial sector. There is also potential utility for surface surveillance operations in support of homeland security, law enforcement personnel, rescue workers, firefighters, and special operations forces in non-aviation applications.},
	author_keywords = {Air Traffic Tower Controllers; Augmented Reality; Display Symbology; Near-to-Eye Display},
	keywords = {Computer hardware; Computer software; Control equipment; Decision making; Display devices; Military equipment; Virtual reality; Air traffic tower controllers; Display symbology; Ground control; Near-to-Eye display; Air traffic control},
	correspondence_address = {J.W. Ruffner; DCS Corporation, Alexandria, VA 22314, 1330 Braddock Place, United States; email: jruffner@dcscorp.com},
	issn = {0277786X},
	coden = {PSISD},
	language = {English},
	abbrev_source_title = {Proc SPIE Int Soc Opt Eng},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; Conference name: Helmet- and Head-Mounted Displays IX: Technologies and Applications; Conference date: 12 April 2004 through 13 April 2004; Conference code: 64175}
}

@CONFERENCE{Bretschneider2006109,
	author = {Bretschneider, Nora and Brattke, Simon and Rein, Karlheinz},
	title = {Head mounted displays for fire fighters},
	year = {2006},
	journal = {IFAWC 2006 - 3rd International Forum on Applied Wearable Computing 2006, Proceedings},
	pages = {109 – 123},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962834606&partnerID=40&md5=6d0079945a1634fe0055c1dc980b6e5f},
	affiliations = {Carl Zeiss AG, Oberkochen Research Center, Oberkochen, 73446, Germany},
	abstract = {Head Mounted Displays have the potential to increase the fire fighter's safety and make their work more efficient. Typical applications of Head Mounted Displays in the area of fire fighting are to display thermal imaging data or tactical information such as maps or navigation information. As fire fighters work under hazardous conditions they have to wear special equipment such as helmets and breathing masks. This makes an appropriate design of a Head Mounted Display for fire fighters especially challenging. In this paper we discuss the requirements of Head Mounted Displays for fire fighters and evaluate different design options. © IFAWC 2006 - 3rd International Forum on Applied Wearable Computing 2006, Proceedings. All rights reserved.},
	keywords = {Fire extinguishers; Fires; Infrared imaging; Street traffic control; Wearable computers; Appropriate designs; Breathing masks; Fire fighting; Head mounted displays; Navigation in formation; Tactical information; Thermal-imaging data; Typical application; Helmet mounted displays},
	correspondence_address = {K. Rein; Carl Zeiss AG, Oberkochen Research Center, Oberkochen, 73446, Germany; email: k.rein@zeiss.de},
	editor = {Herzog O. and Kenn H. and Lawo M. and Lukowicz P. and Troster G.},
	publisher = {VDE VERLAG GMBH},
	isbn = {3800729547; 978-380072954-8},
	language = {English},
	abbrev_source_title = {IFAWC - Int. Forum Appl. Wearable Comput., Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 11; Conference name: 3rd International Forum on Applied Wearable Computing 2006, IFAWC 2006; Conference date: 15 March 2006 through 16 March 2006; Conference code: 161493}
}

@CONFERENCE{Samuels1992147,
	author = {Samuels, Mark A. and Patterson, Scott W. and Eppstein, Jonathan A. and Fowler, R.},
	title = {Low-cost hand-held lidar system for automotive speed detection and law enforcement},
	year = {1992},
	journal = {Proceedings of SPIE - The International Society for Optical Engineering},
	volume = {1633},
	pages = {147 – 159},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-0026459157&partnerID=40&md5=c804d99850bf765948ac871a76e1375f},
	affiliations = {Laser Atlanta Optics Inc., Norcross,, GA, USA},
	abstract = {A low cost, handheld lidar or laser range finder (LRF) system based on a GaAs laser diode was developed for automotive speed detection and law enforcement. The innovative lidar incorporates a head up display (HUD) to provide both an aiming reticle and data display of range and/or velocity. The design of this eyesafe lidar system is based on shared aperture optics, a pulsed high power Gallium Arsenide laser diode and a proprietary 'telephoto' HUD that allows the use of off the shelf displays. An embedded processor continuously computes range and velocity using a special algorithm optimized for the system.},
	keywords = {Highway Traffic Control - Laser Applications; Mathematical Techniques - Algorithms; Range Finders - Laser Applications; Automotive Speed Detection; Laser Radar Measurements; Laser Range Finder; Police Radar; Radar, Optical},
	publisher = {Publ by Int Soc for Optical Engineering},
	issn = {0277786X},
	isbn = {0819407798},
	coden = {PSISD},
	language = {English},
	abbrev_source_title = {Proc SPIE Int Soc Opt Eng},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 9; Conference name: Laser Radar VII: Advanced Technology for Applications; Conference date: 23 January 1992 through 24 January 1992; Conference code: 17232}
}

@ARTICLE{Meinander2005278,
	author = {Meinander, Harriet and Honkala, Markku},
	title = {Potential applications of smart clothing solutions in health care and personal protection},
	year = {2005},
	journal = {Studies in Health Technology and Informatics},
	volume = {108},
	pages = {278 – 285},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-14844333285&partnerID=40&md5=8bd1b0b9ae10a31e3485859e1184cdba},
	affiliations = {Tampere University of Technology, SmartWearLab, Fin-33720 Tampere, Sinitaival 6, Finland},
	abstract = {The rapid development in the fields of sensor and telecommunication technologies has created completely new possibilities also for the textile and clothing field. New smart textile and clothing systems can be developed by integrating sensors in the textile constructions. Application fields for these added-value products are e.g. protective clothing for extreme environments, garments for the health care sector, technical textiles, sport and leisure wear. Some products have already been introduced on the markets, but generally it can be stated that the development is only in its starting phase, and the expectations for the future are big. Many different aspects have to be considered in the development of the wearable technology products for the health care sector: medical problems and their diagnosis, sensor choice, data processing and telecommunication solutions, clothing requirements. A functional product can be achieved only if all aspects work together, and therefore experts from all fields should participate in the RTD projects. In the EC-funded project DE3002 Easytex clothing and textiles for disabled and elderly people were investigated. Some recommendations concerning durability, appearance, comfort, service and safety of products for different special user groups were defined, based on user questionnaires and seminars, general textile and clothing requirements and on laboratory test series. 'Clothing Area Network - Clan' is a research project aiming to develop a technical concept and technology needed in enabling both wired and wireless data and power transfer between different intelligent modules (user interfaces, sensors, CPU's, batteries etc.) integrated into a smart clothing system. Fire-fighters clothing system is chosen as the development platform, being a very challenging application from which the developed technology can be transferred to other protective clothing systems.},
	keywords = {Absorbent Pads; Biosensing Techniques; Clothing; Computer Communication Networks; Fires; Humans; Monitoring, Ambulatory; Protective Clothing; Rescue Work; Telemedicine; Textiles; Data handling; Diagnosis; Durability; Energy transfer; Health care; Medical problems; Protective clothing; Smart textiles; Surveys; User interfaces; Added value products; Development platform; Functional products; Integrating sensors; Personal protection; Special user groups; Telecommunication technologies; Textile and clothings; ambulatory monitoring; article; clothing; computer network; diaper; disaster; fire; genetic procedures; human; instrumentation; methodology; protective clothing; telemedicine; textile; Wearable sensors},
	publisher = {IOS Press},
	issn = {09269630},
	pmid = {15718657},
	language = {English},
	abbrev_source_title = {Stud. Health Technol. Informatics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 12; Conference name: 1st International Workshop on New Generation of Wearable Systems for eHealth; Conference date: 11 December 2003 through 14 December 2003; Conference code: null}
}

@CONFERENCE{Beringer200926,
	author = {Beringer, Dennis B. and Luke, Terri and Quate, Allison and Walters, Elizabeth},
	title = {Helicopter pilot use of a see-through, head-mounted display with pathway guidance for visually guided flight: Observations of navigation behavior and obstacle avoidance},
	year = {2009},
	journal = {Proceedings of the Human Factors and Ergonomics Society},
	volume = {1},
	pages = {26 – 30},
	doi = {10.1518/107118109x12524440832944},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-77951564872&doi=10.1518%2f107118109x12524440832944&partnerID=40&md5=9b13370ace3dec6c32a5929582ef4e02},
	affiliations = {Civil Aerospace Medical Institute, Oklahoma City, OK, United States; School of Industrial Engineering, OU, Norman, OK, United States},
	abstract = {An exploratory study was conducted to evaluate synthetic imagery, presented in a binocular, stereoptic, head-mounted see-through display (HMD) for providing destination guidance and navigation data to helicopter pilots. The intended application was to Helicopter Emergency Medical Services (HEMS). Participants flew a simulator from an airfield to a remote, unimproved site to pick up an accident victim. Synthetic cues included approach and landing-zone signposts, highway-in-the-sky guidance for a 6-degree approach, approach direction lights, landing direction lights, and a synthetic helipad. Performance measures included destination visual acquisition time, transit time, obstacle avoidance, landing accuracy, and workload. Signposts allowed significantly shorter destination visual acquisition times. There were no significant differences in perceived workload. The baseline flights using the Global Positioning System (GPS) terminated further from the desired landing zone than flights using the HMD imagery. Successful visual avoidance of obstacles in the out-the-window view varied for different types of obstacles.},
	keywords = {Air navigation; Emergency services; Ergonomics; Global positioning system; Helicopter services; Landing; Approach and landings; Emergency medical services; Exploratory studies; Guidance and navigation; Head mounted displays; Highway-in-the sky; Navigation behavior; Performance measure; Helmet mounted displays},
	publisher = {Human Factors an Ergonomics Society Inc.},
	issn = {10711813},
	isbn = {978-161567623-1},
	coden = {PHFSD},
	language = {English},
	abbrev_source_title = {Proc Hum Factors Ergon Soc},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; Conference name: 53rd Human Factors and Ergonomics Society Annual Meeting 2009, HFES 2009; Conference date: 19 October 2009 through 23 October 2009; Conference code: 80015}
}

@CONFERENCE{Johnson2005,
	author = {Johnson, Mark},
	title = {Life support breathing system for first responders and homeland security: "TACR" - Tactical rebreather},
	year = {2005},
	journal = {Proceedings of MTS/IEEE OCEANS, 2005},
	volume = {2005},
	doi = {10.1109/OCEANS.2005.1639768},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-33947163497&doi=10.1109%2fOCEANS.2005.1639768&partnerID=40&md5=8605c30d532d3d10c60c2e1c0f8c8b1b},
	affiliations = {O2 Dive Technologies},
	abstract = {In response to requirements by the Counter Terrorism Tactical Support Office's, (CTTSO), Technical Support Working Group, (TSWG), a Tactical Rebreather, called "TACR" was designed and built by ESS of CA and O2 Dive Technologies of TX, under contract with TPI of MA. The increasing threat of international and domestic terrorism has expanded the need for protective equipment within and beyond traditional boundaries. Tactical security, law enforcement and other response units are sometimes required to enter or transit an area which may be contaminated with toxic industrial chemicals, fire by-products or chemical or biological agents. Depending on the situation, it may not be acceptable or operationally suitable for the personnel to use 'open loop' or negative pressure filtered respirators due to the nature of the contaminant or even its physical state (e.g. super heated air). In these situations a CBR is required. TACR - or TACtical Rebreather, is capable of 180 minutes of life support, is ergonomically small, lightweight (weighing less then 20 Ibs.), rapidly donnable, low cost, and interface with existing full-face masks with standard NATO interfaces. Additionally, it is to be easy to maintain, and have a short training period for first responders. Besides these fundamental requirements, TSWG provided valuable meetings with field first responders so that their various needs were also incorporated into the design, TACR is a CBR unit and is expected to go on for NIOSH testing and approval. Its many design features allow it to be adapted for all capabilities including meeting NFPA requirements of passive alarm and heads up display. Further adaptations will include environmental HAZMET "bunny" suits and other rigorous environments and applications. This device will be of commercial interest to DOD/SOCOM, FBI, and USSS, other federal, state and local Law Enforcement Agencies, fire fighters, urban and rural rescue teams and industrial First Responders. The TACR unit and AD AR second stage regulator, and all components herein are prototype proprietary by ESS and O2 Dive Technologies. This unit is currently not for sale.},
	keywords = {Biomaterials; Engineering technology; Environmental engineering; Law enforcement; Requirements engineering; Security systems; Domestic terrorism; Homeland security; Breath controlled devices},
	isbn = {0933957343; 978-093395734-3},
	language = {English},
	abbrev_source_title = {Proc. MTS/IEEE OCEANS},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: MTS/IEEE OCEANS, 2005; Conference date: 18 September 2005 through 23 September 2005; Conference code: 69333}
}

@ARTICLE{Why200399,
	author = {Why, Yong Peng and Bishop, George D. and Tong, Eddie M.W. and Diong, Siew Maan and Enkelmann, Hwee Chong and Khader, Majeed and Ang, Jansen},
	title = {Cardiovascular reactivity of Singaporean male police officers as a function of task, ethnicity and hostility},
	year = {2003},
	journal = {International Journal of Psychophysiology},
	volume = {49},
	number = {2},
	pages = {99 – 110},
	doi = {10.1016/S0167-8760(03)00082-5},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-0041706152&doi=10.1016%2fS0167-8760%2803%2900082-5&partnerID=40&md5=550a63f2c93d70d3ae08a4c44801dfb7},
	affiliations = {Dept. of Social Work and Psychology, National University of Singapore, Singapore 117570, 11 Law Link, Singapore; Police Psychological Unit, Singapore Police Force, Singapore, Singapore},
	abstract = {Objective: This research examined hemodynamic processes in cardiovascular reactivity (CVR) as a function of task, ethnicity and trait hostility. Method: One hundred and fourteen male patrol officers from the Singapore Police Force participated in this experimental study. Trait hostility was measured using the interpersonal hostility assessment technique to derive a hostile behavior index (HBI). Heart rate, blood pressure and hemodynamic measures were taken while participants performed three tasks: mental arithmetic, number reading and anger recall (AR). Results: AR elicited the greatest blood pressure, vascular and cardiac output reactivity. HBI scores were positively related to systolic blood pressure reactivity during AR for Malays whereas this was not true for Indians and Chinese. Across tasks Indians with high HBI scores appeared to be cardiac reactors whereas the reactivity patterns for Malays and Chinese were undifferentiated. Self-report of negative mood was not related to CVR. Conclusion: These results are consistent with the higher rates of coronary heart disease deaths among Indians as well as the higher rates for hypertension among Malays in Singapore. © 2003 Elsevier Science B.V. All rights reserved.},
	author_keywords = {Anger; Cardiovascular reactivity; Ethnicity; Hemodynamic processes; Hostility; Impedance cardiography; Singapore},
	keywords = {adult; anger; arithmetic; article; blood pressure measurement; cardiovascular response; comparative study; controlled study; ethnology; heart function; heart output; heart rate; hostility; human; male; normal human; police; psychologic assessment; reading; scoring system; self report; Singapore; systolic blood pressure; task performance},
	correspondence_address = {G.D. Bishop; Dept. of Social Work and Psychology, National University of Singapore, Singapore 117570, 11 Law Link, Singapore; email: george_bishop@nus.edu.sg},
	publisher = {Elsevier},
	issn = {01678760},
	coden = {IJPSE},
	pmid = {12919713},
	language = {English},
	abbrev_source_title = {Int. J. Psychophysiol.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 22}
}